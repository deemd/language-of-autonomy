{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1ea44f3",
   "metadata": {},
   "source": [
    "# üéØ Step 4 : Topic Modeling (LDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe4ca67",
   "metadata": {},
   "source": [
    "**Objectif**: Identifier les th√®mes latents dominants dans le corpus\n",
    "\n",
    "**M√©thode**: Latent Dirichlet Allocation (LDA)\n",
    "\n",
    "**Analyses r√©alis√©es**:\n",
    "1. Pr√©paration des donn√©es pour LDA\n",
    "2. D√©termination du nombre optimal de topics (2-10)\n",
    "3. Entra√Ænement du mod√®le LDA\n",
    "4. Extraction et interpr√©tation des topics\n",
    "5. Distribution des topics par document\n",
    "6. Analyse comparative par type de source (Consulting vs Academic vs Industry)\n",
    "7. Visualisations (pyLDAvis, bar charts, heatmaps)\n",
    "\n",
    "**Output**: Topics identifi√©s + visualisations pour le rapport"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284eea8a",
   "metadata": {},
   "source": [
    "## üîß Setup Config & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b925ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Imports\n",
    "import json\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# LDA & topic modeling\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel, CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "\n",
    "# Clustering\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "# Utilities\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Viz Config\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"‚úÖ Imports\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13a0114",
   "metadata": {},
   "source": [
    "## üìÇ Load processed corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93ac48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "PROCESSED_DATA = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "CORPUS_FILE = PROCESSED_DATA / \"preprocessed_corpus.pkl\"\n",
    "METADATA_FILE = PROCESSED_DATA / \"metadata\" / \"corpus_metadata.json\"\n",
    "\n",
    "# Create folder for topic modeling results\n",
    "TOPICS_DIR = PROCESSED_DATA / \"topics\"\n",
    "TOPICS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ Topic modeling folder : {TOPICS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa28eada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed corpus\n",
    "with open(CORPUS_FILE, 'rb') as f:\n",
    "    processed_corpus = pickle.load(f)\n",
    "\n",
    "# Load metadata\n",
    "with open(METADATA_FILE, 'r', encoding='utf-8') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "print(f\"‚úÖ {len(processed_corpus)} documents loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcc96be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping doc_id -> source_type\n",
    "doc_to_source = {doc_id: metadata[doc_id]['source_type'] \n",
    "                 for doc_id in processed_corpus.keys()}\n",
    "\n",
    "print(f\"\\nüìä Type distribution:\")\n",
    "for source_type, count in Counter(doc_to_source.values()).items():\n",
    "    print(f\"  ‚Ä¢ {source_type:15} : {count} document(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6097c35d",
   "metadata": {},
   "source": [
    "## üîÑ Data preparation for LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3298d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract each doc tokens\n",
    "documents_tokens = []\n",
    "doc_ids_ordered = []\n",
    "\n",
    "for doc_id, doc_data in processed_corpus.items():\n",
    "    documents_tokens.append(doc_data['tokens'])\n",
    "    doc_ids_ordered.append(doc_id)\n",
    "\n",
    "print(f\"\\n‚úÖ {len(documents_tokens)} documents prepared\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de77a7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary (vocabulary)\n",
    "dictionary = corpora.Dictionary(documents_tokens)\n",
    "\n",
    "print(f\"\\nüìö Gensim dictionary created:\")\n",
    "print(f\"   Initial vocabulary size : {len(dictionary)} words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a37391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter extremums\n",
    "# no_below: min docs where the word must exist\n",
    "# no_above: max proportion of documents (avoid overly common words)\n",
    "dictionary.filter_extremes(no_below=2, no_above=0.7)\n",
    "print(f\"   After filtering      : {len(dictionary)} words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cce96a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create corpus (bag-of-words)\n",
    "corpus_bow = [dictionary.doc2bow(doc) for doc in documents_tokens]\n",
    "\n",
    "print(f\"\\n‚úÖ Bag-of-Words corpus created ({len(corpus_bow)} documents)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fa8ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample\n",
    "print(f\"\\nüìÑ Example (1rst document):\")\n",
    "print(f\"   Number of unique tokens: {len(corpus_bow[0])}\")\n",
    "print(f\"   First 5 terms:\")\n",
    "for word_id, count in corpus_bow[0][:5]:\n",
    "    print(f\"      {dictionary[word_id]:20} : {count} occurrences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef775ab",
   "metadata": {},
   "source": [
    "## üîç Topics optimal number determination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1677176b",
   "metadata": {},
   "source": [
    "### Using coherence score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87623534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different topic numbers\n",
    "topic_range = range(2, 11)  # 2~10 topics\n",
    "coherence_scores = []\n",
    "\n",
    "print(\"\\nüîÑ Computing coherence scores (2~5 min)...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0767b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_topics in tqdm(topic_range, desc=\"Testing topic counts\"):\n",
    "    # Train LDA model\n",
    "    lda_model = LdaModel(\n",
    "        corpus=corpus_bow,\n",
    "        id2word=dictionary,\n",
    "        num_topics=num_topics,\n",
    "        random_state=42,\n",
    "        passes=10,\n",
    "        iterations=100,\n",
    "        alpha='auto',\n",
    "        per_word_topics=True\n",
    "    )\n",
    "    \n",
    "    # Coherence score\n",
    "    coherence_model = CoherenceModel(\n",
    "        model=lda_model,\n",
    "        texts=documents_tokens,\n",
    "        dictionary=dictionary,\n",
    "        coherence='c_v'\n",
    "    )\n",
    "    \n",
    "    coherence_score = coherence_model.get_coherence()\n",
    "    coherence_scores.append(coherence_score)\n",
    "    \n",
    "    print(f\"  {num_topics} topics: coherence = {coherence_score:.4f}\")\n",
    "\n",
    "print(\"\\n‚úÖ Computation of coherence scores completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4a886c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal number\n",
    "optimal_num_topics = list(topic_range)[np.argmax(coherence_scores)]\n",
    "\n",
    "print(f\"\\nüéØ Optimal number of topics (max coherence): {optimal_num_topics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f4381f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax.plot(topic_range, coherence_scores, marker='o', linewidth=2, markersize=8, color='#2E86AB')\n",
    "ax.axvline(x=optimal_num_topics, color='red', linestyle='--', linewidth=2, \n",
    "           label=f'Optimal: {optimal_num_topics} topics')\n",
    "\n",
    "ax.set_xlabel('Number of Topics', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Coherence Score', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Coherence Score vs. Number of Topics', fontsize=14, fontweight='bold', pad=20)\n",
    "ax.set_xticks(topic_range)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend(fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(TOPICS_DIR / 'coherence_scores.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüíæ Graph saved to: {TOPICS_DIR / 'coherence_scores.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae4a8a1",
   "metadata": {},
   "source": [
    "### Using manual determination (if necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f3d5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possibilit√© d'override manuel bas√© sur l'interpr√©tabilit√©\n",
    "# Par d√©faut, on utilise le nombre optimal trouv√©\n",
    "# Mais tu peux choisir manuellement si les topics ne sont pas interpr√©tables\n",
    "\n",
    "MANUAL_OVERRIDE = None  # Put a number (ex: 5, 6, 7) to force\n",
    "\n",
    "if MANUAL_OVERRIDE:\n",
    "    final_num_topics = MANUAL_OVERRIDE\n",
    "    print(f\"\\n‚ö†Ô∏è Manual override: use of {final_num_topics} topics\")\n",
    "else:\n",
    "    final_num_topics = optimal_num_topics\n",
    "    print(f\"\\n‚úÖ Use of optimal number: {final_num_topics} topics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5837f398",
   "metadata": {},
   "source": [
    "## üöÄ LDA model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0084901",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_final = LdaModel(\n",
    "    corpus=corpus_bow,\n",
    "    id2word=dictionary,\n",
    "    num_topics=final_num_topics,\n",
    "    random_state=42,\n",
    "    passes=20,           # More passes for better training\n",
    "    iterations=200,      # More iterations\n",
    "    alpha='auto',        # Alpha auto\n",
    "    eta='auto',          # Eta auto\n",
    "    per_word_topics=True\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ LDA model trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f293ef49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute perplexity (lower = better)\n",
    "perplexity = lda_model_final.log_perplexity(corpus_bow)\n",
    "print(f\"   Perplexity: {perplexity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1e47ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute final coherence score\n",
    "coherence_model_final = CoherenceModel(\n",
    "    model=lda_model_final,\n",
    "    texts=documents_tokens,\n",
    "    dictionary=dictionary,\n",
    "    coherence='c_v'\n",
    ")\n",
    "coherence_final = coherence_model_final.get_coherence()\n",
    "print(f\"   Coherence:  {coherence_final:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92070ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "lda_model_final.save(str(TOPICS_DIR / 'lda_model.model'))\n",
    "dictionary.save(str(TOPICS_DIR / 'dictionary.dict'))\n",
    "print(f\"\\nüíæ Model saved to: {TOPICS_DIR / 'lda_model.model'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2236f13b",
   "metadata": {},
   "source": [
    "## üè∑Ô∏è Topics extraction and interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d341ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract topics\n",
    "topics_data = []\n",
    "\n",
    "for topic_id in range(final_num_topics):\n",
    "    # Top 15 topic words\n",
    "    topic_words = lda_model_final.show_topic(topic_id, topn=15)\n",
    "    \n",
    "    print(f\"TOPIC {topic_id}\")\n",
    "    \n",
    "    words_str = []\n",
    "    for word, prob in topic_words:\n",
    "        print(f\"  {word:20} : {prob:.4f}\")\n",
    "        words_str.append(f\"{word} ({prob:.3f})\")\n",
    "    \n",
    "    topics_data.append({\n",
    "        'topic_id': topic_id,\n",
    "        'top_words': ', '.join([w for w, p in topic_words[:10]]),\n",
    "        'words_detailed': words_str\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8d1bec",
   "metadata": {},
   "source": [
    "## üè∑Ô∏è Topics manual labellisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b294a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bas√© sur les mots cl√©s, assigner des labels interpr√©tables\n",
    "# TU DEVRAS ADAPTER CETTE SECTION EN FONCTION DES TOPICS OBTENUS\n",
    "\n",
    "# Exemple de mapping (√† adapter selon tes r√©sultats)\n",
    "TOPIC_LABELS = {\n",
    "    0: \"Productivity & ROI\",\n",
    "    1: \"Workforce Transformation\",\n",
    "    2: \"Governance & Compliance\",\n",
    "    3: \"Technical Architecture & Infrastructure\",\n",
    "    4: \"Autonomous Work Orchestration\",\n",
    "    5: \"AI Models & Algorithms\",\n",
    "    6: \"Business Strategy & Implementation\",\n",
    "    7: \"Human-AI Collaboration\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a02dfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only existing labels\n",
    "topic_labels_final = {k: v for k, v in TOPIC_LABELS.items() if k < final_num_topics}\n",
    "\n",
    "# If missing labels, create automatically\n",
    "for topic_id in range(final_num_topics):\n",
    "    if topic_id not in topic_labels_final:\n",
    "        top_words = [w for w, p in lda_model_final.show_topic(topic_id, topn=3)]\n",
    "        topic_labels_final[topic_id] = f\"Topic {topic_id}: {', '.join(top_words)}\"\n",
    "\n",
    "print(\"\\nüìã Assigned labels:\")\n",
    "for topic_id, label in topic_labels_final.items():\n",
    "    print(f\"  Topic {topic_id}: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027cb2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n‚ö†Ô∏è NOTE: V√©rifiez et ajustez manuellement les labels dans la cellule pr√©c√©dente\")\n",
    "print(\"         en fonction des mots cl√©s observ√©s pour chaque topic.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587b2196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add labels to DataFrame\n",
    "for item in topics_data:\n",
    "    item['label'] = topic_labels_final[item['topic_id']]\n",
    "\n",
    "df_topics = pd.DataFrame(topics_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9c506c",
   "metadata": {},
   "source": [
    "## üìä Topics visualization (Key words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a9130a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_topics = final_num_topics\n",
    "n_cols = 2\n",
    "n_rows = (n_topics + 1) // 2\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, 5*n_rows))\n",
    "axes = axes.flatten() if n_topics > 1 else [axes]\n",
    "\n",
    "for topic_id in range(n_topics):\n",
    "    ax = axes[topic_id]\n",
    "    \n",
    "    # Words + proba\n",
    "    topic_words = lda_model_final.show_topic(topic_id, topn=12)\n",
    "    words = [w for w, p in topic_words]\n",
    "    probs = [p for w, p in topic_words]\n",
    "    \n",
    "    # Plotting\n",
    "    colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(words)))\n",
    "    ax.barh(range(len(words)), probs, color=colors)\n",
    "    ax.set_yticks(range(len(words)))\n",
    "    ax.set_yticklabels(words, fontsize=9)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlabel('Probabilit√©', fontsize=10)\n",
    "    ax.set_title(f'Topic {topic_id}: {topic_labels_final[topic_id]}', \n",
    "                fontsize=11, fontweight='bold')\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Remove empty axes if odd number of topics\n",
    "if n_topics % 2 == 1:\n",
    "    fig.delaxes(axes[-1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(TOPICS_DIR / 'topics_keywords.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"üíæ Graph saved to: {TOPICS_DIR / 'topics_keywords.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f3200f",
   "metadata": {},
   "source": [
    "## üìà Topics per document distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bde02a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topics distribution for each document\n",
    "doc_topics_data = []\n",
    "\n",
    "for doc_idx, doc_id in enumerate(doc_ids_ordered):\n",
    "    # Topic distribution for doc\n",
    "    topic_dist = lda_model_final.get_document_topics(corpus_bow[doc_idx])\n",
    "    \n",
    "    # Convert to dictionary (including prob=0 topics)\n",
    "    topic_dict = {i: 0.0 for i in range(final_num_topics)}\n",
    "    for topic_id, prob in topic_dist:\n",
    "        topic_dict[topic_id] = prob\n",
    "    \n",
    "    # Find dominant topic\n",
    "    dominant_topic = max(topic_dict.items(), key=lambda x: x[1])[0]\n",
    "    \n",
    "    doc_topics_data.append({\n",
    "        'doc_id': doc_id,\n",
    "        'filename': metadata[doc_id]['filename'],\n",
    "        'source_type': doc_to_source[doc_id],\n",
    "        'dominant_topic': dominant_topic,\n",
    "        'dominant_topic_label': topic_labels_final[dominant_topic],\n",
    "        **{f'topic_{i}': prob for i, prob in topic_dict.items()}\n",
    "    })\n",
    "\n",
    "df_doc_topics = pd.DataFrame(doc_topics_data)\n",
    "df_doc_topics.head() # Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fbed30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüìã Distribution per document (first documents):\\n\")\n",
    "display_cols = ['filename', 'source_type', 'dominant_topic_label'] + \\\n",
    "               [f'topic_{i}' for i in range(final_num_topics)]\n",
    "\n",
    "df_doc_topics[display_cols].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f7c551",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_columns = [f'topic_{i}' for i in range(final_num_topics)]\n",
    "topic_data = df_doc_topics[topic_columns].values\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 10))\n",
    "\n",
    "# Create stacked bars\n",
    "bottom = np.zeros(len(df_doc_topics))\n",
    "colors = plt.cm.Set3(np.linspace(0, 1, final_num_topics))\n",
    "\n",
    "for topic_id in range(final_num_topics):\n",
    "    values = df_doc_topics[f'topic_{topic_id}'].values\n",
    "    ax.barh(range(len(df_doc_topics)), values, left=bottom, \n",
    "           label=f'T{topic_id}: {topic_labels_final[topic_id]}',\n",
    "           color=colors[topic_id])\n",
    "    bottom += values\n",
    "\n",
    "ax.set_yticks(range(len(df_doc_topics)))\n",
    "ax.set_yticklabels(df_doc_topics['filename'].str[:35], fontsize=8)\n",
    "ax.set_xlabel('Topic Proportion', fontsize=11, fontweight='bold')\n",
    "ax.set_title('Topics per Document Distribution', fontsize=14, fontweight='bold', pad=20)\n",
    "ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(TOPICS_DIR / 'topic_distribution_by_document.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"üíæ Graph saved to: {TOPICS_DIR / 'topic_distribution_by_document.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99d442f",
   "metadata": {},
   "source": [
    "## üìä Topics global distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957c9a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average proportion of each topic in corpus\n",
    "topic_proportions = df_doc_topics[topic_columns].mean().values\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Bar chart\n",
    "axes[0].bar(range(final_num_topics), topic_proportions, \n",
    "           color=colors, edgecolor='black', linewidth=1.5)\n",
    "axes[0].set_xticks(range(final_num_topics))\n",
    "axes[0].set_xticklabels([f'T{i}' for i in range(final_num_topics)])\n",
    "axes[0].set_ylabel('Average Proportion', fontsize=11, fontweight='bold')\n",
    "axes[0].set_title('Topics Global Distribution', fontsize=13, fontweight='bold')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "for i, prop in enumerate(topic_proportions):\n",
    "    axes[0].text(i, prop + 0.01, f'{prop:.2%}', ha='center', fontsize=9)\n",
    "\n",
    "# Pie chart\n",
    "axes[1].pie(topic_proportions, \n",
    "           labels=[topic_labels_final[i] for i in range(final_num_topics)],\n",
    "           autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "axes[1].set_title('Topics Distribution (Full Corpus)', \n",
    "                 fontsize=13, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(TOPICS_DIR / 'topic_global_distribution.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"üíæ Graph saved to: {TOPICS_DIR / 'topic_global_distribution.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73480905",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüìä Global topic proportions:\")\n",
    "for i, prop in enumerate(topic_proportions):\n",
    "    print(f\"  {topic_labels_final[i]:40} : {prop:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7e91b7",
   "metadata": {},
   "source": [
    "## üîç Comparative analysis per source type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee87527a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average proportions per type\n",
    "topic_by_source = df_doc_topics.groupby('source_type')[topic_columns].mean()\n",
    "\n",
    "print(\"\\nüìã Average topics proportions per source type:\\n\")\n",
    "topic_by_source.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5913c8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap visualization\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "# Rename columns\n",
    "topic_by_source_labeled = topic_by_source.copy()\n",
    "topic_by_source_labeled.columns = [topic_labels_final[i] for i in range(final_num_topics)]\n",
    "\n",
    "sns.heatmap(topic_by_source_labeled.T, annot=True, fmt='.3f', cmap='YlOrRd',\n",
    "           linewidths=0.5, cbar_kws={'label': 'Average Proportion'}, ax=ax)\n",
    "\n",
    "ax.set_xlabel('Source Type', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Topic', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Topics Distribution per Source Heatmap', \n",
    "            fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(TOPICS_DIR / 'heatmap_topics_by_source.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"üíæ Heatmap saved to: {TOPICS_DIR / 'heatmap_topics_by_source.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f1dac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart grouped\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "topic_by_source_labeled.T.plot(kind='bar', ax=ax, width=0.8, color=colors[:len(topic_by_source)])\n",
    "\n",
    "ax.set_ylabel('Average Proportion', fontsize=12, fontweight='bold')\n",
    "ax.set_xlabel('Topic', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Topics Distribution per Source Type', \n",
    "            fontsize=14, fontweight='bold', pad=20)\n",
    "ax.legend(title='Source Type', fontsize=10, title_fontsize=11)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig(TOPICS_DIR / 'topics_by_source_grouped.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"üíæ Graph saved to: {TOPICS_DIR / 'topics_by_source_grouped.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe975b0",
   "metadata": {},
   "source": [
    "## üéØ Dominant topic per source type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8904850b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for source_type in topic_by_source.index:\n",
    "    dominant_topic_id = topic_by_source.loc[source_type].idxmax()\n",
    "    dominant_topic_id = int(dominant_topic_id.split('_')[1])\n",
    "    proportion = topic_by_source.loc[source_type, f'topic_{dominant_topic_id}']\n",
    "    \n",
    "    print(f\"\\n{source_type}:\")\n",
    "    print(f\"  Dominant topic : {topic_labels_final[dominant_topic_id]}\")\n",
    "    print(f\"  Proportion     : {proportion:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aea94e1",
   "metadata": {},
   "source": [
    "## üìä Interactive visualization using `pyLDAvis`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94387ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_data = gensimvis.prepare(lda_model_final, corpus_bow, dictionary, sort_topics=False)\n",
    "\n",
    "# Save HTML\n",
    "html_path = TOPICS_DIR / 'lda_visualization.html'\n",
    "pyLDAvis.save_html(vis_data, str(html_path))\n",
    "\n",
    "print(f\"\\n‚úÖ Interactive visualization generated: {html_path}\")\n",
    "print(f\"   Open file in browser to explore topics\")\n",
    "\n",
    "# Display in notebook (optional => too slow, would not recommend)\n",
    "# pyLDAvis.display(vis_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4713e7",
   "metadata": {},
   "source": [
    "## üíæ Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a9547b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save topics with associated key words\n",
    "df_topics.to_csv(TOPICS_DIR / 'topics_keywords.csv', index=False)\n",
    "print(f\"‚úÖ Topics and key words saved to: {TOPICS_DIR / 'topics_keywords.csv'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729393a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save distribution per document\n",
    "df_doc_topics.to_csv(TOPICS_DIR / 'document_topic_distribution.csv', index=False)\n",
    "print(f\"‚úÖ Distribution per document saved to: {TOPICS_DIR / 'document_topic_distribution.csv'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59765d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save proportions per type\n",
    "topic_by_source.to_csv(TOPICS_DIR / 'topics_by_source_type.csv')\n",
    "print(f\"‚úÖ Topics per type saved to: {TOPICS_DIR / 'topics_by_source_type.csv'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25174f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results summary\n",
    "summary = {\n",
    "    'num_topics': final_num_topics,\n",
    "    'coherence_score': float(coherence_final),\n",
    "    'perplexity': float(perplexity),\n",
    "    'topic_labels': topic_labels_final,\n",
    "    'global_proportions': {topic_labels_final[i]: float(prop) \n",
    "                          for i, prop in enumerate(topic_proportions)}\n",
    "}\n",
    "\n",
    "with open(TOPICS_DIR / 'lda_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Summary saved to: {TOPICS_DIR / 'lda_summary.json'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d740e482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create textual report\n",
    "report = f\"\"\"\n",
    "{'='*70}\n",
    "TOPIC MODELING (LDA) REPORT\n",
    "{'='*70}\n",
    "\n",
    "MODEL PARAMETERS\n",
    "{'‚îÄ'*70}\n",
    "Number of topics    : {final_num_topics}\n",
    "Coherence score     : {coherence_final:.4f}\n",
    "Perplexity          : {perplexity:.4f}\n",
    "Number of documents : {len(doc_ids_ordered)}\n",
    "\n",
    "IDENTIFIED TOPICS\n",
    "{'‚îÄ'*70}\n",
    "\"\"\"\n",
    "\n",
    "for topic_id in range(final_num_topics):\n",
    "    top_words = ', '.join([w for w, p in lda_model_final.show_topic(topic_id, topn=10)])\n",
    "    report += f\"\\nTopic {topic_id}: {topic_labels_final[topic_id]}\\n\"\n",
    "    report += f\"  Key words: {top_words}\\n\"\n",
    "    report += f\"  Global proportion: {topic_proportions[topic_id]:.1%}\\n\"\n",
    "\n",
    "report += f\"\\n{'‚îÄ'*70}\\n\"\n",
    "report += \"DISTRIBUTION PER SOURCE TYPE\\n\"\n",
    "report += f\"{'‚îÄ'*70}\\n\"\n",
    "\n",
    "for source_type in topic_by_source.index:\n",
    "    report += f\"\\n{source_type}:\\n\"\n",
    "    for topic_id in range(final_num_topics):\n",
    "        prop = topic_by_source.loc[source_type, f'topic_{topic_id}']\n",
    "        if prop > 0.05:  # Display only if > 5%\n",
    "            report += f\"  ‚Ä¢ {topic_labels_final[topic_id]:40} : {prop:.1%}\\n\"\n",
    "\n",
    "report += f\"\\n{'='*70}\\n\"\n",
    "\n",
    "# Save report\n",
    "report_path = TOPICS_DIR / 'lda_report.txt'\n",
    "with open(report_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(f\"‚úÖ Textual report saved to: {report_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8014c935",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + report) # Check format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9e0efd",
   "metadata": {},
   "source": [
    "## üìä Insights summary for report use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c36a523",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüîπ DOMINANTS TOPICS (Global):\")\n",
    "sorted_topics = sorted(enumerate(topic_proportions), key=lambda x: x[1], reverse=True)\n",
    "for i, (topic_id, prop) in enumerate(sorted_topics[:3], 1):\n",
    "    print(f\"  {i}. {topic_labels_final[topic_id]:40} : {prop:.1%}\")\n",
    "\n",
    "print(\"\\nüîπ DIFFERENCES PER SOURCE TYPE:\")\n",
    "for source_type in topic_by_source.index:\n",
    "    top_2_topics = topic_by_source.loc[source_type].nlargest(2)\n",
    "    print(f\"\\n  {source_type}:\")\n",
    "    for topic_col in top_2_topics.index:\n",
    "        topic_id = int(topic_col.split('_')[1])\n",
    "        prop = top_2_topics[topic_col]\n",
    "        print(f\"    ‚Ä¢ {topic_labels_final[topic_id]:35} : {prop:.1%}\")\n",
    "\n",
    "print(\"\\nüîπ CONVERGENCE/DIVERGENCE:\")\n",
    "# Compute variance between types for each topic\n",
    "topic_variances = []\n",
    "for topic_id in range(final_num_topics):\n",
    "    col = f'topic_{topic_id}'\n",
    "    variance = topic_by_source[col].var()\n",
    "    topic_variances.append((topic_id, variance))\n",
    "\n",
    "# Topics with greatest variance = more divergence between types\n",
    "sorted_by_variance = sorted(topic_variances, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\n  Topics with STRONG divergence between types:\")\n",
    "for topic_id, var in sorted_by_variance[:3]:\n",
    "    print(f\"    ‚Ä¢ {topic_labels_final[topic_id]:35} (variance: {var:.4f})\")\n",
    "\n",
    "print(\"\\n  Topics with WEAK divergence (consensus):\")\n",
    "for topic_id, var in sorted_by_variance[-3:]:\n",
    "    print(f\"    ‚Ä¢ {topic_labels_final[topic_id]:35} (variance: {var:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99812744",
   "metadata": {},
   "source": [
    "## üéØ Documents hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7451fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use topics distributions as features\n",
    "topic_features = df_doc_topics[topic_columns].values\n",
    "\n",
    "# Compute cosine matrix\n",
    "distances = pdist(topic_features, metric='cosine')\n",
    "\n",
    "# Hierarchical linkage\n",
    "linkage_matrix = linkage(distances, method='ward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51d9909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(16, 10))\n",
    "\n",
    "# Create labels (name + type)\n",
    "labels = [f\"{metadata[doc_id]['filename'][:30]} ({doc_to_source[doc_id]})\" \n",
    "          for doc_id in doc_ids_ordered]\n",
    "\n",
    "dendrogram(\n",
    "    linkage_matrix,\n",
    "    labels=labels,\n",
    "    leaf_rotation=90,\n",
    "    leaf_font_size=8,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "ax.set_title('Documents Hierarchical Clustering (Topic-based)', \n",
    "            fontsize=14, fontweight='bold', pad=20)\n",
    "ax.set_xlabel('Documents', fontsize=11)\n",
    "ax.set_ylabel('Distance', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(TOPICS_DIR / 'hierarchical_clustering.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"üíæ Dendrogram saved to: {TOPICS_DIR / 'hierarchical_clustering.png'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0811e339",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüìä Interpretation:\")\n",
    "print(\"  ‚Ä¢ Near documents = similar topics distributions\")\n",
    "print(\"  ‚Ä¢ Clusters = groups of documents on similar themes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb5bfda",
   "metadata": {},
   "source": [
    "## üìã Step 4 summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20220933",
   "metadata": {},
   "source": [
    "**‚úÖ Analyses compl√©t√©es:**\n",
    "- D√©termination nombre optimal de topics (coherence score)\n",
    "- Entra√Ænement mod√®le LDA final\n",
    "- Extraction et labellisation des topics\n",
    "- Distribution des topics par document\n",
    "- Analyse comparative par type de source\n",
    "- Clustering hi√©rarchique des documents\n",
    "\n",
    "**üìÇ Fichiers g√©n√©r√©s:**\n",
    "- Mod√®le LDA et dictionnaire sauvegard√©s\n",
    "- 8+ visualisations PNG\n",
    "- 4 fichiers CSV avec donn√©es d√©taill√©es\n",
    "- Visualisation interactive HTML (pyLDAvis)\n",
    "- Rapport texte complet\n",
    "\n",
    "**üìä Visuels pour le rapport:**\n",
    "1. `coherence_scores.png` - Choix du nombre de topics\n",
    "2. `topics_keywords.png` - Mots cl√©s par topic\n",
    "3. `topic_distribution_by_document.png` - Distribution par document\n",
    "4. `topic_global_distribution.png` - Vue d'ensemble\n",
    "5. `heatmap_topics_by_source.png` - Comparaison par type\n",
    "6. `topics_by_source_grouped.png` - Barres group√©es\n",
    "7. `hierarchical_clustering.png` - Clustering documents\n",
    "8. `lda_visualization.html` - Visualisation interactive\n",
    "\n",
    "**‚û°Ô∏è Prochaine √©tape:**\n",
    "- √âtape 5: Mini-Taxonomy des d√©finitions d'\"Agentic AI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d93e773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Step 4\n",
    "print(\"STEP 4 FINISHED SUCCESSFULLY!\")\n",
    "print(f\"\\nüìä Topic Modeling summary:\")\n",
    "print(f\"  ‚Ä¢ Number of topics         : {final_num_topics:,}\")\n",
    "print(f\"  ‚Ä¢ Coherence score          : {coherence_final:.4f}\")\n",
    "print(f\"  ‚Ä¢ Identified topics        : {', '.join([f'T{i}' for i in range(final_num_topics)])}\")\n",
    "print(f\"  ‚Ä¢ Analyzed documents       : {len(doc_ids_ordered)}\")\n",
    "print(f\"  ‚Ä¢ Sources types            : {len(topic_by_source)}\")\n",
    "print(f\"\\nüìÇ All files saved to: {TOPICS_DIR}\")\n",
    "print(f\"\\n‚û°Ô∏è Ready for Step 5: Mini-Taxonomy of Definitions\\n\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
