Artificial Intelligence Index Report 2025 Artificial Intelligence Index Report 2025 Introduction to the AI Index Report 2025 Welcome to the eighth edition of the AI Index report. The 2025 Index is our most comprehensive to date and arrives at an important moment, as AI’s influence across society, the economy, and global governance continues to intensify. New in this year’s report are in-depth analyses of the evolving landscape of AI hardware, novel estimates of inference costs, and new analyses of AI publication and patenting trends. We also introduce fresh data on corporate adoption of responsible AI practices, along with expanded coverage of AI’s growing role in science and medicine. Since its founding in 2017 as an offshoot of the One Hundred Year Study of Artificial Intelligence, the AI Index has been committed to equipping policymakers, journalists, executives, researchers, and the public with accurate, rigorously validated, and globally sourced data. Our mission has always been to help these stakeholders make better-informed decisions about the development and deployment of AI. In a world where AI is discussed everywhere—from boardrooms to kitchen tables—this mission has never been more essential. The AI Index continues to lead in tracking and interpreting the most critical trends shaping the field—from the shifting geopolitical landscape and the rapid evolution of underlying technologies, to AI’s expanding role in business, policymaking, and public life. Longitudinal tracking remains at the heart of our mission. In a domain advancing at breakneck speed, the Index provides essential context—helping us understand where AI stands today, how it got here, and where it may be headed next. Recognized globally as one of the most authoritative resources on artificial intelligence, the AI Index has been cited in major media outlets such as The New York Times, Bloomberg, and The Guardian; referenced in hundreds of academic papers; and used by policymakers and government agencies around the world. We have briefed companies like Accenture, IBM, Wells Fargo, and Fidelity on the state of AI, and we continue to serve as an independent source of insights for the global AI ecosystem. 1 Artificial Intelligence Index Report 2025 Message From the Co-directors As AI continues to reshape our lives, the corporate world, and public discourse, the AI Index continues to track its progress— offering an independent, data-driven perspective on AI’s development, adoption, and impact, across time and geography. What a year 2024 has been for AI. The recognition of AI’s role in advancing humanity’s knowledge is reflected in Nobel prizes in physics and chemistry, and the Turing award for foundational work in reinforcement learning. The once-formidable Turing Test is no longer considered an ambitious goal, having been surpassed by today’s sophisticated systems. Meanwhile, AI adoption has accelerated at an unprecedented rate, as millions of people are now using AI on a regular basis both for their professional work and leisure activities. As high-performing, low-cost, and openly available models proliferate, AI’s accessibility and impact are set to expand even further. After a brief slowdown, corporate investment in AI rebounded. The number of newly funded generative AI startups nearly tripled, and after years of sluggish uptake, business adoption accelerated significantly in 2024. AI has moved from the margins to become a central driver of business value. Governments, too, are ramping up their involvement. Policymakers are no longer just debating AI—they’re investing in it. Several countries launched billion-dollar national AI infrastructure initiatives, including major efforts to expand energy capacity to support AI development. Global coordination is increasing, even as local initiatives take shape. Yet trust remains a major challenge. Fewer people believe AI companies will safeguard their data, and concerns about fairness and bias persist. Misinformation continues to pose risks, particularly in elections and the proliferation of deepfakes. In response, governments are advancing new regulatory frameworks aimed at promoting transparency, accountability, and fairness. Public attitudes are also shifting. While skepticism remains, a global survey in 2024 showed a notable rise in optimism about AI’s potential to deliver broad societal benefits. AI is no longer just a story of what’s possible—it’s a story of what’s happening now and how we are collectively shaping the future of humanity. Explore this year’s AI Index report and see for yourself. Yolanda Gil and Raymond Perrault Co-directors, AI Index Report 2 Artificial Intelligence Index Report 2025 Top Takeaways 1. AI performance on demanding benchmarks continues to improve. In 2023, researchers introduced new benchmarks—MMMU, GPQA, and SWE-bench—to test the limits of advanced AI systems. Just a year later, performance sharply increased: scores rose by 18.8, 48.9, and 67.3 percentage points on MMMU, GPQA, and SWE-bench, respectively. Beyond benchmarks, AI systems made major strides in generating high-quality video, and in some settings, language model agents even outperformed humans in programming tasks with limited time budgets. 2. AI is increasingly embedded in everyday life. From healthcare to transportation, AI is rapidly moving from the lab to daily life. In 2023, the FDA approved 223 AI-enabled medical devices, up from just six in 2015. On the roads, self-driving cars are no longer experimental: Waymo, one of the largest U.S. operators, provides over 150,000 autonomous rides each week, while Baidu’s affordable Apollo Go robotaxi fleet now serves numerous cities across China. 3. Business is all in on AI, fueling record investment and usage, as research continues to show strong productivity impacts. In 2024, U.S. private AI investment grew to $109.1 billion—nearly 12 times China’s $9.3 billion and 24 times the U.K.’s $4.5 billion. Generative AI saw particularly strong momentum, attracting $33.9 billion globally in private investment—an 18.7% increase from 2023. AI business usage is also accelerating: 78% of organizations reported using AI in 2024, up from 55% the year before. Meanwhile, a growing body of research confirms that AI boosts productivity and, in most cases, helps narrow skill gaps across the workforce. 4. The U.S. still leads in producing top AI models—but China is closing the performance gap. In 2024, U.S.- based institutions produced 40 notable AI models, compared to China’s 15 and Europe’s three. While the U.S. maintains its lead in quantity, Chinese models have rapidly closed the quality gap: performance differences on major benchmarks such as MMLU and HumanEval shrank from double digits in 2023 to near parity in 2024. China continues to lead in AI publications and patents. Model development is increasingly global, with notable launches from the Middle East, Latin America, and Southeast Asia. 5. The responsible AI ecosystem evolves—unevenly. AI-related incidents are rising sharply, yet standardized RAI evaluations remain rare among major industrial model developers. However, new benchmarks like HELM Safety, AIR-Bench, and FACTS offer promising tools for assessing factuality and safety. Among companies, a gap persists between recognizing RAI risks and taking meaningful action. In contrast, governments are showing increased urgency: In 2024, global cooperation on AI governance intensified, with organizations including the OECD, EU, U.N., and African Union releasing frameworks focused on transparency, trustworthiness, and other core responsible AI principles. 3 Artificial Intelligence Index Report 2025 Top Takeaways (cont’d) 6. Global AI optimism is rising—but deep regional divides remain. In countries like China (83%), Indonesia (80%), and Thailand (77%), strong majorities see AI products and services as more beneficial than harmful. In contrast, optimism remains far lower in places like Canada (40%), the United States (39%), and the Netherlands (36%). Still, sentiment is shifting: Since 2022, optimism has grown significantly in several previously skeptical countries, including Germany (+10%), France (+10%), Canada (+8%), Great Britain (+8%), and the United States (+4%). 7. AI becomes more efficient, affordable, and accessible. Driven by increasingly capable small models, the inference cost for a system performing at the level of GPT-3.5 dropped over 280-fold between November 2022 and October 2024. At the hardware level, costs have declined by 30% annually, while energy efficiency has improved by 40% each year. Open-weight models are closing the gap with closed models, reducing the performance difference from 8% to just 1.7% on some benchmarks in a single year. Together, these trends are rapidly lowering the barriers to advanced AI. 8. Governments are stepping up on AI—with regulation and investment. In 2024, U.S. federal agencies introduced 59 AI-related regulations—more than double the number in 2023—and issued by twice as many agencies. Globally, legislative mentions of AI rose 21.3% across 75 countries since 2023, marking a ninefold increase since 2016. Alongside growing attention, governments are investing at scale: Canada pledged $2.4 billion, China launched a $47.5 billion semiconductor fund, France committed €109 billion, India pledged $1.25 billion, and Saudi Arabia’s Project Transcendence represents a $100 billion initiative. 9. AI and computer science education is expanding—but gaps in access and readiness persist. Two-thirds of countries now offer or plan to offer K–12 CS education—twice as many as in 2019—with Africa and Latin America making the most progress. In the U.S., the number of graduates with bachelor’s degrees in computing has increased 22% over the last 10 years. Yet access remains limited in many African countries due to basic infrastructure gaps like electricity. In the U.S., 81% of K–12 CS teachers say AI should be part of foundational CS education, but less than half feel equipped to teach it. 10. Industry is racing ahead in AI—but the frontier is tightening. Nearly 90% of notable AI models in 2024 came from industry, up from 60% in 2023, while academia remains the top source of highly cited research. Model scale continues to grow rapidly—training compute doubles every five months, datasets every eight, and power use annually. Yet performance gaps are shrinking: the Elo skill score difference between the top and 10th-ranked models fell from 11.9% to 5.4% in a year, and the top two are now separated by just 0.7%. The frontier is increasingly competitive—and increasingly crowded. 4 Artificial Intelligence Index Report 2025 Top Takeaways (cont’d) 11. AI earns top honors for its impact on science. AI’s growing importance is reflected in major scientific awards: Two Nobel Prizes recognized work that led to deep learning (physics) and to its application to protein folding (chemistry), while the Turing Award honored groundbreaking contributions to reinforcement learning. 12. Complex reasoning remains a challenge. AI models excel at tasks like International Mathematical Olympiad problems but still struggle with complex reasoning benchmarks like PlanBench. They often fail to reliably solve logic tasks even when provably correct solutions exist, limiting their effectiveness in high-stakes settings where precision is critical. 5 Artificial Intelligence Index Report 2025 Steering Committee Chair Members Raymond Perrault Erik Brynjolfsson Terah Lyons Vanessa Parli SRI International Stanford University JPMorgan Chase & Co. Stanford University Chair-elect Jack Clark James Manyika Yoav Shoham Yolanda Gil Anthropic, OECD Google, University of Stanford University, University of Southern Oxford AI21 Labs California, Information John Etchemendy Sciences Institute Stanford University Juan Carlos Niebles Russell Wald Stanford University, Stanford University Katrina Ligett Salesforce Hebrew University Toby Walsh UNSW Sydney Staff and Researchers Research Manager and Editor-in-Chief Nestor Maslej, Stanford University Research Associate Loredana Fattorini, Stanford University Affiliated Researchers Graduate Researchers Elif Kiesow Cortez, Stanford Law School Research Fellow Emily Capstick, Stanford University Julia Betts Lotufo, Researcher Malou van Draanen Glismann, Stanford University Anka Reuel, Stanford University Njenga Kariuki, Stanford University Alexandra Rome, Researcher Angelo Salatino, Knowledge Media Institute, Undergraduate Researchers The Open University Armin Hamrah, Claremont McKenna College Lapo Santarlasci, IMT School for Advanced Studies Lucca Sukrut Oak, Stanford University Ngorli Fiifi Paintsil, Stanford University Andrew Shi, Stanford University 6 Artificial Intelligence Index Report 2025 How to Cite This Report Nestor Maslej, Loredana Fattorini, Raymond Perrault, Yolanda Gil, Vanessa Parli, Njenga Kariuki, Emily Capstick, Anka Reuel, Erik Brynjolfsson, John Etchemendy, Katrina Ligett, Terah Lyons, James Manyika, Juan Carlos Niebles, Yoav Shoham, Russell Wald, Toby Walsh, Armin Hamrah, Lapo Santarlasci, Julia Betts Lotufo, Alexandra Rome, Andrew Shi, Sukrut Oak. “The AI Index 2025 Annual Report,” AI Index Steering Committee, Institute for Human-Centered AI, Stanford University, Stanford, CA, April 2025. https://doi.org/10.48550/arXiv.2504.07139 The AI Index 2025 Annual Report by Stanford University is licensed under Attribution-NoDerivatives 4.0 International. Public Data and Tools The AI Index 2025 Report is supplemented by raw data and an interactive tool. We invite each reader to use the data and the tool in a way most relevant to their work and interests. • Raw data and charts: The public data and high-resolution images of all the charts in the report are available on Google Drive. • Global AI Vibrancy Tool: Compare the AI ecosystems of over 30 countries. The Global AI Vibrancy tool will be updated in the summer of 2025. AI Index and Stanford HAI The AI Index is an independent initiative at the Stanford Institute for Human-Centered Artificial Intelligence (HAI). The AI Index was conceived within the One Hundred Year Study on Artificial Intelligence (AI100). The AI Index welcomes feedback and new ideas for next year. Contact us at nmaslej@stanford.edu. The AI Index acknowledges that while authored by a team of human researchers, its writing process was aided by AI tools. Specifically, the authors used ChatGPT and Claude to help tighten and copy edit initial drafts. The workflow involved authors writing the original copy and utilizing AI tools as part of the editing process. 7 Artificial Intelligence Index Report 2025 Supporting Partners Analytics and Research Partners 8 Artificial Intelligence Index Report 2025 Contributors The AI Index would like to acknowledge the following individuals by chapter and section for their contributions of data, analysis, advice, and expert commentary included in the AI Index Report 2025: Introduction Loredana Fattorini, Yolanda Gil, Nestor Maslej, Vanessa Parli, Ray Perrault Chapter 1: Research and Development Nancy Amato, Andrea Brown, Ben Cottier, Lucía Ronchi Darré, Virginia Dignum, Meredith Ellison, Robin Evans, Loredana Fattorini, Yolanda Gil, Armin Hamrah, Katrina Ligett, Nestor Maslej, Maurice Pagnucco, Ngorli Fiifi Paintsil, Vanessa Parli, Ray Perrault, Robi Rahman, Christine Raval, Vesna Sabljakovic-Fritz, Angelo Salatino, Lapo Santarlasci, Andrew Shi, Nathan Sturtevant, Daniel Weld, Kevin Xu, Meg Young Chapter 2: Technical Performance Rishi Bommasani, Erik Brynjolfsson, Loredana Fattorini, Tobi Gertsenberg, Yolanda Gil, Noah Goodman, Nicholas Haber, Armin Hamrah, Sanmi Koyejo, Percy Liang, Katrina Ligett, Nestor Maslej, Juan Carlos Niebles, Sukrut Oak, Vanessa Parli, Marco Pavone, Ray Perrault, Anka Reuel, Andrew Shi, Yoav Shoham, Toby Walsh Chapter 3: Responsible AI Medha Bankhwal, Emily Capstick, Dmytro Chumachenko, Patrick Connolly, Natalia Dorogi, Loredana Fattorini, Ann Fitz-Gerald, Yolanda Gil, Armin Hamrah, Ariel Lee, Katrina Ligett, Shayne Longpre, Natasha Maniar, Nestor Maslej, Katherine Ottenbreit, Halyna Padalko, Vanessa Parli, Ray Perrault, Brittany Presten, Anka Reuel, Roger Roberts, Andrew Shi, Georgio Stoev, Shekhar Tewari, Dikshita Venkatesh, Cayla Volandes, Jakub Wiatrak Chapter 4: Economy Medha Bankhwal, Erik Brynjolfsson, Mar Carpanelli, Cara Christopher, Michael Chui, Natalia Dorogi, Heather English, Murat Erer, Loredana Fattorini, Yolanda Gil, Heather Hanselman, Rosie Hood, Vishy Kamalapuram, Kory Kantenga, Njenga Kariuki, Akash Kaura, Elena Magrini, Nestor Maslej, Katherine Ottenbreit, Vanessa Parli, Ray Perrault, Brittany Presten, Roger Roberts, Cayla Volandes, Casey Weston, Hansen Yang Chapter 5: Science and Medicine Russ Altman, Kameron Black, Jonathan Chen, Jean-Benoit Delbrouck, Joshua Edrich, Loredana Fattorini, Alejandro Lozano, Yolanda Gil, Ethan Goh, Armin Hamrah, Fateme Nateghi Haredasht, Tina Hernandez-Boussard, Yeon Mi Hwang, Rohan Koodli, Arman Koul, Curt Langlotz, Ashley Lewis, Chase Ludwig, Stephen P. Ma, Abdoul Jalil Djiberou Mahamadou, David Magnus, James Manyika, Nestor Maslej, Gowri Nayar, Madelena Ng, Sophie Ostmeier, Vanessa Parli, Ray Perrault, Malkiva Pillai, Ossian Karl-Johan Ferdinand Rabow, Sean Riordan, Brennan Geti Simon, Kotoha Togami, Artem Trotsyuk, Maya Varma, Quinn Waeiss, Betty Xiong Chapter 6: Policy Elif Kiesow Cortez, Loredana Fattorini, Yolanda Gil, Julia Betts Lotufo, Vanessa Parli, Ray Perrault, Alexandra Rome, Lapo Santarlasci, Georgio Stoev, Russell Wald, Daniel Zhang 9 Artificial Intelligence Index Report 2025 Contributors (cont’d) Chapter 7: Education John Etchemendy, Loredana Fattorini, Lili Gangas, Yolanda Gil, Rachel Goins, Laura Hinton, Sonia Koshy, Kirsten Lundgren, Nestor Maslej, Lisa Cruz Novohatski, Vanessa Parli, Ray Perrault, Allison Scott, Andreen Soley, Bryan Twarek, Laurens Vehmeijer Chapter 8: Public Opinion Emily Capstick, John Etchemendy, Loredana Fattorini, Yolanda Gil, Njenga Kariuki, Nestor Maslej, Vanessa Parli, Ray Perrault The AI Index would like to acknowledge the following individuals by chapter and section for their contributions of data, analysis, advice, and expert commentary included in the AI Index Report 2025: Organizations Accenture LinkedIn Arnab Chakraborty, Patrick Connolly, Shekhar Tewari, Mar Carpanelli, Akash Kaura, Kory Kantenga, Dikshita Venkatesh, Jakub Wiatrak Rosie Hood, Casey Weston Epoch AI McKinsey & Company Ben Cottier, Robi Rahman Medha Bankhwal, Natalia Dorogi, Natasha Maniar, Katherine Ottenbreit, Brittany Presten, Roger Roberts, GitHub Cayla Volandes Lucía Ronchi Darré, Kevin Xu Quid Lightcast Heather English, Hansen Yang Cara Christopher, Elena Magrini The AI Index also thanks Jeanina Matias, Nancy King, Carolyn Lehman, Shana Lynch, Jonathan Mindes, and Michi Turner for their help in preparing this report; Christopher Ellis for his help in maintaining the AI Index website; and Annie Benisch, Stacey Sickels Boyce, Marc Gough, Caroline Meinhardt, Drew Spence, Casey Weston, Madeleine Wright, and Daniel Zhang for their work in helping promote the report. 10 AArrttiifificciiaall IInntteelllliiggeennccee IInnddeexx RReeppoorrtt 22002255 Table of Contents Report Highlights 12 Chapter 1 Research and Development 24 Chapter 2 Technical Performance 81 Chapter 3 Responsible AI 160 Chapter 4 Economy 214 Chapter 5 Science and Medicine 280 Chapter 6 Policy and Governance 323 Chapter 7 Education 364 Chapter 8 Public Opinion 394 Appendix 414 ACCESS THE PUBLIC DATA 11 Artificial Intelligence Index Report 2025 Report Highlights CHAPTER 1: Research and Development 1. Industry continues to make significant investments in AI and leads in notable AI model development, while academia leads in highly cited research. Industry’s lead in notable model development, highlighted in the two previous AI Index reports, has only grown more pronounced, with nearly 90% of notable models in 2024 (compared to 60% in 2023) originating from industry. Academia has remained the single leading institutional producer of highly cited (top 100) publications over the past three years. 2. China leads in AI research publication totals, while the United States leads in highly influential research. In 2023, China produced more AI publications (23.2%) and citations (22.6%) than any other country. Over the past three years, U.S. institutions have contributed the most top-100-cited AI publications. 3. AI publication totals continue to grow and increasingly dominate computer science. Between 2013 and 2023, the total number of AI publications in venues related to computer science and other scientific disciplines nearly tripled, increasing from approximately 102,000 to over 242,000. Proportionally, AI’s share of computer science publications has risen from 21.6% in 2013 to 41.8% in 2023. 4. The United States continues to be the leading source of notable AI models. In 2024, U.S.-based institutions produced 40 notable AI models, significantly surpassing China’s 15 and Europe’s combined total of three. In the past decade, more notable machine learning models have originated from the United States than any other country. 5. AI models get increasingly bigger, more computationally demanding, and more energy intensive. New research finds that the training compute for notable AI models doubles approximately every five months, dataset sizes for training LLMs every eight months, and the power required for training annually. Large-scale industry investment continues to drive model scaling and performance gains. 6. AI models become increasingly cheaper to use. The cost of querying an AI model that scores the equivalent of GPT-3.5 (64.8) on MMLU, a popular benchmark for assessing language model performance, dropped from $20.00 per million tokens in November 2022 to just $0.07 per million tokens by October 2024 (Gemini-1.5-Flash-8B)—a more than 280-fold reduction in approximately 18 months. Depending on the task, LLM inference prices have fallen anywhere from 9 to 900 times per year. 12 Artificial Intelligence Index Report 2025 Report Highlights CHAPTER 1: Research and Development (cont’d) 7. AI patenting is on the rise. Between 2010 and 2023, the number of AI patents has grown steadily and significantly, ballooning from 3,833 to 122,511. In just the last year, the number of AI patents has risen 29.6%. As of 2023, China leads in total AI patents, accounting for 69.7% of all grants, while South Korea and Luxembourg stand out as top AI patent producers on a per capita basis. 8. AI hardware gets faster, cheaper, and more energy efficient. New research suggests that machine learning hardware performance, measured in 16-bit floating-point operations, has grown 43% annually, doubling every 1.9 years. Price performance has improved, with costs dropping 30% per year, while energy efficiency has increased by 40% annually. 9. Carbon emissions from AI training are steadily increasing. Training early AI models, such as AlexNet (2012), had modest amounts of carbon emissions at 0.01 tons. More recent models have significantly higher emissions for training: GPT-3 (2020) at 588 tons, GPT-4 (2023) at 5,184 tons, and Llama 3.1 405B (2024) at 8,930 tons. For perspective, the average American emits 18 tons of carbon per year. CHAPTER 2: Technical Performance 1. AI masters new benchmarks faster than ever. In 2023, AI researchers introduced several challenging new benchmarks, including MMMU, GPQA, and SWE-bench, aimed at testing the limits of increasingly capable AI systems. By 2024, AI performance on these benchmarks saw remarkable improvements, with gains of 18.8 and 48.9 percentage points on MMMU and GPQA, respectively. On SWE-bench, AI systems could solve just 4.4% of coding problems in 2023—a figure that jumped to 71.7% in 2024. 2. Open-weight models catch up. Last year’s AI Index revealed that leading open-weight models lagged significantly behind their closed-weight counterparts. By 2024, this gap had nearly disappeared. In early January 2024, the leading closed- weight model outperformed the top open-weight model by 8.0% on the Chatbot Arena Leaderboard. By February 2025, this gap had narrowed to 1.7%. 13 Artificial Intelligence Index Report 2025 Report Highlights CHAPTER 2: Technical Performance (cont’d) 3. The gap closes between Chinese and U.S. models. In 2023, leading American models significantly outperformed their Chinese counterparts—a trend that no longer holds. At the end of 2023, performance gaps on benchmarks such as MMLU, MMMU, MATH, and HumanEval were 17.5, 13.5, 24.3, and 31.6 percentage points, respectively. By the end of 2024, these margins had narrowed substantially to 0.3, 8.1, 1.6, and 3.7 percentage points. 4. AI model performance converges at the frontier. According to last year’s AI Index, the Elo score difference between the top and 10th-ranked model on the Chatbot Arena Leaderboard was 11.9%. By early 2025, this gap had narrowed to 5.4%. Likewise, the difference between the top two models shrank from 4.9% in 2023 to just 0.7% in 2024. The AI landscape is becoming increasingly competitive, with high-quality models now available from a growing number of developers. 5. New reasoning paradigms like test-time compute improve model performance. In 2024, OpenAI introduced models like o1 and o3 that are designed to iteratively reason through their outputs. This test-time compute approach dramatically improved performance, with o1 scoring 74.4% on an International Mathematical Olympiad qualifying exam, compared to GPT-4o’s 9.3%. However, this enhanced reasoning comes at a cost: o1 is nearly six times more expensive and 30 times slower than GPT-4o. 6. More challenging benchmarks are continually being proposed. The saturation of traditional AI benchmarks like MMLU, GSM8K, and HumanEval, coupled with improved performance on newer, more challenging benchmarks such as MMMU and GPQA, has pushed researchers to explore additional evaluation methods for leading AI systems. Notable among these are Humanity’s Last Exam, a rigorous academic test where the top system scores just 8.80%; FrontierMath, a complex mathematics benchmark where AI systems solve only 2% of problems; and BigCodeBench, a coding benchmark where AI systems achieve a 35.5% success rate—well below the human standard of 97%. 7. High-quality AI video generators demonstrate significant improvement. In 2024, several advanced AI models capable of generating high-quality videos from text inputs were launched. Notable releases include OpenAI’s SORA, Stable Video Diffusion 3D and 4D, Meta’s Movie Gen, and Google DeepMind’s Veo 2. These models produce videos of significantly higher quality compared to those from 2023. 14 Artificial Intelligence Index Report 2025 Report Highlights CHAPTER 2: Technical Performance (cont’d) 8. Smaller models drive stronger performance. In 2022, the smallest model registering a score higher than 60% on MMLU was PaLM, with 540 billion parameters. By 2024, Microsoft’s Phi-3-mini, with just 3.8 billion parameters, achieved the same threshold—the equivalent of a 142-fold reduction in two years. 9. Complex reasoning remains a problem. Even though the addition of mechanisms such as chain-of-thought reasoning has significantly improved the performance of LLMs, these systems still cannot reliably solve problems for which provably correct solutions can be found using logical reasoning, such as arithmetic and planning, especially on instances larger than those they were trained on. This has a significant impact on the trustworthiness of these systems and their suitability in high-risk applications. 10. AI agents show early promise. The launch of RE-Bench in 2024 introduced a rigorous benchmark for evaluating complex tasks for AI agents. In short time-horizon settings (two-hour budget), top AI systems score four times higher than human experts, but as the time budget increases, human performance surpasses AI—outscoring it two to one at 32 hours. AI agents already match human expertise in select tasks, such as writing Triton kernels, while delivering results faster and at lower costs. CHAPTER 3: Responsible AI 1. Evaluating AI systems with responsible AI (RAI) criteria is still uncommon, but new benchmarks are beginning to emerge. Last year’s AI Index highlighted the lack of standardized RAI benchmarks for LLMs. While this issue persists, new benchmarks such as HELM Safety and AIR-Bench help to fill this gap. 2. The number of AI incident reports continues to increase. According to the AI Incidents Database, the number of reported AI-related incidents rose to 233 in 2024—a record high and a 56.4% increase over 2023. 15 Artificial Intelligence Index Report 2025 Report Highlights CHAPTER 3: Responsible AI (cont’d) 3. Organizations acknowledge RAI risks, but mitigation efforts lag. A McKinsey survey on organizations’ RAI engagement shows that while many identify key RAI risks, not all are taking active steps to address them. Risks including inaccuracy, regulatory compliance, and cybersecurity were top of mind for leaders with only 64%, 63%, and 60% of respondents, respectively, citing them as concerns. 4. Across the globe, policymakers demonstrate a significant interest in RAI. In 2024, global cooperation on AI governance intensified, with a focus on articulating agreed-upon principles for responsible AI. Several major organizations— including the OECD, European Union, United Nations, and African Union—published frameworks to articulate key RAI concerns such as transparency and explainability, and trustworthiness. 5. The data commons is rapidly shrinking. AI models rely on massive amounts of publicly available web data for training. A recent study found that data use restrictions increased significantly from 2023 to 2024, as many websites implemented new protocols to curb data scraping for AI training. In actively maintained domains in the C4 common crawl dataset, the proportion of restricted tokens jumped from 5–7% to 20–33%. This decline has consequences for data diversity, model alignment, and scalability, and may also lead to new approaches to learning with data constraints. 6. Foundation model research transparency improves, yet more work remains. The updated Foundation Model Transparency Index—a project tracking transparency in the foundation model ecosystem—revealed that the average transparency score among major model developers increased from 37% in October 2023 to 58% in May 2024. While these gains are promising, there is still considerable room for improvement. 7. Better benchmarks for factuality and truthfulness. Earlier benchmarks like HaluEval and TruthfulQA, aimed at evaluating the factuality and truthfulness of AI models, have failed to gain widespread adoption within the AI community. In response, newer and more comprehensive evaluations have emerged, such as the updated Hughes Hallucination Evaluation Model leaderboard, FACTS, and SimpleQA. 8. AI-related election misinformation spread globally, but its impact remains unclear. In 2024, numerous examples of AI-related election misinformation emerged in more than a dozen countries and across over 10 social media platforms, including during the U.S. presidential election. However, questions remain about the measurable impacts of this problem, with many expecting misinformation campaigns to have affected elections more profoundly than they did. 16 Artificial Intelligence Index Report 2025 Report Highlights CHAPTER 3: Responsible AI (cont’d) 9. LLMs trained to be explicitly unbiased continue to demonstrate implicit bias. Many advanced LLMs— including GPT-4 and Claude 3 Sonnet—were designed with measures to curb explicit biases, but they continue to exhibit implicit ones. The models disproportionately associate negative terms with Black individuals, more often associate women with humanities instead of STEM fields, and favor men for leadership roles, reinforcing racial and gender biases in decision making. Although bias metrics have improved on standard benchmarks, AI model bias remains a pervasive issue. 10. RAI gains attention from academic researchers. The number of RAI papers accepted at leading AI conferences increased by 28.8%, from 992 in 2023 to 1,278 in 2024, continuing a steady annual rise since 2019. This upward trend highlights the growing importance of RAI within the AI research community. CHAPTER 4: Economy 1. Global private AI investment hits record high with 26% growth. Corporate AI investment reached $252.3 billion in 2024, with private investment climbing 44.5% and mergers and acquisitions up 12.1% from the previous year. The sector has experienced dramatic expansion over the past decade, with total investment growing more than thirteenfold since 2014. 2. Generative AI funding soars. Private investment in generative AI reached $33.9 billion in 2024, up 18.7% from 2023 and over 8.5 times higher than 2022 levels. The sector now represents more than 20% of all AI-related private investment. 3. The U.S. widens its lead in global AI private investment. U.S. private AI investment hit $109.1 billion in 2024, nearly 12 times higher than China’s $9.3 billion and 24 times the U.K.’s $4.5 billion. The gap is even more pronounced in generative AI, where U.S. investment exceeded the combined total of China and the European Union plus the U.K. by $25.4 billion, expanding on its $21.8 billion gap in 2023. 4. Use of AI climbs to unprecedented levels. In 2024, the proportion of survey respondents reporting AI use by their organizations jumped to 78% from 55% in 2023. Similarly, the number of respondents who reported using generative AI in at least one business function more than doubled—from 33% in 2023 to 71% last year. 17 Artificial Intelligence Index Report 2025 Report Highlights CHAPTER 4: Economy (cont’d) 5. AI is beginning to deliver financial impact across business functions, but most companies are early in their journeys. Most companies that report financial impacts from using AI within a business function estimate the benefits as being at low levels. 49% of respondents whose organizations use AI in service operations report cost savings, followed by supply chain management (43%) and software engineering (41%), but most of them report cost savings of less than 10%. With regard to revenue, 71% of respondents using AI in marketing and sales report revenue gains, 63% in supply chain management, and 57% in service operations, but the most common level of revenue increases is less than 5%. 6. Use of AI shows dramatic shifts by region, with Greater China gaining ground. While North America maintains its leadership in organizations’ use of AI, Greater China demonstrated one of the most significant year-over-year growth rates, with a 27 percentage point increase in organizational AI use. Europe followed with a 23 percentage point increase, suggesting a rapidly evolving global AI landscape and intensifying international competition in AI implementation. 7. China’s dominance in industrial robotics continues despite slight moderation. In 2023, China installed 276,300 industrial robots, six times more than Japan and 7.3 times more than the United States. Since surpassing Japan in 2013, when China accounted for 20.8% of global installations, its share has risen to 51.1%. While China continues to install more robots than the rest of the world combined, this margin narrowed slightly in 2023, marking a modest moderation in its dramatic expansion. 8. Collaborative and interactive robot installations become more common. In 2017, collaborative robots represented a mere 2.8% of all new industrial robot installations, a figure that climbed to 10.5% by 2023. Similarly, 2023 saw a rise in service robot installations across all application categories except medical robotics. This trend indicates not just an overall increase in robot installations but also a growing emphasis on deploying robots for human-facing roles. 9. AI is driving significant shifts in energy sources, attracting interest in nuclear energy. Microsoft announced a $1.6 billion deal to revive the Three Mile Island nuclear reactor to power AI, while Google and Amazon have also secured nuclear energy agreements to support AI operations. 10. AI boosts productivity and bridges skill gaps. Last year’s AI Index was among the first reports to highlight research showing AI’s positive impact on productivity. This year, additional studies reinforced those findings, confirming that AI boosts productivity and, in most cases, helps narrow the gap between low- and high-skilled workers. 18 Artificial Intelligence Index Report 2025 Report Highlights CHAPTER 5: Science and Medicine 1. Bigger and better protein sequencing models emerge. In 2024, several large-scale, high-performance protein sequencing models, including ESM3 and AlphaFold 3, were launched. Over time, these models have grown significantly in size, leading to continuous improvements in protein prediction accuracy. 2. AI continues to drive rapid advances in scientific discovery. AI’s role in scientific progress continues to expand. While 2022 and 2023 marked the early stages of AI-driven breakthroughs, 2024 brought even greater advancements, including Aviary, which trains LLM agents for biological tasks, and FireSat, which significantly enhances wildfire prediction. 3. The clinical knowledge of leading LLMs continues to improve. OpenAI’s recently released o1 set a new state- of-the-art 96.0% on the MedQA benchmark—a 5.8 percentage point gain over the best score posted in 2023. Since late 2022, performance has improved 28.4 percentage points. MedQA, a key benchmark for assessing clinical knowledge, may be approaching saturation, signaling the need for more challenging evaluations. 4. AI outperforms doctors on key clinical tasks. A new study found that GPT-4 alone outperformed doctors—both with and without AI—in diagnosing complex clinical cases. Other recent studies show AI surpassing doctors in cancer detection and identifying high-mortality-risk patients. However, some early research suggests that AI-doctor collaboration yields the best results, making it a fruitful area of further research. 5. The number of FDA-approved, AI-enabled medical devices skyrockets. The FDA authorized its first AI-enabled medical device in 1995. By 2015, only six such devices had been approved, but the number spiked to 223 by 2023. 6. Synthetic data shows significant promise in medicine. Studies released in 2024 suggest that AI-generated synthetic data can help models better identify social determinants of health, enhance privacy-preserving clinical risk prediction, and facilitate the discovery of new drug compounds. 7. Medical AI ethics publications are increasing year over year. The number of publications on ethics in medical AI nearly quadrupled from 2020 to 2024, rising from 288 in 2020 to 1,031 in 2024. 19 Artificial Intelligence Index Report 2025 Report Highlights CHAPTER 5: Science and Medicine (cont’d) 8. Foundation models come to medicine. In 2024, a wave of large-scale medical foundation models were released, ranging from general-purpose multimodal models like Med-Gemini to specialized models such as EchoCLIP for echocardiology, VisionFM for ophthalmology, and ChexAgent for radiology. 9. Publicly available protein databases grow in size. Since 2021, the number of entries in major public protein science databases has grown significantly, including UniProt (31%), PDB (23%), and AlphaFold (585%). This expansion has important implications for scientific discovery. 10. AI research recognized by two Nobel Prizes. In 2024, AI-driven research received top honors, with two Nobel Prizes awarded for AI-related breakthroughs. Google DeepMind’s Demis Hassabis and John Jumper won the Nobel Prize in Chemistry for their pioneering work on protein folding with AlphaFold. Meanwhile, John Hopfield and Geoffrey Hinton received the Nobel Prize in Physics for their foundational contributions to neural networks. CHAPTER 6: Policy and Governance 1. U.S. states are leading the way on AI legislation amid slow progress at the federal level. In 2016, only one state-level AI-related law was passed, increasing to 49 by 2023. In the past year alone, that number more than doubled to 131. While proposed AI bills at the federal level have also increased, the number passed remains low. 2. Governments across the world invest in AI infrastructure. Canada announced a $2.4 billion AI infrastructure package, while China launched a $47.5 billion fund to boost semiconductor production. France committed $117 billion to AI infrastructure, India pledged $1.25 billion, and Saudi Arabia’s Project Transcendence includes a $100 billion investment in AI. 3. Across the world, mentions of AI in legislative proceedings keep rising. Across 75 countries, AI mentions in legislative proceedings increased by 21.3% in 2024, rising to 1,889 from 1,557 in 2023. Since 2016, the total number of AI mentions has grown more than ninefold. 20 Artificial Intelligence Index Report 2025 Report Highlights CHAPTER 6: Policy and Governance (cont’d) 4. AI safety institutes expand and coordinate across the globe. In 2024, countries worldwide launched international AI safety institutes. The first emerged in November 2023 in the U.S. and the U.K. following the inaugural AI Safety Summit. At the AI Seoul Summit in May 2024, additional institutes were pledged in Japan, France, Germany, Italy, Singapore, South Korea, Australia, Canada, and the European Union. 5. The number of U.S. AI-related federal regulations skyrockets. In 2024, 59 AI-related regulations were introduced—more than double the 25 recorded in 2023. These regulations came from 42 unique agencies, twice the 21 agencies that issued them in 2023. 6. U.S. states expand deepfake regulations. Before 2024, only five states—California, Michigan, Washington, Texas, and Minnesota—had enacted laws regulating deepfakes in elections. In 2024, 15 more states, including Oregon, New Mexico, and New York, introduced similar measures. Additionally, by 2024, 24 states had passed regulations targeting deepfakes. CHAPTER 7: Education 1. Access to and enrollment in high school computer science (CS) courses in the U.S. has increased slightly from the previous school year, but gaps remain. Student participation varies by state, race and ethnicity, school size, geography, income, gender, and disability. 2. CS teachers in the U.S. want to teach AI but do not feel equipped to do so. Despite the 81% of CS teachers who agree that using AI and learning about AI should be included in a foundational CS learning experience, fewer than half of high school CS teachers feel equipped to teach AI. 3. Two-thirds of countries worldwide offer or plan to offer K–12 CS education. This fraction has doubled since 2019, with African and Latin American countries progressing the most. However, students in African countries have the least amount of access to CS education due to schools’ lack of electricity. 21 Artificial Intelligence Index Report 2025 Report Highlights CHAPTER 7: Education (cont’d) 4. Graduates who earned their master’s degree in AI in the U.S. nearly doubled between 2022 and 2023. While increased attention on AI will be slower to emerge in the number of bachelor’s and PhD degrees, the surge in master’s degrees could indicate a developing trend for all degree levels. 5. The U.S. continues to be a global leader in producing information, technology, and communications (ICT) graduates at all levels. Spain, Brazil, and the United Kingdom follow the U.S. as top producers at various levels, while Turkey boasts the best gender parity. CHAPTER 8: Public Opinion 1. The world grows cautiously optimistic about AI products and services. Among the 26 nations surveyed by Ipsos in both 2022 and 2024, 18 saw an increase in the proportion of people who believe AI products and services offer more benefits than drawbacks. Globally, the share of individuals who see AI products and services as more beneficial than harmful has risen from 52% in 2022 to 55% in 2024. 2. The expectation and acknowledgment of AI’s impact on daily life is rising. Around the world, two thirds of people now believe that AI-powered products and services will significantly impact daily life within the next three to five years—an increase of 6 percentage points since 2022. Every country except Malaysia, Poland, and India saw an increase in this perception since 2022, with the largest jumps in Canada (17%) and Germany (15%). 3. Skepticism about the ethical conduct of AI companies is growing, while trust in the fairness of AI is declining. Globally, confidence that AI companies protect personal data fell from 50% in 2023 to 47% in 2024. Likewise, fewer people today believe that AI systems are unbiased and free from discrimination compared to last year. 4. Regional differences persist regarding AI optimism. First reported in the 2023 AI Index, significant regional differences in AI optimism endure. A large majority of people believe AI-powered products and services offer more benefits than drawbacks in countries like China (83%), Indonesia (80%), and Thailand (77%), while only a minority share this view in Canada (40%), the United States (39%), and the Netherlands (36%). 22 Artificial Intelligence Index Report 2025 Report Highlights CHAPTER 8: Public Opinion (cont’d) 5. People in the United States remain distrustful of self-driving cars. A recent American Automobile Association survey found that 61% of people in the U.S. fear self-driving cars, and only 13% trust them. Although the percentage who expressed fear has declined from its 2023 peak of 68%, it remains higher than in 2021 (54%). 6. There is broad support for AI regulation among local U.S. policymakers. In 2023, 73.7% of local U.S. policymakers—spanning township, municipal, and county levels—agreed that AI should be regulated, up significantly from 55.7% in 2022. Support was stronger among Democrats (79.2%) than Republicans (55.5%), though both registered notable increases over 2022. 7. AI optimism registers sharp increase among countries that previously showed the most skepticism. Globally, optimism about AI products and services has increased, with the sharpest gains in countries that were previously the most skeptical. In 2022, Great Britain (38%), Germany (37%), the United States (35%), Canada (32%), and France (31%) were among the least likely to view AI as having more benefits than drawbacks. Since then, optimism has grown in these countries by 8%, 10%, 4%, 8%, and 10%, respectively. 8. Workers expect AI to reshape jobs, but fear of replacement remains lower. Globally, 60% of respondents agree that AI will change how individuals do their job in the next five years. However, a smaller subset of respondents, 36%, believe that AI will replace their jobs in the next five years. 9. Sharp divides exist among local U.S. policymakers on AI policy priorities. While local U.S. policymakers broadly support AI regulation, their priorities vary. The strongest backing is for stricter data privacy rules (80.4%), retraining for the unemployed (76.2%), and AI deployment regulations (72.5%). However, support drops significantly for a law enforcement facial recognition ban (34.2%), wage subsidies for wage declines (32.9%), and universal basic income (24.6%). 10. AI is seen as a time saver and entertainment booster, but doubts remain on its economic impact. Global perspectives on AI’s impact vary. While 55% believe it will save time, and 51% expect it will offer better entertainment options, fewer are confident in its health or economic benefits. Only 38% think AI will improve health, whilst 36% think AI will improve the national economy, 31% see a positive impact on the job market, and 37% believe it will enhance their own jobs. 23 Artificial Intelligence Index Report 2025 CHAPTER 1: Research and Development Artificial Intelligence Index Report 2025 Chapter 1: Research and Development Overview 26 1.4 Hardware 68 Chapter Highlights 27 Overview 68 Highlight: Energy Efficiency and 1.1 Publications 29 Environmental Impact 71 Overview 29 1.5 AI Conferences 75 Total Number of AI Publications 29 Conference Attendance 75 By Venue 31 By National Affiliation 32 1.6 Open-Source AI Software 77 By Sector 36 Projects 77 By Topic 38 Stars 79 Top 100 Publications 39 By National Affiliation 39 By Sector 40 ACCESS THE PUBLIC DATA By Organization 41 1.2 Patents 42 Overview 42 By National Affiliation 43 1.3 Notable AI Models 46 By National Affiliation 46 By Sector 47 By Organization 49 Model Release 50 Parameter Trends 52 Compute Trends 56 Highlight: Will Models Run Out of Data? 59 Inference Cost 64 Training Cost 65 Table of Contents 25 AArrttiifificciiaall IInntteelllliiggeennccee IInnddeexx RReeppoorrtt 22002255 CHAPTER 1: Research and Development Overview This chapter explores trends in AI research and development, beginning with an analysis of AI publications, patents, and notable AI systems. These topics are examined through the lens of the countries, organizations, and sectors producing them. The chapter also covers AI model training costs, AI conference attendance, and open- source AI software. New additions this year include profiles of the evolving AI hardware ecosystem, an assessment of AI training’s energy requirements and environmental impact, and a temporal analysis of model inference costs. Table of Contents Chapter 1 Preview 26 AArrttiifificciiaall IInntteelllliiggeennccee IInnddeexx RReeppoorrtt 22002255 CHAPTER 1: Research and Development Chapter Highlights 1. Industry continues to make significant investments in AI and leads in notable AI model development, while academia leads in highly cited research. Industry’s lead in notable model development, highlighted in the two previous AI Index reports, has only grown more pronounced, with nearly 90% of notable models in 2024 (compared to 60% in 2023) originating from industry. Academia has remained the single leading institutional producer of highly cited (top 100) publications over the past three years. 2. China leads in AI research publication totals, while the United States leads in highly influential research. In 2023, China produced more AI publications (23.2%) and citations (22.6%) than any other country. Over the past three years, U.S. institutions have contributed the most top-100-cited AI publications. 3. AI publication totals continue to grow and increasingly dominate computer science. Between 2013 and 2023, the total number of AI publications in venues related to computer science and other scientific disciplines nearly tripled, increasing from approximately 102,000 to over 242,000. Proportionally, AI’s share of computer science publications has risen from 21.6% in 2013 to 41.8% in 2023. 4. The United States continues to be the leading source of notable AI models. In 2024, U.S.-based institutions produced 40 notable AI models, significantly surpassing China’s 15 and Europe’s combined total of three. In the past decade, more notable machine learning models have originated from the United States than any other country. 5. AI models get increasingly bigger, more computationally demanding, and more energy intensive. New research finds that the training compute for notable AI models doubles approximately every five months, dataset sizes for training LLMs every eight months, and the power required for training annually. Large-scale industry investment continues to drive model scaling and performance gains. Table of Contents Chapter 1 Preview 27 AArrttiifificciiaall IInntteelllliiggeennccee IInnddeexx RReeppoorrtt 22002255 CHAPTER 1: Research and Development Chapter Highlights (cont’d) 6. AI models become increasingly affordable to use. The cost of querying an AI model that scores the equivalent of GPT-3.5 (64.8) on MMLU, a popular benchmark for assessing language model performance, dropped from $20.00 per million tokens in November 2022 to just $0.07 per million tokens by October 2024 (Gemini-1.5-Flash-8B)—a more than 280- fold reduction in approximately 18 months. Depending on the task, LLM inference prices have fallen anywhere from 9 to 900 times per year. 7. AI patenting is on the rise. Between 2010 and 2023, the number of AI patents has grown steadily and significantly, ballooning from 3,833 to 122,511. In just the last year, the number of AI patents has risen 29.6%. As of 2023, China leads in total AI patents, accounting for 69.7% of all grants, while South Korea and Luxembourg stand out as top AI patent producers on a per capita basis. 8. AI hardware gets faster, cheaper, and more energy efficient. New research suggests that machine learning hardware performance, measured in 16-bit floating-point operations, has grown 43% annually, doubling every 1.9 years. Price performance has improved, with costs dropping 30% per year, while energy efficiency has increased by 40% annually. 9. Carbon emissions from AI training are steadily increasing. Training early AI models, such as AlexNet (2012), had modest amounts of carbon emissions at 0.01 tons. More recent models have significantly higher emissions for training: GPT-3 (2020) at 588 tons, GPT-4 (2023) at 5,184 tons, and Llama 3.1 405B (2024) at 8,930 tons. For perspective, the average American emits 18 tons of carbon per year. Table of Contents Chapter 1 Preview 28 Artificial Intelligence Index Report 2025 250 242.74 200 150 100 50 0 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 Table of Contents Chapter 1 Preview 29 )sdnasuoht ni( SC ni snoitacilbup IA fo rebmuN Chapter 1: Research and Development 1.1 Publications 1.1 Publications The figures below show the global count of English-language report, the AI Index team elected to examine publication AI publications from 2010 to 2023, categorized by affiliation trends only through 2023. type, publication type, and region. New to this year’s report, Overview the AI Index includes a section analyzing trends among the 100 most-cited AI publications, which can offer insights The following section reports on trends in the total number of into particularly high-impact research. This year, the AI English-language AI publications. Index analyzed AI publication trends using the OpenAlex database. As a result, the numbers in this year’s report differ Total Number of AI Publications slightly from those in previous editions.1 Given that there is a Figure 1.1.1 displays the global count of AI publications. These significant lag in the collection of publication metadata, and are the publications with a computer science (CS) label in the that in some cases it takes until the middle of any given year OpenAlex catalog that were classified by the AI Index as being to fully capture the previous year’s publications, in this year’s related to AI.2 Between 2013 and 2023, the total number of AI Number of AI publications in CS worldwide, 2013–23 Source: AI Index, 2025 | Chart: 2025 AI Index report Figure 1.1.1 1 OpenAlex is a fully open catalog of scholarly metadata, including scientific papers, authors, institutions, and more. The AI Index used OpenAlex as a bibliographic database and automatically classified AI-related research using the latest version of the CSO Classifier. In previous years, the Index relied on third-party providers with different underlying data sources and classification methods. As a result, this year’s findings differ slightly from those included in previous reports. Additionally, the AI Index applied the classifier only to papers that OpenAlex categorized under the broad field of computer science. This approach may have led to an undercount of AI-related publications by excluding research from fields like social sciences that employ AI methodologies but fall outside the computer science–designated classification. 2 The CSO Classifier (v3.3) is an automated text classification system designed to categorize research papers in computer science using a comprehensive ontology of 15,000 topics and 166,000 relationships, including emerging fields like GenAI, LLMs, and prompt engineering. It processes metadata (such as title and abstract) through three modules: a syntactic module for exact topic matches, a semantic module leveraging word embeddings to infer related topics, and a post-processing module that refines results by filtering outliers and adding relevant higher- level areas. Artificial Intelligence Index Report 2025 publications more than doubled, rising from approximately to human-computer interaction, are now contributing to 102,000 in 2013 to more than 242,000 in 2023. The increase AI. As a result, the observed growth reflects a broader and over the last year was a meaningful 19.7%. Many fields within increased interest in AI across the discipline. computer science, from hardware and software engineering 45% 40% 35% 30% 25% 20% 15% 10% 5% 0% 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 Table of Contents Chapter 1 Preview 30 )latot fo %( SC ni snoitacilbup IA Chapter 1: Research and Development 1.1 Publications AI publications in CS (% of total) worldwide, 2013–23 Source: AI Index, 2025 | Chart: 2025 AI Index report 41.76% Figure 1.1.2 Artificial Intelligence Index Report 2025 Chapter 1: Research and Development 1.1 Publications Figure 1.1.2 shows the proportion of computer science by venue type. In 2023, journals accounted for the largest publications in the OpenAlex corpus classified as AI-related. share of AI publications (41.8%), followed by conferences Figure 1.1.2 features the same data included in Figure 1.1.1 but (34.3%). Even though the total number of journal and in a proportional form. The share of AI publications has grown conference publications has increased since 2013, the share significantly, almost doubling from 2013 to 2023. of AI publications in journals and conferences has steadily declined, from 52.6% and 36.4% in 2013 to 41.8% and By Venue 34.3%, respectively, in 2023. Conversely, AI publications in AI researchers publish their work across various venues. repositories like arXiv have seen a growing share. Figure 1.1.3 visualizes the total number of AI publications 100 80 60 40 20 0 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 Table of Contents Chapter 1 Preview 31 )sdnasuoht ni( SC ni snoitacilbup IA fo rebmuN Number of AI publications in CS by venue type, 2013–23 Source: AI Index, 2025 | Chart: 2025 AI Index report 101.57, Journal 83.30, Conference 44.54, Repository 10.73, Book 1.64, Other 0.96, Dissertation Figure 1.1.3 Artificial Intelligence Index Report 2025 Chapter 1: Research and Development 1.1 Publications By National Affiliation Figure 1.1.4 visualizes AI publications over time by region.3 of total AI publication citations attributed to work originating In 2023, East Asia and the Pacific led AI research output, from each region. As of 2023, AI publications from East Asia accounting for 34.5% of all AI publications, followed by and the Pacific accounted for the largest share of AI article Europe and Central Asia (18.2%) and North America (10.3%).4 citations at 37.1% (Figure 1.1.5). In 2017, citation shares from East Asia and the Pacific and North America were roughly While Figure 1.1.4 examines the geographic distribution of equal, but since then, North American and European citation AI publications, identifying which regions produce the most shares have declined, while East Asia and the Pacific’s share research, Figure 1.1.5 focuses on citations, measuring the share has risen sharply. 35% 30% 25% 20% 15% 10% 5% 0% 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 Table of Contents Chapter 1 Preview 32 )latot fo %( SC ni snoitacilbup IA AI publications in CS (% of total) by region, 2013–23 Source: AI Index, 2025 | Chart: 2025 AI Index report 34.46%, East Asia and Paci c 19.37%, Unknown 18.15%, Europe and Central Asia 10.31%, North America 9.98%, South Asia 5.18%, Middle East and North Africa 1.66%, Latin America and the Caribbean 0.89%, Sub-Saharan Africa Figure 1.1.4 3 Regions in this chapter are classified according to the World Bank analytical grouping. The AI Index determines the country affiliation of authors using the “countries” field from the authorship data. This field lists all the countries an author is affiliated with, as retrieved from OpenAlex based on institutional affiliations. These affiliations can be explicitly stated in the paper or inferred from the author’s most recent publications. When counting publications by country, the AI Index assigns one count to each country linked to the publication. For example, if a paper has three authors, two affiliated with institutions in the U.S. and one in China, the publication is counted once for the U.S. and once for China. 4 A publication may have an “unknown” country affiliation when the author’s institutional affiliation is missing or incomplete. This issue arises due to various factors, including unstructured or omitted institution names, platform functional deficiencies, group authorship practices, unstandardized affiliation labeling, document type inconsistencies, or the author’s limited publication record. The problem as it relates to OpenAlex is addressed in this paper; however, the issue of missing institutions pertains to other bibliographic databases as well. Artificial Intelligence Index Report 2025 Chapter 1: Research and Development 1.1 Publications 40% 35% 30% 25% 20% 15% 10% 5% 0% 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 Table of Contents Chapter 1 Preview 33 )latot fo %( SC ni snoitatic noitacilbup IA AI publication citations in CS (% of total) by region, 2013–23 Source: AI Index, 2025 | Chart: 2025 AI Index report 37.07%, East Asia and Paci c 21.88%, Europe and Central Asia 15.59%, North America 7.97%, Middle East and North Africa 7.69%, South Asia 7.55%, Unknown 1.35%, Latin America and the Caribbean 0.89%, Sub-Saharan Africa Figure 1.1.5 Artificial Intelligence Index Report 2025 In 2023, China was the global leader in AI article publications, to Europe has declined. AI publications attributed to the accounting for 23.2% of the total, compared to 15.2% from United States remained relatively stable until 2021 but have Europe and 9.2% from India (Figure 1.1.6).5 Since 2016, China’s shown a slight decline since then. share has steadily increased, while the proportion attributed 25% 20% 15% 10% 5% 0% 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 Table of Contents Chapter 1 Preview 34 )latot fo %( SC ni snoitacilbup IA Chapter 1: Research and Development 1.1 Publications AI publications in CS (% of total) by select geographic areas, 2013–23 Source: AI Index, 2025 | Chart: 2025 AI Index report 23.20%, China 22.51%, Rest of the world 20.65%, Unknown 15.22%, Europe 9.22%, India 9.20%, United States Figure 1.1.66 5 For the “Europe” designation in this and other chapters of the report, the AI Index follows the list of countries defined by the United Nations Statistics Division. 6 To maintain concision, the AI Index visualized results for a select group of countries. However, full results for all countries will be available on the AI Index’s Global Vibrancy Tool, which is set to be updated in summer 2025. For immediate access to country-specific research and development data, please contact the AI Index team. Artificial Intelligence Index Report 2025 In 2023, Chinese AI publications accounted for 22.6% of all AI citations, followed by Europe at 20.9% and the United States at 13.0% (Figure 1.1.7). As with total AI publications, the late 2010s marked a turning point when China surpassed Europe and the U.S. as the leading source of AI publication citations. 35% 30% 25% 20% 15% 10% 5% 0% 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 Table of Contents Chapter 1 Preview 35 )latot fo %( SC ni snoitatic noitacilbup IA Chapter 1: Research and Development 1.1 Publications AI publication citations in CS (% of total) by select geographic areas, 2013–23 Source: AI Index, 2025 | Chart: 2025 AI Index report 29.83%, Rest of the world 22.60%, China 20.90%, Europe 13.03%, United States 7.54%, Unknown 6.10%, India Figure 1.1.7 Artificial Intelligence Index Report 2025 By Sector Academic institutions remain the primary source of AI at 84.9%, in 2023. Industry contributed 7.1% of AI publications publications worldwide (Figure 1.1.8). In 2013, they accounted in 2023, followed by government institutions at 4.9% and for 85.9% of all AI publications, a figure that remained high, nonprofit organizations at 1.7%. 90% 80% 70% 60% 50% 40% 30% 20% 10% 0% 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 Table of Contents Chapter 1 Preview 36 )latot fo %( SC ni snoitacilbup IA Chapter 1: Research and Development 1.1 Publications AI publications in CS (% of total) by sector, 2013–23 Source: AI Index, 2025 | Chart: 2025 AI Index report 84.91%, Academia 7.14%, Industry 4.90%, Government 1.70%, Nonpro t 1.35%, Other Figure 1.1.87 7 For Figures 1.1.8 and 1.1.9, publications with unknown affiliations were excluded from the final visualization. Artificial Intelligence Index Report 2025 Chapter 1: Research and Development 1.1 Publications AI publications emerge from various sectors in differing compared to China (8.0%) (Figure 1.1.9). Among major proportions across geographic regions. In the United States, geographic areas, China has the highest percentage of AI a higher share of AI publications (16.5%) comes from industry publications originating from the education sector (84.5%). AI publications in CS (% of total) by sector and select geographic areas, 2023 Source: AI Index, 2025 | Chart: 2025 AI Index report 75.61% Academia 79.49% 84.45% 16.49% Industry 9.62% 8.02% 4.02% Nonpro t 4.09% 0.58% 3.88% United States Government 6.79% Europe China 6.96% 0% 10% 20% 30% 40% 50% 60% 70% 80% 90% AI publications (% of total) Figure 1.1.9 Table of Contents Chapter 1 Preview 37 Artificial Intelligence Index Report 2025 By Topic Machine learning was the most prevalent research topic in (25.9%) and natural language processing (17.1%) (Figure AI publications in 2023, comprising 75.7% of publications, 1.1.10). Over the past year, there has been a sharp increase in followed by computer vision (47.2%), pattern recognition publications on generative AI. 150 100 50 0 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 Table of Contents Chapter 1 Preview 38 )sdnasuoht ni( snoitacilbup IA fo rebmuN Chapter 1: Research and Development 1.1 Publications Number of AI publications by select top topics, 2013–23 Source: AI Index, 2025 | Chart: 2025 AI Index report 183.78, Machine learning 114.61, Computer vision 62.90, Pattern recognition 41.40, Natural language processing 21.82, Knowledge based systems 17.34, Evolutionary computation 13.07, Generative AI 12.00, Logic and reasoning 11.28, Multi-agent systems 5.25, Robotics Figure 1.1.108 8 The AI Index categorized papers using its own topic classifier. It is possible for a single publication to be assigned multiple topic labels. Artificial Intelligence Index Report 2025 Chapter 1: Research and Development 1.1 Publications Top 100 Publications While tracking total AI publications provides a broad view of technical report. It is important to note that due to citation research activity, focusing on the most-cited papers offers a lag, the most-cited papers in this year’s report may change perspective of the field’s most influential work. This analysis in future editions. sheds light on where some of the most groundbreaking and influential AI research is emerging. This year, the AI Index By National Affiliation identified the 100 most-cited AI publications in 2021, 2022, Figure 1.1.11 illustrates the geographic distribution of the top and 2023, using citation data from OpenAlex. This analysis 100 most-cited AI publications by year. From 2021 to 2023, was further supplemented with insights from Google Scholar the U.S. consistently had the highest number of top-cited and Semantic Scholar.9 Some of the most highly cited AI publications, with 64 in 2021, 59 in 2022, and 50 in 2023.10 publications in 2023 included OpenAI’s GPT-4 technical In each of these years, China ranked second. Since 2021, the report, Meta’s Llama 2 technical report, and Google’s PaLM-E U.S. share of top AI publications has gradually declined. Number of highly cited publications in top 100 by select geographic areas, 2021–23 Source: AI Index, 2025 | Chart: 2025 AI Index report 50 United States 59 64 34 China 34 33 7 Germany 7 10 7 Hong Kong 4 8 6 Canada 3 4 6 South Korea 1 3 5 United Kingdom 6 7 4 United Arab Emirates 2 1 4 2023 Israel 3 1 2022 4 2021 Singapore 4 7 0 2 4 6 8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48 50 52 54 56 58 60 62 64 66 Number of highly cited publications in top 100 Figure 1.1.11 9 The full methodological guide can be accessed in the Appendix, along with the list of the top 100 articles. 10 A publication can have multiple authors from different countries or organizations. For example, if a paper includes authors from multiple countries, each country is credited once. As a result, the totals in this section’s figures exceed 100. Table of Contents Chapter 1 Preview 39 Artificial Intelligence Index Report 2025 45 2023 42 2022 40 2021 35 35 34 31 30 27 25 25 24 20 19 17 17 17 15 10 7 5 2 1 0 Academia Industry Industry and academia Mixed Other Sector Table of Contents Chapter 1 Preview 40 001 pot ni snoitacilbup detic ylhgih fo rebmuN Chapter 1: Research and Development 1.1 Publications By Sector Academia consistently produces the most top-cited AI dropping from 17 in 2021 and 19 in 2022 to just 7 in 2023. publications, with 42 in 2023, 27 in 2022, and 34 in 2021 As AI research grows more competitive, many industrial AI (Figure 1.1.12). Notably, there was a sharp decline in industry labs are publishing less frequently or disclosing fewer details contributions, with the number of top 100 publications about their research in their publications. Number of highly cited publications in top 100 by sector, 2021–23 Source: AI Index, 2025 | Chart: 2025 AI Index report Figure 1.1.1211 11 The “mixed” designation includes all intersector collaborations that are not industry and academia (e.g., industry and government, academia and nonprofit). Some institutions lack data for 2021 because they did not have papers included in the top 100 that year. Since papers can have multiple authors from different institutions, the total institutional tags in Figure 1.1.12 may exceed 100. Also, because two of the papers had authors with an unknown sectoral affiliation, the total sum of publications in Figure 1.1.12 is 98. Artificial Intelligence Index Report 2025 By Organization Figure 1.1.13 highlights the organizations that produced the Google led each year, but it tied with Tsinghua University in top 100 most-cited AI publications from 2021 to 2023. Some 2023, when both contributed eight publications to the top organizations may have empty bars on the chart if they lacked 100. In 2023, Carnegie Mellon University was the highest- a top 100 publication in a given year. Additionally, Figure 1.1.13 ranked U.S. academic institution. highlights only the top 10 institutions, though many others contribute significant research. 22 2023 20 2022 20 2021 18 16 15 14 12 10 10 10 9 9 8 8 8 7 6 6 6 5 5 5 5 4 4 4 4 4 3 3 2 2 2 2 2 2 1 0 Google Un T i s v i e n r g s h it u y a Un C iv a e rn rs e i g ty ie M ellon M icrosoft Ar B t e i ij c in ia g l A In c t a e d lli e g m en y S c c o H e i f e o n n c g e K a o n n d g T U e n c i h v n A e o r I S s l L o h it a g a y b n y o o g f r h a a t i ory of C S h c i i n e e n s c e e A s cadem y M eta Nvidia Organization Table of Contents Chapter 1 Preview 41 001 pot ni snoitacilbup detic ylhgih fo rebmuN Chapter 1: Research and Development 1.1 Publications Number of highly cited publications in top 100 by organization, 2021–23 Source: AI Index, 2025 | Chart: 2025 AI Index report Figure 1.1.13 Artificial Intelligence Index Report 2025 This section examines trends over time in global AI patents, which can reveal important insights into the evolution of innovation, research, and development within AI. Additionally, analyzing AI patents can reveal how these advances are distributed globally. Similar to the publications data, there is a noticeable delay in AI patent data availability, with 2023 being the most recent year for which data is accessible. The data in this section is sourced from patent- level bibliographic records in PATSTAT Global, a comprehensive database provided by the European Patent Office (EPO).12 122.51 120 100 80 60 40 20 0 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 Table of Contents Chapter 1 Preview 42 )sdnasuoht ni( detnarg stnetap IA fo rebmuN Chapter 1: Research and Development 1.2 Patents 1.2 Patents Overview Figure 1.2.1 examines the global growth in granted AI patents from 2010 to 2023. Over the past dozen years, the number of AI patents has grown steadily and significantly, increasing from 3,833 in 2010 to 122,511 in 2023. In the last year, the number of AI patents has risen 29.6%. Number of AI patents granted worldwide, 2010–23 Source: AI Index, 2025 | Chart: 2025 AI Index report Figure 1.2.1 12 More details on the methodology behind the patent analysis in this section can be found in the Appendix. Artificial Intelligence Index Report 2025 90% 80% 70% 60% 50% 40% 30% 20% 10% 0% 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 Table of Contents Chapter 1 Preview 43 )latot dlrow fo %( stnetap IA detnarG Chapter 1: Research and Development 1.2 Patents By National Affiliation Figure 1.2.2 showcases the regional breakdown of granted the Pacific, with North America being the next largest AI patents, as in the number of patents filed in different contributor at 14.2%. Since 2010, the gap in AI patent grants regions across the world. As of 2023, the bulk of the world’s between East Asia and the Pacific and North America has granted AI patents (82.4%) originated from East Asia and steadily widened. Granted AI patents (% of world total) by region, 2010–23 Source: AI Index, 2025 | Chart: 2025 AI Index report 82.40%, East Asia and Paci c 14.23%, North America 2.77%, Europe and Central Asia 0.37%, South Asia 0.15%, Rest of the world 0.04%, Latin America and the Caribbean 0.02%, Middle East and North Africa 0.02%, Sub-Saharan Africa Figure 1.2.213 13 Patent standards and laws vary across countries and regions, so these charts should be interpreted with caution. More detailed country-level patent information will be released in a subsequent edition of the AI Index’s Global Vibrancy Tool. Artificial Intelligence Index Report 2025 Disaggregated by geographic area, the majority of the Figure 1.2.3 and Figure 1.2.4 document which countries lead world’s granted AI patents are from China (69.7%) and the in AI patents per capita. In 2023, the country with the most United States (14.2%) (Figure 1.2.3). The share of AI patents granted AI patents per 100,000 inhabitants was South Korea originating from the United States has declined from a peak (17.3), followed by Luxembourg (15.3) and China (6.1) (Figure of 42.8% in 2015. 1.2.3). Figure 1.2.5 highlights the change in granted AI patents per capita from 2013 to 2023. Luxembourg, China and Sweden experienced the greatest increase in AI patenting per capita during that time period. 70% 60% 50% 40% 30% 20% 10% 0% 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 Figure 1.2.3 Table of Contents Chapter 1 Preview 44 )latot dlrow fo %( stnetap IA detnarG Chapter 1: Research and Development 1.2 Patents Granted AI patents (% of world total) by select geographic areas, 2010–23 Source: AI Index, 2025 | Chart: 2025 AI Index report 69.70%, China 14.16%, United States 13.00%, Rest of the world 2.77%, Europe 0.37%, India Artificial Intelligence Index Report 2025 Chapter 1: Research and Development 1.2 Patents Granted AI patents per 100,000 inhabitants by country, 2023 Source: AI Index, 2025 | Chart: 2025 AI Index report South Korea 17.27 Luxembourg 15.31 China 6.08 United States 5.20 Japan 4.58 Germany 1.22 Singapore 0.98 Finland 0.97 Sweden 0.74 United Kingdom 0.52 Denmark 0.47 France 0.43 Netherlands 0.40 Australia 0.38 Greece 0.27 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 Granted AI patents (per 100,000 inhabitants) Figure 1.2.4 Percentage change of granted AI patents per 100,000 inhabitants by country, 2013 vs. 2023 Source: AI Index, 2025 | Chart: 2025 AI Index report Luxembourg 8,216% China 6,317% Sweden 3,453% Greece 2,851% Singapore 2,546% Finland 1,653% Germany 1,097% South Korea 1,043% Netherlands 1,028% United Kingdom 730% United States 580% France 463% Japan 365% Australia 240% Denmark 230% 0% 1,000% 2,000% 3,000% 4,000% 5,000% 6,000% 7,000% 8,000% % change of granted AI patents (per 100,000 inhabitants) Figure 1.2.5 Table of Contents Chapter 1 Preview 45 Artificial Intelligence Index Report 2025 Number of notable AI models by select geographic areas, 2024 Source: Epoch AI, 2025 | Chart: 2025 AI Index report United States 40 China 15 France 3 Canada 1 Israel 1 Saudi Arabia 1 South Korea 1 0 5 10 15 20 25 30 35 40 Number of notable AI models Table of Contents Chapter 1 Preview 46 3002 6002 9002 2102 5102 8102 1202 4202 70 60 50 40 30 20 10 0 sledom IA elbaton fo rebmuN Chapter 1: Research and Development 1.3 Notable AI Models This section explores notable AI models.14 Epoch AI, an AI Index data provider, uses the term “notable machine learning models” to designate particularly influential models within the AI/machine learning ecosystem. Epoch maintains a database of 900 1.3 Notable AI Models AI models released since the 1950s, selecting entries based on criteria such as state-of-the-art advancements, historical significance, or high By National Affiliation citation rates. Since Epoch manually curates To illustrate the evolving geopolitical landscape of AI, the AI Index shows the data, some models considered notable by some may not be included. Analyzing these the country of origin of notable models. Figure 1.3.1 displays the total number models provides a comprehensive overview of of notable AI models attributed to the location of researchers’ affiliated the machine learning landscape’s evolution, both institutions.16 In 2024, the United States led with 40 notable AI models, in recent years and over the past few decades.15 followed by China with 15 and France with three. All major geographic Some models may be missing from the dataset; however, the dataset can reveal trends in relative groups, including the United States, China, and Europe, reported releasing terms. Examples of notable AI models include fewer notable models in 2024 than in the previous year (Figure 1.3.2). Since GPT-4o, Claude 3.5, and AlphaGeometry. 2003, the United States has produced more models than other major Within this section, the AI Index explores trends countries such as the United Kingdom, China, and Canada (Figure 1.3.3). in notable models from various perspectives, including country of origin, originating It is difficult to pinpoint the exact cause of the decline in total model organization, gradient of model release, parameter releases, but it may stem from a combination of factors: increasingly large count, and compute usage. The analysis concludes with an examination of machine learning training training runs, the growing complexity of AI technology, and the heightened as well as inference costs. challenge of developing new modeling approaches. Epoch AI’s curation of Number of notable AI models by select geographic areas, 2003–24 Source: Epoch AI, 2025 | Chart: 2025 AI Index report 40, United States 15, China 3, Europe Figure 1.3.117 Figure 1.3.2 14 “AI system” refers to a computer program or product based on AI, such as ChatGPT. “AI model” includes a collection of parameters whose values are learned during training, such as GPT-4. 15 New and historic models are continually added to the Epoch AI database, so the total year-by-year counts of models included in this year’s AI Index might not exactly match those published in last year’s report. The data is from a snapshot taken on March 17, 2025. 16 A machine learning model is associated with a specific country if at least one author of the paper introducing it has an affiliation with an institution based in that country. In cases where a model’s authors come from several countries, double-counting can occur. 17 This chart highlights model releases from a select group of geographic areas. More comprehensive data on model releases by country will be available in the upcoming AI Index Global Vibrancy Tool release. Artificial Intelligence Index Report 2025 Chapter 1: Research and Development 1.3 Notable AI Models notable models may overlook releases from certain countries the AI model ecosystem. If readers believe that models from that receive less coverage. The AI Index, in cooperation with specific countries are missing, they are encouraged to contact Epoch, is committed to improving global representation in the AI Index team, which will work to address the issue. Number of notable AI models by geographic area, 2003–24 (sum) Source: Epoch AI, 2025 | Chart: 2025 AI Index report 1–10 11–20 21–60 61–100 101–560 Figure 1.3.3 By Sector Figure 1.3.4 illustrates the sectoral origin of notable AI releases Until 2014, academia led in terms of releasing machine by the year the models were released. Epoch categorizes learning models. Since then, industry has taken the lead. models based on their source: Industry includes companies According to Epoch AI, in 2024, industry produced 55 notable such as Google, Meta, and OpenAI; academia covers AI models. That same year, Epoch AI identified no notable universities like Tsinghua, MIT, and Oxford; government AI models originating from academia (Figure 1.3.5).18 Over refers to state-affiliated research institutes like the UK’s Alan time, industry-academia collaborations have contributed to Turing Institute for AI and Abu Dhabi’s Technology Innovation a growing number of models. The proportion of notable AI Institute; and research collectives encompass nonprofit AI models originating from industry has steadily increased over research organizations such as the Allen Institute for AI and the past decade, growing to 90.2% in 2024. the Fraunhofer Institute. 18 This figure should be interpreted with caution. A count of zero academic models does not mean that no notable models were produced by academic institutions in 2023, but rather that Epoch AI has not identified any as notable. Additionally, academic publications often take longer to gain recognition, as highly cited papers introducing significant architectures may take years to achieve prominence. Table of Contents Chapter 1 Preview 47 Artificial Intelligence Index Report 2025 Table of Contents Chapter 1 Preview 48 3002 4002 5002 6002 7002 8002 9002 0102 1102 2102 3102 4102 5102 6102 7102 8102 9102 0202 1202 2202 3202 4202 100% 80% 60% 40% 20% 0% )latot fo %( sledom IA elbatoN Notable AI models (% of total) by sector, 2003–24 Source: Epoch AI, 2025 | Chart: 2025 AI Index report 90.16%, Industry 8.20%, Industry–academia collaboration 1.64%, Industry–government collaboration 0.00%, Government 0.00%, Industry–research collective collaboration 0.00%, Research collective 0.00%, Academia–research collective collaboration 0.00%, Academia–government collaboration 0.00%, Academia 3002 4002 5002 6002 7002 8002 9002 0102 1102 2102 3102 4102 5102 6102 7102 8102 9102 0202 1202 2202 3202 4202 60 50 40 30 20 10 0 sledom IA elbaton fo rebmuN Chapter 1: Research and Development 1.3 Notable AI Models Number of notable AI models by sector, 2003–24 Source: Epoch AI, 2025 | Chart: 2025 AI Index report 55, Industry 5, Industry–academia collaboration 1, Industry–government collaboration 0, Government 0, Industry–research collective collaboration 0, Research collective 0, Academia–research collective collaboration 0, Academia–government collaboration 0, Academia Figure 1.3.4 Figure 1.3.5 Artificial Intelligence Index Report 2025 Chapter 1: Research and Development 1.3 Notable AI Models By Organization Figure 1.3.6 and Figure 1.3.7 highlight the organizations leading Google has led with 187 notable models, followed by Meta (82) in the production of notable machine learning models in 2024 and Microsoft (39). Among academic institutions, Carnegie and over the past decade. In 2024, the top contributors were Mellon University (25), Stanford University (25), and Tsinghua Google (7), OpenAI (7 models), and Alibaba (6). Since 2014, University (22) have been the most prolific since 2014. Number of notable AI models by organization, 2024 Source: Epoch AI, 2025 | Chart: 2025 AI Index report Google 7 OpenAI 7 Alibaba 6 Apple 4 Meta 4 Nvidia 4 Anthropic 3 Mistral AI 3 ByteDance 2 DeepSeek 2 MIT 2 Tencent 2 UC Berkeley 2 Academia Writer 2 Industry Zhipu AI 2 0 1 2 3 4 5 6 7 Number of notable AI models Figure 1.3.619 Number of notable AI models by organization, 2014–24 (sum) Source: Epoch AI, 2025 | Chart: 2025 AI Index report Google 187 Meta 82 Microsoft 39 OpenAI 36 Carnegie Mellon University 25 Stanford University 25 Tsinghua University 22 UC Berkeley 22 Nvidia 17 University of Oxford 16 MIT 15 Salesforce 15 Academia University of Washington 15 Industry Alibaba 14 Research collective Allen Institute for AI 12 0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 Number of notable AI models Figure 1.3.7 19 In the organizational tally figures, research published by DeepMind is classified under Google. Table of Contents Chapter 1 Preview 49 Artificial Intelligence Index Report 2025 Model Release Machine learning models are released under various proprietary, accessible only to their developers or select access types, each with varying levels of openness and partners. The unknown designation refers to models that usability. API access models, like OpenAI’s o1, allow users have unclear or undisclosed access types. to interact with models via queries without direct access to their underlying weights. Open weights (restricted use) Figure 1.3.8 illustrates the different access types under which models, like DeepSeek’s-V3, provide access to their weights models have been released.20 In 2024, API access was the but impose limitations, such as prohibiting commercial most common release type, with 20 of 61 models made use or redistribution. Hosted access (no API) models, like available this way, followed by open weights with restricted Gemini 2.0 Pro, refer to models available through a platform use and unreleased models. interface but without programmatic access. Open weights (unrestricted) models, like AlphaGeometry, are fully open, Figure 1.3.9 visualizes machine learning model access types allowing free use, modification, and redistribution. Open over time from a proportional perspective. In 2024, most AI weights (noncommercial) models, like Mistral Large 2, share models were released via API access (32.8%), which has seen their weights but restrict use to research or noncommercial a steady rise since 2020. purposes. Lastly, unreleased models, like ESM3 98B, remain API access Hosted access (no API) Open weights (noncommercial) Open weights (restricted use) Open weights (unrestricted) Unreleased 120 Unknown 105 100 86 30 80 75 72 26 13 14 61 60 58 54 50 51 36 19 20 10 22 17 40 38 21 11 32 28 36 16 32 20 23 27 20 30 19 27 12 10 19 10 20 10 9 12 0 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 Table of Contents Chapter 1 Preview 50 sledom IA elbaton fo rebmuN Chapter 1: Research and Development 1.3 Notable AI Models Number of notable AI models by access type, 2014–24 Source: Epoch AI, 2025 | Chart: 2025 AI Index report Figure 1.3.821 20 Hosted access refers to using computing resources or services (such as software, hardware, or storage) provided remotely by a third party, rather than personally owning or managing them. Instead of running software or infrastructure locally, hosted access involves accessing these resources via the cloud or another remote service, typically over the internet. For example, using GPUs through platforms like AWS, Google Cloud, or Microsoft Azure—rather than running them on one’s own hardware—is considered hosted access. 21 Not all models in the Epoch database are categorized by access type, so the totals in Figures 1.3.8 through 1.3.10 may not fully align with those reported elsewhere in the chapter. Artificial Intelligence Index Report 2025 Chapter 1: Research and Development 1.3 Notable AI Models 100% 90% 80% 70% 60% 50% 40% 30% 20% 10% 0% 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 Table of Contents Chapter 1 Preview 51 )latot fo %( sledom IA elbatoN Notable AI models (% of total) by access type, 2014–24 Source: Epoch AI, 2025 | Chart: 2025 AI Index report 32.79%, API access 18.03%, Open weights (restricted use) 16.39%, Unreleased 11.48%, Open weights (unrestricted) 9.84%, Open weights (noncommercial) 8.20%, Hosted access (no API) 3.28%, Unknown Open source Open (restricted use) Open (noncommercial) Unreleased Unknown 120 105 100 86 80 48 75 72 14 38 61 60 58 26 54 50 51 18 29 40 40 19 11 37 32 24 28 28 37 15 37 20 30 21 33 29 11 22 9 16 16 13 0 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 sledom IA elbaton fo rebmuN Figure 1.3.9 In traditional open-source software releases, all components, withhold the training code. Figure 1.3.10 categorizes notable including the training code, are typically made available. AI models by the openness of their code release. In 2024, However, this is often not the case with AI technologies, the majority—60.7%—were launched without corresponding where even developers who release model weights may training code. Number of notable AI models by training code access type, 2014–24 Source: Epoch AI, 2025 | Chart: 2025 AI Index report Figure 1.3.10 Artificial Intelligence Index Report 2025 Academia Industry Industry–academia Research collective 1T Academia–government Industry–research collective Government 10B 100M 1M 10K 100 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 Publication date Table of Contents Chapter 1 Preview 52 )elacs gol( sretemarap fo rebmuN Chapter 1: Research and Development 1.3 Notable AI Models Parameter Trends Parameters in machine learning models are numerical models. Parameter counts have risen sharply since the early values learned during training that determine how a model 2010s, reflecting the growing complexity of their architecture, interprets input data and makes predictions. Models with greater availability of data, improvements in hardware, and more parameters require more data to be trained, but they proven efficacy of larger models. High-parameter models are can take on more tasks and typically outperform models with particularly notable in the industry sector, underscoring the fewer parameters. substantial financial resources available to industry to cover the computational costs of training on vast volumes of data. Figure 1.3.11 demonstrates the parameter count of machine Several of the figures below use a log scale to reflect the learning models in the Epoch dataset, categorized by exponential growth in AI model parameters and compute in the sector from which the models originate. Figure 1.3.12 recent years. visualizes the same data, but for a smaller selection of notable Number of parameters of notable AI models by sector, 2003–24 Source: Epoch AI, 2025 | Chart: 2025 AI Index report Figure 1.3.11 Artificial Intelligence Index Report 2025 Chapter 1: Research and Development 1.3 Notable AI Models 1T Academia Industry Industry–academia Megatron-Turing NLG 530B DeepSeek-V3 PaLM (540B) ERNIE 3.0 Titan GPT-3 175B (davinci) Mistral Large 2 100B Llama 2-70B Qwen2.5-72B 10B 1B BERT-Large RoBERTa Large Transformer 100M AlexNet 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 Publication date Table of Contents Chapter 1 Preview 53 )elacs gol( sretemarap fo rebmuN Number of parameters of select notable AI models by sector, 2012–24 Source: Epoch AI, 2025 | Chart: 2025 AI Index report Figure 1.3.12 Artificial Intelligence Index Report 2025 100T 1T 10B 100M 1M 10K 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 Publication date Table of Contents Chapter 1 Preview 54 )elacs gol - snekot( ezis tesatad gniniarT Chapter 1: Research and Development 1.3 Notable AI Models As model parameter counts have increased, so has the volume GPT-3 175B—one of the models underpinning the original of data used to train AI systems. Figure 1.3.13 illustrates the ChatGPT—was trained on an estimated 374 billion tokens. growth in dataset sizes used to train notable machine learning In contrast, Meta’s flagship LLM, Llama 3.3, released in the models. The Transformer model, released in 2017 and widely summer of 2024, was trained on roughly 15 trillion tokens. credited with sparking the large language model revolution, According to Epoch AI, LLM training datasets double in size was trained on approximately 2 billion tokens. By 2020, approximately every eight months. Training dataset size of notable AI models, 2010–24 Source: Epoch AI, 2025 | Chart: 2025 AI Index report DeepSeek-V3 GPT-4 Llama 3.1-405B PaLM (540B) GPT-3 175B (davinci) Qwen2.5-72B Transformer AlexNet Figure 1.3.13 Artificial Intelligence Index Report 2025 Training models on increasingly large datasets has led to took around 100 days. This stands in stark contrast to AlexNet, significantly longer training times (Figure 1.3.14). Some one of the first models to leverage GPUs for enhanced state-of-the-art models, such as Llama 3.1-405B, required performance, which trained in just five to six days in 2012. approximately 90 days to train—a typical window by today’s Notably, AlexNet was trained on far less advanced hardware. standards. Google’s Gemini 1.0 Ultra, released in late 2023, 100 10 1 0.1 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 Publication date Table of Contents Chapter 1 Preview 55 )elacs gol - syad( htgnel gniniarT Chapter 1: Research and Development 1.3 Notable AI Models Training length of notable AI models, 2010–24 Source: Epoch AI, 2025 | Chart: 2025 AI Index report PaLM (540B) GPT-4 Megatron-Turing NLG 530B GPT-3 175B (davinci) Llama 3.1-405B AlexNet BERT-Large Transformer RoBERTa Large Figure 1.3.14 Artificial Intelligence Index Report 2025 Compute Trends The term “compute” in AI models denotes the computational Figure 1.3.15 visualizes the training compute required for resources required to train and operate a machine learning notable machine learning models over the past 22 years. model. Generally, the complexity of the model and the size Recently, the compute usage of notable AI models has of the training dataset directly influence the amount of increased exponentially.22 Epoch estimates that the training compute needed. The more complex a model is, and the compute of notable AI models doubles roughly every five larger the underlying training data, the greater the amount of months. This trend has been especially pronounced in the last compute required for training. Before the final training run, five years. This rapid rise in compute demand has important researchers conduct numerous test runs throughout the R&D implications. For instance, models requiring more computation phase. While training a single model is relatively inexpensive, often have larger environmental footprints, and companies the cumulative cost of multiple R&D runs and the necessary typically have more access to computational resources than datasets quickly becomes significant. These figures reflect academic institutions. For reference, Chapter 2 of the AI only the final training run, not the entire R&D process. Index analyzes the relationship between improvements in computational resources and model performance. Academia Industry Industry–academia Academia–government Industry–research collective Government Research collective 10B 100M 1M 10K 100 1 0.01 100μ 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 Publication date Table of Contents Chapter 1 Preview 56 )elacs gol - POLFatep( etupmoc gniniarT Chapter 1: Research and Development 1.3 Notable AI Models Training compute of notable AI models by sector, 2003–24 Source: Epoch AI, 2025 | Chart: 2025 AI Index report Figure 1.3.1523 22 FLOP stands for “floating-point operation.” A floating-point operation is a single arithmetic operation involving floating-point numbers, such as addition, subtraction, multiplication, or division. The number of FLOP a processor or computer can perform per second is an indicator of its computational power. The higher the FLOP rate, the more powerful the computer. The number of floating-point operations used to train an AI model reflects its requirement for computational resources during development. 23 Estimating training compute is an important aspect of AI model analysis, yet it often requires indirect measurement. When direct reporting is unavailable, Epoch estimates compute by using hardware specifications and usage patterns or by counting arithmetic operations based on model architecture and training data. In cases where neither approach is feasible, benchmark performance can serve as a proxy to infer training compute by comparing models with known compute values. Full details of Epoch’s methodology can be found in the documentation section of their website. Artificial Intelligence Index Report 2025 Chapter 1: Research and Development 1.3 Notable AI Models Figure 1.3.16 highlights the training compute of notable models, required 38 billion petaFLOP. Creating cutting- machine learning models since 2012. For example, AlexNet, edge AI models now demands a colossal amount of data, one of the models that popularized the now standard practice computing power, and financial resources that are not of using GPUs to improve AI models, required an estimated available to academia. Most leading AI models are coming 470 petaFLOP for training.24 The original Transformer, from industry, a trend that was first highlighted in last year’s released in 2017, required around 7,400 petaFLOP. OpenAI’s AI Index. Although the gap has slightly narrowed this year, GPT-4o, one of the current state-of-the-art foundation the trend persists. Language Vision Multimodal 100B GPT-4 10B Claude 2 Qwen2.5-72B PaLM (540B) Llama 2-70B DeepSeek-V3 1B Megatron-Turing NLG 530B GPT-3 175B (davinci) 100M RoBERTa Large Segment Anything Model 10M 1M BERT-Large 100K Transformer 10K 1000 AlexNet 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 Publication date 24 A petaFLOP (PFLOP) is a unit of computing power equal to one quadrillion (10¹⁵) floating-point operations per second. Table of Contents Chapter 1 Preview 57 )elacs gol - POLFatep( etupmoc gniniarT Training compute of notable AI models by domain, 2012–24 Source: Epoch AI, 2025 | Chart: 2025 AI Index report Claude 3.5 Sonnet Mistral Large 2 GPT-4o Gemini 1.5 Pro ERNIE 3.0 Titan Figure 1.3.16 Artificial Intelligence Index Report 2025 Chapter 1: Research and Development 1.3 Notable AI Models The launch of DeepSeek’s V3 model in December 2024 have generally been far more computationally intensive than garnered significant attention, particularly because it Chinese models. According to Epoch AI, the top 10 Chinese achieved exceptionally high performance while requiring language models by training compute have scaled at a rate far fewer computational resources than many leading LLMs. of about three times per year since late 2021—considerably Figure 1.3.17 compares the training compute of notable slower than the five times per year trend observed in the rest machine learning models from the United States and China, of the world since 2018. highlighting a key trend: Top-tier AI models from the U.S. United States China 100B 10B 1B 100M 10M 1M 100K 10K 1000 100 2018 2019 2020 2021 2022 2023 2024 Publication date Table of Contents Chapter 1 Preview 58 )elacs gol – POLFatep( etupmoc gniniarT Training compute of select notable AI models in the United States and China, 2018–24 Source: Epoch AI, 2025 | Chart: 2025 AI Index report Claude 3.5 Sonnet GPT-4 Grok-2 ERNIE 3.0 Titan Doubao-pro GPT-3 175B (davinci) Qwen2.5-72B DeepSeek-V3 Figure 1.3.17 Artificial Intelligence Index Report 2025 Highlight: Will Models Run Out of Data? One of the key drivers of substantive algorithmic Epoch AI has updated its previous estimates for when AI improvements in AI systems has been the scaling researchers might run out of data. In its latest research, of models and their training on ever-larger datasets. the team estimated the total effective stock of data However, as the supply of internet training data becomes available for training models according to token count increasingly depleted, concerns have grown about the (Figure 1.3.18). Common Crawl, an open repository of web sustainability of this scaling approach and the potential crawl data frequently used in AI training, is estimated to for a data bottleneck, where returns to scale diminish. contain a median of 130 trillion tokens. The indexed web Last year’s AI Index explored various factors in this holds approximately 510 trillion tokens, while the entire debate, including the availability of existing internet data web contains around 3,100 trillion. Additionally, the total and the potential for training models on synthetic data. stock of images is estimated at 300 trillion, and video at New research this year suggests that the current stock of 1,350 trillion. data may last longer than previously expected. 3,100T 3000T 1,350T 1000T 510T 300T 300T 130T Common Crawl Index web Whole web Images Video (incl. private data) Data source Table of Contents Chapter 1 Preview 59 )elacs gol - naidem( snekot fo rebmuN Chapter 1: Research and Development 1.3 Notable AI Models Estimated median data stocks Source: Epoch AI, 2025 | Chart: 2025 AI Index report Figure 1.3.18 Artificial Intelligence Index Report 2025 The Epoch AI research team projects, with an 80% are overtrained to achieve more compute-efficient confidence interval, that the current stock of training inference performance, the stock is likely to be depleted data will be fully utilized between 2026 and 2032 (Figure sooner. When AI models are overtrained, meaning they 1.3.19). Several factors influence the point in time when are trained for an extended period beyond the typical data is likely to run out. One key factor is the historical point of diminishing returns, they may achieve more growth of dataset sizes, which depends on how compute-efficient inference—that is, they can process many people generate and contribute content to the prompts (make predictions, generate text, etc.) using internet. Another important factor is computer usage. less computational power. However, this comes at a If models are trained in a compute-optimal manner, the cost: The stock (i.e., data available to train the model) available data stock can last longer. However, if models may be depleted more quickly. 101 5 100T Llama 3.1-405B 10T DBRX FLAN 137B Falcon-180B 1T PaLM (540B) GPT-3 175B (davinci) 100B Estimated stock of data Median date of full stock utilization (5x overtraining) Median date of full stock utilization 10B 2020 2022 2024 2026 2028 2030 2032 2034 Publication date Table of Contents Chapter 1 Preview 60 )elacs gol - snekot fo rebmun( kcots evitce E Chapter 1: Research and Development 1.3 Notable AI Models Highlight: Will Models Run Out of Data? (cont’d) Projections of the stock of public text and data usage Source: Epoch AI, 2025 | Chart: 2025 AI Index report Figure 1.3.19 Artificial Intelligence Index Report 2025 These projections differ slightly from Epoch’s earlier Index suggests there are limitations associated with estimates, which predicted that high-quality text data this approach, namely that models trained this way are would be depleted by 2024. The revised projections likely to lose representation of the tails of distributions reflect an updated methodology that incorporates new when performing repeated training cycles on synthetic research showing that web data performs better than data. This leads to degraded model output quality. This curated corpora and that models can be trained on phenomenon was observed across different model the same datasets multiple times. The realization that architectures, including variational autoencoders (VAEs), carefully filtered web data is effective and that repeated Gaussian mixture models (GMMs), and LLMs. However, training on the same dataset is viable has expanded newer research suggests that when synthetic data is estimates of the available data stock. As a result, the layered on top of real data, rather than replacing it, the Epoch researchers pushed back their forecasts of when model collapse phenomenon does not occur. While this data depletion might occur. accumulation does not necessarily improve performance or reduce test loss (lower test loss indicates better model Using synthetic data—data generated by AI models performance), it also does not result in the same degree of themselves—to train models has also been suggested degradation as outright data replacement (Figure 1.3.20). as a solution to potential data shortages. The 2024 AI Llama-2 (126M) Llama-2 (42M) Llama-2 (12M) GPT-2 (9M) 2.8 2.8 2.6 2.6 2.4 2.4 2.2 2.2 2 2 1.8 1.8 1.6 1.6 1 2 3 4 5 1 2 3 4 5 Model- tting iteration Model- tting iteration Table of Contents Chapter 1 Preview 61 ↓ )tset( yportne ssorC Chapter 1: Research and Development 1.3 Notable AI Models Highlight: Will Models Run Out of Data? (cont’d) E ect of data accumulation on language models pretrained on TinyStories Source: Gerstgrasser et al., 2024 | Chart: 2025 AI Index report Replace Accumulate Figure 1.3.20 Artificial Intelligence Index Report 2025 Chapter 1: Research and Development 1.3 Notable AI Models Highlight: Will Models Run Out of Data? (cont’d) This year, there have been advances in generating performance on classification and prediction tasks by high-fidelity synthetic data. However, synthetic data is training on synthetically augmented datasets, increasing still generally distinguishable from real data, and there F1 scores or AUROC by 5%–10% on minority classes.25 is no existing scalable method to achieve the same performance training LLMs on synthetic data compared There are concerns around the quality and fidelity of to real data. A team of Slovenian researchers compared synthetically generated data, as LLMs are known to the performance of models trained on synthetic and real hallucinate and provide factually incorrect outputs. When data across multiple architectures and datasets. They training on hallucinated content in datasets, models can evaluated how well synthetic relational data preserves key experience compounded degradation in output quality. characteristics of the original data (“fidelity”) and remains New techniques have been developed to combat this useful for downstream tasks (“utility”). They found that issue. For example, researchers from Stanford and the most methods are systematically detectable as synthetic, University of North Carolina at Chapel Hill have used especially once relational information is considered. automated fact-checking and confidence scores to rank Furthermore, performance typically deteriorates factuality scores of model response pairs. The FactTune- compared to real data–trained models, but some methods FS methods introduced by these researchers have tended still yield moderately good predictive scores. In a few to outperform other RLHF and decoding-based methods experiments, synthetic data outperformed real data such for factuality improvement (Figure 1.3.21). Human-in-the- as using Synthetic Data Vault (SDV) vs. Walmart data to loop approaches to label preferred responses have also train an XGBoost classifier. The researchers showed that been used to align language models. While promising, training on the synthetic dataset achieves a lower mean the human-in-the-loop approaches tend to be more squared error (MSE). There is also evidence that synthetic expensive. Finally, post hoc filtering and debiasing data shows promise in the healthcare domain. More methods can be used to remove anomalies in synthetic specifically, some model architectures lead to enhanced data before the training stage. 25 AUROC (area under the receiver operating characteristic) curve is a widely used metric for evaluating AI model performance, particularly in classification tasks. Table of Contents Chapter 1 Preview 62 Artificial Intelligence Index Report 2025 Chapter 1: Research and Development 1.3 Notable AI Models Highlight: Will Models Run Out of Data? (cont’d) 89.50% 84.60% 81.20% 78.30% 75.40% 76.00% 74.80% 70.10% 69.60% 66.90% 56.80% As the prevalence of synthetic data grows, particularly performance. One approach to expanding datasets is with an increasing share of web content being AI- data augmentation, which modifies real data—such as generated, future models will inevitably be trained on tilting or image mixing—to create new variations while non-human-generated material. While synthetic data preserving essential characteristics. Both synthetic data offers the advantage of a near-infinite supply, effectively generation and data augmentation present opportunities leveraging it for model training requires a deeper to enhance AI models, but their effective use demands understanding of its impact on learning dynamics and further research. Table of Contents Chapter 1 Preview 63 TFS ITI ALOD CM-enuTtcaF SF-enuTtcaF TFS ITI ALOD tahC CM-enuTtcaF SF-enuTtcaF 100% 80% 60% 40% 20% 0% Llama-1 Llama-2 Base model and method srewsna tcerroc fo egatnecreP Factual accuracy: percentage of correct answers in biographies Source: Tian et al., 2023 | Chart: 2025 AI Index report Figure 1.3.21 Artificial Intelligence Index Report 2025 Inference Cost Last year’s AI Index highlighted the rapidly rising training costs better—so comparing them directly to older, less capable of frontier LLM systems. This year, in addition to updating its models can obscure the real trend: AI performance per dollar analysis on training costs, the Index examines how inference has improved substantially. For instance, the inference cost costs for frontier systems have evolved over time. Inference for an AI model scoring the equivalent of GPT-3.5 (64.8) costs refer to the expense of querying a trained model, and on MMLU, a popular benchmark for assessing language they are typically measured in USD per million tokens. Data on model performance, dropped from $20 per million tokens in AI token pricing comes from both Artificial Analysis and Epoch November 2022 to just $0.07 per million tokens by October AI’s proprietary database on API pricing. The reported price is 2024 (Gemini-1.5-Flash-8B)—a more than 280-fold reduction a 3:1 weighted average of input and output token prices. in approximately 1.5 years. A similar trend is evident in the cost of models scoring above 50% on GPQA, a substantially To analyze inference costs, the AI Index worked with more challenging benchmark than MMLU. There, inference Epoch to measure how costs have decreased for a fixed costs declined from $15 per million tokens in May 2024 to AI performance threshold. This standardized approach $0.12 per million tokens by December 2024 (Phi 4). Epoch AI facilitates a more accurate comparison. While newer models estimates that, depending on the task, LLM inference costs may cost more, they also tend to perform significantly have been falling anywhere from nine to 900 times per year. GPT-3.5 level+ in multitask language understanding (MMLU) GPT-4o level+ in PhD-level science questions (GPQA Diamond) GPT-4 level+ in code generation (HumanEval) GPT-4o level+ in LMSYS Chatbot Arena Elo GPT-4-0314 GPT-3.5 10 GPT-4o-2024-05 Claude-3.5-Sonnet-2024-06 1 DeepSeek-V3 Phi 4 0.1 Llama-3.1-Instruct-8B Gemini-1.5-Flash-8B 2022-Sep 2023-Jan 2023-May 2023-Sep 2024-Jan 2024-May 2024-Sep 2025-Jan Publication date Table of Contents Chapter 1 Preview 64 )elacs gol - snekot noillim rep DSU ni( ecirp ecnerefnI Chapter 1: Research and Development 1.3 Notable AI Models Inference price across select benchmarks, 2022–24 Source: Epoch AI, 2025; Arti cial Analysis, 2025 | Chart: 2025 AI Index report Figure 1.3.22 Artificial Intelligence Index Report 2025 The inference cost to achieve a given level of performance has for leading models from developers such as OpenAI, Meta, and declined notably over time. However, state-of-the-art models Anthropic.26 These top-tier models are generally priced higher remain more expensive than some of the previously mentioned than smaller models from the same companies, reflecting the alternatives. Figure 1.3.23 illustrates the cost per million tokens premium required for cutting-edge performance. 60.00 60 50 40 30 20 15.00 10 6.00 5.00 3.50 2.19 0 o1 Claude 3.5 Sonnet Mistral Large 2 Gemini 1.5 Pro Llama 3.1 405B DeepSeek R1 (Oct 2024) (Nov 2024) (Sep 2024) Model Table of Contents Chapter 1 Preview 65 )snekot noillim rep DSU ni( ecirp tuptuO Chapter 1: Research and Development 1.3 Notable AI Models Output price per million tokens for select models Source: Arti cial Analysis, 2025 | Chart: 2025 AI Index report Figure 1.3.23 Training Cost A frequent discussion around foundation models pertains to Understanding the costs associated with training AI models their high training costs. While AI companies rarely disclose remains important, yet detailed cost information remains exact figures, costs are widely estimated to reach into the scarce. Last year, the AI Index published initial estimates on millions of dollars—and continue to rise. OpenAI CEO Sam the costs of training foundation models. This year, the AI Index Altman, for instance, indicated that training GPT-4 exceeded once again partnered with Epoch AI to update and refine $100 million. In July 2024, Anthropic CEO Dario Amodei noted these estimates. To calculate costs for cutting-edge models, that model training runs costing around $1 billion were already the Epoch team analyzed factors such as training duration, underway. Even more recent models, such as DeepSeek-V3, hardware type, quantity, and utilization rates, relying on reportedly cost less—about $6 million—but overall, training information from academic publications, press releases, and remains extremely expensive.27 technical reports.28 26 The Index visualizes a selection of state-of-the-art models with publicly available pricing as of February 2025. Since publication, newer models may have been released and pricing may have changed. 27 Some reports have disputed the stated cost of DeepSeek-V3, arguing that when factoring in employee salaries, capital expenditures, and research expenses, the actual development costs were significantly higher. 28 A detailed report on Epoch’s research methodology is available in this paper. Artificial Intelligence Index Report 2025 192M 170M 107M 79M 41M 29M 26M 12M 670 160K 4M 6M 1M 3M Table of Contents Chapter 1 Preview 66 remrofsnarT egraL aTREBoR )icnivad( B571 3-TPG B035 GLN gniruT-nortageM ADMaL )B045( MLaP 4-TPG 2 MLaP B07-2 amalL B081-noclaF artlU 0.1 inimeG egraL lartsiM B504-1.3 amalL 2-korG 200M 150M 100M 50M 0 2017 2019 2020 2021 2022 2023 2024 )srallod SU ni( tsoc gniniarT Chapter 1: Research and Development 1.3 Notable AI Models Figure 1.3.24 visualizes the estimated training cost associated One of the few 2024 models for which Epoch could estimate with select AI models, based on cloud compute rental prices. training costs was Llama 3.1-405B, with an estimated cost of Figure 1.3.25 visualizes the training cost of all AI models for $170 million. As the AI landscape grows more competitive, which the AI Index has estimates. companies are disclosing less about their training processes, making it increasingly difficult to estimate computational AI Index estimates validate suspicions that in recent years costs. model training costs have significantly increased. For example, in 2017, the original Transformer model, which As established in previous AI Index reports, there is a direct introduced the architecture that underpins virtually every correlation between the training costs of AI models and their modern LLM, cost around $670 to train. RoBERTa Large, computational requirements. As illustrated in Figure 1.3.26, released in 2019, which achieved state-of-the-art results on models with greater computational training needs cost many canonical comprehension benchmarks like SQuAD substantially more to train. and GLUE, cost around $160,000 to train. Fast-forward to 2023, and training costs for OpenAI’s GPT-4 were estimated around $79 million. Estimated training cost of select AI models, 2019–24 Source: Epoch AI, 2024 | Chart: 2025 AI Index report Figure 1.3.24 29 The cost figures reported in this section are inflation-adjusted. Artificial Intelligence Index Report 2025 Llama 3.1-405B Gemini 1.0 Ultra GPT-4 100M Nemotron-4 340B In ection-2 PaLM 2 Falcon-180B PaLM (540B) GPT-3.5 10M GPT-3 175B (davinci) BLOOM-176B Llama 2-70B LLaMA-65B 1M HyperCLOVA 82B LaMDA AlphaStar Switch GNMT Megatron-BERT RoBERTa Large Meta Pseudo Labels 100K JFT Xception BigGAN-deep 512×512 10K 2016 2017 2018 2019 2020 2021 2022 2023 2024 Publication date Table of Contents Chapter 1 Preview 67 )elacs gol - srallod SU ni( tsoc gniniarT Estimated training cost of select AI models, 2016–24 Source: Epoch AI, 2024 | Chart: 2025 AI Index report Gemini 1.0 Ultra Llama 3.1-405B 100M GPT-4 Grok-2 PaLM 2 Mistral Large Falcon-180B PaLM (540B) 10M Megatron-Turing NLG 530B GPT-3 175B (davinci) Llama 2-70B LaMDA 1M RoBERTa Large 100K 10M 100M 1B 10B 100B Training compute (petaFLOP - log scale) )elacs gol - srallod SU ni( tsoc gniniarT Chapter 1: Research and Development 1.3 Notable AI Models Figure 1.3.25 Estimated training cost and compute of select AI models Source: Epoch AI, 2024 | Chart: 2025 AI Index report Figure 1.3.26 Artificial Intelligence Index Report 2025 Hardware advancements play a critical role in driving AI progress. While scaling models 1.4 Hardware and training on larger datasets have led to significant performance improvements, these advances have largely been enabled by Overview improvements in hardware—particularly the development of more powerful and efficient Figure 1.4.1 illustrates the peak computational performance of ML hardware GPUs (graphics processing units). GPUs across different precision types, where precision refers to the number of bits accelerate complex computations, allowing models to process vast amounts of data in used to represent numerical values, particularly floating-point numbers, in parallel and significantly reducing training computations. The choice of precision depends on the specific goal. For instance, time. This section of the Index leverages lower-precision hardware, which requires fewer bits and has lower memory data from Epoch AI to analyze key trends in machine learning hardware and its impact on bandwidth, is ideal for optimizing computation speed and energy efficiency. This AI development. is particularly beneficial for AI models running on edge or mobile devices or in scenarios where inference speed is a priority. On the other hand, higher-precision While this section currently emphasizes hardware preserves greater numerical accuracy, making it essential for scientific compute performance (FLOP/s), network bandwidth—the speed at which GPUs computing and applications sensitive to precision errors. Of the precisions communicate—is equally critical. Although visualized in the figures below, FP32 has the highest precision, TF32 offers data on network bandwidth of data centers medium-high precision, and Tensor-FP16/BF16 and FP16 are lower-precision is limited, future editions of the AI Index will formats optimized for speed and efficiency. aim to include this information. Measured in 16-bit floating-point operations, Epoch estimates that machine learning hardware performance has grown over the period 2008–2024 at an annual rate of approximately 43%, doubling every 1.9 years. According to Epoch, this progress has been driven by increased transistor counts, advancements in semiconductor manufacturing, and the development of specialized hardware for AI workloads. FP32 FP16 TF32 (19-bit) Tensor-FP16/BF16 10 16 10 15 100T 10T 1T 100B 10B 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 Publication date Table of Contents Chapter 1 Preview 68 )elacs gol - s/POLF( ecnamrofreP Chapter 1: Research and Development 1.4 Hardware Peak computational performance of ML hardware for di erent precisions, 2008–24 Source: Epoch AI, 2025 | Chart: 2025 AI Index report Figure 1.4.1 Artificial Intelligence Index Report 2025 1×10 15 9.89×10 14 0.8×10 15 0.6×10 15 0.4×10 15 3.12×10 14 0.2×10 15 1.25×10 14 1.87×10 13 0 P100 V100 A100 H100 2016 2017 2020 2022 Hardware Table of Contents Chapter 1 Preview 69 )dnoces rep POLF( ecnamrofreP Chapter 1: Research and Development 1.4 Hardware The price-performance of leading machine learning achieves 22 billion FLOP per second per dollar, which is hardware has steadily improved. Figure 1.4.2 illustrates the approximately 1.7 times the price-performance of the A100 performance of selected Nvidia data center GPUs—among (launched in June 2020) and 16.9 times that of the P100 the most commonly used for AI training—in FLOP per (released in April 2016). Epoch estimates that hardware with second. Figure 1.4.3 visualizes the price-performance of a fixed performance level decreases in cost by 30% annually, those same GPUs, measured in FLOP per second per dollar. making AI training increasingly affordable, scalable, and For example, the H100 GPU, announced in March 2022, conducive to model improvements. Performance of leading Nvidia data center GPUs for machine learning Source: Epoch AI, 2025 | Chart: 2025 AI Index report Figure 1.4.2 Artificial Intelligence Index Report 2025 Figure 1.4.4, based on the Epoch AI notable machine learning reported hardware was the A100, used by 64 models, followed models dataset, examines the hardware used to train notable by the V100. An increasing number of models are now being machine learning models. As of 2024, the most commonly trained on the H100, with 15 reported by the end of 2024. P100 1.30×10 9 V100 6.70×10 9 A100 1.30×10 10 H100 2.20×10 10 1×10⁹ 5×10⁹ 1×10¹⁰ 1.5×10¹⁰ 2×10¹⁰ FLOP per second per dollar Table of Contents Chapter 1 Preview 70 erawdraH Price-performance of leading Nvidia data center GPUs for machine learning Source: Epoch AI, 2025 | Chart: 2025 AI Index report 60 50 40 30 20 10 0 2017 2018 2019 2020 2021 2022 2023 2024 Publication date sledom IA elbaton fo rebmun evitalumuC Chapter 1: Research and Development 1.4 Hardware Figure 1.4.3 Cumulative number of notable AI models trained by accelerator, 2017–24 Source: Epoch AI, 2025 | Chart: 2025 AI Index report 65, A100 56, V100 47, TPU v3 37, Other 25, TPU v4 15, H100 6, P100 Figure 1.4.4 Artificial Intelligence Index Report 2025 Chapter 1: Research and Development 1.4 Hardware Highlight: Energy Efficiency and Environmental Impact Training AI systems requires substantial energy, making hardware, measured in FLOP/s per watt. For instance, the the energy efficiency of machine learning hardware Nvidia B100, released in March 2024, achieved an energy a critical factor. Epoch AI reports that ML hardware efficiency of 2.5 trillion FLOP/s per watt, compared to has become increasingly energy efficient over time, the Nvidia P100, released in April 2016, which reported improving by approximately 40% per year. Figure 1.4.5 74 billion FLOP/s per watt. This means the B100 is 33.8 illustrates the energy efficiency of Tensor-FP16 precision times more energy efficient than the P100. 1T 100B 10B 1B Leading hardware Non-leading hardware 2016 2017 2018 2019 2020 2021 2022 2023 2024 Publication date Table of Contents Chapter 1 Preview 71 )elacs gol - ttaw rep s/POLF( ycneic e ygrenE Energy e ciency of leading machine learning hardware, 2016–24 Source: Epoch AI, 2025 | Chart: 2025 AI Index report NVIDIA B200 NVIDIA H100 SXM5 80GB Google TPU v4 Google TPU v5e NVIDIA A100 NVIDIA Tesla V100 SXM2 32 GB Google TPU v3 NVIDIA B100 Google TPU v4i NVIDIA GB200 NVL2 NVIDIA P100 Google TPU v2 Figure 1.4.5 Artificial Intelligence Index Report 2025 Chapter 1: Research and Development 1.4 Hardware Despite significant improvements in the energy efficiency Epoch AI, the power required to train frontier AI models of AI hardware, the overall power consumption required is doubling annually. The rising power consumption of to train AI systems continues to rise rapidly. Figure 1.4.6 AI models reflects the trend of training on increasingly illustrates the total power draw, measured in watts, for larger datasets. training various state-of-the-art AI models. For example, the original Transformer, introduced in 2017, consumed Unsurprisingly, given that the total amount of power an estimated 4,500 watts. In contrast, PaLM, one of used to train AI systems has increased over time, so Google’s first flagship LLMs, had a power draw of 2.6 has the amount of carbon emitted by the models. Many million watts—almost 600 times that of the Transformer. factors determine the amount of carbon emitted by AI Llama 3.1-405B, released in the summer of 2024, systems, including the number of parameters in a model, required 25.3 million watts, consuming over 5,000 times the power usage effectiveness of a data center, and the more power than the original Transformer. According to grid carbon intensity.30 GPT-4 L lama 3.1-405B 10M GPT-3 175B (davinci) PaLM (540B) 1M 100K 10K 1000 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 Publication date Table of Contents Chapter 1 Preview 72 )elacs gol - sttaw( deriuqer ward rewop latoT Highlight: Energy Efficiency and Environmental Impact (cont’d) Total power draw required to train frontier models, 2011–24 Source: Epoch AI, 2025 | Chart: 2025 AI Index report Figure 1.4.6 30 Power usage effectiveness (PUE) is a metric used to evaluate the energy efficiency of data centers. It is the ratio of the total amount of energy used by a computer data center facility, including air conditioning, to the energy delivered to computing equipment. The higher the PUE, the less efficient the data center. Artificial Intelligence Index Report 2025 Chapter 1: Research and Development 1.4 Hardware Figure 1.4.7 illustrates the carbon emissions of selected The carbon emissions from training frontier AI models AI models, sorted by their release year. To estimate have steadily increased over time. While AlexNet’s these emissions, the AI Index used carbon data emissions were negligible, GPT-3 (released in 2020) published by model developers and supplemented it reportedly emitted around 588 tons of carbon during with calculations from a widely used online AI training training, GPT-4 (2023) emitted 5,184 tons, and Llama 3.1 emissions calculator. This step was necessary as 405B (2024) emitted 8,930 tons. DeepSeek V3, released many developers do not disclose their models’ carbon in 2024, and whose performance is comparable to footprints. The calculator estimates emissions based OpenAI’s o1, is estimated to have emissions comparable on the type of hardware used for training, total training to the GPT-3, released five years ago. For context, on hours, cloud provider, and training region.31 average, Americans emit 18.08 tons of carbon per capita per year. 8,930 5,184 2,973 1,432 588 597 301 0.01 0.31 2.60 5.50 Table of Contents Chapter 1 Preview 73 teNxelA 61GGV egraL-TREB egraL aTREBoR 3-TPG GLN gniruT-nortageM B031-MLG B081-noclaF 4-TPG 3v keeSpeeD B504 1.3 amalL 8,000 6,000 4,000 2,000 0 2012 2014 2018 2019 2020 2021 2022 2023 2024 )tnelaviuqe ₂OC fo snot( snoissime nobraC Highlight: Energy Efficiency and Environmental Impact (cont’d) Estimated carbon emissions from training select AI models and real-life activities, 2012–24 Source: AI Index, 2025; Strubell et al., 2019 | Chart: 2025 AI Index report Air travel (1 passenger, NY↔SF): 0.99 Human life (avg., 1 year): 5.51 American life (avg., 1 year): 18.08 Car usage (avg., incl. fuel, 1 lifetime): 63 Figure 1.4.7 31 The AI Index sourced input data—such as training hardware and duration—for the emissions calculator from various online sources. To validate the accuracy of the calculator, the Index compared the calculator’s estimates with actual emissions reported by developers and found that the results were largely consistent. The full estimation methodology is detailed in the Appendix. Artificial Intelligence Index Report 2025 Chapter 1: Research and Development 1.4 Hardware GPT-4 1T DeepSeek v3 Llama 3.1 405B Megatron-Turing NLG GLM-130B GPT-3 Falcon-180B 1B BERT-Large RoBERTa Large VGG16 AlexNet 0.01 0.1 1 10 100 1000 10K Carbon emissions (tons of CO₂ equivalent - log scale) Table of Contents Chapter 1 Preview 74 )elacs gol( sretemarap fo rebmuN Highlight: Energy Efficiency and Environmental Impact (cont’d) Estimated carbon emissions and number of parameters by select AI models Source: AI Index, 2025 | Chart: 2025 AI Index report Figure 1.4.8 Artificial Intelligence Index Report 2025 Chapter 1: Research and Development 1.5 AI Conferences AI conferences serve as essential platforms for researchers to present their findings and network with peers and collaborators. Over the past two decades, these conferences have expanded in scale, quantity, and prestige. This section explores trends in attendance at major AI conferences. 1.5 AI Conferences Conference Attendance Figure 1.5.1 graphs attendance at a selection of AI conferences a growing interest in AI research but also the emergence of since 2010. In 2020 the pandemic forced conferences to be new AI conferences. held fully online, increasing attendance significantly. This was followed by a decline in attendance, likely due to the shift Neural Information Processing Systems (NeurIPS) remains back to in-person formats, returning attendance in 2022 to the most attended AI conference, attracting almost 20,000 prepandemic levels. Since then, there has been a steady participants in 2024 (Figure 1.5.2 and Figure 1.5.3). Among the growth in conference attendance, increasing almost 21.7% major AI conferences, NeurIPS, CVPR, ICML, ICRA, ICLR, from 2023 to 2024.32 Since 2014, the annual number of IROS and AAAI experienced increases in attendance over attendees has risen by more than 60,000, reflecting not just the last year. 90 80 70 60 50 40 30 20 10 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 Table of Contents Chapter 1 Preview 75 )sdnasuoht ni( seednetta fo rebmuN Attendance at select AI conferences, 2010–24 Source: AI Index, 2024 | Chart: 2025 AI Index report 73.26 Figure 1.5.1 32 This data should be interpreted with caution given that many conferences in the last few years have had virtual or hybrid formats. Conference organizers report that measuring the exact attendance numbers at virtual conferences is difficult, as virtual conferences allow for higher attendance of researchers from around the world. The AI Index reports total attendance figures, encompassing virtual, hybrid, and in-person participation. The conferences for which the AI Index tracked data include AAAI, AAMAS, CVPR, EMNLP, FAccT, ICAPS, ICCV, ICLR, ICML, ICRA, IJCAI, IROS, KR, NeurIPS, and UAI. Artificial Intelligence Index Report 2025 Chapter 1: Research and Development 1.5 AI Conferences 30 25 20 15 10 5 0 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 Table of Contents Chapter 1 Preview 76 )sdnasuoht ni( seednetta fo rebmuN Attendance at large conferences, 2010–24 Source: AI Index, 2024 | Chart: 2025 AI Index report 19.76, NeurIPS 12.00, CVPR 9.10, ICML 7.00, ICRA 6.53, ICLR 5.20, IROS 5.15, AAAI 3.50, EMNLP 3.50 3.00 2.50 2.00 1.50 1.00 0.50 0.00 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 )sdnasuoht ni( seednetta fo rebmuN Figure 1.5.233 Attendance at small conferences, 2010–24 Source: AI Index, 2024 | Chart: 2025 AI Index report 2.84, IJCAI 0.69, FaccT 0.63, AAMAS 0.43, UAI 0.24, ICAPS 0.20, KR Figure 1.5.3 33 The significant spike in ICML attendance in 2021 was likely due to the conference being held virtually that year. Artificial Intelligence Index Report 2025 Chapter 1: Research and Development 1.6 Open-Source AI Software GitHub is a web-based platform that enables individuals and teams to host, review, and collaborate on code repositories. Widely used by software developers, GitHub facilitates code management, project collaboration, 1.6 Open-Source AI Software and open-source software support. This section draws on data from GitHub that provides insights into broader trends in Projects open-source AI software development not A GitHub project comprises a collection of files, including source code, reflected in academic publication data.34 documentation, configuration files, and images, that together make up a software project. Figure 1.6.1 looks at the total number of GitHub AI projects over time.35 Since 2011, the number of AI-related GitHub projects has consistently increased, growing from 1,549 in 2011 to approximately 4.3 million in 2024. Notably, there was a sharp 40.3% rise in the total number of GitHub AI projects in the last year alone. 4.50 4.00 3.50 3.00 2.50 2.00 1.50 1.00 0.50 0.00 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 Table of Contents Chapter 1 Preview 77 )snoillim ni( stcejorp IA fo rebmuN Number of GitHub AI projects, 2011–24 Source: GitHub, 2024 | Chart: 2025 AI Index report 4.32 Figure 1.6.1 34 This year, GitHub updated its methodology to capture a broader range of AI-related topics, including more recent developments. As a result, the figures in this year’s AI Index may not align with those from previous editions. Chinese researchers often use alternative sites to GitHub for code sharing, such as Gitee and GitCode, but the data from those sites is not included in this report. A full methodological description is available in the Appendix. 35 GitHub used AI-topic classification methods to identify AI-related repositories. Details on the methodology are available in the Appendix. Artificial Intelligence Index Report 2025 Chapter 1: Research and Development 1.6 Open-Source AI Software Figure 1.6.2 reports GitHub AI projects by geographic contributor with 19.9%, followed closely by Europe, which area since 2011. As of 2024, a significant share of GitHub accounted for 19.5%. Notably, the share of open-source AI AI projects were located in the United States, accounting projects on GitHub from U.S.-based developers has declined for 23.4% of contributions. India was the second largest since 2016 and appears to have stabilized in recent years. 60% 50% 40% 30% 20% 10% 0% 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 Table of Contents Chapter 1 Preview 78 )latot fo %( stcejorp IA GitHub AI projects (% of total) by geographic area, 2011–24 Source: GitHub, 2024 | Chart: 2025 AI Index report 35.43%, Rest of the world 23.42%, United States 19.91%, India 19.15%, Europe 2.08%, China Figure 1.6.2 Artificial Intelligence Index Report 2025 Chapter 1: Research and Development 1.6 Open-Source AI Software Stars GitHub users can show their interest in a repository by of tools for computer vision, such as object detection and “starring” it, a feature similar to liking a post on social feature extraction. media, which signifies support for an open-source project. Among the most starred repositories are libraries such as The total number of stars for AI-related projects on GitHub TensorFlow, OpenCV, Keras, and PyTorch, which enjoy continued to rise last year, increasing from 14.0 million in widespread popularity among software developers in the 2023 to 17.7 million in 2024 (Figure 1.6.3).36 This follows a broader developer community beyond AI. TensorFlow, Keras, particularly sharp rise from 2022 to 2023, when the total and PyTorch are popular libraries for building and deploying more than doubled. machine learning models, while OpenCV offers a variety 18 16 14 12 10 8 6 4 2 0 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 Table of Contents Chapter 1 Preview 79 )snoillim ni( srats buHtiG fo rebmuN Number of GitHub stars in AI projects, 2011–24 Source: GitHub, 2024 | Chart: 2025 AI Index report 17.64 Figure 1.6.3 36 Figure 1.6.3 shows new stars given to GitHub projects within a year, not the total accumulated over time. Artificial Intelligence Index Report 2025 Chapter 1: Research and Development 1.6 Open-Source AI Software In 2024, the United States led in receiving the highest number India, saw a year-over-year increase in the total number of of GitHub stars, totaling 21.1 million (Figure 1.6.4). All major GitHub stars awarded to projects located in their countries. geographic regions sampled, including Europe, China, and 20 15 10 5 0 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 Table of Contents Chapter 1 Preview 80 )snoillim ni( srats buHtiG evitalumuc fo rebmuN Number of GitHub stars by geographic area, 2011–24 Source: GitHub, 2024 | Chart: 2025 AI Index report 21.08, United States 16.39, Rest of the world 10.29, Europe 4.06, India 3.67, China Figure 1.6.4 Artificial Intelligence Index Report 2025 Table of Contents Chapter 1 Preview 81 Artificial Intelligence Index Report 2025 CHAPTER 2: Technical Performance Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance Overview 84 VCR: Visual Commonsense Reasoning 119 Chapter Highlights 85 MVBench 120 Generation 122 2.1 Overview of AI in 2024 87 Chatbot Arena: Vision 123 Timeline: Significant Model and Highlight: The Rise of Video Dataset Releases 87 Generation 124 State of AI Performance 93 Overall Review 93 2.4 Speech 126 Closed vs. Open-Weight Models 94 Speech Recognition 126 US vs. China Technical Performance 96 LSR2: Lip Reading Sentences 2 126 Improved Performance From Smaller Models 98 2.5 Coding 128 Model Performance Converges HumanEval 128 at the Frontier 99 SWE-bench 129 Benchmarking AI 100 BigCodeBench 130 Chatbot Arena: Coding 131 2.2 Language 103 Understanding 104 2.6 Mathematics 132 MMLU: Massive Multitask GSM8K 132 Language Understanding 104 MATH 133 Generation 105 Chatbot Arena: Math 134 Chatbot Arena Leaderboard 105 FrontierMath 134 Arena-Hard-Auto 107 Highlight: Learning and WildBench 108 Theorem Proving 136 Highlight: o1, o3, and Inference- Time Compute 110 2.7 Reasoning 137 MixEval 112 General Reasoning 137 RAG: Retrieval Augment Generation 113 MMMU: A Massive Multi-discipline Berkeley Function Calling Leaderboard 113 Multimodal Understanding and MTEB: Massive Text Embedding Reasoning Benchmark for Expert AGI 137 Benchmark 115 GPQA: A Graduate-Level Google-Proof Highlight: Evaluating Retrieval Q&A Benchmark 138 Across Long Contexts 117 ARC-AGI 139 Humanity’s Last Exam 141 2.3 Image and Video 119 Planning 143 Understanding 119 PlanBench 143 Table of Contents 83 Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance (cont’d) 2.8 AI Agents 144 VisualAgentBench 144 RE-Bench 145 GAIA 147 2.9 Robotics and Autonomous Motion 148 Robotics 148 RLBench 148 Highlight: Humanoid Robotics 150 Highlight: DeepMind’s Developments 151 Highlight: Foundation Models for Robotics 154 Self-Driving Cars 155 Deployment 155 Technical Innovations and New Benchmarks 156 Safety Standards 157 ACCESS THE PUBLIC DATA Table of Contents 84 AArrttiifificciiaall IInntteelllliiggeennccee IInnddeexx RReeppoorrtt 22002255 CHAPTER 2: Technical Performance Overview The Technical Performance section of this year’s AI Index provides a comprehensive overview of AI advancements in 2024. It begins with a high-level summary of AI technical progress, covering major AI-related launches, the state of AI capabilities, and key trends—such as the rising performance of open-weight models, the convergence of frontier model performance, and the improving quality of Chinese LLMs. The chapter then examines the current state of various AI capabilities, including language understanding and generation, retrieval-augmented generation, coding, mathematics, reasoning, computer vision, speech, and agentic AI. New this year are significantly expanded analyses of performance trends in robotics and self-driving cars. Table of Contents Chapter 2 Preview 85 AArrttiifificciiaall IInntteelllliiggeennccee IInnddeexx RReeppoorrtt 22002255 CHAPTER 2: Technical Performance Chapter Highlights 1. AI masters new benchmarks faster than ever. In 2023, AI researchers introduced several challenging new benchmarks, including MMMU, GPQA, and SWE-bench, aimed at testing the limits of increasingly capable AI systems. By 2024, AI performance on these benchmarks saw remarkable improvements, with gains of 18.8 and 48.9 percentage points on MMMU and GPQA, respectively. On SWE-bench, AI systems could solve just 4.4% of coding problems in 2023—a figure that jumped to 71.7% in 2024. 2. Open-weight models catch up. Last year’s AI Index revealed that leading open-weight models lagged significantly behind their closed-weight counterparts. By 2024, this gap had nearly disappeared. In early January 2024, the leading closed- weight model outperformed the top open-weight model by 8.04% on the Chatbot Arena Leaderboard. By February 2025, this gap had narrowed to 1.70%. 3. The gap between Chinese and US models closes. In 2023, leading American models significantly outperformed their Chinese counterparts—a trend that no longer holds. At the end of 2023, performance gaps on benchmarks such as MMLU, MMMU, MATH, and HumanEval were 17.5, 13.5, 24.3, and 31.6 percentage points, respectively. By the end of 2024, these differences had narrowed substantially to just 0.3, 8.1, 1.6, and 3.7 percentage points. 4. AI model performance converges at the frontier. According to last year’s AI Index, the Elo score difference between the top and 10th-ranked model on the Chatbot Arena Leaderboard was 11.9%. By early 2025, this gap had narrowed to just 5.4%. Likewise, the difference between the top two models shrank from 4.9% in 2023 to just 0.7% in 2024. The AI landscape is becoming increasingly competitive, with high-quality models now available from a growing number of developers. 5. New reasoning paradigms like test-time compute improve model performance. In 2024, OpenAI introduced models like o1 and o3 that are designed to iteratively reason through their outputs. This test-time compute approach dramatically improved performance, with o1 scoring 74.4% on an International Mathematical Olympiad qualifying exam, compared to GPT- 4o’s 9.3%. However, this enhanced reasoning comes at a cost: o1 is nearly six times more expensive and 30 times slower than GPT-4o. Table of Contents Chapter 2 Preview 86 AArrttiifificciiaall IInntteelllliiggeennccee IInnddeexx RReeppoorrtt 22002255 CHAPTER 2: Technical Performance Chapter Highlights (cont’d) 6. More challenging benchmarks are continually proposed. The saturation of traditional AI benchmarks like MMLU, GSM8K, and HumanEval, coupled with improved performance on newer, more challenging benchmarks such as MMMU and GPQA, has pushed researchers to explore additional evaluation methods for leading AI systems. Notable among these are Humanity’s Last Exam, a rigorous academic test where the top system scores just 8.80%; FrontierMath, a complex mathematics benchmark where AI systems solve only 2% of problems; and BigCodeBench, a coding benchmark where AI systems achieve a 35.5% success rate—well below the human standard of 97%. 7. High-quality AI video generators demonstrate significant improvement. In 2024, several advanced AI models capable of generating high-quality videos from text inputs were launched. Notable releases include OpenAI’s SORA, Stable Video 3D and 4D, Meta’s Movie Gen, and Google DeepMind’s Veo 2. These models produce videos of significantly higher quality compared to those from 2023. 8. Smaller models drive stronger performance. In 2022, the smallest model registering a score higher than 60% on MMLU was PaLM, with 540 billion parameters. By 2024, Microsoft’s Phi-3-mini, with just 3.8 billion parameters, achieved the same threshold. This represents a 142-fold reduction in over two years. 9. Complex reasoning remains a problem. Even though the addition of mechanisms such as chain-of-thought reasoning has significantly improved the performance of LLMs, these systems still cannot reliably solve problems for which provably correct solutions can be found using logical reasoning, such as arithmetic and planning, especially on instances larger than those they were trained on. This has a significant impact on the trustworthiness of these systems and their suitability in high-risk applications. 10. AI agents show early promise. The launch of RE-Bench in 2024 introduced a rigorous benchmark for evaluating complex tasks for AI agents. In short time-horizon settings (two-hour budget), top AI systems score four times higher than human experts, but as the time budget increases, human performance surpasses AI—outscoring it two to one at 32 hours. AI agents already match human expertise in select tasks, such as writing Triton kernels, while delivering results faster and at lower costs. Table of Contents Chapter 2 Preview 87 Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.1 Overview of AI in 2024 The Technical Performance chapter begins with a high- level overview of significant model releases in 2024 and reviews the current state of AI technical performance. 2.1 Overview of AI in 2024 Timeline: Significant Model and Dataset Releases As chosen by the AI Index Steering Committee, here are some of the most notable model and dataset releases of 2024. Date Name Category Creator(s) Significance Image Jan 19, 2024 Stable LM 2 LLM Stability AI Stability’s latest language model builds on the original Stable LM, offering enhanced performance. With only 1.6 billion parameters, it is designed to run Figure 2.1.1 efficiently on portable devices such as Source: Wikipedia, 2025 laptops and smartphones. Feb 8, 2024 Aya Dataset Dataset Cohere for A collection of 513 million prompt- AI, Beijing completion pairs spanning 114 Academy of languages, released as part of Cohere’s AI, Cohere, Aya initiative. This paper and its Binghamton accompanying dataset represent University significant milestones in multilingual Figure 2.1.2 Source: Cohere, 2025 instruction tuning. Feb 15, 2024 Gemini 1.5 Pro LLM Google Google’s Gemini model set a new DeepMind benchmark with its 1M token context window, far exceeding GPT-4 Turbo’s 128K token limit. Figure 2.1.3 Source: Google, 2024 Feb 20, 2024 SDXL-Lightning Text-to- ByteDance Developed by ByteDance, the creators image of TikTok, this model was among the fastest text-to-image systems at its release, generating high-quality synthetic images in under a second. Its speed was achieved through progressive adversarial Figure 2.1.4 distillation, unlike other models that rely Source: Hugging Face, 2025 on diffusion-based techniques. Mar 4, 2024 Claude 3 LLM Anthropic Anthropic’s latest LLM outperforms GPT-4 and Gemini on nearly all industry benchmarks, reduces incorrect prompt refusals, and delivers significantly higher accuracy. Figure 2.1.5 Source: Anthropic, 2025 Table of Contents Chapter 2 Preview 88 Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.1 Overview of AI in 2024 Mar 7, 2024 Inflection-2.5 LLM Inflection AI Inflection’s flagship product, “Pi,” featured an exceptional model with GPT-4–level performance while using only 40% of its computing resources. Just two weeks after the model’s release, Microsoft acquired Inflection for $650 million. Figure 2.1.6 Source: Inflection, 2025 Mar 19, 2024 Moirai and Model/ Salesforce Salesforce unveils Moirai, a foundation LOTSA dataset model for universal forecasting, alongside LOTSA—a diverse, large- scale time series dataset with 27 billion observations spanning nine domains. Figure 2.1.7 Source: Salesforce, 2025 Mar 27, 2024 DBRX LLM Databricks Databricks’ open-source mixture-of- experts (MoE) LLM is a fine-grained model, surpassing similar small MoE models like Mixtral and Grok. This Figure 2.1.8 transformer decoder-only model features Source: Databricks, 2025 132B parameters (36B active per input) and was trained on 12 trillion tokens. Apr 2, 2024 Stable Audio 2 Text-to- Stability AI The latest version of Stable Audio, song and Stability’s AI-powered song generator, song-to- now supports audio-to-audio song functionality. Users can upload songs and manipulate them using natural language Figure 2.1.9 Source: Stability AI, 2025 prompts for seamless customization. Apr 17, 2024 Llama 3 LLM Meta The Llama 3 series debuts with 8B and 70B parameter text-based models, ranking among the highest performing models of their size to date. Figure 2.1.10 Source: Meta, 2025 May 13, 2024 GPT-4o Multimodal OpenAI GPT-4o is a new multimodal model capable of processing inputs in any combination of text, audio, images, and video, and generating outputs in the same formats. It responds to audio in as little as 320 milliseconds, matching human response times. Figure 2.1.11 Source: OpenAI, 2024 Table of Contents Chapter 2 Preview 89 Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.1 Overview of AI in 2024 Jun 7, 2024 Qwen2 LLM Alibaba Qwen2, developed by China’s Alibaba, is a series of advanced base and instruction-tuned models. These models rival competitors like Llama 3-70B and Mixtral-8x22B in performance across Figure 2.1.12 numerous benchmarks. Source: Qwen, 2024 Jun 17, 2024 Runway Gen-3 Text-to- Runway Runway’s upgraded video generation video and model sets a new standard for the image-to- field, particularly excelling in creating video photorealistic humans with vivid and expressive emotionality. Figure 2.1.13 Source: Runway, 2024 Jul 23, 2024 Llama 3.1 405B LLM Meta Meta has released its largest model to date, the final in the Llama 3.1 family, featuring 405B parameters. Upon its release, it became the most capable openly available foundation model, rivaling many closed models across a Figure 2.1.14 variety of benchmarks. Source: Meta, 2024 Aug 12, 2024 Falcon Mamba LLM Technology A powerful new 7B parameter model, Innovation built on the Mamba State Space Institute in Language Model (SSLM) architecture, Abu Dhabi enables Falcon—one of the few government-created AI models—to dynamically adjust parameters and filter Figure 2.1.15 out irrelevant inputs, making it more Source: Hugging Face, 2025 efficient than transformer-based models. Aug 13, 2024 Grok-2 Text-to-text xAI Developed by xAI, Grok is an advanced and text-to- text- and image-generation model that image excels in image creation, advanced reasoning, and problem-solving. Its launch was particularly notable, as it quickly rivaled the performance of leading models despite xAI being founded only in March 2023. Figure 2.1.16 Source: xAI, 2025 Table of Contents Chapter 2 Preview 90 Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.1 Overview of AI in 2024 Aug 15, 2024 Imagen 3 Text-to- Google Labs Google’s updated AI image generator image achieves the highest Elo score on the GenAI-Bench image benchmark, setting a new standard for quality in AI- generated visuals. Figure 2.1.17 Source: Google, 2025 Aug 22, 2024 Jamba 1.5 LLM AI21 Labs The first LLM to combine state-space models with transformers, delivering high-quality results for text-based applications. This hybrid approach significantly enhances speed while preserving the quality of outputs. Figure 2.1.18 Source: AI21, 2025 Aug 29, 2024 SynthID v2 Tool Google SynthID v2 is the updated version of SynthID, Google’s watermarking and identification software. It now supports AI-generated content across images, video, audio, and text, and offers enhanced tracking and verification capabilities. Figure 2.1.19 Source: Google, 2025 Sep 11, 2024 NotebookLM Text-to- Google Labs The second end-to-end AI podcast Podcast Tool podcast generator to hit the market, following Synthpod, went viral. It gained popularity among students leveraging NotebookLM for studying and tech employees using it Figure 2.1.20 to listen to AI-generated summaries. Source: Google, 2025 Sep 12, 2024 o1-preview Language, OpenAI OpenAI’s first model in the “o series” is math, designed for advanced reasoning and biology tackling complex tasks. It is significantly more powerful than GPT, particularly in math, science, and coding. Figure 2.1.21 Source: OpenAI, 2025 Sep 17, 2024 NVLM (D, H, X) Vision, Nvidia Nvidia released three open-access language models for vision-language tasks, achieving top scores on OCRBench (for optical character recognition) and VQAv2 (for natural language understanding). Figure 2.1.22 Source: Dai et al., 2024 Table of Contents Chapter 2 Preview 91 Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.1 Overview of AI in 2024 Sep 19, 2024 Qwen2.5 LLM Alibaba Qwen2.5, the latest series of foundation models from Chinese e-commerce giant Alibaba, includes a range of efficient smaller models and specialized coding and math models designed for targeted functionality. Figure 2.1.23 Source: Qwen, 2025 Oct 16, 2024 Ministral LLM Mistral Ministral is a pair of compact models (3B and 8B parameters) that outperformed Gemma and Llama models of similar size across all major industry-recognized Figure 2.1.24 benchmarks. Source: Mistral, 2025 Oct 22, 2024 Anthropic Agentic Anthropic Anthropic Computer Use is a Computer Use Capability groundbreaking computer control feature for Claude 3.5 Sonnet users, allowing Claude to move the cursor, type, and autonomously complete tasks on the user’s computer in real time. Figure 2.1.25 Source: Anthropic, 2025 Oct 28, 2024 Apple iPhone Apple Apple’s suite of AI-powered features Intelligence feature includes Image Playground (for image creation), Genmoji (for custom emoji creation), Siri integration with ChatGPT, and more. Figure 2.1.26 Source: Apple, 2025 Dec 3, 2024 Nova Pro Multimodal Amazon Nova Pro is the most powerful model in Amazon Web Services’ Nova family, capable of processing both visual and textual information. It especially excels at analyzing financial documents. Figure 2.1.27 Source: Amazon, 2025 Dec 11, 2024 Gemini 2 LLM Google The improved version of Gemini, DeepMind Google’s LLM, now includes computer control along with image and audio generation capabilities. It is twice as fast as Gemini 1.5 Pro and offers significantly enhanced performance in coding and Figure 2.1.28 image analysis. Source: Google, 2025 Table of Contents Chapter 2 Preview 92 Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.1 Overview of AI in 2024 Dec 12, 2024 Sora Text-to- OpenAI OpenAI’s highly anticipated video video generation model can create videos up to 20 seconds long at 1080p resolution for ChatGPT Pro users (and five seconds at 720p for ChatGPT Plus users). Sora demos had been circulating at tech Figure 2.1.29 meetups since early 2024, but OpenAI Source: OpenAI, 2025 delayed the official release to improve model safety. Dec 13, 2024 Global MMLU Dataset Cohere A multilingual evaluation set featuring professionally translated MMLU questions across 42 languages, designed to serve as a more global AI benchmark. It evaluates AI performance in diverse languages while addressing Western Figure 2.1.30 Source: Singh et al., 2025 biases in the original MMLU dataset, where an estimated 28% of questions rely on Western cultural knowledge. Dec 20, 2024 o3 (beta) Multimodal OpenAI OpenAI’s newest frontier model, released for safety testing by AI researchers, outperforms all previous models in SWE, competition code, competition math, PhD-level science, and research math benchmarks. It also set a new record Figure 2.1.31 on the ARC-AGI benchmark, achieving Source: VentureBeat, 2025 87.5% on the ARC Prize team’s private holdout set. Dec 27, 2024 DeepSeek-V3 LLM DeepSeek DeepSeek V3, an open-source model developed with significantly fewer computing resources than state-of-the- art models, outperforms leading models on benchmarks like MMLU and GPQA. Figure 2.1.32 Source: Dirox, 2025 Table of Contents Chapter 2 Preview 93 Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.1 Overview of AI in 2024 State of AI Performance In this section, the AI Index offers a high-level view into major Figure 2.1.33 illustrates the progress of AI systems relative AI trends that occurred in 2024. to human baselines for eight AI benchmarks corresponding to 11 tasks (e.g., image classification or basic-level reading Overall Review comprehension).1 The AI Index team selected one benchmark Last year’s AI Index highlighted that AI had already surpassed to represent each task. This year, the AI Index team added human performance across many tasks, with only a few newly released benchmarks, such as GPQA Diamond and exceptions, such as competition-level mathematics and visual MMMU, to showcase the progress of AI systems in tackling commonsense reasoning. Over the past year, AI systems extremely challenging cognitive tasks. have continued to improve, exceeding human performance on several of these previously challenging benchmarks. 120% 100% 80% 60% 40% 20% 0% 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 Image classi cation (ImageNet Top-5) Visual reasoning (VQA) Medium-level reading comprehension (SQuAD 2.0) English language understanding (SuperGLUE) Multitask language understanding (MMLU) Competition-level mathematics (MATH) PhD-level science questions (GPQA Diamond) Multimodal understanding and reasoning (MMMU) 1 An AI benchmark is a standardized test used to evaluate the performance and capabilities of AI systems on specific tasks. For example, ImageNet is a canonical AI benchmark that features a large collection of labeled images, and AI systems are tasked with classifying these images accurately. Tracking progress on benchmarks has been a standard way for the AI community to monitor the advancement of AI systems. 2 In Figure 2.1.33, the values are scaled to establish a standard metric for comparing different benchmarks. The scaling function is calibrated such that the performance of the best model for each year is measured as a percentage of the human baseline for a given task. A value of 105% indicates, for example, that a model performs 5% better than the human baseline Table of Contents Chapter 2 Preview 94 )%( enilesab namuh eht ot evitaler ecnamrofreP Select AI Index technical performance benchmarks vs. human performance Source: AI Index, 2025 | Chart: 2025 AI Index report Human baseline Figure 2.1.332 Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.1 Overview of AI in 2024 As of 2024, there are very few task categories where human Last year’s AI Index highlighted a notable performance gap ability surpasses AI. Even in these areas, the performance gap between closed and open-weight LLM models. Figure 2.1.34 between AI and humans is shrinking rapidly. For example, on illustrates the performance trends of the top closed-weight MATH, a benchmark for competition-level mathematics, and open-weight LLMs on the Chatbot Arena Leaderboard, state-of-the-art AI systems are now 7.9 percentage points a public platform for benchmarking LLM performance. ahead of human performance, a significant improvement In early January 2024, the leading closed-weight model from the 0.3-point gap in 2024.3 Similarly, on MMMU, a outperformed the top open-weight model by 8.0%. By benchmark for complex, multidisciplinary, expert-level February 2025, this gap had narrowed to 1.7%. questions, the best 2024 model, o1, scored 78.2%, only 4.4 points below the human benchmark of 82.6%. Conversely, The same trend is evident across other question-answering at the end of 2023, Google Gemini scored 59.4%, further benchmarks. In 2023, closed-weight models consistently illustrating the rapid advancements in AI performance on outperformed open-weight counterparts on nearly every cognitively demanding tasks. major benchmark—MMLU, HumanEval, MMMU, and MATH. However, by 2024, the gap had narrowed significantly (Figure Closed vs. Open-Weight Models 2.1.35). For instance, in late 2023, closed-weight models led AI models can be released with different levels of openness. open models on MMLU by 15.9 points, but by the end of Certain models, like Google’s Med-Gemini, remain entirely 2024, that difference had shrunk to just 0.1 percentage point. closed, accessible only to their developers. Meanwhile, This rapid improvement was largely driven by Meta’s summer models such as OpenAI’s GPT-4o and Anthropic’s Claude 3.5 release of Llama 3.1, followed by the launch of other high- provide limited public access through APIs. However, weights performing open-weight models, such as DeepSeek’s V3. for these models are not released, preventing independent modification or thorough public scrutiny. In contrast, weights for Meta’s Llama 3.3 and Stable Video 4D are fully available, allowing anyone to modify and use them freely.4 Perspectives on open versus closed-weight AI models are sharply divided. Advocates of open-weight models highlight their potential to reduce market monopolies, spur innovation, improve security and robustness, and enhance transparency within the AI ecosystem. For example, Meta’s Llama models have been leveraged to create tools like Meditron, power military applications, and drive the development of numerous open-weight models worldwide. However, critics warn that open-weight models pose significant security risks, including the spread of disinformation and the creation of bioweapons, arguing for a more cautious and controlled approach. 3 The benchmark data in this figure, along with those in other sections of this chapter, was collected in early January 2025. Since the publication of the AI Index, individual benchmark scores may have improved. 4 In the software community, “open source” refers to software released under a license that grants users the right to use, study, modify, and distribute both the software and its source code freely. Open-weight models, though more accessible than closed-weight models, are not necessarily fully open source, as the underlying code or training data is often withheld. Table of Contents Chapter 2 Preview 95 Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.1 Overview of AI in 2024 1,400 1,350 1,300 1,250 1,200 1,150 1,100 2024-Jan 2024-Feb 2024-M ar 2024-Apr 2024-M ay 2024-Jun 2024-Jul 2024-Aug 2024-Sep 2024-Oct 2024-Nov 2024-Dec 2025-Jan 2025-Feb Table of Contents Chapter 2 Preview 96 erocS Performance of top closed vs. open models on LMSYS Chatbot Arena Source: LMSYS, 2025 | Chart: 2025 AI Index report 1,385, closed 1,362, open Closed Open 100% 100% 80% 80% 60% 60% 40% 40% 20% 20% 0% 0% 2022 2023 2024 2022 2023 2024 100% 100% 80% 80% 60% 60% 40% 40% 20% 20% 0% 0% 2022 2023 2024 2022 2023 2024 ycarucca egarevA ycaruccA ycarucca llarevO 1@ssaP Figure 2.1.34 Performance of top closed vs. open models on select benchmarks Source: AI Index, 2025 | Chart: 2025 AI Index report General language: MMLU General reasoning: MMMU Mathematical reasoning: MATH Coding: HumanEval Figure 2.1.35 Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.1 Overview of AI in 2024 US vs. China Technical Performance The United States has historically dominated AI research and on benchmarks such as MMLU, MMMU, MATH, and model development, with China consistently ranking second. HumanEval, the performance gaps were 17.5, 13.5, 24.3, and Recent evidence, however, suggests the landscape is rapidly 31.6 percentage points, respectively (Figure 2.1.37). By the changing and that China-based models are catching up to end of 2024, these differences had narrowed significantly their U.S. counterparts. to just 0.3, 8.1, 1.6, and 3.7 percentage points. The launch of DeepSeek-R1 garnered attention for another reason: The In 2023, leading American models significantly outperformed company reported achieving its results using only a fraction their Chinese counterparts. On the LMSYS Chatbot Arena, of the hardware resources typically required to train such a the top U.S. model outperformed the best Chinese model model. Beyond impacting U.S. stock markets, DeepSeek’s by 9.3% in January 2024. By February 2025, this gap had R1 launch raised doubts about the effectiveness of U.S. narrowed to just 1.7% (Figure 2.1.36). At the end of 2023, semiconductor export controls. 1,400 1,350 1,300 1,250 1,200 1,150 1,100 2024-Jan 2024-Feb 2024-M ar 2024-Apr 2024-M ay 2024-Jun 2024-Jul 2024-Aug 2024-Sep 2024-Oct 2024-Nov 2024-Dec 2025-Jan 2025-Feb Table of Contents Chapter 2 Preview 97 erocS Performance of top United States vs. Chinese models on LMSYS Chatbot Arena Source: LMSYS, 2025 | Chart: 2025 AI Index report 1,385, United States 1,362, China Figure 2.1.36 Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.1 Overview of AI in 2024 United States China 100% 100% 80% 80% 60% 60% 40% 40% 20% 20% 0% 0% 2022 2023 2024 2022 2023 2024 100% 100% 80% 80% 60% 60% 40% 40% 20% 20% 0% 0% 2022 2023 2024 2022 2023 2024 Table of Contents Chapter 2 Preview 98 ycarucca egarevA ycaruccA ycarucca llarevO 1@ssaP Performance of top United States vs. Chinese models on select benchmarks Source: AI Index, 2025 | Chart: 2025 AI Index report General language: MMLU General reasoning: MMMU Mathematical reasoning: MATH Coding: HumanEval Figure 2.1.37 Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.1 Overview of AI in 2024 Improved Performance From Smaller Models Recent AI progress has been driven by scaling—the idea 2024 was a breakthrough year for smaller AI models. Nearly that increasing model size and training data improves every major AI developer released compact, high-performing performance. While scaling has significantly boosted AI models, including GPT-4o mini, o1-mini, Gemini 2.0 Flash, capabilities, a notable recent trend is the emergence of Llama 3.1 8B, and Mistral Small 3.5 The rise of small models smaller high-performing models. Figure 2.1.38 illustrates the is significant for several reasons. It demonstrates increasing reduction in size of the smallest model that scores above 60% algorithmic efficiency, allowing developers to achieve more on MMLU, a widely used language model benchmark. For with less data and at lower training cost. These efficiency context, early models powering ChatGPT, such as GPT-3.5 gains, combined with growing datasets, could lead to Turbo, scored around 70% on MMLU. In 2022, the smallest even higher-performing models. Additionally, inference on model surpassing 60% on MMLU was PaLM, with 540 billion smaller models is typically faster and less expensive. Their parameters. By 2024, Microsoft’s Phi-3 Mini, with just 3.8 emergence also lowers the barrier to entry for AI developers billion parameters, achieved the same threshold, marking a and businesses looking to integrate AI into their operations. 142-fold reduction in model size over two years. PaLM 100B LLaMA-65B Llama 2 34B 10B Mistral 7B Phi-3-mini 2022-May 2022-Sep 2023-Jan 2023-May 2023-Sep 2024-Jan 2024-May Publication date Table of Contents Chapter 2 Preview 99 )elacs gol( sretemarap fo rebmuN Smallest AI models scoring above 60% on MMLU, 2022–24 Source: Abdin et al., 2024 | Chart: 2025 AI Index report Figure 2.1.38 5 These are just a few of the small models launched in 2024. Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.1 Overview of AI in 2024 Model Performance Converges at the Frontier In recent years, AI model performance at the frontier has Flyer’s DeepSeek, Mistral’s Le Chat, and xAI with Grok. converged, with multiple providers now offering highly As competition has intensified, model performance has capable models. This marks a shift from late 2022, when increasingly converged (Figure 2.1.39). According to last year’s ChatGPT’s launch—widely seen as AI’s breakthrough AI Index, the performance gap between the highest- and into public consciousness—coincided with a landscape 10th-ranked models on the Chatbot Arena Leaderboard—a dominated by just two major players: OpenAI and Google. widely used AI ranking platform—was 11.9%. By early 2025, it OpenAI, founded in 2015, released GPT-3 in 2020, while had narrowed to 5.4%. Similarly, the difference between the Google introduced models like PaLM and Chinchilla in 2022. top two models fell from 4.9% in 2023 to just 0.7% in 2024. The AI landscape is becoming more competitive, validating Since then, new players have entered the scene, including 2023 predictions that AI companies lack a technological Meta with its Llama models, Anthropic with Claude, High- moat to shield them from rivals. 1,400 1,350 1,300 1,250 1,200 1,150 1,100 1,050 2024-Jan 2024-Feb 2024-M ar 2024-Apr 2024-M ay 2024-Jun 2024-Jul 2024-Aug 2024-Sep 2024-Oct 2024-Nov 2024-Dec 2025-Jan 2025-Feb Figure 2.1.39 Table of Contents Chapter 2 Preview 100 erocS Performance of top models on LMSYS Chatbot Arena by select providers Source: LMSYS, 2025 | Chart: 2025 AI Index report 1,385, Google 1,366, OpenAI 1,362, DeepSeek 1,288, xAI 1,284, Anthropic 1,269, Meta 1,252, Mistral AI Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.1 Overview of AI in 2024 Benchmarking AI For years, the AI Index has used benchmarks to monitor the intelligence, and AI systems have improved over the decades technical progress of AI systems over time. While benchmarks to the point of defeating the best humans at increasingly remain a key tool in this effort, it is important to acknowledge complex games. Games with a physical component or team their limitations and guide the community toward more capabilities are also a good measure of progress for AI, and effective benchmarking practices. the robotics community has embarked on challenging game competitions such as RoboCup for soccer-playing robots. As noted in last year’s AI Index, many prominent AI benchmarks Another area of AI where competitions are used involves are reaching saturation. With AI systems advancing rapidly, coordination and teamwork where multi-agent systems even newly designed, more challenging tests often remain demonstrate advances in distributed reasoning. relevant for only a few years. Some experts suggest that the era of new academic benchmarks may be coming to an end. Benchmarks have been developed by the AI community To truly assess the capabilities of AI systems, more rigorous for a very long time. Significant advances in AI have been and comprehensive evaluations are needed. possible because different approaches and methods could be evaluated against the same gold standard represented Additionally, when model developers release new models, they by a benchmark. In machine learning, benchmarks with typically report benchmark scores, which are often accepted at different kinds of data in diverse domains have enabled face value by the broader community. However, this approach significant advances. Many of these benchmarks are has flaws. In some cases, companies use nonstandard evaluated automatically by a third party without releasing the prompting techniques, making model-to-model comparisons test data to the AI developers, which makes the evaluations unreliable. For example, when Google launched Gemini Ultra, more trustworthy. One interesting recent trend is that it reported an MMLU benchmark score using a chain-of- various benchmark tasks are addressed by the same model. thought prompting technique that other developers did not For example, natural language was addressed for many use. Additionally, third-party researchers have documented years as a collection of separate tasks (e.g., understanding, cases where models perform worse in independent testing generation, question answering), each with its own models compared with the results first reported by their developers. and each with its own benchmarks. Similarly, speech tasks were benchmarked separately from language understanding There are critical aspects of intelligence that do not easily or generation tasks. Today, the same model can address lend themselves to benchmarking. Benchmarks are effective all language tasks, and, in some cases, a single model can for evaluating certain intelligent capabilities, such as vision address language, images, and multimodal tasks. This is a and language, where tasks are discrete—e.g., classifying an very important AI advance concerning the integration of image correctly or answering a multiple-choice question. otherwise separate intelligent tasks and capabilities. However, developing benchmarks is more challenging in areas of AI such as multi-agent systems and human-AI The rapid progress of AI systems, evidenced by their consistent interaction because of factors including the variability in outperformance on benchmarks, is perhaps best illustrated human behaviors and the sheer diversity of correct answers. by the diminishing relevance of the well-known and long- standing challenge for AI: the Turing test. Originally proposed In addition, AI advances have traditionally been evaluated in in Alan Turing’s 1950 paper “Computing Machinery and competitions designed to measure human performance, such Intelligence,” the test evaluates a machine’s ability to exhibit as games and other open challenges posed to humans or humanlike intelligence. In it, a human judge engages in a text- machines. Games such as chess and poker involve significant based conversation with both a machine and a human; if the Table of Contents Chapter 2 Preview 101 Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.1 Overview of AI in 2024 judge cannot reliably distinguish between them, the machine with new questions from unfamiliar sources that LLMs are is said to have passed the Turing test. Recent evidence unlikely to have seen in their training data. suggests that LLMs have advanced so significantly that people struggle to differentiate the best-performing language models Lastly, research has shown that many benchmarks are poor- from a human, signaling that modern AI models can pass the ly constructed. In BetterBench, researchers systematically Turing test. While the merits and shortfalls of this test have analyzed 24 prominent benchmarks and identified systemic long been debated, it remains an important historical and deficiencies: 14 failed to report statistical significance, 17 cultural benchmark for machine intelligence. The questioning lacked scripts for result replication, and most suffered from of its relevance highlights the remarkable progress of LLMs in inadequate documentation, limiting their reproducibility and recent years and the evolving perception of effective computer effectiveness in evaluating models. Despite widespread use, science benchmarks and AI measurement. benchmarks like MMLU demonstrated poor adherence to quality standards, while others, such as GPQA, performed In robotics, many models have emerged that address significantly better. To address these issues, the paper pro- interacting with the physical world and reasoning about natural posed a 46-criteria framework covering all phases of bench- laws. A number of robotics benchmarks, such as ARMBench, mark development—design, implementation, documenta- focus on perception tasks. However, other benchmarks, such tion, and maintenance (Figure 2.1.40). It also introduced a as VIMA-Bench, assess robot performance in simulated publicly accessible repository to enable continuous updates environments where they simultaneously incorporate and improve benchmark comparability. Figure 2.1.41, from perception, communication, and deep learning. BetterBench, assesses many prominent benchmarks on their usability and design. These findings underscore the need for Benchmarks can also suffer from contamination, where LLMs standardized benchmarking to ensure reliable AI evaluation encounter test questions that were present in their training and to prevent misleading conclusions about model per- data. A recent study by Scale found significant contamination formance. Benchmarks have the potential to shape policy in the performance of many LLMs on GSM8K, a widely decisions and influence procurement decisions within or- used mathematics benchmark. Some researchers have ganizations highlighting the importance of consistency and sought to combat these contamination issues by introducing rigor in evaluation. benchmarks like LiveBench, which are periodically updated Five stages of the benchmark lifecycle Source: Reuel et al., 2024 Figure 2.1.40 Table of Contents Chapter 2 Preview 102 Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.1 Overview of AI in 2024 15 Foundation models Non-foundation models ALE GPQA FinRL-Meta AgentBench 10 BIG-bench Procgen WinoGrande RL Unplugged ARC-Challenge SafeBench GSM8K HellaSwag Wordcraft BBQ BOLD MMLU 5 0 0 5 10 15 20 Design score Table of Contents Chapter 2 Preview 103 erocs ytilibasU Design vs. usability scores across select benchmarks Source: Reuel et al., 2024 | Chart: 2025 AI Index report DecodingTrust PDEBench MLCommons AI Safety v0.5 Machiavelli HumanEval TruthfulQA MedMNIST v2 Figure 2.1.41 In this chapter, the AI Index continues to report on operates under the assumption that the scores reported by benchmarks, recognizing their importance in tracking AI’s companies are accurate and factual. The benchmark scores technical progress. As a standard practice, the Index sources in this section are current as of mid-February 2025. However, benchmark scores from leaderboards, public repositories since the publication of the AI Index, newer models may have such as Papers With Code and RankedAGI, as well as been released that surpass current state-of-the-art scores. company papers, blog posts, and product releases. The Index Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.2 Language 2.2 Language Natural language processing (NLP) enables computers to A sample output from GPT-4o Source: AI Index, 2025 understand, interpret, generate, and transform text. Current state-of-the-art models, such as OpenAI’s GPT-4o, Anthropic’s Claude 3.5, and Google’s Gemini, are able to generate fluent and coherent prose and display high levels of language understanding ability (Figure 2.2.1). Unlike earlier versions, which were restricted to text input and output, newer language models can now reason across a growing range of input and output modalities, including audio, images, and goal-oriented tasks (Figure 2.2.2). Figure 2.2.1 Gemini 2.0 in an agentic workflow Source: AI Index, 2025 Figure 2.2.2 Table of Contents Chapter 2 Preview 104 Artificial Intelligence Index Report 2025 100% 90% 80% 70% 60% 50% 40% 30% 20% 10% 0% 2019 2020 2021 2022 2023 2024 Table of Contents Chapter 2 Preview 105 ycarucca egarevA Chapter 2: Technical Performance 2.2 Language Understanding English language understanding challenges AI systems to The MMLU benchmark was created in 2020 by a team of understand the English language in various ways, such as researchers from UC Berkeley, Columbia University, University reading comprehension and logical reasoning. of Chicago, and University of Illinois Urbana-Champaign. MMLU: Massive Multitask Language Understanding The highest recorded score on MMLU, 92.3%, was achieved The Massive Multitask Language Understanding (MMLU) by OpenAI’s o1-preview model in September 2024. For benchmark assesses model performance in zero-shot or few- comparison, GPT-4, launched in March 2023, scored 86.4% shot scenarios across 57 subjects, including the humanities, on the benchmark. Notably, one of the earliest models STEM, and the social sciences (Figure 2.2.3). MMLU has tested on MMLU, RoBERTa, achieved just 27.9% in 2019 emerged as a premier benchmark for assessing LLM (Figure 2.2.4). This latest state-of-the-art result represents a capabilities: Many state-of-the-art models like GPT-4o, Claude remarkable 64.4 percentage point increase over five years. 3.5, and Gemini 2.0 have been evaluated against MMLU. A sample question from MMLU Source: Hendrycks et al., 2021 Figure 2.2.3 MMLU: average accuracy Source: Papers With Code, 2025 | Chart: 2025 AI Index report 89.8%, human baseline 92.30% Figure 2.2.4 Artificial Intelligence Index Report 2025 100% 84.00% 80.30% 80% 71.59% 71.85% 72.55% 73.11% 73.30% 74.68% 75.46% 75.70% 75.87% 76.24% 77.64% 77.90% 78.00% 60% 40% 20% 0% Qwen2.5-72 G B rok-2-m in G i PT-4o (20 A 24 th -0 en 5 e -1 - 3 V ) 2- L C la h m at a ( - 0 3 - . s 1- h 4 o G 0 t 5 ) P B T - - I 4 n o s t ( r 2 u 0 c G 2 t 4 ro -0 k 8 -2 -06) M iniM ax-Te D x e t- e 0 p 1 Seek-V G 3 em ini-2.0 C -F l l a a u s d h e -e -3 x . p 5- G S P o T n - n 4 e o t ( ( 2 2 0 0 C 2 2 4 4 la - - u 1 1 1 0 d - - 2 e 2 0 - 2 3 ) ) .5- G S P o T n - n o e 1 t - m (2 i 0 n D 2 i 4 e - e 0 p 6 S - e 2 e 0 k ) -R1 Table of Contents Chapter 2 Preview 106 ycarucca llarevO Chapter 2: Technical Performance 2.2 Language Despite its prominence, MMLU has faced notable criticisms. Generation These include claims that the benchmark contains erroneous or overly simplistic questions, which may not challenge In generation tasks, AI models are tested on their ability to increasingly advanced systems. In 2024, a team of researchers produce fluent and practical language responses. from the University of Toronto, University of Waterloo, and Carnegie Mellon introduced MMLU-Pro, a more challenging Chatbot Arena Leaderboard variant of MMLU. This version eliminates noisy and trivial The rise of capable LLMs has made it increasingly important questions, expands complex ones, and increases the number to understand which models are preferred by the general of answer choices available to models. Figure 2.2.5 highlights public. Launched in 2023, the Chatbot Arena Leaderboard performance trends on MMLU-Pro, with DeepSeek-R1 from LMSYS is one of the first comprehensive evaluations posting the highest score to date (84.0%). of public LLM preference. The leaderboard allows users to query two anonymous models and vote for the preferred Additionally, concerns have been raised about the testing generations (Figure 2.2.6). By early 2025, the platform had landscape. Developers sometimes report MMLU scores accumulated over 1 million votes, with users ranking one of using nonstandard prompting techniques that boost Google’s Gemini models as the community’s most preferred performance but can lead to misleading comparisons. choice. Furthermore, evidence suggests that publicly reported scores by developers can differ—sometimes by as much as five percentage points—from those later evaluated by academic researchers. As such, MMLU performance results should be interpreted with caution. MMLU-Pro: overall accuracy Source: MMLU-Pro Leaderboard, 2025 | Chart: 2025 AI Index report Figure 2.2.5 Artificial Intelligence Index Report 2025 1,380 1,370 1,360 1,350 1,340 1,330 1,320 1,310 1,300 Gem ini-1.5-Pro-0 S 0 t 2 ep-2-16K-Exp o1-m ini DeepSeek-V3 o1-preview o1-2024-12-17 Gem ini-2.0-Flash G -E em xp ini-2.0-Flash C -T h h at in G k P in T g -4 -E o x -l p a - t 1 e 2 G s 1 t e 9 m (2 i 0 n 2 i- 4 E - x 11 p - - 2 1 0 2 ) 06 Model Table of Contents Chapter 2 Preview 107 gnitar olE Chapter 2: Technical Performance 2.2 Language A sample model response on the Chatbot Arena Leaderboard Source: Chatbot Arena Leaderboard, 2024 Figure 2.2.6 Figure 2.2.7 provides a snapshot of the top 10 models on the AI Index, the difference in Arena scores between the top Chatbot Arena Leaderboard as of January 2025. Interestingly, model and the 10th-ranked model was 11.9%.6 By 2025, this the performance gap between top leaderboard models has gap had decreased to just 5.4%. This convergence highlights narrowed over time. In 2023, according to data from the 2024 a growing parity in the quality of recent LLMs. LMSYS Chatbot Arena for LLMs: Elo rating (overall) Source: LMSYS, 2025 | Chart: 2025 AI Index report Figure 2.2.7 6 The Arena score is a relative ranking system used by the Arena Leaderboard to compare model performance. For more details on the scoring methodology, refer to the paper introducing the Chatbot Arena Leaderboard. Artificial Intelligence Index Report 2025 Arena-Hard-Auto One of the challenges in developing new benchmarks to keep pace with rapidly improving AI capabilities is that creating high-quality, human-curated benchmarks is often expensive and time-consuming. In response, this year saw the launch of BenchBuilder. Created by a team of UC Berkeley researchers, BenchBuilder leverages LLMs to create an automated pipeline for curating high-quality, open-ended prompts from large, crowdsourced datasets. BenchBuilder can be used to update or create new benchmarks without significant human involvement. This tool was used by the LMSYS team to develop Arena-Hard-Auto, a benchmark designed to evaluate instruction-tuned LLMs (Figure 2.2.8). Arena-Hard- Auto includes 500 challenging user queries sourced from Chatbot Arena. In this benchmark, GPT-4 Turbo serves as the judge that compares model responses against a baseline model (GPT-4-0314). As of November 2024, the top-scoring models on the Arena- Hard-Auto leaderboard were o1-mini (92.0), o1-preview (90.4), and Claude-3.5-Sonnet (85.2) (Figure 2.2.9). Arena- Hard-Auto also features a style control leaderboard, which Table of Contents Chapter 2 Preview 108 weiverp-5210-4-tpg 31-50-4202-o4-tpg 02-60-4202-tennos-5-3-edualc gninthgil-iy 90-40-4202-obrut-4-tpg tcurtsni-b07-nortomen-1.3-amall tahc-2v-enehta 22-01-4202-tennos-5-3-edualc 21-90-4202-weiverp-1o 21-90-4202-inim-1o 100 80 60 40 20 0 Model erocS Arena-Hard-Auto with no modi cation Source: LMSYS, 2025 | Chart: 2025 AI Index report 90.40 92.00 78.00 79.20 79.30 81.50 82.60 84.90 85.00 85.20 31-50-4202-o4-tpg tcurtsni-b07-nortomen-1.3-amall 60-80-4202-o4-tpg tahc-2v-enehta weiverp-5210-4-tpg 90-40-4202-obrut-4-tpg 21-90-4202-inim-1o 21-90-4202-weiverp-1o 02-60-4202-tennos-5-3-edualc 22-01-4202-tennos-5-3-edualc 100 80 60 40 20 0 Model erocS Chapter 2: Technical Performance 2.2 Language Arena-Hard-Auto vs. other benchmarks Source: Li et al., 2024 Figure 2.2.8 accounts for how the style of an LLM’s responses might inadvertently influence user preferences. The top model on the style leaderboard is the November variant of Anthropic’s Claude Sonnet 3.5 (Figure 2.2.10). Automated benchmarks like Arena-Hard-Auto have faced criticism for uneven question distribution, which limits their ability to provide a comprehensive assessment of LLM capabilities. For instance, over 50% of Arena-Hard-Auto questions focus solely on coding and debugging. Arena-Hard-Auto with style control Source: LMSYS, 2025 | Chart: 2025 AI Index report 86.40 79.30 81.70 82.20 69.90 71.00 71.10 72.10 73.60 74.30 Figure 2.2.9 Figure 2.2.10 Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.2 Language WildBench WildBench, developed by researchers from the Allen Institute on academic questions and does not assess open-ended, for AI and the University of Washington, is a benchmark real-world problems. Similarly, benchmarks like LMSYS, launched in 2024 to evaluate LLMs on challenging real- which address real-world challenges, rely heavily on human world queries. The creators highlight several limitations oversight and lack consistency in evaluating all models with of existing LLM evaluations. For example, MMLU focuses the same dataset. Evaluation framework for WildBench Source: Lin et al., 2024 Figure 2.2.11 Table of Contents Chapter 2 Preview 109 Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.2 Language WildBench addresses many shortcomings of existing are periodically updated to ensure relevance. The creators benchmarks by providing an automated evaluation framework also maintain a live leaderboard to track model performance for LLMs, incorporating a diverse set of real-world (“in the over time. Currently, the top-performing model on WildBench wild”) questions that language models are likely to encounter is GPT-4o, with an Elo score of 1227.1, narrowly surpassing the (Figure 2.2.11). The questions in WildBench are meticulously second-place model, Claude 3.5 Sonnet, which scored 1215.4 selected from over 1 million human-chatbot interactions and (Figure 2.2.12). 1,200 1,176 1,179 1,181 1,182 1,185 1,188 1,192 1,196 1,197 1,199 1,209 1,210 1,215 1,215 1,227 1,000 800 600 400 200 0 Gem m a-2-2 N 7 e B m -i o t tron- A 4 t - h 34 en 0 e B - - 7 In 0 s B Y t i-Large DeepSeek- L V l 2 a - m C a o - d 3 e -7 r 0 G B e -I m ns in tr i u 1 c .5 t C Fl l a a s u h de 3 O g p p u t s -4-0125 D -p e r e e p v S ie e w ek- Y V i 2 -L -C ar h g a e t -Pr g e p v t i - e 4 w -turbo G - e 2 m 02 in 4 i - 0 1. 4 5 - C P 0 r l 9 a o ude 3.5 g S p o t n -4 n o e - t 2024-05-13 Model Table of Contents Chapter 2 Preview 110 )dellortnoc htgnel( olE-BW WildBench: WB-Elo (length controlled) Source: WildBench Leaderboard, 2025 | Chart: 2025 AI Index report Figure 2.2.12 Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.2 Language Highlight: o1, o3, and Inference-Time Compute OpenAI’s latest two models, o1 and o3, mark a paradigm smaller, more manageable steps before executing them, shift in AI models’ ability to “think” and exhibit signs of enhancing the resulting output quality. For example, advanced reasoning. o1 and o3 have shown impressive when asked to decipher scrambled text, o1 will specify its results across a variety of tasks, including programming, thought and reasoning process more thoroughly than GPT- quantum physics, and logic. The models’ advanced 4 (Figure 2.2.13). This process, through which AI systems reasoning capabilities are attributed to their chain-of- iterate as they answer, has been referred to as inference or thought process and ability to iteratively check answers. test-time computation. This means that the models break complex problems into Chain-of-thought thinking in o1 Source: OpenAI, 2024 Figure 2.2.13 Table of Contents Chapter 2 Preview 111 Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.2 Language Figure 2.2.14 juxtaposes the scores of GPT-4o, OpenAI’s 2024, a notoriously difficult mathematics competition. previous state-of-the-art model, with o1 and o1-preview on Finally, o3 demonstrates more complex reasoning than any a variety of benchmarks.7 For example, o1 outperforms GPT- other AI model known today, posting an 87.5% accuracy 4o with a 2.8-point gain on MMLU, 34.5 points on MATH, rate on the ARC-AGI machine intelligence benchmark and 26.7 points on GPQA Diamond, and 65.1 points on AIME passing the previous record of 55.5%. 100% 88.00% 90.80% 92.30% 100% 85.50% 94.80% 80% 80% 60.30% 60% 60% 40% 40% 20% 20% 0% 0% GPT-4o o1 o1-preview GPT-4o o1-preview o1 100% 100% 80% 73.30% 77.30% 80% 74.40% 60% 50.60% 60% 44.60% 40% 40% 20% 20% 9.30% 0% 0% GPT-4o o1-preview o1 GPT-4o o1-preview o1 While these models enhance reasoning capabilities, this available, is presumably even higher. o1 and o3’s strong comes at a price—both a financial and latency cost. For capabilities are likely to continue fueling powerful AI example, GPT-4o costs $2.50 per 1 million input tokens systems and agents. and $10 per 1 million output tokens. Conversely, o1 costs $15 per 1 million input tokens and $60 per 1 million output OpenAI first released o1-preview to ChatGPT Plus and tokens.8 Moreover, o1 is approximately 40 times slower Teams users on Sept. 12, 2024, and released the full version than GPT-4o, with 29.7 seconds to first token as opposed of o1 (as well as access to ChatGPT Pro, a $200 monthly to GPT-4o’s 0.72. The latency of o3, while not publicly subscription enabling access to o1) on Dec. 5, 2024. Table of Contents Chapter 2 Preview 112 1@ssaP 1@ssaP 1@ssaP 1@ssaP Highlight: o1, o3, and Inference-Time Compute (cont’d) GPT-4o vs. o1-preview vs. o1 on select benchmarks Source: OpenAI, 2024 | Chart: 2025 AI Index report MMLU MATH GPQA Diamond AIME 2024 Figure 2.2.14 7 The o1-preview model is OpenAI’s early release of o1, made available before its broader public launch. 8 o3 is currently only available to select researchers and developers via OpenAI’s safety testing program. Artificial Intelligence Index Report 2025 MixEval MixEval, launched by researchers at the National University of in Chatbot Arena, with ground-truth-based questions, like those Singapore, Carnegie Mellon University, and the Allen Institute featured in MMLU (Figure 2.2.15). MixEval includes various for AI, is another newly released benchmark designed to evaluation suites, with MixEval-Hard representing the more address some of the aforementioned limitations in the current challenging version of the benchmark. This suite focuses on field of LLM evaluation. MixEval combines comprehensive, substantially harder queries, making it one of the most effective well-distributed, real-world user queries, similar to those found tools for assessing how models handle complex questions. The highest-scoring model on the MixEval-Hard benchmark Llama-3 1-405B-Instruct model, which scored 66.2 (Figure is OpenAI’s o1-preview, with a score of 72.0. In second 2.2.16). All three models were released in 2024. place is the Claude 3.5 Sonnet-0620 model, followed by the 72.00 70 68.10 66.20 64.70 62.60 63.50 60 55.80 55.90 56.80 57.00 57.40 58.30 58.70 52.90 54.00 50 40 30 20 10 0 Reka Core- C 20 la 2 u 4 d 0 e 4 3 15 So Q n w n e e n t -M ax L -0 L 4 aM 28 A-3-7 Y 0 i B -L -I a n r s g t e ru -p ct r S e p v a ie r w k4.0 M istral Larg G e e 2 m ini 1.5 G Pr e o m -A in P i I - 1 0 .5 5 G P 14 r P o T -A -4 P -T I- u 0 r 4 b C 0 o 9 l - a 2 u 0 d 2 e 4 - 3 0 O 4 G - p 0 u P 9 s T-4o-20 L 24 La -0 M 5 A -1 - 3 3.1- C 40 la 5 u B d - e In 3 s . t 5 r u O S c o p t n e n n e A t I - 0 o1 6 - 2 p 0 review Model Table of Contents Chapter 2 Preview 113 erocS Chapter 2: Technical Performance 2.2 Language Evaluation framework for MixEval Source: Ni et al., 2024 Figure 2.2.15 MixEval-Hard on chat models: score Source: MixEval Leaderboard, 2025 | Chart: 2025 AI Index report Figure 2.2.16 Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.2 Language RAG: Retrieval Augment Generation (RAG) An increasingly common capability being tested in LLMs models. 2024 also saw the release of numerous benchmarks is retrieval-augmented generation (RAG). This approach for evaluating RAG systems, including Ragnarok (a RAG integrates LLMs with retrieval mechanisms to enhance arena battleground) and CRAG (Comprehensive RAG their response generation. The model first retrieves relevant benchmark). Additionally, specialized RAG benchmarks, such information from files or documents and then generates a as FinanceBench for financial question answering, have been response tailored to the user’s query based on the retrieved developed to address specific use cases. content. RAG has diverse use cases, including answering precise questions from large databases and addressing Berkeley Function Calling Leaderboard customer queries using information from company documents. The Berkeley Function Calling Leaderboard evaluates the ability of LLMs to accurately call functions or tools. The In recent years, RAG has received increasing attention from evaluation suite includes over 2,000 question-function- researchers and companies. For example, in September answer pairs across multiple programming languages (such 2024, Anthropic introduced Contextual Retrieval, a method as Python, Java, JavaScript, and REST API) and spans a that significantly enhances the retrieval capabilities of RAG variety of testing domains (Figure 2.2.17). Data composition on the Berkeley Function Calling Leaderboard Source: Yan et al., 2024 Figure 2.2.179 9 In this context: AST (abstract syntax tree) refers to tasks that involve analyzing or manipulating code at the structural level, using its parsed representation as a tree of syntactic elements. Evaluations labeled with “AST” likely test an AI model’s ability to understand, generate, or manipulate code in a structured manner. Exec (execution-based) indicates tasks that require actual execution of function calls to verify correctness. Evaluations labeled with “Exec” likely assess whether the AI model can correctly call and execute functions, ensuring the expected outputs are produced. Table of Contents Chapter 2 Preview 114 Artificial Intelligence Index Report 2025 100 80 74.31 72.08 66.73 67.88 67.98 69.58 60.97 61.31 61.38 61.74 61.83 62.19 62.73 62.79 64.10 60 40 20 0 Gem ini-1.5- Q P w ro e -0 n2 0 . 2 5 - ( 7 F 2 A C B m ) -I a n z s o tr n u -N ct o G ( v P e a r m - o P m in ro p i- - t 2 v ) . 1 0 :0 H -F a ( l F m a C s m h ) - e E r x 2 p .1 G - ( 7 P e b r m o ( m F in C p i- ) t 1 ) .5- F P u r n o c -0 ti 0 o 2 n a (P ry o r - o 1 M - m m e p i d n t) i i u -2 m 0 - 2 G v 4 3 P - .1 0 T ( 9 - F 4 - C 1 o 2 - ) m (P i r n o o i 1 - m - 2 2 0 p 0 2 t 2 ) 4 4 - - 0 12 7 - - G 1 1 7 8 P ( T ( P F - r 4 C o - ) m tu p rb t w ) o- a 2 t 0 t- 2 to 4 o -0 l- 4 8 g - B 0 p 9 ( t F - ( C 4 F o ) C -2 ) 02 g 4 p -1 t 1 - - 4 2 o 0 - 2 (F 0 C 2 w 4 ) - a 1 t 1 t - - 2 t 0 o o (P l- r 7 o 0 m B p (F t) C) Model Table of Contents Chapter 2 Preview 115 ycarucca llarevO Chapter 2: Technical Performance 2.2 Language The top model on the Berkeley Function Calling Leaderboard score of 72.08. Performance on this benchmark has improved is watt-tool-70b, a fine-tuned variant of Llama-3.3-70B- significantly over the course of 2024, with top models at the Instruct designed specifically for function calling. It achieved end of the year achieving accuracies up to 50 points higher an overall accuracy of 74.31 (Figure 2.2.18). The next-highest- than those recorded early in the year. scoring model was a November variant of GPT-4o, with a Berkeley Function-Calling: overall accuracy Source: Berkeley Function-Calling Leaderboard, 2025 | Chart: 2025 AI Index report Figure 2.2.18 Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.2 Language MTEB: Massive Text Embedding Benchmark The Massive Text Embedding Benchmark (MTEB), created transforms it into an embedding vector. This transformation by a team at Hugging Face and Cohere, was introduced in enables the model to then search for relevant information. late 2022 to comprehensively evaluate how models perform MTEB includes 58 datasets spanning 112 languages and on various embedding tasks. Embedding involves converting eight embedding tasks (Figure 2.2.19).10 For example, in the data, such as words, texts, or documents, into numerical bitext mining task, there are two sets of sentences from two vectors that capture rough semantic meanings and distance different languages, and for every sentence in the first set, between vectors. Embedding is an essential component of the model is tasked to find the best match in the second set. RAG. During a RAG task, when users input a query, the model Tasks in the MTEB benchmark Source: Muennighoff et al., 2023 Figure 2.2.19 10 The benchmark covers the following eight tasks: bitext mining, classification, clustering, pair classification, reranking, retrieval, semantic textual similarity, and summarization. For details on each task, refer to the MTEB paper. Table of Contents Chapter 2 Preview 116 Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.2 Language As of early 2025, the top-performing embedding model on the training to improve its performance. The voyage-3-m-exp MTEB benchmark was Voyage AI’s voyage-3-m-exp, with a model narrowly outperformed NV-Embed-v2 (72.31), which score of 74.03. Voyage AI is focused on creating high-quality held the top spot for most of 2024 (Figure 2.2.20). When AI embedding models. The voyage-3-m-exp model is a variant the MTEB benchmark was first introduced in late 2022, the of the voyage-3-large, a large foundation model specifically leading model achieved an average score of 59.5. Over the designed for embedding tasks, and it uses strategies like past two years, therefore, performance on the benchmark Matryoshka Representation Learning and quantization-aware has meaningfully improved. 100 80 74.03 67.56 68.17 68.23 69.32 69.88 70.11 70.24 70.31 71.19 71.21 71.62 71.67 72.02 72.31 60 40 20 0 SFR-Em bed L d in in q g - - E M m i b st e r d v a o - l M ya is g t e r - a l l arg N e V -2 -E -i m ns b tr e u d c - b t v g 1 e-multilin st g e u ll a a l- _ g e e n m _4 m g 0 t a 0 e 2 M -Q _ w v5 en2 S -7 F B R - - i E n m str b u e c d t s d te in ll g a - _ 2 e _ n R _1. L 5 E B N _v S 5 -d400 L 0 ENS-d800 b 0 ge-en-icl jasper_en_v N is V io -E n m _l b a e n d g - u v v o a 2 y g a e g _ e v - 1 3-m -exp Model Figure 2.2.20 Table of Contents Chapter 2 Preview 117 erocs egarevA MTEB on English subsets across 56 datasets: average score Source: MTEB Leaderboard, 2025 | Chart: 2025 AI Index report Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.2 Language Highlight: Evaluating Retrieval Across Long Contexts Table of Contents Chapter 2 Preview 118 )B41( muidem-3ihP )B27( 2newQ )B07( 3amalL/IAtneidarG )B401( sulp-R-dnammoC )B43( iY )B8( 1.3amalL )B07( 1.3amalL )B9( 4MLG weiverp-6011-4-TPG orp-5.1-inimeG 100% 80% 60% 40% 20% 0% Model ).cni( erocs egareva dethgieW RULER: weighted average score (increasing) Source: Hsieh et al., 2024 | Chart: 2025 AI Index report 95.50% 82.60%82.70%84.80%85.40%85.50%88.00%89.00% 79.60% 74.80% Claimed E ective 1M 800K 600K 400K 200K 0 Phi3-me Q d w iu e m n 2 (1 G ( 4 7 B r 2 a ) B d ) ien C tA o I m /L m la a m Y n i d a ( 3 - 3 R 4 ( - 7 B p 0 ) l L u B l s ) a m (10 a 4 3 B . L 1 ) l ( a 8 m B) a3. G 1 ( L 7 M 0B 4 ) (9 G B P ) T-4-1 G 10 e 6 m -p in r i e - v 1. i 5 e - w pro Model htgnel txetnoC As AI models have advanced, their ability to handle longer contexts has significantly improved. For example, models like GPT-4 and Llama 2, released in 2023 by OpenAI and Meta, featured context windows of 8,000 and 4,000 tokens, respectively. In contrast, more recent models such as GPT-4o (May 2024) and Gemini 2.0 Pro Experimental (February 2025) boast context windows ranging from 128 thousand to 2 million. These extended context windows allow users to input and process increasingly large amounts of data, enabling more complex and detailed interactions. As the context windows of LLMs have expanded, evaluating their performance in long-context settings has become increasingly important. However, existing long-context evaluation methods have been relatively limited. Typically, these evaluations focus on “needle-in-the-haystack” scenarios, where models are tasked with retrieving specific pieces of information from lengthy texts. While useful, such Figure 2.2.21 evaluations provide only a baseline assessment of a model’s RULER: claimed vs. e ective context length ability to function effectively in long-context environments. Source: Hsieh et al., 2024 | Chart: 2025 AI Index report In 2024, several new evaluation suites were introduced to address the limitations of long-context model assessments and improve their evaluation. One such benchmark is Nvidia’s RULER, which assesses long-context performance by examining retrieval performance and multihop reasoning, aggregation, and question answering. Among the models evaluated on RULER, Gemini-1.5-Pro achieved the highest weighted performance average (95.5), followed by GPT- 4 (89.0) and GLM4(88.0) (Figure 2.2.21). The researchers behind RULER also revealed that many models suffer performance issues in longer context settings. In fact, the RULER team demonstrated that while most popular LLMs claim context sizes of 32K tokens or greater, only half of them can maintain satisfactory performance at the length of 32K. This means that their actual operational context Figure 2.2.22 windows are shorter than those claimed by their developers (Figure 2.2.22). Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.2 Language 8k 32k 128k 100 80 66.30 64.20 63.90 63.80 63.50 62.70 58.60 59.50 59.80 60.20 60.80 60 53.50 49.30 39.90 39.50 40 20 0 GPT-4 GPT-4o-08 Claude-3.5-Sonnet Gemini-1.5-Pro Llama-3.1-70B Model Table of Contents Chapter 2 Preview 119 erocs egarevA Highlight: Evaluating Retrieval Across Long Contexts (cont’d) HELMET (How to Evaluate Long-Context Models and generation with citations. Figure 2.2.24 illustrates Effectively and Thoroughly), an Intel and Princeton the average performance of several notable models collaboration, is another long-context evaluation on the HELMET benchmark across 8K, 32K, and 128K benchmark introduced in 2024. The researchers behind context settings. While models like GPT-4, Claude 3.5 HELMET were motivated by the inadequacies of existing Sonnet, and Llama 3.1-70B struggle with performance benchmarks, which suffered from insufficient coverage degradation in longer context settings, others, such as of downstream tasks, context lengths too short to Gemini 1.5 Pro and the August variant of GPT-4, maintain test evolving long-context capabilities, and unreliable their effectiveness. The introduction of benchmarks like metrics (Figure 2.2.23). Even more comprehensive than RULER and HELMET highlights how the rapid evolution RULER, HELMET features seven long-context evaluation of LLMs is compelling researchers to rethink and refine categories, including synthetic recall, passage re-ranking, evaluation methodologies. Comparing long- context benchmarks Source: Yen et al., 2024 Figure 2.2.23 HELMET: average score Source: Yen et al., 2024 | Chart: 2025 AI Index report Figure 2.2.24 Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.3 Image and Video Computer vision allows machines to understand images and videos and to create realistic visuals from textual prompts or other inputs. This technology is widely used in fields such as autonomous driving, medical imaging, and video game development. 2.3 Image and Video Understanding Vision models are evaluated on their ability to understand these cases, algorithms process natural language questions, and reason about the content of images and videos. Vision identify objects from an open set of images, and generate understanding was one of the first AI capabilities widely answers based on image content or prior knowledge. tested during the deep learning era. ImageNet, created by Fei-Fei Li and extensively covered in past editions of the VCR: Visual Commonsense Reasoning AI Index, served as a foundational benchmark for image Introduced in 2019 by researchers from the University understanding. As AI systems have advanced, researchers of Washington and the Allen Institute for AI, the Visual have shifted toward evaluating image models on more Commonsense Reasoning (VCR) challenge tests the complex and comprehensive understanding tasks, such as commonsense visual reasoning abilities of AI systems. In this those involving video or commonsense reasoning in images. challenge, AI systems not only answer questions based on images but also reason about the logic behind their answers In the ImageNet era, vision algorithms were tasked with more (Figure 2.3.1). Performance in VCR is measured using the straightforward tasks (e.g., classifying images into predefined Q->AR score, which evaluates the machine’s ability to both categories). However, modern computer vision benchmarks select the correct answer to a question (Q->A) and choose like VCR and MVBench introduce more open-ended the appropriate rationale behind that answer (Q->R). challenges, where no fixed categories or classes exist. In Sample question from Visual Commonsense Reasoning (VCR) challenge Source: Zellers et al., 2018 Figure 2.3.1 Table of Contents Chapter 2 Preview 120 Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.3 Image and Video The VCR benchmark was one of the few benchmarks routinely score of 85.0, matching the human benchmark (Figure 2.3.2). featured in the AI Index where AI systems consistently This milestone represented a significant 4.2% improvement fell short of the human baseline. However, 2024 marked a on the benchmark since 2023. Even previously challenging turning point, with AI systems finally reaching this baseline. benchmarks are now being surpassed. A model posted to the leaderboard in July 2024 achieved a 80 70 60 50 2018 2019 2020 2021 2022 2023 2024 MVBench MVBench, introduced by a team of researchers from Hong Kong and China in 2023, is a challenging, multimodal, video-understanding benchmark.11 Unlike earlier video benchmarks that primarily tested spatial understanding through static image tasks, MVBench incorporates more complex video tasks requiring temporal reasoning across multiple frames (Figure 2.3.3). Table of Contents Chapter 2 Preview 121 erocs RA>-Q Visual Commonsense Reasoning (VCR) task: Q->AR score Source: VCR Leaderboard, 2025 | Chart: 2025 AI Index report 85, human baseline 85 Figure 2.3.2 Sample tasks on MVBench Source: Li et al., 2023 Figure 2.3.3 11 The researchers were affiliated with the Chinese Academy of Sciences, University of Chinese Academy of Sciences, Shanghai AI Laboratory, the University of Hong Kong, Fudan University, and Nanjing University. Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.3 Image and Video As of 2024, the top model on the MVBench leaderboard is late 2023 (Figure 2.3.4). These results highlight the gradual Video-CCAM-7B-v1.2, built on the Queen 2.5-7B-Instruct but steady progress in the dynamic video understanding language model. Its score of 69.23 marks a significant 14.6% capabilities of AI models. improvement on the benchmark since its introduction in 100% 80% 69.23% 67.25% 67.42% 64.60% 65.35% 62.30% 62.80% 60% 58.10% 58.77% 60.40% 54.73% 54.85% 50.90% 51.10% 48.70% 40% 20% 0% interlm -7b vicuna-7b-d V e id lt e a o -v C 0 hat K 2 wai-Video S L T L - M LLM PLLaVA 34 C B VLM VideoChat V 2_ id m e i o s C tr h a a l t V 2_ id H e D o _ -C m C is A t V r M a id l - e 4 o B - - C v C 1.1 A J M T- - V 9 L B - - C v h 1. a 1 t InternVideo T 2 im -8 e B M -H ar D k - e V C r i h d a e t o -f - 1 C 6 CAM -7B-v1.2 Table of Contents Chapter 2 Preview 122 ycarucca egarevA MVBench: average accuracy Source: MVBench Leaderboard, 2025 | Chart: 2025 AI Index report Figure 2.3.4 Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.3 Image and Video Generation Image generation is the task of generating images that are Which face is real? Source: Which Face Is Real, 2024 indistinguishable from real ones. As noted in last year’s AI Index, today’s image generators are so advanced that most people struggle to differentiate between AI-generated images and actual images of human faces (Figure 2.3.5). Figure 2.3.6 highlights several generations from various Midjourney model variants from 2022 to 2025 for the prompt “a hyper-realistic image of Harry Potter.” The progression demonstrates the significant improvement in Midjourney’s ability to generate hyper-realistic images over a two-year period. In 2022, the model produced cartoonish and inaccurate renderings of Harry Potter, but by 2025, it could create startlingly realistic Figure 2.3.5 depictions. Midjourney generations over time: “a hyper-realistic image of Harry Potter” Source: Midjourney, 2024 V1, February V2, April 2022 2022 V3, July 2022 V4, November 2022 V5, March 2023 V6, December 2023 V6.1, July 2024 Figure 2.3.6 Table of Contents Chapter 2 Preview 123 Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.3 Image and Video Chatbot Arena: Vision The AI community has increasingly embraced public evaluation platforms, such as the Chatbot Arena Leaderboard, to assess the capabilities of leading AI systems, including top AI image generators. This leaderboard also features a Vision Arena, which ranks the performance of over 50 vision models. Users can submit text-to-image prompts, such as “Batman drinking a coffee,” and vote for their preferred generation (Figure 2.3.7). To date, the Vision Arena has garnered more than 150,000 votes. As of early 2025, the top-ranked vision model on the leaderboard is Google’s Gemini-2.0-Flash-Thinking- Exp-1219 (Figure 2.3.8). Similar to other Chatbot Arena categories—such as general, coding, and math—the leading models are closely clustered in performance. For example, the gap between the top model and the fourth-ranked model, ChatGPT-4o-latest (2024-11- 20), is just 3.4%. 1,280 1,260 1,240 1,220 1,200 1,180 1,160 Pixtral-Large-2 C 4 l 1 a 1 ude 3.5 Son C n l e a t u ( d 2 e 0 3 2 . 4 5 1 0 S 2 o 2 n G ) n e e m t ( i 2 n 0 i- 2 1. 4 5 0 -F 6 l 2 a 0 s G h ) P -0 T- 0 4 2 o-2024-0 G 5 e - m 13 ini-1.5-Pro C -0 h 0 a 2 tGPT-4o-la G te e s m t i ( n 2 i 0 -E 2 x 4 p -1 - 1 1 - 2 2 G 0 0 6 e ) m ini-2.0-Fla G sh e - m E i x n p i-2.0-Flash-Thinking-Exp-1219 Model Table of Contents Chapter 2 Preview 124 gnitar olE Sample from the Chatbot Vision Arena Source: Chatbot Arena Leaderboard, 2025 Figure 2.3.7 LMSYS Chatbot Arena for LLMs: Elo rating (vision) Source: LMSYS, 2025 | Chart: 2025 AI Index report Figure 2.3.8 Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.3 Image and Video Highlight: The Rise of Video Generation As highlighted in last year’s AI Index, recent years have follows a three-step process: text-to-image pretraining, witnessed the rise of video generation models capable of video pretraining, and high-quality video fine-tuning. creating videos from text prompts. While earlier models Shortly after, in March, Stability AI introduced Stable demonstrated some promise, they were plagued by Video 3D, a model designed to generate multiple 3D views significant limitations, such as producing low-quality and videos of an object from a single image. In February videos, omitting sound, or generating only very short 2024, OpenAI responded with a preview of Sora, its own clips. However, 2024 marked a significant leap forward in video generation model, which moved out of research AI video generation, with several major industry players mode and became publicly accessible in December 2024. unveiling advanced video generation systems. Sora can generate 20-second videos at resolutions up to 1080p (Figure 2.3.10). As a diffusion model, it creates a In November 2023, Stability AI launched its Stable Video base video and progressively refines it by removing noise Diffusion model, their first foundation model capable of over multiple steps to enhance quality. generating high-quality videos (Figure 2.3.9). The model Still generations from Stable Video Diffusion Source: Stability AI, 2025 Figure 2.3.9 Still generation from Sora Source: OpenAI, 2024 Figure 2.3.10 Table of Contents Chapter 2 Preview 125 Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.3 Image and Video Highlight: The Rise of Video Generation (cont’d) Other major tech players have entered the video generation space. In October 2024, Meta unveiled the latest version of its Movie Gen model. Unlike earlier iterations, the new Movie Veo preferred Ties Other preferred Gen includes advanced instruction-based video editing 100% features, personalized video generation from images, and the ability to incorporate sound into videos. Meta’s most 30.60% 32.60% 30.30% 26.70% advanced Movie Gen model can create 16-second videos at 80% 16 frames per second, with a resolution of 1080p. Google also 14.50% made significant strides in 2024, launching two major video 60% 15.60% 17.80% 15.20% generation models: Veo in May and Veo 2 in December. Internal benchmarking by Google revealed that Veo 2 40% outperformed other leading video generators, such as Meta’s Movie Gen, Kling v1.5, and Sora Turbo. In user comparisons, 53.80% 54.50% 58.80% 49.50% videos generated by Veo 2 were consistently favored over 20% those produced by competing models (Figure 2.3.11). 0% Meta Movie Gen Kling v1.5 Minimax Sora Turbo Figure 2.3.11 Will Smith eating spaghetti, 2023 vs. 2025 Source: Pika, 2025 Figure 2.3.12 Table of Contents Chapter 2 Preview 126 ecnereferp llarevO Veo 2: overall preference Source: DeepMind, 2024 | Chart: 2025 AI Index report Smaller players have also made notable contributions to video generation, with models such as Runway’s Gen-3 Alpha, Luma’s Dream Machine, and Kuaishou’s Kling 1.5. The remarkable progress in this field is evident when comparing videos generated in 2023 to those produced in 2024. A popular prompt on the internet, “Will Smith eating spaghetti,” demonstrates this advancement, with videos generated in 2025 from one popular video generator Pika showcasing a dramatic improvement in quality compared to their 2023 counterparts (Figure 2.3.12). V1.0 December 2023 V1.5 October 2024 V2.2 February 2025 Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.4 Speech AI systems are adept at processing human speech, with audio capabilities that include transcribing spoken words to text and recognizing individual speakers. More recently, AI has advanced in generating synthetic audio content. 2.4 Speech Speech Recognition Speech recognition is the ability of AI systems to identify LSR2: Lip Reading Sentences 2 spoken words and convert them into text. Speech recognition The Oxford-BBC Lip Reading Sentences 2 (LRS2) dataset, has progressed so much that today many computer programs introduced in 2017, is one of the most comprehensive public and texting apps are equipped with dictation devices that can datasets for lipreading in authentic, in-the-wild scenarios reliably transcribe speech into writing. (Figure 2.4.1). The dataset consists of audio-visual clips from a variety of talk shows and news programs. On automatic speech recognition (ASR) tasks, systems’ ability to transcribe speech are evaluated on word error rate (WER), with lower scores indicating more precise transcription. Still images from the BBC lip reading sentences 2 dataset Source: Chung et al., 2024 Figure 2.4.1 Table of Contents Chapter 2 Preview 127 Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.4 Speech This year, the model Whisper-Flamingo set a new standard 1.5 set in 2023 (Figure 2.4.2). However, given the already on the LRS2 benchmark, achieving a word error rate of 1.3 low WER, significant further improvements appear unlikely, percent, surpassing the previous state-of-the-art score of suggesting that the benchmark may be nearing saturation. 8% 7% 6% 5% 4% 3% 2% 1% 0% 2018 2019 2020 2021 2022 2023 2024 Figure 2.4.2 Table of Contents Chapter 2 Preview 128 )REW( etar rorre droW LRS2: word error rate (WER) Source: Papers With Code, 2025 | Chart: 2025 AI Index report 1.30% Artificial Intelligence Index Report 2025 100% 80% 60% 40% 20% 0% 2021 2022 2023 2024 Table of Contents Chapter 2 Preview 129 1@ssaP Chapter 2: Technical Performance 2.5 Coding Coding involves the generation of instructions that computers can follow to perform tasks. Recently, LLMs have become proficient coders, serving as valuable assistants to computer scientists. 2.5 Coding There is also increasing evidence that many coders find AI coding assistants highly useful. As highlighted in last year’s HumanEval AI Index, LLMs have become increasingly proficient coders, to the extent that many HumanEval, a benchmark introduced by OpenAI researchers in 2021, evaluates the foundational coding benchmarks, such coding abilities of AI systems through 164 challenging, handwritten programming as HumanEval, are slowly becoming problems (Figure 2.5.1). The current leader in HumanEval performance is Claude 3.5 saturated. In response, researchers have shifted their focus toward testing LLMs Sonnet (HPT), which achieved a score of 100% (Figure 2.5.2). on more complex coding challenges. Sample HumanEval problem Source: Chen et al., 2023 Figure 2.5.1 HumanEval: Pass@1 Source: Papers With Code, 2025 | Chart: 2025 AI Index report 100% Figure 2.5.2 Artificial Intelligence Index Report 2025 71.70% 55.00%53.20%55.00%55.40%57.00%57.20%58.20%60.20%62.20%62.80%64.60% 44.67%47.33%48.33%48.67%49.00% 40.67%41.00%41.33% 41.67% Table of Contents Chapter 2 Preview 130 + 5.1-sseltnegA )22-01-4202( tennoS 5.3-edualC )03-01-4202( tiK-EWS oisopmoC + 9.0-yttiKhctaP )22-01-4202( tennoS 5.3-edualC 1.2v tcAedoC + sdnaHnepO )22-01-4202-tennos-5-3-edualc( + 1v-udoK )22-01-4202( tennoS 5.3-edualC olved tnegA rexiF edoC tnabolG )80-21-4202( urG tnegA IA xobkcalB mrofosI hs.tekcarB tnegA repoleveD Q nozamA )ved-20-21-4202v( repoleveD nuR/IA MAPE + 21-21-4202v tnegA tennoS 5.3 edualC cipohtnA )80-21-4202( urG )32-21-4202v( 1E tnegremE olved tcaretni-yb-nraeL + tnegA tiwdiM yrotSedoC hcraes-ews tnegA IA xobkcalB 5kcehcssorc 1O remmargorP B&W 3o 100% Lite Veri ed 80% 60% 40% 20% 0% Lite Veri ed Model devlos tnecreP Chapter 2: Technical Performance 2.5 Coding SWE-bench In October 2023, researchers from Princeton and the University A sample model input from SWE-bench of Chicago introduced SWE-bench, a dataset comprising Source: Jimenez et al., 2023 2,294 software engineering problems sourced from real GitHub issues and popular Python repositories (Figure 2.5.3). SWE-bench presents a tougher test for AI coding proficiency, demanding that systems coordinate changes across multiple functions, interact with various execution environments, and perform complex reasoning. SWE-bench features a Lite subset that is curated to make evaluation more accessible and a Verified subset that is filtered by a human annotator. The charts below report on the Verified score. SWE-bench highlights the rapid improvement of LLMs on tasks that were once considered extremely demanding. At the end of 2023, the best performing model on SWE-bench achieved a score of just 4.4%. By early 2025, the top model, OpenAI’s o3 model, is reported to have successfully solved 71.7% of the problems on the Verified benchmark set (Figure 2.5.4). This significant performance increase suggests that Figure 2.5.3 AI researchers may soon need to develop more challenging coding benchmarks to effectively test LLMs. SWE-bench: percent solved Source: SWE-bench Leaderboard, 2025; OpenAI, 2024 | Chart: 2025 AI Index report Figure 2.5.4 Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.5 Coding Programming tasks in BigCodeBench Source: Zhuo et al., 2024 Figure 2.5.5 30.80 31.10 31.40 32.10 32.10 32.80 33.80 34.10 34.50 35.50 Table of Contents Chapter 2 Preview 131 tcurtsnI-B23-redoC-5.2newQ 02-11-4202-o4-TPG tnegA-2V-enehtA tahC-2V-enehtA 90-40-4202-obruT-4-TPG 71-21-4202-1o )muidem=gninosaer ,1=erutarepmet( tahC-3V-keeSpeeD 6021-pxE-inimeG 71-21-4202-1o )wol=gninosaer ,1=erutarepmet( 71-21-4202-1o )hgih=gninosaer ,1=erutarepmet( 100 80 60 40 20 0 Model )egareva( 1@ssaP BigCodeBench on the hard set: Pass@1 (average) Source: Hugging Face, 2025 | Chart: 2025 AI Index report 52.90 53.20 53.50 53.50 54.00 54.10 54.20 54.70 56.10 56.10 pxE-hsalF-0.2-inimeG 90-40-4202-obruT-4-TPG tcurtsnI-B23-redoC-5.2newQ 02-11-4202-o4-TPG tcurtsnI-2V-redoC-keeSpeeD )82-60-4202( tahC-2V-keeSpeeD 4111-pxE-inimeG 6021-pxE-inimeG tahC-3V-keeSpeeD 31-50-4202-o4-TPG 100 80 60 40 20 0 Model )egareva( 1@ssaP BigCodeBench One limitation of existing coding benchmarks is that many coding evaluation (Figure 2.5.5). BigCodeBench requires are restricted to short, self-contained algorithmic tasks or LLMs to invoke multiple function calls across 139 libraries standalone function calls. However, solving complex and and seven domains, encompassing 1,140 fine-grained tasks. practical tasks often requires the ability to invoke diverse Current AI systems struggle on BigCodeBench. For example, functions, such as tools for data analysis or web development. on both the “complete” (code completion based on structured Effective coding also requires the ability to follow coding docstrings) and “instruct” (code completion based on instructions expressed in language, a task not tested by many natural-language instructions) tasks on the hard subset of the current coding benchmarks. benchmark, the current best model, OpenAI’s o1, achieves an average score of just 35.5 (Figure 2.5.6). Models perform To address the limitations of existing coding benchmarks, slightly better on the full set of the benchmark (Figure 2.5.7). an international team in 2024 released BigCodeBench, a BigCodeBench highlights the gap that persists for AI systems comprehensive, diverse, and challenging benchmark for to achieve human-level coding proficiency. BigCodeBench on the full set: Pass@1 (average) Source: Hugging Face, 2025 | Chart: 2025 AI Index report Figure 2.5.6 Figure 2.5.7 Artificial Intelligence Index Report 2025 1,380 1,360 1,340 1,320 1,300 Qwen2.5-plus-112 D 7 eepSeek-V3 Claude 3.5 Sonn G et e ( m 20 in 2 i 4 -2 10 .0 2 - 2 F ) lash G -T e h m in in k i i - n 2 g .0 -E -F x l p a - s 1 h 2 C - 1 E h 9 a xp tGPT-4o-late o s 1 t - p (2 r 0 ev 2 i 4 e - w 11-20) o1-m ini o1-2024-12-17 Gem ini-Exp-1206 Model Table of Contents Chapter 2 Preview 132 gnitar olE Chapter 2: Technical Performance 2.5 Coding Chatbot Arena: Coding The Chatbot Arena LLM leaderboard now features a coding LLM for coding is Gemini-Exp-1206, with an arena score of filter, offering valuable insights into how coders and the 1,369, closely followed by OpenAI’s latest o1 model at 1,361. broader community perceive the coding capabilities of Among Chinese models, DeepSeek-V3 leads with a score different models. This public feedback adds a new dimension of 1,317, trailing the highest-ranking model by 3.8% (Figure to evaluating model performance. Currently, the top-rated 2.5.8). LMSYS Chatbot Arena for LLMs: Elo rating (coding) Source: LMSYS, 2025 | Chart: 2025 AI Index report Figure 2.5.8 Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.6 Mathematics Mathematical problem-solving benchmarks evaluate AI systems’ ability to reason mathematically. AI models can be tested with a range of math problems, from grade-school level to competition-standard mathematics. 2.6 Mathematics Sample problems from GSM8K Source: Cobbe et al., 2023 GSM8K GSM8K, introduced by OpenAI in 2021, is a dataset containing approximately 8,000 diverse grade-school math word problems that challenges AI models to generate multistep solutions using arithmetic operations (Figure 2.6.1). Alongside MMLU, GSM8K has become a widely used benchmark for evaluating advanced LLMs. However, recent concerns have emerged regarding potential contamination and saturation of the benchmark. Figure 2.6.1 The top-performing model on GSM8K is a variant of Claude Sonnet 3.5, which was optimized using the HPT prompting strategy and achieved a 97.72% score (Figure 2.6.2). This marks a significant improvement 100% 80% Figure 2.6.1 60% 40% 20% 0% 2022 2023 2024 Figure 2.6.2 Table of Contents Chapter 2 Preview 133 ycaruccA over the previous high of 91.00% in 2023. However, in 2024, several models from Mistral, Meta, and Qwen scored around 96%, indicating that the GSM8K benchmark may be approaching saturation. GSM8K: accuracy Source: Papers With Code, 2024 | Chart: 2025 AI Index report 97.72% Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.6 Mathematics Sample problem from MATH dataset Source: Hendrycks et al., 2023 Figure 2.6.3 100% 80% 60% 40% 20% 0% 2021 2022 2023 2024 2025 Figure 2.6.4 Table of Contents Chapter 2 Preview 134 ycaruccA MATH MATH is a dataset of 12,500 challenging, competition- level mathematics problems introduced by UC Berkeley and University of Chicago researchers in 2021 (Figure 2.6.3). AI systems struggled on MATH when it was first released, managing to solve only 6.9% of the problems. Performance has significantly improved. In January 2025, OpenAI’s o3-mini (high) model was released and achieved the best performance on the MATH dataset, solving 97.9% of the problems (Figure 2.6.4). As highlighted in last year’s AI Index, MATH was one of the few datasets where AI systems had not yet outperformed the human baseline. This fact no longer remains true. MATH word problem-solving: accuracy Source: Papers With Code, 2024; OpenAI, 2025 | Chart: 2025 AI Index report 97.90% 90%, human baseline Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.6 Mathematics 1,380 1,360 1,340 1,320 1,300 1,280 1,260 Claude 3.5 Sonne G t e (2 m 0 in 24 i- 1 1 0 .5 2 - 2 P ) ro-0 D 02 eepSeek-V3 ChatGPT-4o-late G st e ( m 20 in 2 i 4 -2 -1 .0 1- - 2 F 0 la ) sh G -E e x m p ini-Exp-1206 Gem ini-2.0-Flash o -T 1- h m in in k i ing-Exp-12 o 19 1-preview o1-2024-12-17 Model Table of Contents Chapter 2 Preview 135 gnitar olE Chatbot Arena: Math The Chatbot Arena includes a math filter, allowing the public Unlike the general and coding arenas, where Gemini-based to rank models based on their performance in generating models lead, the top-ranked model in the Math Arena is math-related answers. The Math Arena evaluates over 181 OpenAI’s o1 variant, released in December 2024 (Figure models and has collected more than 340,000 public votes. 2.6.5). LMSYS Chatbot Arena for LLMs: Elo rating (Math) Source: LMSYS, 2025 | Chart: 2025 AI Index report Figure 2.6.5 FrontierMath Members of the math community have highlighted limitations mathematical problems. These problems, vetted by in the current suite of math benchmarks, calling for the expert mathematicians, often require hours, days, or even development of new benchmarks to evaluate increasingly collaborative research efforts to solve. Figure 2.6.6 illustrates advanced AI systems. One significant challenge is saturation: sample problems included on the benchmark. Epoch AI AI systems are approaching near-perfect performance evaluated six leading LLMs on the FrontierMath benchmark: on benchmarks like GSM8K and MATH, which primarily o1-preview, o1-mini, GPT-4o, Claude 3.5 Sonnet, Grok 2 assess high school and college-level mathematics. To push Beta, and Gemini 1.5 Pro 002. At the time the benchmark the boundaries further, researchers have voiced a need for was released, the best-performing model, Gemini 1.5 Pro, benchmarks that test truly advanced mathematics, including managed to solve just 2.0% of the problems—a significantly problems in number theory, real analysis, algebraic geometry, lower success rate than it achieved on other math benchmarks and category theory. (Figure 2.6.7). However, OpenAI’s o3 model is reported to have scored 25.2% on the benchmark. The creators of FrontierMath is a new benchmark introduced by Epoch AI FrontierMath hope the benchmark will remain a rigorous that features hundreds of original, exceptionally challenging challenge for cutting-edge AI systems for years to come. Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.6 Mathematics Sample problems from FrontierMath Source: Glazer et al., 2024 Figure 2.6.6 100% 80% 60% 40% 25.20% 20% 0.00% 1.00% 1.00% 2.00% 2.00% 0% Grok 2 Beta GPT-4o o1-preview Claude 3.5 Sonnet Gemini 1.5 Pro o3 (2024-08-06) (2024-10-22) (002) Model Figure 2.6.7 Table of Contents Chapter 2 Preview 136 devlos tnecreP FrontierMath: percent solved Source: Glazer et al., 2024; OpenAI, 2025 | Chart: 2025 AI Index report Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.6 Mathematics Highlight: Learning and Theorem Proving DeepMind employed its systems, AlphaProof and AlphaGeometry 2, to solve four out of six problems in 25 the 2024 International Mathematical Olympiad (IMO), achieving a performance level equivalent to that of a silver 20 medalist. AlphaGeometry solved 25 out of 30 Olympiad geometry problems in the benchmarking set, surpassing 15 the average score of an IMO silver medalist, who typically solves 22.9 (Figure 2.6.8). The IMO, established in 1959, 10 is the world’s oldest and most prestigious competition for young mathematicians. 5 AlphaProof is a reinforcement learning system derived from 0 A an lp d h G aZ o e . r I o t , t w ra h in ic s h i w ts a e s lf p t r o e v s i o o l u v s e l y p a r p o p b l l i e e m d s t o b c y h g e e s n s, e s ra h t o in g g i, W u’s method Honorable m B e r n o t n io z n e s meda S li i s lv t er medali A st lphaGeome G tr o y ld medalist hypotheses that are then verified using the Lean interactive Figure 2.6.8 proof system. A fine-tuned Gemini model is utilized to translate natural language problem statements into formal representations, building a comprehensive training library. A 2024 update of that report, based on the latest version of In this year’s competition, AlphaProof successfully solved TPTP containing over 25,000 problems, indicates that fully two algebra problems and one number theory problem, automatic systems can now solve 89% of the problems in but failed to solve two combinatorics problems. TPTP v.9.0.0. AlphaGeometry 2 is a neuro-symbolic hybrid system Ideally, TPTP systems could be tested on IMO problems, featuring a language model based on Gemini and trained and AlphaProof and AlphaGeometry on TPTP problems— on extensive synthetic data. Prior to 2024, AlphaGeometry some of which have never been solved by humans, let could solve 83% of historical IMO geometry problems. alone by ATP systems. Unfortunately, neither of these tests During the 2024 competition, it solved the sole geometry has been conducted. The primary reason is that the logics problem in just 24 seconds. For the 2024 test, competition supported by the different systems differ significantly, and problems were manually translated into Lean’s formal translators between them do not yet exist. Additionally, representation. while substantial, the TPTP library is not large enough to serve as a training set for AlphaProof without generating a It remains unknown how AlphaProof and AlphaGeometry considerable number of synthetic examples. would perform on traditional theorem-proving benchmarks such as TPTP, which has been used since 1997 to assess the performance of automatic theorem-proving (ATP) systems, particularly those applied to software verification. The AI Index reported on the state of ATP in its 2021 report. Table of Contents Chapter 2 Preview 137 smelborp devlos fo rebmuN Number of solved geometry problems in IMO-AG-30 Source: Trinh et al., 2024 | Chart: 2025 AI Index report 25.93 25.00 22.85 19.29 14.27 10.00 Artificial Intelligence Index Report 2025 100% 80% 60% 40% 20% 0% 2023 2024 Table of Contents Chapter 2 Preview 138 ycarucca llarevO Chapter 2: Technical Performance 2.7 Reasoning Reasoning in AI involves the ability of AI systems to draw logically valid conclusions from different forms of information. AI systems are increasingly being tested in diverse reasoning contexts, including visual (reasoning about images), moral (understanding moral dilemmas), and social reasoning (navigating social situations). 2.7 Reasoning Sample MMMU questions Source: Yue et al., 2023 General Reasoning General reasoning pertains to AI systems being able to reason across broad, rather than specific, domains. As part of a general reasoning challenge, for example, an AI system might be asked to reason across multiple subjects rather than perform one narrow task (e.g., playing chess). MMMU: A Massive Multi-discipline Multimodal Figure 2.7.1 Understanding and Reasoning Benchmark for Expert AGI In recent years, the reasoning abilities of AI systems have MMMU on validation set: overall accuracy advanced so much that older benchmarks like SQuAD (for Source: MMMU Leaderboard, 2024 | Chart: 2025 AI Index report textual reasoning) and VQA (for visual reasoning) have become saturated, indicating a need for more challenging reasoning tests. 82.60%, human expert (medium) 78.20% Responding to this, researchers from the United States and Canada recently developed MMMU, the massive multi- discipline multimodal understanding and reasoning benchmark for expert AGI (artificial general intelligence). MMMU comprises about 11,500 college-level questions from six core disciplines: art and design, business, science, health and medicine, humanities and social science, and technology and engineering (Figure 2.7.1). The question formats include charts, maps, tables, chemical structures, and more. MMMU is among the most demanding tests of perception, knowledge, and reasoning in AI to date. As of January 2025, the highest-performing model is OpenAI’s o1, achieving a score of 78.2%—a significant improvement from the state-of-the-art score of 59.4% reported in last year’s AI Index Figure 2.7.2 (Figure 2.7.2). While this top score remains below the medium and high human expert baselines, as with other benchmarks covered in the Index, AI systems are rapidly closing the gap. Artificial Intelligence Index Report 2025 100% 80% 60% 40% 20% 0% 2023 2024 Table of Contents Chapter 2 Preview 139 ycaruccA Chapter 2: Technical Performance 2.7 Reasoning GPQA: A Graduate-Level Google-Proof Q&A Benchmark In 2023, researchers from NYU, Anthropic, and Meta Last year’s AI Index reported that the best-performing AI introduced the GPQA benchmark to test general, model, GPT-4, achieved only 38.8% on the diamond test set. multisubject AI reasoning. This dataset consists of 448 In just a year, top AI systems have made significant strides, difficult multiple-choice questions that cannot be easily with OpenAI’s o3 model, launched in December 2024, answered by web search. The questions were crafted posting a state-of-the-art score of 87.7%, a 48.9 percentage by subject-matter experts in various fields like biology, point improvement from the state-of-the-art score in 2023 physics, and chemistry (Figure 2.7.3). On the diamond set— (Figure 2.7.4). In fact, o3’s score was the first to exceed the most challenging subset of the dataset and the one the baseline set by expert human validators. AI systems most frequently tested by AI developers—human experts are rapidly advancing on challenging new benchmarks like achieved an accuracy rate of 81.3%. MMMU and GPQA, which were recently introduced to push the limits of AI capabilities. Sample chemistry question from GPQA Source: Rein et al., 2023 Figure 2.7.3 GPQA on the diamond set: accuracy Source: AI Index, 2025 | Chart: 2025 AI Index report 87.70% 81.20%, expert human validators Figure 2.7.4 Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.7 Reasoning ARC-AGI As AI systems continue to advance, claims about the imminent learning library. ARC-AGI tests the ability of systems to arrival of artificial general intelligence (AGI) have become generalize beyond prior training. More specifically, the more frequent. There is no universally accepted definition ARC-AGI benchmark presents AI systems with a set of of AGI. Some computer scientists define it as AI systems independent tasks. Each task includes demonstration or input that match or surpass human cognitive abilities across a pairs followed by one or more test or output scenarios (Figure broad range of tasks. Others emphasize that the definition 2.7.5). This benchmark emphasizes generalized learning should encompass the capacity for general learning and skill ability: It is impossible for systems to prepare in advance, acquisition, describing AGI as a system “capable of efficiently as each task introduces a unique logic. The tasks require no acquiring new skills and solving novel problems for which it specialized world knowledge or language skills but instead was neither designed nor trained.” draw on assumed prior knowledge, such as the concept of objects, basic topology, and elementary arithmetic— ARC-AGI is a benchmark introduced in 2019 by François concepts typically mastered by children at an early age. Chollet, the creator of Keras, a popular open-source deep Sample ARC-AGI task Source: Chollet et al., 2025 Figure 2.7.5 Table of Contents Chapter 2 Preview 140 Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.7 Reasoning 100% 80% 60% 40% 20% 0% 2019 2020 2021 2022 2023 2024 Figure 2.7.6 Table of Contents Chapter 2 Preview 141 erocs hgiH ARC-AGI has proven to be an exceptionally challenging Researchers attribute the overall slow progress in previous benchmark. When it was first run in 2020, the top-performing years to an overemphasis on scaling AI models—making system achieved a score of only 20% (Figure 2.7.6). Four years them larger and feeding them increasing amounts of training later, this score had risen to just 33%. However, this year has data. While this approach improved task-specific skills, seen substantial progress, with OpenAI’s o3 model achieving it did little to enhance the ability of AI systems to tackle a score of 75.7%. In settings where o3 was allocated a high- problems without prior exposure or training data. This compute budget exceeding the benchmark’s $10,000 limit, it year’s improvements suggest a shift in focus toward more achieved a score of 87.5%. meaningful advancements in generalization and search capabilities. ARC-AGI-1 on private evaluation set: high score Source: Chollet et al., 2025; OpenAI, 2025 | Chart: 2025 AI Index report 75.70% Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.7 Reasoning Humanity’s Last Exam As highlighted in both this and last year’s AI Index, questions across dozens of subject areas (Figure 2.7.7). The many popular AI benchmarks, such as MMLU, GSM8K, dataset features multimodal questions, contributed by and HumanEval, have reached saturation. In response, subject matter experts, including leading professors and researchers have developed more challenging benchmarks graduate-level reviewers, that resist simple internet lookups to better assess AI capabilities. Recently, members of the or database retrieval. Additionally, each question was tested team behind MMLU introduced Humanity’s Last Exam against state-of-the-art LLMs before inclusion; if an existing (HLE), a new benchmark comprising 2,700 highly challenging model could answer it, the question was rejected. Same questions on HLE Source: Phan et al., 2025 Figure 2.7.7 Table of Contents Chapter 2 Preview 142 Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.7 Reasoning 100% 80% 60% 40% 20% 8.80% 7.20% 3.10% 3.90% 4.80% 5.20% 0% GPT-4o Grok-2 Clause 3.5 Sonnet Gemini 1.5 Pro Gemini 2.0 Flash Thinking o1 Table of Contents Chapter 2 Preview 143 ycaruccA Initial testing indicates that HLE is highly challenging for the benchmark are closely monitoring how quickly LLMs current AI systems. Even top models, such as OpenAI’s improve, and they speculate that performance could exceed o1, score just 8.8% (Figure 2.7.8). The researchers behind 50% by the end of 2025. Humanity’s Last Exam (HLE): accuracy Source: Phan et al., 2025 | Chart: 2025 AI Index report Figure 2.7.8 Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.7 Reasoning Blocksworld Mystery Blocksworld 100% 97.80% 80% 62.60% 60% 54.80% 52.80% 40% 35.50% 23.80% 20% 8.00% 0.00% 0.00% 0% Claude 3.5 (Sonnet) GPT-4o LLama 3.1 405B Gemini 1.5 Pro o1-preview Model Table of Contents Chapter 2 Preview 144 tcerroc secnatsnI Planning Planning is an intelligent task that involves reasoning The release of OpenAI’s o1 was met with enthusiasm from the about actions that alter the world. It requires considering AI research community, as it was designed to actively reason hypothetical future states, including potential external rather than function purely as an autoregressive LLM. When actions and other transformative events. tested on the PlanBench benchmark, o1 showed significant improvements, though it still struggles with reliable and PlanBench consistent planning. In the Blocksworld zero-shot evaluation Claims have been made that LLMs can solve planning (one specific planning evaluation domain), o1 achieved a score problems. A group from Arizona State University has of 97.8%—far surpassing the next best LLM, Llama 3.1 405B proposed PlanBench, a benchmark suite containing problems (62.6%), and dramatically outperforming GPT-4o (35.5%) used in the automated planning community, especially those (Figure 2.7.9). In the more challenging Mystery Blocksworld used in the International Planning Competition. PlanBench is domain, where some answers are syntactically obfuscated, designed to test LLMs on planning tasks. The benchmark tests o1 scored 52.8% zero-shot, compared to just 0.8% for Llama models on 600 problems in which a hand tries to construct 3.1 405B. GPT-4, by contrast, scored 0%. stacks of blocks when it is only allowed to move one block at a time to a table or to the top of a clear block. After the Planning is a combinatorial problem, and solving problems benchmark was released in 2022, researchers demonstrated with long solutions is expected to take more than linear time. that models like GPT-4 and GPT-3.5 still struggled with Not surprisingly, when tested on instances that require at planning tasks. least 20 steps, o1 manages to solve just 23.6%. PlanBench: instances correct Source: Valmeekam et al., 2024 | Chart: 2025 AI Index report Figure 2.7.9 Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.8 AI Agents AI agents, autonomous or semiautonomous systems designed to operate within specific environments to accomplish goals, represent an exciting frontier in AI research. 2.8 AI Agents These agents have a diverse range of potential applications, from assisting For decades, the topic of AI agents has been widely discussed in the AI community, in academic research and scheduling meetings to facilitating online yet few benchmarks have achieved widespread adoption, including those featured shopping and vacation booking. As in last year’s Index, such as AgentBench and MLAgentBench. This is partly due to suggested by many recent corporate the inherent complexity of benchmarking agentic tasks, which are typically more releases, agentic AI has become a topic of increasing interest in the diverse, dynamic, and variable than tasks like image classification or answering technical world of AI. language questions. As AI continues to evolve, it will become important to develop effective methods to evaluate AI agents. VisualAgentBench VisualAgentBench (VAB), launched in 2024, represents a tests agents across three broad categories of tasks: embodied significant step forward in the evaluation of agentic AI. This agents (operating in household and gaming environments), benchmark reflects the growing multimodality of AI models GUI agents (interacting with mobile and web applications), and their increasing proficiency in navigating both virtual and and visual design agents (such as CSS debugging) (Figure embodied environments. VAB addresses the need to assess 2.8.1). This comprehensive approach creates a robust agent performance in diverse settings that extend beyond evaluation suite of agents’ capabilities across varied and environments reliant solely on linguistic commands. VAB dynamic contexts. Tasks on VisualAgentBench Source: Liu et al., 2024 Figure 2.8.1 Table of Contents Chapter 2 Preview 145 Artificial Intelligence Index Report 2025 VAB presents a significant challenge for AI systems. The top- around 20% (Figure 2.8.2). According to the benchmark’s performing model, GPT-4o, achieves an overall success rate of authors, these results reveal that current AI models are far just 36.2%, while most proprietary language models average from ready for direct deployment in agentic settings. 36.20 35 31.70 29.90 30 26.90 25 21.90 20.50 19.80 20 16.00 15 12.00 10.30 10.50 10 8.40 8.90 7.70 6.30 5 0 gem ini-1.0- L p L ro a V |5 A 8 -1.5 CogVLM (Fine-tuning L ) M C M og s A C g o e g n L V t L L a M VA 2 -NeX G T LM -4V InternVL-2 gem ini-1.5- ( p P r r o o | m 48 pting c ) l g a p u t d - e 4 - o 3 - - m op c in u la i s - u 2 d 0 e 2 - 4 3 - . 0 5 7 - g s -1 p o 8 t n - n 4 e -t t urbo g - p 0 t 4 -4 0 - 9 vision g - p p t r - e 4 v 0 i - e 2 w 024-05-13 Model RE-Bench The emergence of increasingly capable agentic AI systems has fueled predictions that AI might soon take on the work of computer scientists or researchers. However, until recently, there were few benchmarks designed to rigorously test the R&D capabilities of top-performing AI systems. In 2024, researchers addressed this gap with the launch of RE-Bench, a benchmark featuring seven challenging, open-ended ML research environments. These tasks, informed by data from 71 eight-hour attempts by over 60 human experts, include optimizing a kernel, conducting a scaling law experiment, and fine- tuning GPT-2 for question answering, among others (Figure 2.8.3). Table of Contents Chapter 2 Preview 146 )egareva( etar sseccuS Chapter 2: Technical Performance 2.8 AI Agents VisualAgentBench on the test set: success rate Source: VisualAgentBench Leaderboard, 2025 | Chart: 2025 AI Index report Figure 2.8.2 RE-Bench Process and Flow Source: Wijk et al., 2024 Figure 2.8.3 Artificial Intelligence Index Report 2025 Researchers uncovered two key findings when comparing the 32-hour budget, humans outperform AI by a factor of two. performance of humans and frontier AI models. In short time The researchers also note that for certain tasks, AI agents horizon settings, such as with a two-hour budget, the best AI already demonstrate expertise comparable to humans but systems achieve scores four times higher than human experts can deliver results significantly faster and at a lower cost. (Figure 2.8.4). However, as the time budget increases, human For example, AI agents can write custom Triton kernels more performance begins to surpass that of AI. With an eight-hour quickly than any human expert. budget, human performance slightly exceeds AI, and with a 1.40 Claude 3.5 Sonnet (Old) (Modular) Claude 3.5 Sonnet (New) (Modular) Claude 3.5 Sonnet (New) (AIDE) o1-preview (AIDE) Human 1.20 1.00 0.80 0.60 0.40 0.20 0.00 30min 2h 8h 16h 32h 64h Time budget (time limit per run x number of attempts) Table of Contents Chapter 2 Preview 147 erocs dezilamron egarevA Chapter 2: Technical Performance 2.8 AI Agents RE-Bench: average normalized score@k Source: Wijk et al., 2024 | Chart: 2025 AI Index report Figure 2.8.4 Artificial Intelligence Index Report 2025 100% 80% 60% 40% 20% 0% 2023 2024 Table of Contents Chapter 2 Preview 148 erocs egarevA Chapter 2: Technical Performance 2.8 AI Agents GAIA GAIA is a benchmark for General AI assistants Sample questions on GAIA introduced by Meta in May 2024. It consists of 466 Source: Meta, 2024 questions designed to assess AI systems’ ability to perform a broad range of tasks, including reasoning, multimodal processing, web browsing, and tool use. Unlike straightforward, exam-style questions, GAIA challenges AI models with complex, multistep problems that may require searching the open web, interpreting multimodal inputs, and reasoning through intricate scenarios (Figure 2.8.5). When researchers launched GAIA, they found that existing LLMs lagged significantly behind human performance. For instance, GPT-4 with plugins correctly answered only 15% of the questions, compared to 92% for human respondents. Figure 2.8.5 As with other recently introduced AI benchmarks, performance on GAIA has improved rapidly. In 2024, the GAIA: average score top system achieved a score of 65.1%, marking a roughly Source: GAIA Leaderboard, 2025 | Chart: 2025 AI Index report 30 percentage point increase from the highest score recorded in 2023 (Figure 2.8.6). 65.12% Figure 2.8.6 Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.9 Robotics and Automous Motion Advancements in AI over the past decade have paved the way for exciting new developments in the field of robotics. Especially with the rise of foundation models, robots 2.9 Robotics and are now able to iteratively learn from their surroundings, adapt flexibly to Autonomous Motion new settings, and make autonomous decisions. This section explores key robotic benchmarks and recent trends, including the rise of humanoids, Robotics algorithmic advancements from DeepMind, and the emergence of robotic foundation models. It RLBench concludes by studying developments One of the most widely adopted benchmarks in the robotics community is RLBench in self-driving cars. (Robot Learning Benchmark). Launched in 2019, it features 100 unique tasks of varying complexity, from simple target reaching to opening an oven and placing a tray inside.12 Researchers typically evaluate new robotic systems on a standardized subset of 18 tasks to gauge performance. Figure 2.9.1 visualizes some of the tasks in RLBench. Tasks on VisualAgentBench Source: James et al., 2019 Figure 2.9.1 12 Target reaching in robotics refers to the process by which a robotic system moves its end-effector (such as a robotic arm or gripper) toward a specific goal position or object in space. Table of Contents Chapter 2 Preview 149 Artificial Intelligence Index Report 2025 100% 80% 60% 40% 20% 0% 2022 2023 2024 2025 Table of Contents Chapter 2 Preview 150 etar sseccuS Chapter 2: Technical Performance 2.9 Robotics and Automous Motion As of January 2025, the top-performing model on this subset an 86.8% success rate, marking a 2.8 percentage point is SAM2Act, a collaboration between researchers at the improvement over the previous state-of-the-art in 2024 and University of Washington, Universidad Católica San Pablo, a 66.7 percentage point increase from the leading score in Nvidia, and the Allen Institute for AI. SAM2Act achieved 2021 (Figure 2.9.2). RLBench: success rate (18 tasks, 100 demo/task) Source: Papers With Code, 2025 | Chart: 2025 AI Index report 86.80% Figure 2.9.2 Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.9 Robotics and Automous Motion Highlight: Humanoid Robotics 2024 was a significant year for robotics, marked by the to perform complex tasks such as making coffee and growing prevalence of humanoid robots—machines with assisting in automotive assembly by placing sheet metal humanlike bodies designed to mimic human functions. into a car fixture (Figure 2.9.3 and Figure 2.9.4). They are For example, Figure AI, a robotics startup dedicated to also integrated with OpenAI and can engage in speech-to- developing general-purpose humanoid robots, launched speech reasoning, whereby the robot explains its actions Figure 02 in 2024, its most advanced model yet. Standing and responds to queries about its behavior. Figure’s success 5 feet 6 inches tall, weighing 154 pounds, and capable of follows that of other companies that released humanoid handling a 44-pound payload, Figure 02 operates for up robots, like Tesla’s Optimus, first launched in 2002 and to five hours on a single charge. Figure robots are able redesigned in 2023, and Boston Dynamics’ Atlas humanoid. Figure robot making coffee Source: Figure AI Figure 2.9.3 Figure robot assisting in automotive assembly Source: Figure AI Figure 2.9.4 Table of Contents Chapter 2 Preview 151 Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.9 Robotics and Automous Motion Highlight: DeepMind’s Developments In 2023, DeepMind launched two robotic models, AutoRT workflow Source: Google DeepMind, 2024 PaLM-E and RT-2. These models were novel in their use of transformer-based architectures, typically found in language modeling, and their training on both manipulation data and language data. This dual training approach enabled them to excel at both robotic manipulation and text generation. In 2024, DeepMind introduced AutoRT, an AI system that leverages large foundation models to autonomously generate diverse training data for robots. It coordinates multiple video-equipped robots, guiding them through various environments, devising creative tasks for them to perform, and meticulously documenting these tasks (Figure 2.9.5). This documentation then serves as training data for future robotic learning. To date, AutoRT has generated a dataset of 77,000 robotic trials spanning 6,650 unique tasks. Greater amounts of robotic training data will be important to improve the training of future robotic systems. Conversely, SARA-RT, also from Google DeepMind, improves the efficiency of transformer-based robotic Figure 2.9.5 models by significantly improving their speed. While transformers are powerful, they are also computationally with a technique called “up-training,” which converts the intensive as they rely on quadratic complexity attention quadratic complexity of standard transformers into a linear mechanisms. This means that doubling the input size of model. This method drastically reduces computational data provided to a model can quadruple computational demands while maintaining performance quality. Figure 2.9.6 requirements. This challenge complicates attempts to compares speed tests of AI models enhanced with the SARA scale robotic models. SARA-RT addresses this challenge technique against those without. In point cloud processing, Speed tests for SARA vs. non-SARA enhanced models Source: Google DeepMind, 2024 Figure 2.9.6 Table of Contents Chapter 2 Preview 152 Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.9 Robotics and Automous Motion Highlight: DeepMind’s Developments (cont’d) which enables robots to interpret 3D environments, and in tasks that historically have been extremely challenging for image processing, SARA-based models run significantly faster robots. The researchers demonstrated that combining a large while avoiding major increases in run-time at scale. imitation learning dataset with a transformer-based learning architecture is a highly effective approach for overcoming Other developments from DeepMind include ALOHA these difficulties. The ALOHA approach enabled Google’s (Autonomous Learning of High-level Activities) and robot to effectively learn a diverse range of tasks, including DemoStart. ALOHA Unleashed is a breakthrough in enabling hanging a shirt, stacking kitchen items, and tying shoelaces robots to perform intricate dexterous manipulation tasks, (Figure 2.9.7). As shown in Figure 2.9.8, ALOHA-trained robots such as tying shoelaces or hanging T-shirts on coat hangers— achieved a high success rate across these tasks. ALOHA-trained robot attempting complex tasks Source: Google DeepMind, 2024 Figure 2.9.7 95% 95% 75% 75% 75% 70% 70% 65% 40% 40% 25% Table of Contents Chapter 2 Preview 153 ysseMtrihS ysaEtrihS ysseMecaL ysaEecaL ecalpeRregniF 3-tresnIraeG 2-tresnIraeG 1-tresnIraeG nehctiKmodnaR kroF+puC+lwoB- nehctiKmodnaR puC+lwoB- nehctiKmodnaR lwoB- 100% 80% 60% 40% 20% 0% Shirt hanging Shoelace tying Robot nger Gear insertion Random kitchen replacement stack etar sseccuS ALOHA: success rate Source: Zhao et al., 2024 | Chart: 2025 AI Index report Figure 2.9.8 Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.9 Robotics and Automous Motion Highlight: DeepMind’s Developments (cont’d) Similarly, DemoStart introduces a novel auto-curriculum adopted. DeepMind also introduced a robotic model in reinforcement learning method that enables a robotic arm 2024 that was capable of reaching amateur human-level to master complex behaviors using only sparse rewards performance in competitive table tennis (Figure 2.9.9). and a limited number of demonstrations. This breakthrough Given that achieving human-level speed and performance highlights the potential for robots to learn efficiently with on real-world tasks is an important benchmark for robotics minimal data, reducing the need for data-intensive training research, this achievement is a notable step forward in and making advanced robotics more accessible and widely robotic ability. Robots playing amateur-level table tennis Source: Google DeepMind, 2024 Figure 2.9.9 Table of Contents Chapter 2 Preview 154 Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.9 Robotics and Automous Motion Highlight: Foundation Models for Robotics In 2024, there was a strong push toward developing Nvidia was not alone in this space. Covariant launched foundational models for robotics—systems capable of RFM-1, a robotic foundation model with language reasoning with language while physically operating in the capabilities and real-world maneuverability. Meanwhile, real world. Nvidia introduced GR00T (Generalist Robot LLaRA, developed by researchers at Stony Brook 00 Technology), a general-purpose foundation model University and the University of Wisconsin-Madison, for humanoid robots designed to understand natural integrates perception, communication, and action into language and mimic human movements. Alongside a monolithic, end-to-end deep learning model. These GR00T, Nvidia released data pipelines, simulation new models continue a trend from 2023, which saw the frameworks, and the Thor robotics computer. Figure launch of robotic foundation models like RT-2, PaLM-E, 2.9.10 illustrates the components of GROOT’s launch. This and Open-X Embodiment. robotic development suite is intended to make it easier for the robotic community to scale and build increasingly advanced robotics. GROOT blueprint for synthetic motion generation Source: Nvidia, 2024 Figure 2.9.10 Table of Contents Chapter 2 Preview 155 Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.9 Robotics and Automous Motion Self-Driving Cars Waymo rider-only miles driven without a human Self-driving vehicles have long been a goal for AI researchers driver and technologists. However, their widespread adoption has Source: Waymo, 2024 | Table: 2025 AI Index report been slower than anticipated. Despite many predictions Location Rider-only miles through that fully autonomous driving is imminent, widespread use September 2024 of self-driving vehicles has yet to become a reality. Still, in Los Angeles 1.947M recent years, significant progress has been made. In cities San Francisco 10.209M like San Francisco and Phoenix, fleets of self-driving taxis Phoenix 20.823M are now operating commercially. This section examines Austin 124K recent advancements in autonomous driving, focusing Figure 2.9.11 on deployment, technological breakthroughs and new benchmarks, safety performance, and policy challenges. China’s self-driving revolution is also accelerating, led by companies like Baidu’s Apollo Go, which reported 988,000 Deployment rides across China in Q3 2024, reflecting a 20% year-over-year Self-driving cars are increasingly being deployed worldwide. increase. In October 2024, the company was operating 400 Cruise, a subsidiary of General Motors, launched its robotaxis and announced plans to expand its fleet to 1,000 autonomous vehicles in San Francisco in late 2022 before by the end of 2025. Pony.AI, another Chinese autonomous having its license suspended in 2023 after a litany of safety vehicle manufacturer, has pledged to scale its robotaxi fleet incidents. Waymo, a subsidiary of Alphabet, began deploying from 200 to at least 1,000 vehicles—with expectations that its robotaxis in Phoenix in early 2022 and expanded to San the fleet will reach 2,000 to 3,000 by the end of 2026. China Francisco in 2024. The company has since emerged as one is leading the way in autonomous vehicle testing, with reports of the more successful players in the self-driving industry: As indicating that it is testing more driverless cars than any of January 2025, Waymo operates in four major U.S. cities— other country and currently rolling them out across 16 cities. Phoenix, San Francisco, Los Angeles, and Austin (Figure Robotaxis in China are notably affordable—even cheaper, 2.9.11). Data sourced from October 2024 suggests that across in some cases, than rides provided by human drivers. To the four cities the company provides 150,000 paid rides per support this growth, China has prioritized establishing week, covering over a million miles. Looking ahead, Waymo national regulations to govern the deployment of driverless plans to test its vehicles in 10 additional cities, including Las cars. Beyond the self-driving revolution taking place in the Vegas, San Diego, and Miami. The company chose testing U.S. and China, European startups like Wayve are beginning locations, such as upstate New York and Truckee, California, to gain traction in the industry. that experience snowy weather so it can assess the vehicles in diverse driving conditions. There has also been notable progress in self-driving trucks, with companies like Kodiak completing its first driverless deliveries and Aurora reporting steady advancements, including over 1 million miles of autonomous freight hauling on U.S. highways since 2021— albeit with human safety drivers present. Still, challenges remain in bringing this technology to market, with Aurora recently announcing it would delay the commercial launch of its fleet from the end of 2024 until April 2025. Table of Contents Chapter 2 Preview 156 Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.9 Robotics and Automous Motion Technical Innovations and New Benchmarks Baidu’s RT-6 Source: Verge, 2024 Over the past year, self-driving technology has advanced significantly, both in vehicle capabilities and benchmarking methods. In October 2024, Tesla unveiled the Cybercab, a two-passenger autonomous vehicle without a steering wheel or pedals, which is set for production in 2026 at a price of under $30,000. Tesla also unveiled the Robovan, an electric autonomous van designed to transport up to 20 passengers. Meanwhile, Baidu’s Apollo Go launched its latest-generation robotaxi, the RT6, across multiple cities in China (Figure 2.9.12). With a price tag of just $30,000 and a battery-swapping system, the RT6 represents a major step toward making self-driving technology more cost-effective and scalable. As costs continue Figure 2.9.12 to decline, the adoption of autonomous vehicles is expected to accelerate. Notable business partnerships have also advanced Most existing benchmarks for end-to-end autonomous self-driving technology, including Uber’s collaboration with driving rely on open-loop evaluation, which can be WeRide—the world’s first publicly listed robotaxi company— restrictive. Open-loop settings fail to test how autonomous to develop an autonomous ride-sharing platform in Abu Dhabi. agents react to real-world conditions and often lead to models that memorize driving patterns rather than learning In 2024, several new benchmarks were introduced to evaluate to drive authentically. While closed-loop benchmarks like self-driving capabilities. One notable example is nuPlan, Town05Long and Longest6 exist, they primarily assess basic developed by Motional. It is a large-scale, autonomous driving driving skills rather than performance in complex, interactive dataset designed to test machine-learning-based motion scenarios. Bench2Drive is another new benchmark that planners. The benchmark includes 1,282 hours of diverse improves on these limitations by providing a comprehensive, driving scenarios from multiple cities, along with a simulation realistic, closed-loop testing simulation environment for end- and evaluation framework that enables planners’ actions to to-end autonomous vehicles (Figure 2.9.13). It includes a be tested in closed-loop settings. Another recent benchmark training set with over 2 million fully annotated frames sourced is OpenAD, the first real-world, open-world autonomous from more than 10,000 clips, as well as an evaluation suite driving benchmark for 3D object detection. OpenAD focuses with 220 short routes designed to test autonomous driving on domain generalization—the ability of autonomous driving capabilities in diverse conditions. Figure 2.9.14 displays systems to adapt across diverse sensor configurations—and the driving scores of various autonomous driving methods open-vocabulary recognition, which allows systems to identify evaluated on the Bench2Drive benchmark.13 previously unseen semantic categories. An overview of Bench2Drive Source: Jia et al., 2024 Figure 2.9.13 13 This metric accounts for both route completion and infractions, averaging route completion percentages while applying penalties based on infraction severity. For more detail on the driving score methodology, see Section 3 of the Bench2Drive paper. Table of Contents Chapter 2 Preview 157 Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.9 Robotics and Automous Motion 64.22 62.44 59.90 49.30 45.81 42.35 40.70 40.73 30.47 18.05 Table of Contents Chapter 2 Preview 158 *lrtc-PCT *PCT noitallitsid o/w jart-PCT *jart-PCT PLM-DA yniT-DAinU DAV esaB-DAinU *eciwTknihT *retpadAevirD 60 50 40 30 20 10 0 2022 2023 ↑erocs gnivirD Bench2Drive: driving score Source: Jia et al., 2024 | Chart: 2025 AI Index report Figure 2.9.14 Safety Standards Emerging research suggests that self-driving cars may be 3.65 fewer police-reported crashes per million miles (Figure safer than human-driven vehicles. Figure 2.9.15 compares 2.9.15). Figure 2.9.16 highlights the differences in incident the number of reported incidents per million miles driven by rates across various crash locations, revealing that across all Waymo vehicles to the estimated rates if humans had driven locations with available data, Waymo vehicles consistently the same distance. The data shows that Waymo vehicles recorded lower rates of airbag deployments, injury-reported had significantly fewer incidents, including 1.42 fewer airbag crashes, and police-reported incidents. deployments, 3.16 fewer crashes with reported injuries, and Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.9 Robotics and Automous Motion 6 5.91 5 4.06 4 3 2.26 2 1.74 1 0.90 0.32 0 Human benchmark Waymo Human benchmark Waymo Human benchmark Waymo Airbag deployment Any-injury-reported Police-reported Table of Contents Chapter 2 Preview 159 selim noillim rep stnedicnI Waymo driver vs. human benchmarks in Phoenix and San Francisco Source: Waymo, 2024 | Chart: 2025 AI Index report Airbag deployment Any-injury-reported Police-reported 0% −20% −40% -51% −60% -59% -62% −80% -78% -77% -76% -81% -87% -88% −100% Phoenix and San Francisco Phoenix San Francisco kramhcneb ot ecnere id tnecreP Figure 2.9.1514 Waymo driver percent di erence to human benchmark in Phoenix and San Francisco Source: Waymo, 2024 | Chart: 2025 AI Index report Figure 2.9.16 14 Waymo’s safety data is continuously updated in real time, so the totals reported in this section may not fully align with those currently displayed on their website. Artificial Intelligence Index Report 2025 Chapter 2: Technical Performance 2.9 Robotics and Automous Motion 3.50 3.00 2.50 2.00 1.50 1.00 0.50 0.00 Swiss Re overall Latest-generation Waymo Swiss Re overall Latest-generation Waymo driving population HDVs driving population HDVs Property damage Bodily injury Table of Contents Chapter 2 Preview 160 selim noillim rep ycneuqerf smialC Waymo, in collaboration with Swiss Re, one of the world’s claims and a 92% reduction in bodily injury claims (Figure leading reinsurers, also conducted a study analyzing liability 2.9.17). In real terms, across 25.3 million miles driven, Waymo claims related to collisions over several million miles driven by vehicles were involved in just nine property damage claims and its fully autonomous vehicles. The study compared Waymo’s two bodily injury claims, whereas human drivers over the same liability claims to human-driver baselines derived from Swiss distance would be expected to incur 78 property damage Re’s extensive dataset, which includes over 500,000 claims claims and 26 bodily injury claims. The Waymo drivers were and 200 billion miles of driving data. The results showed that also significantly safer than latest-generation human-driven Waymo vehicles had an 88% reduction in property damage vehicles that are equipped with added safety features. Comparison of liability insurance claims by type: Waymo driver vs. human-driven vehicles Source: Di Lillo et al., 2024 | Chart: 2025 AI Index report Figure 2.9.17 Artificial Intelligence Index Report 2025 CHAPTER 3: Responsible AI Text and analysis by Anka Reuel Artificial Intelligence Index Report 2025 Chapter 3: Responsible AI Overview 162 Measuring Implicit Bias in Chapter Highlights 163 Explicitly Unbiased LLMs 197 3.1 Background 165 3.8 Transparency and Explainability 199 Definitions 165 Featured Research 199 Foundation Model Transparency Index v1.1 199 3.2 Assessing Responsible AI 166 AI Incidents 166 3.9 Security and Safety 201 Examples 167 Benchmarks 201 Limited Adoption of RAI Benchmarks 169 HELM Safety 201 Factuality and Truthfulness 170 AIR-Bench 202 Hughes Hallucination Evaluation Model (HHEM) Leaderboard 170 Featured Research 204 Highlight: FACTS, SimpleQA, Beyond Shallow Safety Alignment 204 and the Launch of Harder Improving the Robustness to Persistently Factuality Benchmarks 171 Harmful Behaviors in LLMs 205 3.3 RAI in Organizations and Businesses 173 3.10 Special Topics on RAI 207 Highlight: Longitudinal Perspective 180 AI Agents 207 Identifying the Risks of LM Agents 3.4 RAI in Academia 184 With LM-Simulated Sandboxes 207 Aggregate Trends 184 Jailbreaking Multimodal Agents With a Single Image 207 Topic Area 187 Election Misinformation 209 AI Misinformation in the 3.5 RAI Policymaking 191 US Elections 209 Rest of World 2024 AI-Generated 3.6 Privacy and Data Governance 192 Election Content 210 Featured Research 192 Large-Scale Audit of Dataset Licensing and Attribution in AI 192 ACCESS THE PUBLIC DATA Data Consent in Crisis 193 3.7 Fairness and Bias 195 Featured Research 195 Racial Classification in Multimodal Models 195 Table of Contents 162 AArrttiifificciiaall IInntteelllliiggeennccee IInnddeexx RReeppoorrtt 22002255 CHAPTER 3: Responsible AI Overview Artificial intelligence is now deeply integrated into nearly every aspect of our lives. It is reshaping sectors like education, finance, and healthcare, where algorithm-driven insights guide critical decisions. While this shift offers significant benefits, it also brings with it notable risks. The past year has seen a continued concentration of effort on the responsible development and deployment of AI systems. This chapter examines trends in responsible AI (RAI) across several dimensions. It begins by establishing key RAI definitions before assessing broadly relevant issues such as AI incidents, standardization challenges in LLM responsibility, and benchmarks for model factuality and truthfulness. Next, it explores RAI trends within key societal sectors—industry, academia, and policymaking—and analyzes specific subtopics, including privacy and data governance, fairness, transparency and explainability, and security and safety, using benchmarks that illuminate model performance and highlights of notable research. The chapter concludes with a study of two special RAI topics: agentic AI and election misinformation. Table of Contents Chapter 3 Preview 163 AArrttiifificciiaall IInntteelllliiggeennccee IInnddeexx RReeppoorrtt 22002255 CHAPTER 3: Responsible AI Chapter Highlights 1. Evaluating AI systems with responsible AI criteria is still uncommon, but new benchmarks are beginning to emerge. Last year’s AI Index highlighted the lack of standardized RAI benchmarks for LLMs. While this issue persists, new benchmarks such as HELM Safety and AIR-Bench help to fill this gap. 2. The number of AI incident reports continues to increase. According to the AI Incidents Database, the number of reported AI-related incidents rose to 233 in 2024—a record high and a 56.4% increase over 2023. 3. Organizations acknowledge RAI risks, but mitigation efforts lag. A McKinsey survey on organizations’ RAI engagement shows that while many identify key RAI risks, not all are taking active steps to address them. Risks including inaccuracy, regulatory compliance, and cybersecurity were top of mind for leaders with only 64%, 63%, and 60% of respondents, respectively, citing them as concerns. 4. Across the globe, policymakers demonstrate a significant interest in RAI. In 2024, global cooperation on AI governance intensified, with a focus on articulating agreed-upon principles for responsible AI. Several major organizations— including the OECD, European Union, United Nations, and African Union—published frameworks to articulate key RAI concerns such as transparency and explainability, and trustworthiness. 5. The data commons is rapidly shrinking. AI models rely on massive amounts of publicly available web data for training. A recent study found that data use restrictions increased significantly from 2023 to 2024, as many websites implemented new protocols to curb data scraping for AI training. In actively maintained domains in the C4 common crawl dataset, the proportion of restricted tokens jumped from 5–7% to 20–33%. This decline has consequences for data diversity, model alignment, and scalability, and may also lead to new approaches to learning with data constraints. 6. Foundation model research transparency improves, yet more work remains. The updated Foundation Model Transparency Index—a project tracking transparency in the foundation model ecosystem—revealed that the average transparency score among major model developers increased from 37% in October 2023 to 58% in May 2024. While these gains are promising, there is still considerable room for improvement. Table of Contents Chapter 3 Preview 164 AArrttiifificciiaall IInntteelllliiggeennccee IInnddeexx RReeppoorrtt 22002255 CHAPTER 3: Responsible AI Chapter Highlights (cont’d) 7. Better benchmarks for factuality and truthfulness. Earlier benchmarks like HaluEval and TruthfulQA, aimed at evaluating the factuality and truthfulness of AI models, have failed to gain widespread adoption within the AI community. In response, newer and more comprehensive evaluations have emerged, such as the updated Hughes Hallucination Evaluation Model leaderboard, FACTS, and SimpleQA. 8. AI-related election misinformation spread globally, but its impact remains unclear. In 2024, numerous examples of AI-related election misinformation emerged in more than a dozen countries and across over 10 social media platforms, including during the U.S. presidential election. However, questions remain about measurable impacts of this problem, with many expecting misinformation campaigns to have affected elections more profoundly than they did. 9. LLMs trained to be explicitly unbiased continue to demonstrate implicit bias. Many advanced LLMs— including GPT-4 and Claude 3 Sonnet—were designed with measures to curb explicit biases, but they continue to exhibit implicit ones. The models disproportionately associate negative terms with Black individuals, more often associate women with humanities instead of STEM fields, and favor men for leadership roles, reinforcing racial and gender biases in decision making. Although bias metrics have improved on standard benchmarks, AI model bias remains a pervasive issue. 10. RAI gains attention from academic researchers. The number of RAI papers accepted at leading AI conferences increased by 28.8%, from 992 in 2023 to 1,278 in 2024, continuing a steady annual rise since 2019. This upward trend highlights the growing importance of RAI within the AI research community. Table of Contents Chapter 3 Preview 165 Artificial Intelligence Index Report 2025 Chapter 3: Responsible AI 3.1 Background 3.1 Background Definitions In this chapter, the AI Index explores four key dimensions of treatment recommendations, and demonstrates how issues responsible AI: privacy and data governance, transparency like privacy, transparency, etc., could be relevant. Although and explainability, security and safety, and fairness. Other Figure 3.1.1 breaks down various dimensions of responsible dimensions of responsible AI, such as sustainability and AI into specific categories to improve definitional clarity, this reliability, are discussed elsewhere in the report. Figure chapter organizes these dimensions into the following broader 3.1.1 offers definitions for the responsible AI dimensions categories: privacy and data governance, transparency and addressed in this chapter, along with an illustrative example explainability, security and safety, and fairness. Since these of how these dimensions might be practically relevant. The topics are often interrelated, the AI Index adopted this “example” column examines a hypothetical platform that structured approach to organization. employs AI to analyze medical patient data for personalized Responsible AI dimensions, de nitions, and examples Source: AI Index, 2025 | Table: 2025 AI Index report Responsible AI dimensions De nition Example Privacy An individual’s right to con dentiality, anonymity, and Patient data is handled with strict con dentiality, ensuring security protections of their personal data, including the anonymity and protection. Patients consent to whether right to consent and be informed about data usage, their data can be used to train a tumor detection system. coupled with an organization’s responsibility to safeguard these rights when handling personal data. Data governance Establishment of policies, procedures, and standards to Policies and procedures are in place to maintain data ensure the quality, access, and licensing of data, which is quality and permissions for reuse of a public health dataset. crucial for broader reuse and improved accuracy of There are clear data quality pipelines and speci cation of models. use licenses. Fairness and bias Creating algorithms that avoid bias or discrimination, and A medical AI platform designed to avoid bias in treatment considering the diverse needs and circumstances of all recommendations, ensuring that patients from all stakeholders, thereby aligning with broader societal demographics receive equitable care. standards of equity. Transparency Open sharing of how AI systems work, including data The development choices, including data sources and sources and algorithmic decisions, as well as how AI algorithmic design decisions are openly shared. How the systems are deployed, monitored, and managed, covering system is deployed and monitored is clear to health care both the creation and operational phases. providers and regulatory bodies. Explainability The capacity to comprehend and articulate the rationale The AI platform can articulate the rationale behind its behind the outputs of an AI system in ways that are treatment recommendations, making these insights understandable to its users and stakeholders. understandable to doctors and patients to increase trust in the AI system. Security and safety The integrity of AI systems against threats, minimizing Measures are implemented to protect against cyber threats harm from misuse, and addressing inherent safety risks like and to ensure the system’s reliability, minimizing risks from reliability concerns as well as the monitoring and misuse and safeguarding patient health and data. management of safety-critical AI systems. Figure 3.1.1 Table of Contents Chapter 3 Preview 166 Artificial Intelligence Index Report 2025 While the responsible development, deployment, and governance of AI received increased attention in 2024, capturing overall trends in this area is still challenging. This section covers some indicators relevant to capturing responsible AI at the aggregate level. 3.2 Assessing Responsible AI AI Incidents The AI Incident Database (AIID) tracks instances of ethical has been reached on a standard definition, these discussions misuse of AI, such as autonomous cars causing pedestrian highlight the need for more detailed reporting to better fatalities or facial recognition systems leading to wrongful document AI-related risks and their implications. arrests. AI-related incidents sharply increased in 2024, reaching Current incident tracking relies on publicly available media a record high of 233—a 56.4% increase from 2023 (Figure reports, meaning the actual number of incidents is likely 3.2.1). This rise likely reflects both the expanding use of AI and higher, as many go unreported. In 2024, discussions centered heightened public awareness of its impact. Greater familiarity on refining methods for defining and tracking incidents, with AI may also be driving more frequent reporting of particularly those classified as “serious.” While no consensus incidents to relevant databases. 233 200 150 100 50 0 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 Table of Contents Chapter 3 Preview 167 stnedicni IA fo rebmuN Chapter 3: Responsible AI 3.2 Assessing Responsible AI Number of reported AI incidents, 2012–24 Source: AI Incident Database (AIID), 2024 | Chart: 2025 AI Index report Figure 3.2.11 1 The number of AI incidents is continually updated over time, including for previous years. Therefore, the totals reported in Figure 3.2.1 might not align with the more recent totals published on the AI Incident Database. Artificial Intelligence Index Report 2025 Chapter 3: Responsible AI 3.2 Assessing Responsible AI Examples Growing threat of deepfake intimate images (Jun. 18, 2024) The next section details recent AI incidents to shed light on Elliston Berry, a 15-year-old high school student from Texas, the ethical challenges commonly linked with AI. became the victim of AI-generated harassment when a male classmate used a clothes-removal app to create fake Misidentifications and the Human Cost of Facial nude images of Berry and her friends, distributing them Recognition Technology (May 25, 2024) anonymously through social media. The realistic but falsified A woman in the U.K. was wrongfully identified as a shoplifter images, made from photos taken from Berry’s private by the Facewatch system while shopping at a Home Instagram account, caused her to experience feelings of fear, Bargains store. After being publicly accused, searched, and shame, and anxiety, which impacted her social and academic banned from stores using the technology, she experienced life. While the perpetrator faced juvenile sanctions and school emotional distress and worried about the long-term impact discipline, the case exposed gaps in legal and institutional on her reputation. Facewatch later acknowledged the error frameworks for addressing AI-driven harassment. Berry and but did not comment or issue a public apology. The case her family have since advocated for stronger protections, and reflects broader issues with the increasing adoption of facial several bills have been introduced in the U.S. Congress to recognition systems by retailers and law enforcement. While criminalize the nonconsensual sharing of intimate images— advocates emphasize their potential to reduce crime and real or fake—and to impose removal obligations on social enhance public safety, critics point to privacy violations, media platforms. Certain countries, including Australia, have misidentifications, and the potential normalization of mass already passed such laws. surveillance. Despite assurances of accuracy, errors still occur. These types of incidents also raise questions about how Source: Restless Network, 2021 system errors are acknowledged and victims compensated. Figure 3.2.3 Source: BBC, 2024 Figure 3.2.2 Table of Contents Chapter 3 Preview 168 Artificial Intelligence Index Report 2025 Chapter 3: Responsible AI 3.2 Assessing Responsible AI AI chatbot exploits deceased individual’s identity (Oct. 7, Chatbot blamed for teenage suicide (Oct. 23, 2024) 2024) A lawsuit against Character.AI has raised concerns about Jennifer Ann Crecente, a high school senior murdered by an the role of AI chatbots in mental health crises. The case ex-boyfriend in 2006, was brought back into public focus involves a 14-year-old boy, Sewell Setzer III, who died by when her name and image appeared in an AI chatbot on suicide after prolonged interactions with a chatbot character, Character.AI. Discovered by her father, Drew Crecente, via which reportedly provided harmful advice rather than a Google Alert, the bot—created by an unknown user— offering support or critical resources. The lawsuit alleges used Jennifer Ann’s yearbook photo and described her as that the chatbot, designed to engage users in deep and a “knowledgeable and friendly AI character.” Crecente, personal conversations, lacked proper safeguards to prevent an advocate for awareness of teenage dating violence, dangerous interactions and encouraged Sewell to take his expressed outrage and distress at the unauthorized use of life. Figure 3.2.5 highlights a screenshot of the conversation his daughter’s identity, calling the experience retraumatizing. between Sewell and “Dany” (the chatbot character), the day Despite the chatbot’s removal for violating Character.AI’s of his suicide. This case speaks to the ethical challenges of impersonation policies, the incident highlights troubling gaps AI-driven companionship and the potential risks of deploying in AI platform oversight and the ethical dilemmas surrounding conversational AI without adequate oversight. While AI digital recreations of deceased individuals. chatbots can offer emotional support, critics warn that without guardrails, they may inadvertently reinforce harmful Source: Business Insider, 2024 behaviors or fail to intervene when users are in distress. Figure 3.2.4 Source: Business Insider, 2024 Figure 3.2.5 Table of Contents Chapter 3 Preview 169 Artificial Intelligence Index Report 2025 Chapter 3: Responsible AI 3.2 Assessing Responsible AI Limited Adoption of RAI Benchmarks Last year’s AI Index was among the first publications to This year’s AI Index confirms that this trend persists. Figure highlight the lack of standard benchmarks for AI safety and 3.2.6 highlights several general capabilities benchmarks (such responsibility evaluations. While major model developers as MMLU, GPQA Diamond, and MATH) used to evaluate consistently test their flagship models on the same general major models released in 2024, while Figure 3.2.7 showcases capabilities benchmarks—covering math, coding, and prominent safety and responsible AI benchmarks, indicating language skills—no such standard exists for safety and whether leading developers tested their models against responsible AI assessments. Standardized evaluation them. As with last year, there is clear consensus among suites are important for enabling direct comparisons model developers on which general capabilities benchmarks between models. This is especially important for safety and to use—but none on similar RAI benchmarks. responsibility features, as businesses and governments are increasingly deploying AI in real-world applications. Reported general capability benchmarks for popular foundation models Source: AI Index, 2025 | Table: 2025 AI Index report Capability o1 GPT-4.5 DeepSeek-R1 Gemini 2.5 Grok-2 Claude 3.7 Llama 3.3 benchmark Sonnet MMLU, ✓ ✓ ✓ ✓ ✓ ✓ ✓ MMLU-Pro or MMMLU GPQA or ✓ ✓ ✓ ✓ ✓ ✓ ✓ GPQA-Diamond MATH-500 ✓ ✓ ✓ ✓ ✓ AIME 2024 ✓ ✓ ✓ ✓ ✓ SWE-bench ✓ ✓ ✓ ✓ ✓ veri ed MMMU ✓ ✓ ✓ ✓ ✓ Figure 3.2.6 Reported safety and responsible AI benchmarks for popular foundation models Source: AI Index, 2025 | Table: 2025 AI Index report Responsible AI o1 GPT-4.5 DeepSeek-R1 Gemini 2.5 Grok-2 Claude 3.7 Llama 3.3 benchmark Sonnet BBQ ✓ ✓ ✓ HarmBench Cybench ✓ SimpleQA ✓ ✓ Toxic WildChat ✓ ✓ ✓ StrongREJECT ✓ ✓ WMDP benchmark ✓ ✓ MakeMePay ✓ ✓ MakeMeSay ✓ ✓ Figure 3.2.7 Table of Contents Chapter 3 Preview 170 Artificial Intelligence Index Report 2025 This does not mean model developers neglect safety Hughes Hallucination Evaluation Model (HHEM) testing—many conduct evaluations—but much like most Leaderboard models are kept proprietary, these evaluations are often The Hughes Hallucination Evaluation Model (HHEM) internal and not standardized, making assessments and leaderboard, developed by Vectara, assesses how comparisons of models difficult. External evaluators also frequently LLMs introduce hallucinations when summarizing present challenges. For example, third-party evaluators like documents. In this benchmark, models generate summaries Gryphon, Apollo Research, and METR assess only select from documents in the CNN and Daily Mail corpus. These models, and their findings cannot be widely validated by the summaries are then evaluated for hallucination rates. HHEM broader AI community. stands out as one of the most comprehensive and up-to-date evaluations of AI systems’ tendency to hallucinate. Recent Factuality and Truthfulness models, including Llama 3, Claude 3.5, and Gemini 2.0, have Despite significant progress, LLMs still face challenges with all been benchmarked on the leaderboard. factual inaccuracies and hallucinations, often generating information that appears credible but is false. Notable real- Currently, the GLM-4-9b-Chat and Gemini-2.0-Flash-Exp world examples include cases where lawyers submitted models are tied for the lowest hallucination rate, each at just court briefs containing citations fabricated by LLM systems. 1.3%. The next closest models, o1-mini and GPT-4o, follow Monitoring the rate of hallucinations in LLMs is therefore closely, with hallucination rates of 1.4% and 1.5%, respectively important. However, some benchmarks highlighted in (Figure 3.2.8). previous editions of the AI Index, such as HaluEval and TruthfulQA, have struggled to gain traction within the AI community. In 2024, several new benchmarks were introduced to better evaluate the factuality of these models. 3.00% 2.90% 2.80% 2.60% 2.50% 2.50% 2.50% 2.40% 2.40% 2.00% 1.90% 1.80% 1.70% 1.70% 1.50% 1.50% 1.40% 1.30% 1.30% 1.00% 0.50% 0.00% ai21labs/AI Q 21 w -J e a n m /Q b w a- I e 1 n . n 5 t 2 e - . l M 5 /n - i 7 e n B u i - r I a n m l s - i c t c r h r u a o c t s t - o 7 f b t - / v m O 3 i r - c c 3 r a o - s 2 o -1 f 3 t/ b o P p h e i- n 3 a .5 i/ - o M 1 o d E e - e in p s s t e r e u k c / t o d p ee e p na se i/ e G k P - o c T p h -3 a e . t n 5 a -T i/ u G rb P o o T p -4 enai/GP o T p -4 e o n - a m i/ i G n P i o T p -4 e - n T a u i r / b G o P o T p -4 e o nai/o1- g m e i m ni ini-2.0 T - H a U s D h- M ex /g p lm -4-9b-chat Table of Contents Chapter 3 Preview 171 etar noitanicullaH Chapter 3: Responsible AI 3.2 Assessing Responsible AI HHEM: hallucination rate Source: HHEM leaderboard, 2025 | Chart: 2025 AI Index report Figure 3.2.8 Artificial Intelligence Index Report 2025 Chapter 3: Responsible AI 3.2 Assessing Responsible AI Highlight: FACTS, SimpleQA, and the Launch of Harder Factuality Benchmarks Still generations from Stable Video Diffusion Source: Google, 2024 Table of Contents Chapter 3 Preview 172 weiverp-1o inim-1o inim-o4-tpg 22014202-ukiah-5.3-edualc o4-tpg 22014202-tennos-5.3-edualc 200-orp-5.1-inimeg 200-hsa -5.1-inimeg pxe-hsa -0.2-inimeg 100% 80% 60% 40% 20% 0% Model erocs ytilautcaF The HHEM leaderboard, while useful, appears to be nearing saturation as model Figure 3.2.9 performance improves. Additionally, its focus on news articles and summarization tasks limits its comprehensiveness. As AI capabilities continue to evolve, there is a growing need for benchmarks that assess factuality in more challenging and diverse contexts. This year, several new benchmarks were introduced for evaluating the factuality and truthfulness of LLMs, including Google’s FACTS Grounding. This benchmark assesses how well FACTS: factuality score LLMs generate responses that are both Source: FACTS leaderboard, 2025 | Chart: 2025 AI Index report factually accurate and detailed enough to provide satisfactory answers. As 78.80% 79.40%80.00%82.90%83.60% part of FACTS, models must craft long- 71.00% 74.20% 61.70% 62.00% form responses to user requests based on a context document (Figure 3.2.9). These documents cover a wide range of domains, including finance, technology, retail, medicine, and law. FACTS is more complex than HHEM, requiring models to perform tasks such as summarization, question-and-answer generation, fact- finding, and explanation. Responses are evaluated by a collection of AI models— Gemini 1.5 Pro, GPT-4o, and Claude 3.5 Sonnet—which assign a factuality Figure 3.2.10 score. Currently, Gemini-2.0-Flash-Exp holds the highest grounding score at 83.6% (Figure 3.2.10). Artificial Intelligence Index Report 2025 Chapter 3: Responsible AI 3.2 Assessing Responsible AI Highlight: FACTS, SimpleQA, and the Launch of Harder Factuality Benchmarks (cont’d) Evaluating the factuality of LLMs is challenging because Sample questions from SimpleQA Source: OpenAI, 2024 their long answers often contain multiple factual claims, Figure 3.2.11 making it difficult to assess the accuracy of each one. To address this, OpenAI researchers introduced SimpleQA, a new benchmark for evaluating LLM factuality. SimpleQA presents models with over 4,000 short fact-seeking questions that are straightforward, easily gradable, and relatively challenging. These questions span a diverse range of topics, including history, science and technology, art, and geography (Figure 3.2.11). SimpleQA presents a significant factuality challenge for leading LLMs. The best-performing model, OpenAI’s o1- preview, successfully answers only 42.7% of the questions (Figure 3.2.12). Researchers also evaluated whether models would attempt to answer certain questions, finding that Correct Not attempted Correct given attempted 100% 80% 75.30% 75.00% 60% 47.00% 44.50% 42.70% 40% 39.60%38.80% 38.20% 38.00% 35.00% 28.90% 28.50% 22.90% 23.50% 20.60% 20% 11.30% 8.60% 8.70% 8.10% 9.20% 5.10% 5.70% 0.90% 1.00% 0% Claude-3-haiku Claude-3-sonnet Claude-3-opus Claude-3.5-sonnet GPT-4o-mini GPT-4o OpenAI o1-mini OpenAI o1-preview (2024-03-07) (2024-02-29) (2024-02-29) (2024-06-20) Model Table of Contents Chapter 3 Preview 173 snoitseuq fo tnecreP some, like the Claude-3 family, refrained from responding to 75% of the prompts. Among models that attempted to respond to questions, o1-preview scored 47.0% of “correct- given-attempted” prompts, followed by Claude 3.5 Sonnet at 44.5%. As expected, larger models tend to perform better on this benchmark. SimpleQA: percent of questions Source: Wei et al., 2024 | Chart: 2025 AI Index report Figure 3.2.12 Artificial Intelligence Index Report 2025 Chapter 3: Responsible AI 3.3 RAI in Organizations and Businesses 3.3 RAI in Organizations and Businesses As AI systems become more widely deployed in real- Figure 3.3.1 visualizes responses to questions asking world settings, understanding how businesses approach organizations which department has primary oversight for responsible AI has become increasingly important. To explore AI governance within their organizations. Notably, no single this, the AI Index partnered with McKinsey & Company in department dominated. The most common response was 2024 to conduct a survey examining the extent to which information security (cyber/fraud/privacy) at 21%, followed businesses integrate RAI into their operations. The survey by data and analytics at 17%. Additionally, 14% of respondents defined RAI as a framework for ensuring that AI is developed reported having dedicated AI governance roles, signaling and deployed in a safe, trustworthy, and ethical manner. It the growing recognition of AI governance as a distinct and assessed RAI along the same key dimensions outlined by the essential function within organizations. AI Index: privacy and data governance, fairness, transparency and explainability, and security and safety. The survey polled business leaders from over 30 countries and had a total sample size of 759 respondents. Business functions assigned primary responsibility for AI governance, 2024 Source: McKinsey & Company Survey, 2024 | Chart: 2025 AI Index report Information security 21% (cyber/fraud/privacy) Data and analytics 17% AI-speci c governance 14% roles Risk/compliance 13% Engineering 10% No business function 9% primarily responsible Legal 7% Internal audit/ethics 4% Customer care 2% Other 1% 0% 2% 4% 6% 8% 10% 12% 14% 16% 18% 20% 22% % of respondents Figure 3.3.12 2 The “Unknown” response option was not shown in this visualization. Table of Contents Chapter 3 Preview 174 Artificial Intelligence Index Report 2025 1–5M 5–10M 10–25M 25–50M <100M 68% 25% 6% 100M–1B 48% 30% 15% 7% 1B–10B 40% 32% 18% 10% 10B–30B 24% 30% 27% 19% 30B+ 25% 29% 21% 25% 0% 20% 40% 60% 80% 100% % of respondents Table of Contents Chapter 3 Preview 175 DSU ni euneveR Chapter 3: Responsible AI 3.3 RAI in Organizations and Businesses The survey also asked organizations about their approximate Larger enterprises—particularly those with annual revenues investment in operationalizing RAI over the next year, exceeding $10 billion—demonstrated higher total investment including both capital and operating expenditures. Examples into RAI. Notably, 27% of organizations with $10 billion–$30 of such investments include developing or purchasing billion in revenue and 21% of those exceeding $30 billion invest technical systems to comply with RAI principles, as well as $10 million–$25 million in RAI. These findings suggest that legal or professional services related to RAI. Responses to larger organizations are more likely to embed RAI as a strategic this question are visualized in Figure 3.3.2, disaggregated by priority and to make higher absolute investments. Smaller organizational revenue size. organizations allocated fewer dollars to RAI, but many still reported substantial investments as a share of their revenue. Investment in responsible AI by company revenue, 2024 Source: McKinsey & Company Survey, 2024 | Chart: 2025 AI Index report Figure 3.3.2 Artificial Intelligence Index Report 2025 Cybersecurity 66% 53% Regulatory compliance 63% 50% Personal/individual privacy 60% 46% Inaccuracy 60% 55% Intellectual property infringement 57% 38% Organizational reputation 45% 29% Explainability 40% 31% Equity and fairness 34% 26% Workforce labor displacement 20% 12% Environmental impact 16% 9% National security 11% 4% Political stability 7% 3% Physical safety 6% 4% 0% 20% 40% 60% 80% 100% 0% 20% 40% 60% 80% 100% % of respondents % of respondents Table of Contents Chapter 3 Preview 176 sksir IA Chapter 3: Responsible AI 3.3 RAI in Organizations and Businesses Figure 3.3.3 presents the AI-related RAI risks that The gap is particularly pronounced for intellectual property organizations consider relevant and are actively working to infringement (57% relevant, 38% mitigated) and organizational mitigate. Cybersecurity (66%), regulatory compliance (63%), reputation (45% relevant, 29% mitigated). Risks related to and personal privacy (60%) rank as the top concerns, yet explainability (40%) and fairness (34%) were selected by a mitigation efforts consistently fall short. Not surprisingly, in smaller share of respondents, with mitigation rates dropping every risk category, fewer organizations take active steps further, to 31% and 26%, respectively. to mitigate risks than those that recognize them as relevant. AI risks: considered relevant vs. actively mitigated, 2024 Source: McKinsey & Company Survey, 2024 | Chart: 2025 AI Index report Considered relevant Actively mitigated Figure 3.3.3 Artificial Intelligence Index Report 2025 1–2 42% 3–5 30% 6–9 13% 10+ 11% Unknown 5% 0% 5% 10% 15% 20% 25% 30% 35% 40% % of respondents Table of Contents Chapter 3 Preview 177 stnedicni IA fo rebmuN Chapter 3: Responsible AI 3.3 RAI in Organizations and Businesses Figure 3.3.4 and Figure 3.3.5 present data on the number of AI incidents reported by organizations over the past year. Only 8% of surveyed organizations reported experiencing AI-related incidents. Among those affected, the majority—42%—reported encountering just one or two incidents. Percentage of organizations that have experienced AI incidents, 2024 Source: McKinsey & Company Survey, 2024 | Chart: 2025 AI Index report Yes No Unknown Responses 8% 89% 3% 0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% % of respondents Figure 3.3.43 Number of AI incidents reported by organizations, 2024 Source: McKinsey & Company Survey, 2024 | Chart: 2025 AI Index report Figure 3.3.5 3 Figure 3.3.4 uses the OECD definition of an AI incident. According to the OECD, an AI incident is defined as an event, circumstance, or series of events where the development, use, or malfunction of one or more AI systems directly or indirectly results in any of the following harms: (a) injury or harm to the health of individuals or groups; (b) disruption of the management or operation of critical infrastructure; (c) violations of human rights or breaches of legal obligations intended to protect fundamental, labor, or intellectual property rights; or (d) harm to property, communities, or the environment. Artificial Intelligence Index Report 2025 Chapter 3: Responsible AI 3.3 RAI in Organizations and Businesses When asked about the impact RAI policies have had in their organizations, 42% reported improving business operations, such as improving efficiency and lowering costs, and 34% reported increasing customer trust (Figure 3.3.6). Only 17% of organizations feel that the results have had no significant impact. Impact of responsible AI policies in organizations, 2024 Source: McKinsey & Company Survey, 2024 | Chart: 2025 AI Index report Improved business operations 42% (e.g., e�ciency, lower costs) Increased customer trust 34% Enhanced brand reputation 29% Improved business outcomes 28% (e.g., revenue) Decrease in number of incidents 22% Faster time-to-market 18% No signi�cant impact 17% Slower time-to-market 12% 0% 5% 10% 15% 20% 25% 30% 35% 40% % of respondents Figure 3.3.64 4 Data for respondents who selected “have not implemented” is excluded. Percentages are based only on those who chose at least one other answer. The “None” response option is not shown. Table of Contents Chapter 3 Preview 178 Artificial Intelligence Index Report 2025 Chapter 3: Responsible AI 3.3 RAI in Organizations and Businesses Figure 3.3.7 reports the main obstacles organizations noted key challenges. Encouragingly, only 16% reported a lack of to implementing RAI measures. Respondents primarily cited executive support as a barrier, suggesting that leadership knowledge and training gaps (51%), resource or budget buy-in is not a major impediment to RAI adoption. constraints (45%), and regulatory uncertainty (40%) as Main obstacles to the implementation of responsible AI measures, 2024 Source: McKinsey & Company Survey, 2024 | Chart: 2025 AI Index report Knowledge and training gaps 51% Resource or budget constraints 45% Regulatory uncertainty 40% Technical limitations 32% Organizational resistance 22% Lack of executive support 16% None 3% Other 2% 0% 5% 10% 15% 20% 25% 30% 35% 40% 45% 50% % of respondents Figure 3.3.75 5 The “Unknown” response option was not shown in this visualization. Table of Contents Chapter 3 Preview 179 Artificial Intelligence Index Report 2025 Chapter 3: Responsible AI 3.3 RAI in Organizations and Businesses Figure 3.3.8 shows the proportion of organizations (GDPR), while 41% cite the EU AI Act. Smaller proportions influenced by specific AI regulations in their RAI decision indicate influence from the OECD AI Principles (21%) and making. Among surveyed organizations, 65% report being President Biden’s Executive Order on AI. influenced by the EU General Data Protection Regulation Percentage of organizations in uenced by AI regulations in responsible AI decision making Source: McKinsey & Company Survey, 2024 | Chart: 2025 AI Index report EU General Data Protection 65% Regulation (GDPR) EU AI Act 41% OECD AI Principles 21% US Presidential 19% Executive Order on AI None of the these/no change 17% 0% 5% 10% 15% 20% 25% 30% 35% 40% 45% 50% 55% 60% 65% % of organizations Figure 3.3.8 Table of Contents Chapter 3 Preview 180 Artificial Intelligence Index Report 2025 Chapter 3: Responsible AI 3.3 RAI in Organizations and Businesses Highlight: Longitudinal Perspective In collaboration with Accenture, this year a team of Figure 3.3.9 presents the types of incidents reported by Stanford researchers ran the Global State of Responsible organizations in the RAI survey. The most common issues— AI survey, the second iteration of the inaugural survey adversarial attacks and privacy violations—underscore launched in 2024. Responses from 1,500 organizations, the urgent need for organizations to prioritize AI system each with revenues of at least $500 million, were collected security and robust data governance. Additionally, with from 20 countries and 19 industries in January–February 51% of respondents reporting unintended decision making 2025.6 The objective of the survey was to gain an and 47% citing model bias, there is ample evidence that understanding of the challenges of adopting RAI principles many organizations are struggling to anticipate and control and practices and to provide a comparison of RAI activities AI behavior—an especially troubling challenge in high- across 10 dimensions over time. Because the RAI survey stakes environments. was conducted in both 2024 and 2025, the data enables a comparison of how organizational perspectives on RAI adoption have evolved over time. Adversarial attack 56% Privacy violation 55% Unintended decision making 51% Model bias 47% Performance failure 46% 0% 10% 20% 30% 40% 50% % of respondents 6 Details about the survey methodology can be found in Reuel et al. (2024). Table of Contents Chapter 3 Preview 181 epyt tnedicnI AI-related types of incidents reported by organizations in the past two years Source: Accenture/Stanford Joint Survey, 2025 | Chart: 2025 AI Index report Figure 3.3.9 Artificial Intelligence Index Report 2025 Chapter 3: Responsible AI 3.3 RAI in Organizations and Businesses Highlight: Longitudinal Perspective (cont’d) Given their AI adoption strategy—whether, for instance, concerned in recent years about certain risks—most they develop, deploy, or use generative or nongenerative notably, financial risks (+38 percentage points), brand and AI—respondents were asked which risks were relevant reputational risks (+16), privacy and data-related risks (+15), to their organization. They were presented with a list of and reliability risks (+14). Conversely, some risks are now 14 risks and could select all that applied to them (Figure considered less pressing, including societal risks (-7) and 3.3.10).7 Companies have grown significantly more socio-environmental risks (-8). Privacy and data-related risks (e.g., reidenti cation of anonymized data, 65% data leakage, use of data without 51% consent) Reliability risks (e.g., output errors, 59% hallucinations) 45% Compliance and lawfulness risks (e.g., 56% IP or copyright violations) 29% Security risks (e.g., adversarial attacks, 52% model theft) 47% Financial risks (e.g., lack of AI-related 50% ROI, AI-related nancial loss) 12% Brand/reputational risks (e.g., 42% damage caused to brand by AI-related incident) 26% Human interaction risks (e.g., misuse by users for the generation of deepfakes or misinformation, 40% overreliance of users on AI models/systems, or 35% physical/mental harm due to model/system usage) Diversity and nondiscrimination risks (e.g., 35% fairness concerns, toxicity, discrimination, and stereotype reproduction) 29% Client/customer risks (e.g., loss of trust, 32% market share, or customer satisfaction) 34% Societal risks (e.g., threats to political 26% stability, national security concerns) 33% Socio-environmental risks (e.g., high 22% 2025 2024 carbon footprint of systems, regional pollution) 30% 0% 10% 20% 30% 40% 50% 60% % of respondents 7 The full list of risks can be found in the corresponding paper. Table of Contents Chapter 3 Preview 182 yrogetac ksiR Relevance of selected responsible AI risks for organizations, 2024 vs. 2025 Source: Accenture/Stanford Joint Survey, 2025 | Chart: 2025 AI Index report Figure 3.3.10 Artificial Intelligence Index Report 2025 Chapter 3: Responsible AI 3.3 RAI in Organizations and Businesses Highlight: Longitudinal Perspective (cont’d) The definitions of organizational and operational maturity are highlighted in Figure 3.3.11. Between 2024 and 2025, organizational RAI maturity advanced notably, with more companies securing CEO support for RAI initiatives and improving AI risk identification, monitoring, and control—signaling a stronger recognition of RAI’s strategic importance (Figure 3.3.12).8 In contrast, operational RAI maturity—focused on practical, system-level safeguards such as bias reduction, adversarial testing, and environmental impact measurement—lagged behind (Figure 3.3.13). This gap highlights a disconnect between high-level RAI commitments and their technical implementation. While organizations are increasingly equipped and motivated to embed RAI into processes and policies, translating that intent into effective system-level risk mitigation remains a persistent challenge 18% 2025 2024 16% 14% 12% 10% 8% 6% 4% 2% 0% 0 25 50 75 100 Maturity score 8 Organizational and operational RAI maturity were calculated as defined in Reuel et al. (2024). Table of Contents Chapter 3 Preview 183 snoitazinagro fo % Organizational responsible AI maturity distribution, 2024 vs. 2025 Source: Accenture/Stanford Joint Survey, 2025 | Chart: 2025 AI Index report 2025 2024 14% 12% 10% 8% 6% 4% 2% 0% 0 25 50 75 100 Maturity score snoitazinagro fo % Organizational and operational maturity model Source: Reuel et al., 2024 Figure 3.3.11 Operational responsible AI maturity distribution, 2024 vs. 2025 Source: Accenture/Stanford Joint Survey, 2025 | Chart: 2025 AI Index report Figure 3.3.12 Figure 3.3.13 Artificial Intelligence Index Report 2025 Chapter 3: Responsible AI 3.3 RAI in Organizations and Businesses Highlight: Longitudinal Perspective (cont’d) Respondents were also asked about their organization’s industry lacks a unified strategic direction on RAI—likely attitudes and philosophies toward RAI, including views on a reflection of ongoing debates and unresolved questions risk ownership, model preferences, and policy positions among experts. The one clear exception is the trade-off (Figure 3.3.14). Across nearly all statements, responses between safety and innovation: 64% of respondents lean were fairly evenly split, even on high-profile issues such toward a safety-first approach, and yet 58% are exploring as the safety of open- versus closed-weight models, and minimally supervised agents, which may introduce whether responsibility for risk mitigation lies with model significant risks—particularly given the current limitations providers or users. This broad distribution suggests that in RAI maturity. Aligns completely with the rst statement Aligns somewhat with the second statement Aligns somewhat with the rst statement Aligns completely with the second statement “Innovate rst, regulate later”/ 13% 23% 30% 34% “Safety rst, prevent future potential risks” “Responsible AI is a compliance issue”/ 17% 28% 33% 21% “Responsible AI is a value driver for unlocking potential” “RAI risks are industry-speci c”/ 18% 37% 30% 16% “RAI risks are industry-agnostic” “GenAI risks are the responsibility of foundation model providers”/ 20% 33% 31% 16% “GenAI risks are the responsibility of GenAI users” “Closed-source models are safer”/ 18% 32% 29% 21% “Open-source models are safer” “Actively exploring minimally supervised AI agents”/ 21% 37% 29% 13% “Agents are currently too risky for large-scale adoption” 0% 20% 40% 60% 80% 100% % of respondents Table of Contents Chapter 3 Preview 184 riap tnemetatS Organizational attitudes and philosophies surrounding responsible AI Source: Accenture/Stanford Joint Survey, 2025 | Chart: 2025 AI Index report Figure 3.3.14 Artificial Intelligence Index Report 2025 3.4 RAI in Academia For this year’s report, the AI Index analyzed the number of Aggregate Trends responsible AI-related papers accepted at six leading AI The number of RAI papers accepted at leading AI conferences conferences: AAAI, AIES, FAccT, ICML, ICLR, and NeurIPS. rose by 28.8%, from 992 in 2023 to 1,278 in 2024 (Figure While these conferences do not represent all responsible AI 3.4.1). research globally, they provide insight into publication trends among AI academics. This section presents aggregate trends in AI publications, with subsequent sections breaking them down by RAI subtopics. In order to identify RAI papers, the AI Index selected papers that contained certain RAI keywords.9 1,278 1,200 992 1,000 800 696 644 600 489 400 329 200 0 2019 2020 2021 2022 2023 2024 Figure 3.4.1 Table of Contents Chapter 3 Preview 185 srepap IAR fo rebmuN Chapter 3: Responsible AI 3.4 RAI in Academia Number of responsible AI papers accepted at select AI conferences, 2019–24 Source: AI Index, 2025 | Chart: 2025 AI Index report 9 A full methodological description of this approach can be found in the Appendix. Artificial Intelligence Index Report 2025 Proportionally, the conferences with the highest share of transparency, while AIES centers on AI ethics and society. At accepted RAI papers relative to total submissions were FAccT NeurIPS, the proportion decreased from 13.8% in 2023 to (69.14%) and AIES (63.33%) (Figure 3.4.2). This aligns with 9.0% in 2024, while at ICML, it rose from 3.4% to 8.2% over their focus: FAccT is dedicated to fairness, accountability, and the same period. 70% 60% 50% 40% 30% 20% 10% 0% 2019 2020 2021 2022 2023 2024 Figure 3.4.2 Table of Contents Chapter 3 Preview 186 )latot fo %( srepap IAR Chapter 3: Responsible AI 3.4 RAI in Academia Responsible AI papers accepted (% of total) at select AI conferences by conference, 2019–24 Source: AI Index, 2025 | Chart: 2025 AI Index report 69.14%, FAccT 63.33%, AIES 13.36%, AAAI 9.02%, NeurIPS 8.24%, ICML 7.56%, ICLR Artificial Intelligence Index Report 2025 Figures 3.4.3 through 3.4.5 examine the geographic affiliation an increasingly significant academic focus. Since 2019, of RAI papers, highlighting where these papers originate. the overall geographic distribution of RAI publications In 2024, the United States led in RAI paper submissions has remained relatively consistent, with the United States with 669, followed by China with 268 and Germany with accounting for the most (3,158), followed by China (1,100) and 80. Across major geographic regions, RAI has become the United Kingdom (485). Number of responsible AI papers accepted at select AI conferences by geographic area, 2024 Source: AI Index, 2025 | Chart: 2025 AI Index report United States 669 700 China 268 Germany 80 600 United Kingdom 67 500 Canada 55 400 Hong Kong 46 India 42 300 Figure 3.4.3 Singapore 39 200 Japan 36 100 Netherlands 31 0 200 400 600 2019 2020 2021 2022 2023 2024 Number of RAI papers Figure 3.4.3 Figure 3.4.4 Number of responsible AI papers accepted at select AI conferences by geographic area, 2019–24 (sum) Source: AI Index, 2025 | Chart: 2025 AI Index report 1–10 11–50 51–150 151–500 501–2,000 Figure 3.4.5 2,001–3,200 Table of Contents Chapter 3 Preview 187 srepap IAR fo rebmuN Chapter 3: Responsible AI 3.4 RAI in Academia Number of responsible AI papers accepted at select AI conferences by select geographic area, 2019–24 Source: AI Index, 2025 | Chart: 2025 AI Index report 669, United States 298, Europe 268, China Artificial Intelligence Index Report 2025 NeurIPS ICML ICLR FAccT AIES AAAI 213 18 200 186 21 36 150 150 15 124 21 17 12 100 92 43 13 160 15 50 97 105 39 71 48 32 0 2019 2020 2021 2022 2023 2024 Table of Contents Chapter 3 Preview 188 srepap ecnanrevog atad dna ycavirp IA fo rebmuN Chapter 3: Responsible AI 3.4 RAI in Academia Topic Area This section examines trends in RAI publications spanning key Over the past year, the number of accepted papers on privacy topics: privacy and data governance, fairness, transparency and data governance topics decreased by 14.5% at select AI and explainability, and security and safety. conferences (Figure 3.4.6). Since 2019, this figure has risen nearly fivefold. AI privacy and data governance papers accepted at select AI conferences, 2019–24 Source: AI Index, 2025 | Chart: 2025 AI Index report Figure 3.4.610 10 These figures likely underestimate the total number of AI privacy papers, as some are published in AI-focused conferences dedicated to privacy, such as the 46th IEEE Symposium on Security and Privacy. Artificial Intelligence Index Report 2025 NeurIPS ICML ICLR FAccT AIES AAAI 408 400 100 350 300 48 250 212 83 200 36 169 150 150 29 33 50 38 100 98 27 65 44 27 75 57 39 27 50 36 83 46 29 34 0 2019 2020 2021 2022 2023 2024 Table of Contents Chapter 3 Preview 189 srepap saib dna ssenriaf IA fo rebmuN Chapter 3: Responsible AI 3.4 RAI in Academia In 2024, the number of fairness and bias papers accepted at select AI conferences saw a significant increase, reaching 408— roughly two times the 2023 figure (Figure 3.4.7). This growth highlights the increasing academic interest in fairness and bias among researchers. AI fairness and bias papers accepted at select AI conferences, 2019–24 Source: AI Index, 2025 | Chart: 2025 AI Index report Figure 3.4.7 Artificial Intelligence Index Report 2025 400 NeurIPS ICML ICLR FAccT AIES AAAI 393 54 355 350 46 98 300 250 56 231 35 200 189 44 44 50 48 150 42 35 134 25 54 100 89 30 24 183 50 89 83 54 63 39 0 2019 2020 2021 2022 2023 2024 Table of Contents Chapter 3 Preview 190 srepap ytilibanialpxe dna ycnerapsnart IA fo rebmuN Chapter 3: Responsible AI 3.4 RAI in Academia Since 2019, the number of papers on transparency and explainability submitted to major academic conferences has increased by a factor of four. In 2024, there were 355 transparency and explainability–related submissions at academic conferences including AAAI, FAccT, AIES, ICML, ICLR, and NeurIPS (Figure 3.4.8). AI transparency and explainability papers accepted at select AI conferences, 2019–24 Source: AI Index, 2025 | Chart: 2025 AI Index report Figure 3.4.8 Artificial Intelligence Index Report 2025 The number of security and safety submissions to select AI conferences has sharply increased, almost doubling in the past year—from 276 to 521 (Figure 3.4.9). This growth reflects the increasing prominence of security and safety as a key focus for responsible AI researchers. NeurIPS ICML ICLR FAccT AIES AAAI 521 500 120 400 79 300 285 276 64 78 215 100 200 162 168 75 41 33 65 77 100 32 51 177 41 152 37 71 33 88 43 0 2019 2020 2021 2022 2023 2024 Table of Contents Chapter 3 Preview 191 srepap ytefas dna ytiruces IA fo rebmuN Chapter 3: Responsible AI 3.4 RAI in Academia AI security and safety papers accepted at select AI conferences, 2019–24 Source: AI Index, 2025 | Chart: 2025 AI Index report Figure 3.4.9 Artificial Intelligence Index Report 2025 Chapter 3: Responsible AI 3.5 RAI Policymaking 3.5 RAI Policymaking While 2023 and early 2024 saw a proliferation of national sought to establish global frameworks for responsible and AI strategies and regulatory approaches, a notable trend in ethical AI. These efforts signal a shift toward coordinated 2024 was the increased global cooperation on AI governance, global action rather than isolated national initiatives. Figure especially around legislating principles pertaining to responsible 3.5.1 highlights several significant international policymaking AI. International bodies and multilateral agreements have initiatives or dialogues on RAI that were recently launched.11 Notable RAI policymaking milestones Source: AI Index, 2025 Date Stakeholders Scope Description May 2024 OECD Global The OECD updated its AI principles and refined its framework to reflect the latest advancements in AI governance. These principles emphasized building AI systems that take into account inclusive growth, transparency, and explainability, as well as respect for the rule of law, human rights, and democratic values. May 2024 Council of Europe The Council of Europe adopted a legally binding AI treaty (The Council of Europe Framework Europe Convention on Artificial Intelligence and Human Rights, Democracy, and the Rule of Law). This treaty was drafted to ensure that the activities within the life cycle of AI systems completely align with human rights, democracy, and the rule of law. Jun 2024 European Union Europe The EU passed the AI Act (EU AI Act), the first comprehensive regulatory framework for AI in a major global economy. The act categorizes AI by risk, regulating them accordingly and ensuring that providers—or developers—of high-risk systems bear most of the obligations. Jul 2024 African Union Africa The African Union launched its Continental AI Strategy (AU AI Strategy), outlining a unified vision for AI development, ethics, and governance across the continent. The strategy emphasizes the ethical, responsible, and equitable development of AI within Africa. Sep 2024 United Nations Global The United Nations updated its Governing AI for Humanity report (U.N. AI Advisory Body), outlining efforts to establish global AI governance mechanisms. The report recommends developing a blueprint to address AI-related risks and calls on national and international standards organizations, technology companies, civil society, and policymakers to collaborate on AI standards. Oct 2024 G7 Global The G7 Digital Competition Communiqué (G7 AI Cooperation) reaffirmed commitments to fair and open AI markets, stressing the need for coordinated regulatory approaches. Previous discussions focused on competition and the regulatory challenges posed by AI’s rapid growth. Oct 2024 ASEAN and US Asia Following the 12th ASEAN-United States Summit, ASEAN-U.S. leaders issued a statement and US on promoting safe, secure, and trustworthy AI. They committed to cooperating on the development of international AI governance frameworks and standards to advance these goals. Nov 2024 International Global The first International Network of AI Safety Institutes was established, bringing together Network of AI nine countries and the EU to formalize global AI safety cooperation. The network unites Safety Institutes technical organizations committed to advancing AI safety, helping governments and societies understand the risks of advanced AI systems, and proposing solutions. Feb 2025 Arab League Arab The Arab Dialogue Circle on “Artificial Intelligence in the Arab World: Innovative Nations Applications and Ethical Challenges” launched at the Arab League headquarters, focusing on AI innovations while placing a strong emphasis on ethical considerations. Figure 3.5.1 11 While AI policymaking is the focus of Chapter 6: Policy and Governance, the AI Index highlights key RAI-related policymaking events here due to their recent significance. Table of Contents Chapter 3 Preview 192 Artificial Intelligence Index Report 2025 Data Provenance GitHub Hugging Face Papers with Code 3,230 3,000 2,500 2,404 2,438 2,030 2,000 1,500 1,279 1,000 843 828 651 484 500 367 193 0 1 45 0 75 0 Academic-only Commercial Noncommercial Unspeci ed License category Table of Contents Chapter 3 Preview 193 stesatad fo rebmuN Chapter 3: Responsible AI 3.6 Privacy and Data Governance 3.6 Privacy and Data Governance A comprehensive definition of privacy is difficult and context- external sources. In the context of AI, data governance is dependent. For the purposes of this report, the AI Index defines important for ensuring that the data used for training and privacy as an individual’s right to the confidentiality, anonymity, operating AI systems is accurate, fair, and used responsibly and protection of their personal data, along with their right and with consent. This is especially the case with sensitive or to consent to and be informed about if and how their data is personally identifiable information (PII). used. Privacy further includes an organization’s responsibility Featured Research to ensure these rights if they collect, store, or use personal data (directly or indirectly). Moreover, individuals should have This section highlights significant recent research on privacy the right to correct their sensitive information if organizations and data governance, including studies on auditing dataset or governments have misrepresented this information. In licensing and attribution, as well as research on stricter data AI, this involves ensuring that personal data is handled in a consent protocols. way that respects individual privacy rights—for example, by implementing measures to protect sensitive information from Large-Scale Audit of Dataset Licensing and exposure, and ensuring that data collection and processing are Attribution in AI transparent and compliant with privacy laws like GDPR. Current foundation models are being trained on massive amounts of data. A team of researchers conducted a large- Data governance, on the other hand, encompasses policies, scale audit of over 1,800 text datasets widely used for training procedures, and standards established by an organization such models and uncovered systemic issues in dataset to ensure the quality, security, and ethical use of data within licensing and attribution. The researchers found that more and outside of the organization where it was created. Data than 70% of datasets on popular dataset hosting sites lacked governance policies may also cover data acquired from adequate license information, while 50% of the licenses were Accuracy of dataset license classi cations by select aggregators Source: Longpre et al., 2025 | Chart: 2025 AI Index report Figure 3.6.1 Artificial Intelligence Index Report 2025 Chapter 3: Responsible AI 3.6 Privacy and Data Governance miscategorized, which poses risks for the responsible usage of updates to robots.txt files and terms of service, explicitly that data. Figure 3.6.1 provides a detailed visualization of the prohibiting AI training use. Figure 3.6.2 shows the proportion researchers’ findings. Specifically, they assigned license labels of websites with robots.txt restrictions, terms-of-service to datasets across four categories: commercial, unspecified, restrictions, and organizational restrictions over time.12 For noncommercial, and academic-only. They then compared example, the proportion of tokens in the top C4 web domains their classifications with those from popular sources such as with full restrictions increased from 10% in 2017 to 48% in GitHub, Papers with Code, and Hugging Face. Oftentimes, 2024. Between 2023 and 2024 alone, this proportion rose by the data license attributions assigned by the data provenance 25 percentage points. Figure 3.6.3 visualizes the percentage team differed sharply from those issued by other organizations. of tokens in the top web domains of C4 by terms-of-service restriction category from 2016 to 2024. This diminishing License misattribution in datasets is significant because it consent is likely related to legal issues around fair use, such creates legal and ethical risks in AI development. If datasets as the New York Times lawsuit against OpenAI. used to train foundation models are mislabeled or misattributed, AI developers may unknowingly violate copyright laws, data OpenAI’s crawlers encounter the highest level of restrictions, usage policies, or privacy regulations. This can lead to legal while smaller developers face fewer barriers. The authors liabilities, challenges in ensuring fair compensation for data highlight inconsistencies in enforcement, driven by ineffective creators, and potential biases in models due to the exclusion signaling mechanisms like robots.txt and mismatches between of properly licensed data. Additionally, unclear licensing can stated and enforced policies. These findings highlight the hinder transparency, accountability, and reproducibility in need for updated consent protocols that address AI-specific AI research, which can make it difficult for researchers and challenges. Additionally, the study suggests a decline in publicly organizations to verify or audit model training data. Based available web data for AI training, with potential consequences on their findings, the authors highlight the need for clear for data diversity, model alignment, and scalability. Many recent documentation, improved standards, and responsible licensing AI performance gains stem from training on increasingly large practices to foster inclusivity and mitigate risks that stem from datasets. If websites become significantly more restrictive, it irresponsible or unlawful data uses in AI development and could hinder future model scaling. deployment. Data Consent in Crisis AI models rely heavily on massive, publicly available web data for training. A recent study conducted a longitudinal audit of consent protocols for web domains used in AI training datasets, including C4, RefinedWeb, and Dolma, analyzing 14,000 web domains. These consent protocols define the permissibility of data scraping for AI model training. The researchers observed a significant increase in data use restrictions between 2023 and 2024, as many websites implemented new protocols to limit data scraping for AI training. These restrictions were primarily enforced through 12 A robots.txt restriction refers to a rule set in a website’s robots.txt file that instructs web crawlers (such as search engine bots or AI data scrapers) on which parts of the site they are allowed or forbidden to access. Table of Contents Chapter 3 Preview 194 Artificial Intelligence Index Report 2025 Chapter 3: Responsible AI 3.6 Privacy and Data Governance No scraping and AI No scraping Noncommercial use only Noncompete No redistribution Unrestricted use 100% 90% 80% 39% 36% 40% 35% 41% 39% 39% 38% 36% 70% 60% 50% 12% 14% 12% 16% 11% 12% 14% 14% 12% 40% 30% 36% 20% 41% 44% 39% 43% 41% 42% 41% 36% 10% 6% 8% 0% 2016 2017 2018 2019 2020 2021 2022 2023 2024 Table of Contents Chapter 3 Preview 195 snekot fo % Full restrictions Pattern-based restrictions Disallow private directories Other restrictions Crawl delay speci ed Sitemap provided No restrictions or sitemap 100% 90% 25% 80% 36% 70% 44% 44% 43% 47% 47% 46% 44% 6% 60% 15% 7% 50% 7% 7% 7% 40% 5% 7% 7% 7% 27% 30% 27% 27% 29% 29% 31% 30% 30% 48% 20% 10% 23% 12% 10% 9% 10% 10% 11% 12% 0% 2016 2017 2018 2019 2020 2021 2022 2023 2024 Percentage of tokens in the top web domains of C4 by terms of service restriction category, 2016–24 Source: Longpre et al., 2025 | Chart: 2025 AI Index report Figure 3.6.3 snekot fo % Percentage of tokens in the top web domains of C4 by robots.txt restriction category, 2016–24 Source: Longpre et al., 2025 | Chart: 2025 AI Index report Figure 3.6.2 Artificial Intelligence Index Report 2025 Chapter 3: Responsible AI 3.7 Fairness and Bias Fairness in AI emphasizes developing systems that are equitable and avoid perpetuating bias or discrimination against any individual or group. It involves considering the diverse needs and circumstances of all stakeholders impacted by AI use. Fairness extends beyond a technical concept and embodies broader social standards related to equity. 3.7 Fairness and Bias Featured Research This section highlights research on the impact of racial in the larger ViT-L models, Black and Latino men were classification in multimodal models and the measurement of disproportionately classified as criminals, with classification implicit bias in explicitly unbiased LLMs. probabilities increasing by up to 69% as dataset size grew from 400 million to 2 billion samples. Figure 3.7.1 displays Racial Classification in Multimodal Models various images alongside the model’s classification scores Recently, researchers have explored how dataset scaling for whether a face was identified as a criminal. affects racial and gender biases in vision-language models (VLMs). Evaluating 14 VLMs trained on LAION-400M and Figure 3.7.2 illustrates how the probability of a face being LAION-2B (popular datasets for training vision-language assigned a specific label (such as animal or criminal) changes models) using the Chicago Face Dataset (CFD), the study by demographic group across various models (the smaller found that while models trained on larger datasets improve ViT-B-16 and ViT-B-32 with the larger ViT-L-14) as the human classification—reducing misidentification of pretrained dataset scales from 400 million to 2 billion images. nonhuman entities like gorillas or orangutans—they also A higher percentage indicates a greater likelihood of a amplify racial biases, especially in larger models. For instance, demographic group being associated with a particular label, Faces and their likelihood of being classified as “criminal” by model and dataset sizes Source: Birhane et al., 2024 Figure 3.7.1 Table of Contents Chapter 3 Preview 196 Artificial Intelligence Index Report 2025 Chapter 3: Responsible AI 3.7 Fairness and Bias while a lower percentage signifies a lesser likelihood. In the when it comes to vision models, scaling may also introduce larger model, ViT-L, increasing the training data consistently other unintended bias problems. The authors suggest that raises the likelihood of an image being classified as a criminal. stereotypes in the training data may explain these results. This finding is significant, as many model developers have To address this bias, they advocate for transparent dataset sought to aggressively scale their models in an attempt to drive curation, detailed hyperparameter documentation, and open performance improvements. The researchers suggest that access for independent audits. Figure 3.7.213 13 The y-axis labels represent different ethnic groups: Black male (BM), Black female (BF), Latino male (LM), Latina female (LF), white male (WM), white female (WF), Asian male (AM), and Asian female (AF). Table of Contents Chapter 3 Preview 197 Artificial Intelligence Index Report 2025 Chapter 3: Responsible AI 3.7 Fairness and Bias Measuring Implicit Bias in Explicitly Unbiased LLMs biases that align with societal stereotypes. Figure 3.7.4 presents In 2024, a team of researchers investigated implicit biases in the implicit bias scores of various LLMs across different LLMs, particularly in those explicitly designed to be unbiased. stereotype categories.14 A score significantly above or below This research is important, as efforts to mitigate bias in LLMs 50% indicates a bias toward or against a particular group. may still not sufficiently solve issues of implicit bias. Figure 3.7.3 illustrates an example of this phenomenon. Figure 3.7.4 suggests that LLMs disproportionately associate negative terms with Black individuals and are more likely The study’s authors make two key contributions. First, they to associate women with humanities over STEM fields. introduce two new methods for detecting bias in LLMs: LLM The research also finds that LLMs favor men for leadership Implicit Bias, which identifies subtle biases by analyzing roles, reinforcing gender biases in decision-making contexts. automatic associations between words or concepts, and Additionally, the study reveals that as models scale, implicit LLM Decision Bias, which captures model behaviors that biases increase, though decision bias and rejection rates reflect these implicit biases. Second, they investigate relative do not. This finding is significant, as it indicates that while discriminatory patterns in decision-making tasks. Applying bias appears to have decreased on standard benchmarks— their methods to eight notable models—including GPT-4 and creating an illusion of neutrality—implicit biases remain Claude 3 Sonnet—across 21 stereotype categories (e.g., race, pervasive, potentially leading to subtle yet meaningful gender, religion, and health), they uncover systemic implicit discriminatory outputs. Example of implicit bias in LLMs Source: Bai et al., 2024 Figure 3.7.3 14 This research examines both implicit and decision bias; however, only implicit bias is documented here for concision. Decision bias, for reference, is defined as a model’s bias relative to an unbiased baseline of 50%. Table of Contents Chapter 3 Preview 198 Artificial Intelligence Index Report 2025 Table of Contents Chapter 3 Preview 199 msicar tliug enot niks nopaew kcalb cinapsih naisa bara hsilgne reerac ecneics rewop ytilauxes malsi msiaduj msihddub ytilibasid thgiew ega lli latnem gnitae 1.00 0.50 0.00 −0.50 −1.00 msicar tliug enot niks nopaew kcalb cinapsih naisa bara hsilgne reerac ecneics rewop ytilauxes malsi msiaduj msihddub ytilibasid thgiew ega lli latnem gnitae 1.00 0.50 0.00 −0.50 −1.00 msicar tliug enot niks nopaew kcalb cinapsih naisa bara hsilgne reerac ecneics rewop ytilauxes malsi msiaduj msihddub ytilibasid thgiew ega lli latnem gnitae 1.00 0.50 0.00 −0.50 −1.00 msicar tliug enot niks nopaew kcalb cinapsih naisa bara hsilgne reerac ecneics rewop ytilauxes malsi msiaduj msihddub ytilibasid thgiew ega lli latnem gnitae 1.00 0.50 0.00 −0.50 −1.00 msicar tliug enot niks nopaew kcalb cinapsih naisa bara hsilgne reerac ecneics rewop ytilauxes malsi msiaduj msihddub ytilibasid thgiew ega lli latnem gnitae 1.00 0.50 0.00 −0.50 −1.00 msicar tliug enot niks nopaew kcalb cinapsih naisa bara hsilgne reerac ecneics rewop ytilauxes malsi msiaduj msihddub ytilibasid thgiew ega lli latnem gnitae 1.00 0.50 0.00 −0.50 −1.00 msicar tliug enot niks nopaew kcalb cinapsih naisa bara hsilgne reerac ecneics rewop ytilauxes malsi msiaduj msihddub ytilibasid thgiew ega lli latnem gnitae 1.00 0.50 0.00 −0.50 −1.00 msicar tliug enot niks nopaew kcalb cinapsih naisa bara hsilgne reerac ecneics rewop ytilauxes malsi msiaduj msihddub ytilibasid thgiew ega lli latnem gnitae Race Gender Religion Health 1.00 0.50 0.00 −0.50 −1.00 saib ticilpmI saib ticilpmI saib ticilpmI saib ticilpmI saib ticilpmI saib ticilpmI saib ticilpmI saib ticilpmI Chapter 3: Responsible AI 3.7 Fairness and Bias LLMs implicit bias across stereotypes in four social categories Source: Bai et al., 2024 | Chart: 2025 AI Index report GPT-4 GPT-3.5 Turbo Claude 3 Opus Claude 3 Sonnet Llama 2 Chat 70B Llama 2 Chat 13B Llama 2 Chat 7B Alpaca 7B Figure 3.7.4 Artificial Intelligence Index Report 2025 Chapter 3: Responsible AI 3.8 Transparency and Explainability Transparency in AI encompasses several aspects. Data and model transparency involve the open sharing of development choices, including data sources and algorithmic decisions. Operational 3.8 Transparency and transparency details how AI systems are deployed, monitored, and managed Explainability in practice. While explainability often falls under the umbrella of transparency, providing insights into the AI’s decision- Featured Research making process, it is sometimes treated as a distinct category. This distinction underscores the importance of AI Foundation Model Transparency Index v1.1 being not only transparent but also The Foundation Model Transparency Index v1.1 is the second iteration of a Stanford- understandable to users and stakeholders. For the purposes of this chapter, the led project tracking transparency in model development and deployment. It AI Index includes explainability within evaluates major AI model developers across three dimensions: upstream, covering transparency, defining it as the capacity to components like data and compute used for training; the model itself, referring to comprehend and articulate the rationale the core AI system; and downstream, encompassing applications and deployments. behind AI decisions. The latest edition reports a notable rise in transparency among foundation model developers over six months. Figure 3.8.1 reports the FMTI scores for major model developers in the May 2024 release of the index, and Figure 3.8.2 reports scores across major dimensions of transparency for each developer. Foundation Model Transparency Index Scores by Domain, May 2024 Source: May 2024 Foundation Model Transparency Index StarCoder 85 Luminous 75 Jurassic-2 75 Granite 64 Phi-2 62 Llama 2 60 Stable Video Di usion 58 Palmyra-X 56 Mistral 7B 55 Claude 3 51 GPT-4 49 Upstream Gemini 1.0 Ultra 47 Model Titan Text Express 42 Downstream Fuyu-8B 33 0 10 20 30 40 50 60 70 80 90 100 Score Figure 3.8.1 Table of Contents Chapter 3 Preview 200 Artificial Intelligence Index Report 2025 Compared to the inaugural v1.0 index from October 2023, downstream impact. Open-source developers outperformed which recorded an average transparency score of 37 out of closed-source counterparts on upstream transparency, 100, v1.1 saw scores increase to 58 out of 100, largely due particularly in data and labor disclosures. Projects like to developers disclosing previously nonpublic data through the FMTI are valuable in that they provide a longitudinal submitted reports. Developers improved their scores across perspective on the state of transparency in the AI ecosystem. 89 of 100 transparency indicators, yet significant opacity At the moment, the findings suggest that transparency is remains in areas such as data access, copyright status, and improving. Titan Text Gemini 1.0 Stable Video Fuyu-8B Jurassic-2 Luminous Express Claude 3 StarCoder Ultra Granite Llama 2 Phi-2 Mistral 7B GPT-4 Di usion Palmyra-X Data 0% 60% 40% 0% 10% 100% 0% 60% 40% 40% 20% 20% 40% 50% Labor 0% 43% 71% 14% 14% 100% 29% 43% 29% 100% 100% 14% 100% 43% Compute 14% 86% 100% 0% 14% 100% 14% 100% 71% 57% 14% 14% 43% 86% Methods 0% 100% 100% 50% 75% 100% 75% 100% 75% 100% 100% 50% 75% 100% Model Basics 83% 100% 100% 83% 50% 100% 83% 100% 100% 100% 100% 50% 100% 100% Model Access 100% 67% 100% 67% 67% 100% 67% 67% 100% 100% 100% 67% 100% 33% Capabilities 80% 80% 100% 80% 100% 100% 80% 60% 100% 100% 100% 100% 60% 100% Risks 0% 57% 57% 43% 86% 100% 43% 71% 71% 29% 14% 57% 14% 14% Mitigations 0% 40% 20% 20% 40% 0% 40% 80% 60% 0% 60% 60% 0% 20% Distribution 57% 86% 100% 57% 86% 100% 57% 86% 71% 71% 71% 71% 86% 71% Usage Policy 40% 100% 100% 80% 100% 100% 100% 40% 40% 100% 40% 80% 60% 80% Feedback 67% 100% 67% 67% 33% 100% 67% 67% 33% 67% 67% 33% 67% 33% Impact 29% 29% 29% 0% 14% 14% 29% 0% 14% 0% 14% 14% 14% 14% Table of Contents Chapter 3 Preview 201 ycnerapsnarT fo snoisnemiD rojaM Chapter 3: Responsible AI 3.8 Transparency and Explainability Foundation Model Transparency Index Scores by Major Dimensions of Transparency, May 2024 Source: May 2024 Foundation Model Transparency Index Average 34% 50% 51% 79% 89% 81% 89% 47% 31% 77% 76% 62% 15% Average 36% 73% 76% 43% 53% 86% 53% 67% 62% 66% 62% 49% 58% 57% Figure 3.8.215 15 Data, labor, compute, and methods were upstream indicators; model basics, access, capabilities, risks, and mitigations were model-level indicators; and distribution, usage policy, feedback, and impact were downstream indicators. Artificial Intelligence Index Report 2025 Chapter 3: Responsible AI 3.9 Security and Safety This section explores three distinct aspects of security and safety. First, guaranteeing the integrity of AI systems 3.9 Security and Safety involves protecting components such as algorithms, data, and infrastructure against external threats like cyberattacks Benchmarks or adversarial attacks. Second, safety involves minimizing harms stemming from the deliberate or inadvertent misuse of AI HELM Safety systems. This includes concerns such as Recently, academic institutions have taken the lead in addressing gaps in AI safety the development of automated hacking benchmark standardization. Notably, Stanford’s Center for Research on Foundation tools or the utilization of AI in cyberattacks. Models (CRFM) recently introduced HELM Safety, a benchmarking suite designed Lastly, safety encompasses inherent risks from AI systems themselves, such as to evaluate AI models against responsibility and safety metrics. HELM Safety reliability concerns (e.g., hallucinations) tests a wide range of recent models from nearly all major developers across and potential risks posed by advanced AI several responsible AI and safety benchmarks, including BBQ, SimpleSafetyTests, systems. HarmBench, AnthropicRedTeam, and XSTest. BBQ measures social bias related to protected classes under more transparent and comparable framework for assessing AI U.S. antidiscrimination laws, while SimpleSafetyTests assesses models’ responsible behavior. risks related to self-harm, physical harm, and child sexual abuse material. HarmBench evaluates responses to prompts involving Figure 3.9.1 presents the mean safety scores of various models harassment, chemical weapons production, and misinformation across all tested benchmarks, where a higher score indicates using red-teaming techniques. AnthropicRedTeam examines a safer model. According to the benchmark, the safest model how models handle adversarial conversations designed to currently is Claude 3.5 Sonnet, scoring 0.977, followed test harmfulness, and XSTest measures the trade-off between closely by o1 at 0.976. Over time, some models appear to be helpfulness and harmlessness by testing false refusals of becoming safer. For example, GPT-3.5 Turbo (0613), released benign prompts and compliance with subtly harmful ones. By in 2022, scored 0.853–0.123 points lower than OpenAI’s best- introducing a standardized approach, HELM Safety provides a performing model today. 0.96 Table of Contents Chapter 3 Preview 202 )3160( obruT 5.3-TPG )B76( tahC MLL keeSpeeD tcurtsnI XRBD )B7( 3.0v tcurtsnI lartsiM R dnammoC )B7×8( tcurtsnI lartxiM )B07( obruT tcurtsnI 1.3 amalL )B22×8( tcurtsnI lartxiM sulP R dnammoC )B8( obruT tcurtsnI 1.3 amalL 3v keeSpeeD )70-30-4202( ukiaH 3 edualC )B27( tahC 5.1newQ )B8( tcurtsnI 3 amalL )B07( tcurtsnI 3 amalL )B504( obruT tcurtsnI 1.3 amalL )100( orP 5.1 inimeG )100( hsalF 5.1 inimeG )81-70-4202( inim o4-TPG )B27( tcurtsnI 2newQ )31-50-4202( o4-TPG )21-90-4202( inim-1o )90-40-4202( obruT 4-TPG )92-20-4202( supO 3 edualC )71-21-4202( 1o )02604202( tennoS 5.3 edualC 1R keeSpeeD )13-10-5202( inim-3o 1 0.8 0.6 0.4 0.2 0 2023 2024 2025 erocs naeM HELM Safety: mean score Source: HELM, 2025 | Chart: 2025 AI Index report 0.92 0.93 0.93 0.93 0.95 0.95 0.960.97 0.98 0.98 0.85 0.87 0.84 0.85 0.86 0.86 0.87 0.88 0.89 0.89 0.900.90 0.86 0.81 0.81 0.73 0.63 Figure 3.9.1 Artificial Intelligence Index Report 2025 Chapter 3: Responsible AI 3.9 Security and Safety AIR-Bench AIR-Bench 2024 is a new safety benchmark that aligns prompt due to safety, ethical, or compliance concerns. AI evaluation with real-world regulatory and corporate Assessments of 22 leading models revealed significant frameworks. It employs a four-tier taxonomy (system and variability, with refusal rates ranging from 91% (Anthropic’s operational risks, content safety risks, societal risks, and legal Claude series) to 25% (DBRX Instruct) (Figure 3.9.2). Figure and rights risks). Among these four broad risk categories are 3.9.3 visualizes refusal rates across various risk categories. 314 granular microrisks. The risks studied in the benchmark The results of AIR-Bench 2024 highlight widespread are derived from eight significant government regulations misalignment between current models and key global and 16 corporate policies. As such, AIR-Bench is designed to regulations, such as the EU AI Act and the U.S. Executive assess model safety through the lens of real-world AI risks Order on the Safe, Secure, and Trustworthy Development identified by businesses and government entities. and Use of AI. While some models demonstrated strong safeguards in areas like hate speech and child harm, broader AIR-Bench evaluates models based on their refusal rates— inconsistencies point to the need for targeted improvements, the frequency with which they decline to respond to a given particularly in automated decision-making contexts. 0.91 0.830.830.84 0.790.80 0.75 0.71 0.72 0.620.620.620.640.64 0.560.58 0.530.54 0.49 0.51 0.440.440.45 0.39 0.41 0.35 0.32 0.29 0.25 Table of Contents Chapter 3 Preview 203 tcurtsnI XRBD sulP R dnammoC R dnammoC )7042( 2 egraL lartsiM )B7×8( tcurtsnI lartxiM 3v keeSpeeD )B22×8( tcurtsnI lartxiM 400-X-arymlaP )21-90-4202( inim-1o )B27( tahC 5.1newQ )B76( tahC MLL keeSpeeD 1R keeSpeeD )B43( tahC iY )81-70-4202( inim o4-TPG )200( orP 0.1 inimeG )B27( tcurtsnI 2newQ )B8( obruT tcurtsnI 1.3 amalL )60-80-4202( o4-TPG )1030( obruT 5.3-TPG )3160( 4-TPG )B8( tcurtsnI 3 amalL )90-40-4202( obruT 4-TPG )13-10-5202( inim-3o hsalF 5.1 inimeG )71-21-4202( 1o )70-30-4202( ukiaH 3 edualC orP 5.1 inimeG )92-20-4202( supO 3 edualC )22-01-4202( tennoS 5.3 edualC 1.00 0.80 0.60 0.40 0.20 0.00 Model etar lasufeR AIR-Bench: refusal rate Source: Zeng et al., 2024 | Chart: 2025 AI Index report Figure 3.9.2 Artificial Intelligence Index Report 2025 Chapter 3: Responsible AI 3.9 Security and Safety Figure 3.9.3 Table of Contents Chapter 3 Preview 204 Artificial Intelligence Index Report 2025 Chapter 3: Responsible AI 3.9 Security and Safety Featured Research Beyond Shallow Safety Alignment Experiments show that even minor modifications can In 2024, an interdisciplinary team of computer scientists drastically weaken a model’s safety mechanisms. For example, introduced the concept of shallow safety alignment—the simply prefilling a model’s response with nonstandard text or idea that AI systems are often trained to be safe in superficial applying minimal fine-tuning increased harmful output rates and ineffective ways. In many cases, a model’s safeguards from 1.5% to 87.9% after just six fine-tuning steps.16 Figure 3.9.4 are limited to its first few words (tokens) of response. As a shows the success rate of different attacks on various models result, if a user manipulates the model to start with anything based on the number of harmful tokens prefilled or inserted other than a standard safety warning (e.g., “Your request into the model’s inference sequence. To address this issue, violates our terms of service”), the rest of the response researchers proposed two key solutions: expanding training becomes significantly more vulnerable to adversarial attacks. data to include examples where the model learns to recover For example, if a user directly asks how to build a bomb, from harmful responses and redirect them toward safe refusals, the model will likely refuse to answer. However, if the same and regularizing initial word choices, ensuring that even if the request is framed in a way that induces the model to begin model starts with an unusual response, it still maintains its its response with “Sure, here’s a detailed guide,” it is far more safety constraints. These techniques significantly improved likely to continue generating harmful content. resistance to adversarial attacks, lowering attack success rates to as little as 2.8% in certain cases. This research highlights a need for deeper and more resilient alignment strategies to prevent the manipulation of AI safety mechanisms. Llama 2 7B (Base) Llama 2 7B Chat (Aligned) Gemma 7B (Base) Gemma 1.1. 7B IT (Aligned) 100% 80% 60% 40% 20% 0% 0 1 2 3 4 5 6 7 8 9 10 Number of pre lled harmful tokens Table of Contents Chapter 3 Preview 205 etar sseccus kcattA Attack success rate vs. number of pre lled harmful tokens in LLMs Source: Qi et al., 2024 | Chart: 2025 AI Index report Figure 3.9.4 16 A fine-tuning step in AI refers to an iteration in the process of training a pretrained model on a smaller, domain-specific dataset to improve its performance on a particular task. Artificial Intelligence Index Report 2025 Llama3-8B-instruct RT RT-EAT-LAT 1.00 1.00 1.00 1.00 0.84 0.84 0.83 0.80 0.64 0.64 0.61 0.60 0.40 0.20 0.00 MMLU MT-Bench Compliance Evaluation metric Table of Contents Chapter 3 Preview 206 ↑ ecnamrofrep lareneG Chapter 3: Responsible AI 3.9 Security and Safety Improving the Robustness to Persistently Targeted latent adversarial training in LLMs Source: Sheshadri et al., 2024 Harmful Behaviors in LLMs Figure 3.9.5 The challenge in eliminating harmful behavior in LLMs is that traditional training methods often teach models to conceal such behavior rather than removing it entirely. A new approach, targeted latent adversarial training (LAT), takes a more precise strategy by actively exposing a model’s weaknesses during training to make it more robust against adversarial attacks (Figure 3.9.5). This method outperforms previous techniques—such as R2D2—while requiring far less computing power. For example, in tests against jailbreaking attempts (where users try to bypass a model’s safeguards), LAT reduced computational costs by 700 times while maintaining strong performance on reducing vulnerability to adversarial attacks (Figure 3.9.6). This finding on regular tasks. For the Llama3-8B-instruct model efficiency is important because if improving model safety requires more family, LAT preserved strong performance on computational resources while reducing performance, fewer developers benchmarks like MMLU while significantly are likely to adopt these safety-improving methods. General performance on nonadversarial data Source: Sheshadri et al., 2024 | Chart: 2025 AI Index report Figure 3.9.6 Artificial Intelligence Index Report 2025 Chapter 3: Responsible AI 3.9 Security and Safety LAT also proved effective in removing backdoor vulnerabilities, from Harry Potter) and made it less likely that knowledge a type of attack where an AI model is subtly modified during would be relearned compared to baseline methods. When training to produce unintended—and possibly malicious— applied to sensitive knowledge areas such as biological or behavior when triggered by specific inputs. Notably, LAT cybersecurity risks, LAT effectively weakened knowledge eliminated these vulnerabilities even without prior knowledge extraction attacks while still allowing the model to correctly of the exact trigger. Beyond security improvements, LAT respond to over 90% of safe and benign requests. Methods enhances the ability to erase harmful or copyrighted like LAT are important not only because they improve model knowledge from a model and prevents it from relearning safety, but also because they are computationally efficient removed content. For example, LAT significantly reduced a and practical to implement. model’s ability to regenerate copyrighted text (e.g., passages Llama3-8B-instruct RT RT-EAT-LAT 0.50 0.49 0.40 0.30 0.20 0.20 0.17 0.15 0.14 0.14 0.10 0.09 0.09 0.07 0.03 0.04 0.03 0.01 0.01 0.000.00 0.00 0.00 0.00 Direct requests PAIR Pre ll AutoPrompt GCG Many-shot Attack type Table of Contents Chapter 3 Preview 207 ↓ etar sseccus kcattA Model resistance to jailbreaking attacks Source: Sheshadri et al., 2024 | Chart: 2025 AI Index report Figure 3.9.7 Artificial Intelligence Index Report 2025 Chapter 3: Responsible AI 3.10 Special Topics on RAI This section explores RAI’s connections with agentic AI and election misinformation—two topics that are rapidly gaining prominence. 3.10 Special Topics on RAI AI Agents The development and deployment of AI agents—defined confirmed that 68.8% of the risks identified by ToolEmu are as “artificial agents with natural language interfaces, whose plausible real-world threats. Using a benchmark of 36 toolkits function is to plan and execute sequences of actions on and 144 test cases, the study found that even the most safety- behalf of a user, across one or more domains, in line with the optimized LM agents failed in 23.9% of critical scenarios, with user’s expectations”—present unique challenges for ensuring errors including dangerous commands, misdirected financial responsible AI. These assistants operate autonomously, transactions, and traffic control failures (Figure 3.10.2). interact dynamically with their environments, and make While LM agents show promise in automating complex decisions that can have significant ethical, legal, and societal tool interactions, their reliability in high-stakes applications implications. As a result, they require specialized approaches remains a significant concern. Suites like ToolEmu are to address the risks they pose with respect to transparency, important for testing the reliability and safety of AI systems, accountability, and reliability; these challenges can be such as agents, by providing a platform to evaluate their amplified by the agents’ capacity for learning, adaptation, performance and assess their real-world risks. and decision making in unstructured or evolving scenarios. Jailbreaking Multimodal Agents With a Single Image Identifying the Risks of LM Agents With LM- The promise of artificial agents lies in their ability to act Simulated Sandboxes independently in the world to solve complex tasks. As agents New research highlights that as language-model-powered proliferate, the likelihood of interactions in increasingly tools and agents advance, they also amplify risks such as multiagent environments grows, introducing vulnerabilities data breaches and financial losses. However, current risk that extend beyond those of single agents. In such settings, assessment methods are resource-intensive and difficult to unforeseen interactions between agents can amplify risks, scale. To address this, researchers introduced ToolEmu, an leading to cascading failures, coordination breakdowns, or environment that emulates tool execution to enable scalable adversarial exploitation that would be less likely in isolated testing and automated safety evaluations (Figure 3.10.1). The deployments. framework includes both a standard emulator for general risk assessments and an adversarial emulator designed to New research from Asia explores a multiagent vulnerability stress-test agents in extreme scenarios. Human evaluations in multimodal large language model (MLLM) systems, Overview of ToolEmu Source: Ruan et al., 2024 Figure 3.10.1 Table of Contents Chapter 3 Preview 208 Artificial Intelligence Index Report 2025 Chapter 3: Responsible AI 3.10 Special Topics on RAI 100% 80% 62.00% 60% 54.60% 45.00% 44.30% 39.40% 40% 20% 0% ChatGPT-3.5 Vicuna-1.5-13B Vicuna-1.5-7B Claude 2 GPT-4 Model demonstrating how jailbreaking one agent can trigger a rapid, system- wide failure. The researchers call this phenomenon “infectious jailbreaks,” where compromising a single agent causes harmful behavior to spread exponentially across others. Specifically, they found that injecting just one adversarial image (e.g., an image suggesting that human beings are a disease) into the memory of an MLLM agent could trigger an uncontrolled cascade, spreading harmful behaviors across interconnected agents without further intervention. The infectious jailbreak leverages interactions between agents to compel infected agents to insert adversarial images into the memory banks of uninfected (benign) agents. In simulations using a network of up to 1 million LLaVA-1.5-based agents, the infection rate reached near-total propagation within 27 to 31 interaction rounds (Figure 3.10.3). While a theoretical containment strategy has been proposed, no practical mitigation measures currently exist, leaving multiagent systems highly vulnerable. The compounded risks of deploying interconnected MLLM agents at scale make this a critical security concern. This research suggests that while MLLM systems are an exciting avenue of AI research, they are still highly vulnerable to low-resource jailbreaks. Table of Contents Chapter 3 Preview 209 ↓ ecnedicni eruliaF Failure incidence of LM agents Source: Ruan et al., 2024 | Chart: 2025 AI Index report Figure 3.10.217 Infection ratio by chat round Source: Gu et al., 2024 Figure 3.10.3 17 The down arrow on the y-axis indicates that a lower score is better. Artificial Intelligence Index Report 2025 Chapter 3: Responsible AI 3.10 Special Topics on RAI Election Misinformation 2024 was a significant year for elections worldwide, with 4 study AI misinformation, especially as AI systems improve in billion people voting in national elections across countries capability and grow in prominence. including the United States, the United Kingdom, Indonesia, Mexico, and Taiwan. Last year’s AI Index examined AI’s impact AI Misinformation in the US Elections on elections, focusing on both its potential influence and real- AI could influence elections in various ways. Recent world examples. This year, the topic is being revisited. While research highlights ethical concerns surrounding AI-driven some reports suggest that AI-driven misinformation has not misinformation and examines their relevance in the recent had the feared impact, others indicate it still poses a potential U.S. election. risk. As a result, it is important to continually monitor and Conceptualization of ethical concerns around AI and information manipulation Source: AI Index, 202518 Ethical concern Description Example Liar’s dividend The existence of deepfake technology enables Donald Trump and his supporters falsely claimed that individuals to deny genuine evidence by claiming the crowd shown in a photo of Kamala Harris’ rally in it is fake, thereby undermining accountability and Detroit was created using AI. truth. This phenomenon erodes public trust in legitimate evidence and fosters an environment where even verified information is questioned. Blackmail AI technology is exploited to create fabricated The American Sunlight Project identified more than content, including deepfakes, for purposes such 35,000 instances of deepfake content depicting as sexual exploitation, financial extortion, and 26 members of Congress (25 of them women) on reputational sabotage. Blackmailers leverage pornographic sites. these tools to extract value from victims who, understandably, struggle to persuasively debunk the fabricated content. Erosion of trust in evidence AI-generated content challenges the authenticity The Doppelganger campaign conducted by Russia of all digital media, fundamentally undermining the involved using cybersquatted domains resembling notion of truth. Hyperrealistic falsifications blur the legitimate news outlets, populated with AI-generated line between legitimate and false content, eroding articles, to disseminate Russian government public confidence in the integrity of information. propaganda while concealing its origins and misleading viewers into believing the content came from credible media sources. Reduction of cognitive AI’s capacity to analyze vast datasets enables The fringe candidate Jason Palmer defeated Joe Biden autonomy advanced voter profiling and microtargeting, in the American Samoa primary, in part by leveraging tailoring messages to individual preferences, AI-generated emails, texts, audio, and video. These AI- behaviors, and vulnerabilities. AI can also exploit driven communications were hyperpersonalized and emotional and subconscious triggers, thereby emotionally charged, targeting specific voter groups to manipulating individuals’ decision-making influence their choices. processes. 18 This table was compiled by Ann Fitz-Gerald, Halyna Padalko, and Dmytro Chumachenko. Table of Contents Chapter 3 Preview 210 Artificial Intelligence Index Report 2025 Chapter 3: Responsible AI 3.10 Special Topics on RAI Exploitation of personal Deepfake technology is harnessed to create Fake celebrity endorsements become the latest brands unauthorized videos or images of well-known weapon in disinformation wars, sowing confusion individuals, including celebrities, public figures, ahead of the 2024 election—for example, Donald and influencers. By stealing personal brands and Trump posted an AI-generated picture of Taylor Swift, fabricating endorsements, malicious actors aim to falsely claiming she had endorsed his presidential run. deceive audiences and exploit their trust in these individuals to lend credibility to false narratives. Amplification of hate AI technologies contribute to the amplification During a disinformation campaign, Donald Trump and speech and normalization of hate speech by creating several of his allies repeatedly promoted an unfounded echo chambers and filter bubbles. These systems conspiracy theory suggesting that Haitian migrants in reinforce preexisting biases and promote divisive Springfield, Ohio, were stealing and eating cats and content, as they prioritize user engagement metrics dogs. This narrative was further amplified through the over ethical considerations. spread of related AI-generated memes designed to evoke fear of and hostility toward Haitian communities. Reduction in the AI enables the creation, translation, and OpenAI disrupted an operation dubbed “Bad traceability of foreign enhancement of linguistically perfect text that is Grammar,” in which accounts linked to Russia used operations indistinguishable from human writing, empowering ChatGPT for comment spamming on Telegram malicious foreign actors and making their activities channels. The messages, tailored with region-specific untraceable. Previously, foreign disinformation language, mimicked diverse demographics and campaigns were often identifiable due to grammar political views in the United States to manipulate mistakes by nonnative speakers, a vulnerability that discourse. AI-generated content effectively eliminates. Privacy violations AI systems often rely on extensive data collection A robocall from a fake Joe Biden targeted New for training, raising ethical concerns about the Hampshire Democrats, misleading them about primary misuse or exposure of personal information. voting. This case highlights how AI-enabled systems The lack of robust safeguards in managing can use personal data to spread disinformation and sensitive data can lead to violations of privacy infringe on individual privacy of potential voters. rights, complicating the ethical landscape of AI deployment. Figure 3.10.4 Rest of World 2024 AI-Generated Election Content Rest of World has been tracking notable cases of AI- spanning four media types—audio, image, text, and video— generated election content that occurred across the world in on 10 different platforms, including Facebook, Instagram, and 2024. Their database documents 60 incidents in 15 countries TikTok. Figure 3.10.5 provides further details. Rest of World 2024 AI elections: summary statistics Source: Rest of World, 2025 | Table: 2025 AI Index report Countries Media modalities Platforms Totals 15 4 10 Individual list Bangladesh, Belarus, China, India, Audio, image, text, video ChatGPT, Facebook, Instagram, Indonesia, Mexico, Pakistan, Panama, Medium, Reddit, television, TikTok, South Africa, South Korea, Sri Lanka, YouTube, WhatsApp, X/Twitter Taiwan, United States, Uruguay, Venezuela Figure 3.10.5 Table of Contents Chapter 3 Preview 211 Artificial Intelligence Index Report 2025 Chapter 3: Responsible AI 3.10 Special Topics on RAI The following section highlights five significant cases from India’s incumbent party motivates campaign workers with the tracker, offering a qualitative look at the nature of AI- personalized videos (India, video, WhatsApp, Apr. 18, generated election content in 2024. 2024) On April 18, over 500 campaign volunteers for the incumbent Fake corporate support of Mexican politician (Mexico, Bharatiya Janata Party received personalized videos from image, X/Twitter, Jun. 2, 2024) a member of the party, created with the help of AI tools. In On March 18, the civic organization Sociedad Civil de México the video, BJP member Shakti Singh called on volunteers encouraged Starbucks to create a special cup to celebrate to share the party’s message with the public, emphasizing Xóchitl Gálvez, the opposition presidential candidate. policies such as “Clean India,” “Digital India,” and “Make In The organization shared an AI-generated image on X of a India.” Despite noticeable edits, each video featured Singh Starbucks coffee cup with the inscription “#Xochitl2024,” addressing the individual recipient by their name (Figure along with the hashtag #StarbucksQueremosTazaXG 3.10.7). Campaign employees involved in making the video (#StarbucksWeWantACupXG) (Figure 3.10.6). The next maintained they did not require Singh to record each name day, Gálvez encouraged her followers on X to order a “café separately but instead relied on a combination of voice- sin miedo” (coffee without fear), which was a play on her cloning and lip-matching software. campaign slogan: “For a Mexico without fear.” She invited supporters to post photos of their coffee cups and tag her Source: Rest of World, 2024 Figure 3.10.7 team on social media. The AI-generated image quickly gained traction as users posted. Starbucks, however, disavowed the designs and stated that it does not endorse political parties. Source: Rest of World, 2024 Figure 3.10.6 Table of Contents Chapter 3 Preview 212 Artificial Intelligence Index Report 2025 Chapter 3: Responsible AI 3.10 Special Topics on RAI Uruguay’s ‘impossible’ debate (Uruguay, video, television, Deepfakes of Pakistani party leaders call for election Oct. 27, 2024) boycotts (Pakistan, audio and video, X/Twitter, Feb. 7, 2024) “Santo y Seña,” a general interest morning show, broadcast The day before Pakistan’s general elections, a voice recording what it called “the impossible debate” ahead of Uruguay’s of former prime minister and founder of the Pakistan Tehreek- presidential election. The debate featured right-wing e-Insaf (PTI) party, Imran Khan, emerged on social media Partido Colorado presidential candidate Andrés Ojeda and (Figure 3.10.9). The voice referred to a crackdown from state his counterpart for the center-left alliance Frente Amplio, institutions on the PTI, and the speaker was heard calling for “Yamandú” Orsi (Figure 3.10.8). However, Orsi did not appear a boycott of the elections, suggesting that there was no use in on the show but was “present” through an AI-powered voting. The official X account of the PTI denounced the audio hologram with a script pulled, according to the show’s host, as fake. A video posted on the same day showed another from the candidate’s recent interviews. Before the debate notable PTI leader, Yasmin Rashid, apparently also calling for started, Orsi and his party went on another channel to a boycott. In the clip, Rashid appeared behind bars, and the criticize the stunt as a “fake interview” posing “an attack on audio alleged that Pakistan’s election commission had been democracy.” The next day, the host responded that the stunt “bought.” The nonprofit fact-checking organization Soch was neither fake news nor an attack on democracy; it was Fact Check determined the video had been doctored. merely a joke. Source: Rest of World, 2024 Source: Rest of World, 2024 Figure 3.10.9 Figure 3.10.8 Table of Contents Chapter 3 Preview 213 Artificial Intelligence Index Report 2025 Chapter 3: Responsible AI 3.10 Special Topics on RAI United States election affected by ‘spamouflage’ campaign AI-generated potholes seek to influence South African (China and US, image, X/Twitter, Facebook, YouTube, voters (South Africa, image, X/Twitter, Facebook, TikTok, Medium, Feb. 15, 2024) Instagram, Reddit, May 4, 2024) The Institute for Strategic Dialogue (ISD), a U.K.-based think On May 4, a Facebook user posted an AI-generated image tank, uncovered actors suspected of being linked to a Chinese showing a long road dotted with potholes leading to Cape government–run influence campaign sharing AI-generated Town’s iconic Table Mountain (Figure 3.10.11). The caption under images as part of an effort to spread misinformation ahead the image suggested that, under the Democratic Alliance (DA) of the 2024 U.S. elections. The “spamouflage” campaign—a party, the municipal government had failed to maintain basic term used to designate online operations leveraging a services, contributing to the deterioration of infrastructure. network of social media accounts to promote propaganda Many shared the image to discourage voters in the Western or misinformation—had been active since 2017, but it began Cape from supporting the DA, which has managed the to make more noticeable use of AI image generators as it province for 15 years. Though the original post was deleted narrowed its focus on the U.S. election. As part of its campaign, from Facebook, it continues to circulate on other social media a network of accounts shared images exacerbating political platforms. AFP Fact Check, which is housed at the Agence polarization and casting doubt on the integrity of elections. France-Presse, reported that the image was AI-generated and Negative posts were disproportionately targeted at President traced it to an Instagram user who creates AI art. Joe Biden (Figure 3.10.10). The ISD highlighted a particular proliferation of these images on X. Source: Rest of World, 2024 Figure 3.10.11 Source: Rest of World, 2024 Figure 3.10.10 Table of Contents Chapter 3 Preview 214 Artificial Intelligence Index Report 2025 CHAPTER 4: Economy Text and analysis by Njenga Kariuki Artificial Intelligence Index Report 2025 Chapter 4: Economy Overview 216 4.4 Corporate Activity 260 Chapter Highlights 217 Industry Usage 260 Use of AI Capabilities 260 4.1 What’s New in 2024: A Timeline 219 Deployment of Generative AI Capabilities 264 AI’s Labor Impact 267 4.2 Jobs 223 AI Labor Demand 223 4.5 Robot Deployments 272 Global AI Labor Demand 223 Aggregate Trends 272 US AI Labor Demand by Skill Industrial Robots: Traditional Cluster and Specialized Skill 225 vs. Collaborative Robots 274 US AI Labor Demand by Sector 228 By Geographic Area 275 US AI Labor Demand by State 229 Country-Level Data on Service AI Hiring 232 Robotics 279 AI Skill Penetration 234 AI Talent 236 ACCESS THE PUBLIC DATA Highlight: Measuring AI’s Current Economic Integration 242 4.3 Investment 246 Corporate Investment 246 Startup Activity 247 Global Trends 247 Regional Comparison by Funding Amount 251 Regional Comparison by Newly Funded AI Companies 255 Focus Area Analysis 258 Table of Contents 216 AArrttiifificciiaall IInntteelllliiggeennccee IInnddeexx RReeppoorrtt 22002255 CHAPTER 4: Economy Overview The economic implications of AI came into sharper focus in 2024, with substantive impact across many sectors. Early productivity gains from generative AI are becoming measurable in specific tasks, while questions persist about the technology’s long-term impact on the broader economy. The labor market has begun to show signs of AI- driven transformation, with certain knowledge-worker roles experiencing disruption as new AI-adjacent positions emerge. Companies across sectors and geographical regions are moving beyond experimental AI adoption toward systematic integration. Investment patterns reflect a growing sophistication in the AI landscape, with funding increasingly directed toward specialized applications in enterprise automation and industry-specific solutions. This chapter examines AI-related economic trends using data from Lightcast, LinkedIn, Quid, McKinsey and the International Federation of Robotics (IFR). It begins by analyzing AI-related occupations, covering labor demand, hiring trends, skill penetration, and talent availability. The chapter then explores corporate investment in AI, including a section focused specifically on generative AI. Finally, it assesses AI’s productivity impact as well as robot installations across various sectors. Table of Contents Chapter 4 Preview 217 AArrttiifificciiaall IInntteelllliiggeennccee IInnddeexx RReeppoorrtt 22002255 CHAPTER 4: Economy Chapter Highlights 1. Global private AI investment hits record high with 26% growth. Corporate AI investment reached $252.3 billion in 2024, with private investment climbing 44.5% and mergers and acquisitions up 12.1% from the previous year. The sector has experienced dramatic expansion over the past decade, with total investment growing more than thirteenfold since 2014. 2. Generative AI funding soars. Private investment in generative AI reached $33.9 billion in 2024, up 18.7% from 2023 and over 8.5 times higher than 2022 levels. The sector now represents more than 20% of all AI-related private investment. 3. The U.S. widens its lead in global AI private investment. U.S. private AI investment hit $109.1 billion in 2024, nearly 12 times higher than China’s $9.3 billion and 24 times the U.K.’s $4.5 billion. The gap is even more pronounced in generative AI, where U.S. investment exceeded the combined total of China and the European Union plus the U.K. by $25.4 billion, expanding on its $21.8 billion gap in 2023. 4. Use of AI climbs to unprecedented levels. In 2024, the proportion of survey respondents reporting AI use by their organizations jumped to 78% from 55% in 2023. Similarly, the number of respondents who reported using generative AI in at least one business function more than doubled—from 33% in 2023 to 71% last year. 5. AI is beginning to deliver financial impact across business functions, but most companies are early in their journeys. Most companies that report financial impacts from using AI within a business function estimate the benefits as being at low levels. 49% of respondents whose organizations use AI in service operations report cost savings, followed by supply chain management (43%) and software engineering (41%), but most of them report cost savings of less than 10%. With regard to revenue, 71% of respondents using AI in marketing and sales report revenue gains, 63% in supply chain management, and 57% in service operations, but the most common level of revenue increases is less than 5%. 6. Use of AI shows dramatic shifts by region, with Greater China gaining ground. While North America maintains its leadership in organizations’ use of AI, Greater China demonstrated one of the most significant year-over-year growth rates, with a 27 percentage point increase in organizational AI use. Europe followed with a 23 percentage point increase, suggesting a rapidly evolving global AI landscape and intensifying international competition in AI implementation. Table of Contents Chapter 4 Preview 218 AArrttiifificciiaall IInntteelllliiggeennccee IInnddeexx RReeppoorrtt 22002255 CHAPTER 4: Economy Chapter Highlights (cont’d) 7. China’s dominance in industrial robotics continues despite slight moderation. In 2023, China installed 276,300 industrial robots, six times more than Japan and 7.3 times more than the United States. Since surpassing Japan in 2013, when it accounted for 20.8% of global installations, China’s share has risen to 51.1%. While China continues to install more robots than the rest of the world combined, this margin narrowed slightly in 2023, marking a modest moderation in its dramatic expansion. 8. Collaborative and interactive robot installations become more common. In 2017, collaborative robots represented a mere 2.8% of all new industrial robot installations, a figure that climbed to 10.5% by 2023. Similarly, 2023 saw a rise in service robot installations across all application categories except medical robotics. This trend indicates not just an overall increase in robot installations but also a growing emphasis on deploying robots for human-facing roles. 9. AI is driving significant shifts in energy sources, attracting interest in nuclear energy. Microsoft announced a $1.6 billion deal to revive the Three Mile Island nuclear reactor to power AI, while Google and Amazon have also secured nuclear energy agreements to support AI operations. 10. AI boosts productivity and bridges skill gaps. Last year’s AI Index was among the first reports to highlight research showing AI’s positive impact on productivity. This year, additional studies reinforced those findings, confirming that AI boosts productivity and, in most cases, helps narrow the gap between low- and high-skilled workers. Table of Contents Chapter 4 Preview 219 Artificial Intelligence Index Report 2025 Chapter 4: Economy 4.1 What’s New in 2024: A Timeline The chapter begins with an overview of some of the most significant AI-related economic events in 2024, as selected by the AI Index Steering Committee. 4.1 What’s New in 2024: A Timeline Date Event Type Image Jan 16, 2024 Synopsys acquires Ansys for $35 billion to improve Acquisition silicon-to-systems design solutions. Figure 4.1.1 Source: Synopsys, 2024 Feb 21, 2024 Reports claim that OpenAI surpassed $2 billion in Valuation milestone annualized revenue in December 2023. Figure 4.1.2 Source: Inc., 2024 Feb 29, 2024 Figure AI, a humanoid robot startup, raises $675 Investment/funding million at a valuation of $2.6 billion. Figure 4.1.3 Source: SiliconAngle, 2024 Mar 21, 2024 Microsoft hires most of Inflection AI’s staff, Acquisition including cofounders, and pays $650 million to license Inflection’s AI models. Figure 4.1.4 Source: Reuters, 2024 May 1, 2024 CoreWeave, an AI cloud infrastructure startup, Investment/funding secures a $1.1 billion funding round at a valuation of $19 billion. Figure 4.1.5 Source: Fortune, 2024 Table of Contents Chapter 4 Preview 220 Artificial Intelligence Index Report 2025 Chapter 4: Economy 4.1 What’s New in 2024: A Timeline May 21, 2024 Scale AI, a data-labeling startup, raises $1 billion Investment/funding and reaches a valuation of $13.8 billion. Figure 4.1.6 Source: Reuters, 2024 Jun 11, 2024 Mistral AI, a French open-source AI model startup, Investment/funding raises $640 million at a valuation of $6 billion. Figure 4.1.7 Source: TechCrunch, 2024 Jun 14, 2024 Tempus AI, a precision medicine company Investment/funding leveraging AI for medical data analysis, goes public, raising $410.7 million and achieving an implied valuation of over $6 billion. Figure 4.1.8 Source: Reuters, 2024 Jul 22, 2024 Cohere, an AI startup specializing in enterprise Investment/funding applications, raises $500 million in funding at a valuation of $5.5 billion. Figure 4.1.9 Source: Crunchbase, 2024 Aug 2, 2024 Google hires Character.AI’s cofounders along with Acquisition research team members and licenses the startup’s AI technology in a deal to buy out Character.AI’s shareholders for approximately $2.5 billion. Figure 4.1.10 Source: The Verge, 2024 Aug 5, 2024 Groq, an AI chip startup specializing in fast Investment/funding inference, raises $640 million at a valuation of $2.8 billion. Figure 4.1.11 Source: Groq, 2024 Table of Contents Chapter 4 Preview 221 Artificial Intelligence Index Report 2025 Chapter 4: Economy 4.1 What’s New in 2024: A Timeline Aug 12, 2024 AMD acquires Silo AI, Europe’s largest private AI Acquisition lab, for approximately $665 million. Figure 4.1.12 Source: AMD, 2024 Sep 5, 2024 Safe Superintelligence (SSI) secures $1 billion in Investment/funding funding. Figure 4.1.13 Source: TechCrunch, 2024 Sep 12, 2024 Salesforce launches Agentforce, a suite of Product launch/integration autonomous AI agents for business operations, across its platform. Figure 4.1.14 Source: Salesforce, 2024 Sep 20, 2024 Microsoft announces a $1.6 billion deal with Partnership Constellation Energy to revive the Three Mile Island nuclear reactor to power AI data centers. Figure 4.1.15 Source: NPR, 2024 Oct 2, 2024 OpenAI raises $6.6 billion at a valuation of $157 Investment/funding billion. Figure 4.1.16 Source: Axios, 2024 Oct 14, 2024 Google announces an agreement to purchase Partnership nuclear energy from multiple small modular reactors (SMRs) developed by Kairos Power. Figure 4.1.17 Source: Google, 2024 Oct 16, 2024 Amazon announces a nuclear energy plan for SMR Partnership development with Energy Northwest, X-energy, and Dominion Energy. Figure 4.1.18 Source: Amazon, 2024 Table of Contents Chapter 4 Preview 222 Artificial Intelligence Index Report 2025 Chapter 4: Economy 4.1 What’s New in 2024: A Timeline Oct 17, 2024 Google’s NotebookLM sheds “experimental” label Product launch/integration and boasts millions of users and 80,000-plus organizations. Figure 4.1.19 Source: Google, 2024 Nov 22, 2024 Anthropic expands its partnership with AWS with Partnership an additional $4 billion investment from Amazon, bringing the total to $8 billion. Figure 4.1.20 Source: Anthropic, 2024 Dec 17, 2024 Databricks, an AI data analytics company, raises Investment/funding $10 billion at a valuation of $62 billion. Figure 4.1.21 Source: TechCrunch, 2024 Dec 18, 2024 Perplexity AI, a startup focused on AI-powered Investment/funding search products, raises $500 million at a valuation of $9 billion. Figure 4.1.22 Source: AI Magazine, 2024 Dec 23, 2024 xAI announces a $6 billion funding round, bringing Investment/funding the total to $12 billion at a valuation of over $40 billion. Figure 4.1.23 Source: Forbes, 2024 Dec 30, 2024 Nvidia acquires Israeli startup Run:ai for $700 Acquisition million to increase its GPU optimization capability in demanding computing environments. Figure 4.1.24 Source: TechCrunch, 2024 Table of Contents Chapter 4 Preview 223 Artificial Intelligence Index Report 2025 4.2 Jobs AI Labor Demand This section analyzes the demand for AI-related skills in labor Global AI Labor Demand markets, drawing on data from Lightcast. Since 2010, Lightcast Figure 4.2.1 and Figure 4.2.2 show the percentage of job has analyzed hundreds of millions of job postings from over postings demanding AI skills. In 2024, Singapore (3.2%), 51,000 websites, identifying those that require AI skills. Luxembourg (2%), and Hong Kong (1.9%) led in this metric. In 2023, AI-related jobs accounted for 1.4% of all American job postings. In 2024, that number increased to 1.8%. Most countries saw an increase from 2023 to 2024 in the share of job postings requiring AI skills. 5.00% 4.00% 3.00% 2.00% 1.00% 0.00% 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 Table of Contents Chapter 4 Preview 224 )sgnitsop boj lla fo %( sgnitsop boj IA Chapter 4: Economy 4.2 Jobs AI job postings (% of all job postings) by select geographic areas, 2014–24 (part 1) Source: Lightcast, 2024 | Chart: 2025 AI Index report 3.27%, Singapore 1.99%, Luxembourg 1.89%, Hong Kong 1.79%, United States 1.72%, United Arab Emirates 1.41%, Canada 1.37%, Switzerland 1.31%, Belgium 1.31%, Sweden 1.26%, United Kingdom 1.25%, Netherlands Figure 4.2.1 Artificial Intelligence Index Report 2025 Chapter 4: Economy 4.2 Jobs 5.00% 4.00% 3.00% 2.00% 1.00% 0.00% 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 Table of Contents Chapter 4 Preview 225 )sgnitsop boj lla fo %( sgnitsop boj IA AI job postings (% of all job postings) by select geographic areas, 2014–24 (part 2) Source: Lightcast, 2024 | Chart: 2025 AI Index report 1.24%, Spain 1.15%, Germany 1.14%, Australia 1.10%, France 1.06%, Austria 0.87%, Italy 0.73%, Mexico 0.65%, Chile 0.55%, New Zealand 0.13%, Croatia Figure 4.2.2 Artificial Intelligence Index Report 2025 1.00% 0.80% 0.60% 0.40% 0.20% 0.00% 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 Table of Contents Chapter 4 Preview 226 )sgnitsop boj lla fo %( sgnitsop boj IA Chapter 4: Economy 4.2 Jobs US AI Labor Demand by Skill Cluster and Specialized Skill Figure 4.2.3 highlights the most sought-after AI skills in 0.2%. Since last year, most AI-related skill clusters tracked the U.S. labor market since 2010. Leading the demand was by Lightcast have had an increase in market share, with the artificial intelligence at 0.9%, followed closely by machine exception of autonomous driving and robotics. Generative AI learning, also at 0.9%, and natural language processing at saw the largest increase, growing by nearly a factor of four. AI job postings (% of all job postings) in the United States by skill cluster, 2010–24 Source: Lightcast, 2024 | Chart: 2025 AI Index report 0.94%, Arti cial intelligence 0.92%, Machine learning 0.23%, Natural language processing 0.22%, Generative AI 0.16%, Neural networks 0.13%, Autonomous driving 0.09%, Visual image recognition 0.07%, Robotics 0.02%, AI ethics, governance, and regulations Figure 4.2.31 1 A single job posting can list multiple AI skills. Artificial Intelligence Index Report 2025 Chapter 4: Economy 4.2 Jobs Figure 4.2.4 compares the top 10 specialized skills sought has increased over the past decade, with Python’s notable in AI job postings in 2024 versus those from 2012 to 2014.2 increase in popularity highlighting its ascendance as a On an absolute scale, the demand for every specialized skill preferred AI programming language. Top 10 specialized skills in 2024 AI job postings in the United States, 2012–14 vs. 2024 Source: Lightcast, 2024 | Chart: 2025 AI Index report 199,213 (+527%) Python (programming language) 31,782 193,341 (+131%) Computer science 83,826 128,938 (+208%) Data analysis 41,842 119,441 (+133%) SQL (programming language) 51,304 110,620 (+833%) Data science 11,861 102,210 (+361%) Automation 22,157 101,127 (+87%) Project management 54,035 100,881 (+1,778%) Amazon Web Services 5,371 88,141 (+334%) Agile methodology 20,330 2024 86,990 (+337%) 2012–14 Scalability 19,886 0 50,000 100,000 150,000 200,000 Number of AI job postings Figure 4.2.4 2 The decision to select 2012–2014 as the point of comparison was due to the scarcity of data at the jobs/skills level from earlier years. Lightcast therefore used 2012–2014 to have a larger sample size for a benchmark from 10 years ago with which to compare. Figure 4.2.4 juxtaposes the total number of job postings requiring certain skills from 2012 to 2014 with the total amount in 2024. Table of Contents Chapter 4 Preview 227 Artificial Intelligence Index Report 2025 Chapter 4: Economy 4.2 Jobs In 2024, year-over-year U.S. job postings citing generative AI skills increased by more than a factor of three (Figure 4.2.5). Figure 4.2.6 illustrates the proportion of AI job postings released in 2024 and 2023 that referenced particular generative AI skills. Generative AI skills in AI job postings in the United States, 2023 vs. 2024 Source: Lightcast, 2024 | Chart: 2025 AI Index report 66,635 (+323%) Generative arti cial intelligence 15,741 19,562 (+295%) Large language modeling 4,956 5,664 (+86%) ChatGPT 3,047 6,263 (+350%) Prompt engineering 1,393 2,213 (+67%) Generative adversarial networks 1,323 1,045 (-48%) Text to speech (TTS) 2,021 2,834 (+2,047%) Retrieval augmented generation 132 1,496 (+2,238%) Microsoft Copilot 64 756 (+89%) Variational autoencoders 400 2024 2023 733 (+1,566%) Multimodal models 44 0 6,000 12,000 18,000 24,000 30,000 36,000 42,000 48,000 54,000 60,000 66,000 72,000 78,000 Number of AI job postings Figure 4.2.5 Share of generative AI skills in AI job postings in the United States, 2023 vs. 2024 Source: Lightcast, 2024 | Chart: 2025 AI Index report 60.48% (+16%) Generative arti cial intelligence 52.23% 17.76% (+8%) Large language modeling 16.45% 5.14% (-49%) ChatGPT 10.11% 5.68% (+23%) Prompt engineering 4.62% 0.95% (-86%) Text to speech (TTS) 6.71% 2.01% (-54%) Generative adversarial networks 4.39% 2.57% (+487%) Retrieval augmented generation 0.44% 0.69% (-48%) Variational autoencoders 1.33% 1.36% (+539%) Microsoft Copilot 0.21% 2024 2023 0.67% (+356%) Multimodal models 0.15% 0% 10% 20% 30% 40% 50% 60% Skill share in AI job postings (%) Figure 4.2.6 Table of Contents Chapter 4 Preview 228 Artificial Intelligence Index Report 2025 Chapter 4: Economy 4.2 Jobs US AI Labor Demand by Sector Figure 4.2.7 shows the percentage of U.S. job postings job postings in 2024 compared to 2023, except for public requiring AI skills by industry sector from 2023 to 2024. Nearly administration. every sector experienced an increase in the proportion of AI AI job postings (% of all job postings) in the United States by sector, 2023 vs. 2024 Source: Lightcast, 2024 | Chart: 2025 AI Index report Information 9.33% (+79.56%) 5.19% Professional, scienti c, and technical services 5.25% (+31.20%) 4.00% Finance and insurance 3.76% (+16.15%) 3.24% Manufacturing 3.75% (+30.21%) 2.88% Utilities 2.15% (+55.08%) 1.39% Educational services 2.05% (+14.98%) 1.79% Management of companies and enterprises 1.92% (+13.57%) 1.69% Mining, quarrying, and oil and gas extraction 1.87% (+67.82%) 1.11% Public administration 1.29% (-26.93%) 1.76% Real estate and rental and leasing 1.21% (+41.95%) 0.85% Wholesale trade 1.20% (+43.41%) 0.84% Retail trade 1.16% (+101.95%) 0.57% Agriculture, forestry, shing and hunting 1.07% (+22.26%) 0.87% 2024 Transportation and warehousing 0.6 0 1 . % 82% (+35.81%) 2023 Waste management and administrative support services 0.48% (+15.65%) 0.41% 0% 1% 2% 3% 4% 5% 6% 7% 8% 9% 10% 11% AI job postings (% of all job postings) Figure 4.2.73 3 The sector classifications in Figure 4.2.7 are based on two-digit NAICS codes. For more information on the Bureau of Labor Statistics’ supersector and NAICS classifications, see the following reference. Table of Contents Chapter 4 Preview 229 Artificial Intelligence Index Report 2025 Chapter 4: Economy 4.2 Jobs US AI Labor Demand by State Number of AI job postings in the United States by state, 2024 Source: Lightcast, 2024 | Chart: 2025 AI Index report Figure 4.2.8 highlights the number of AI job postings in the United States AK ME by state. The top three states were 2,225 2,472 California (103,375), Texas (57,785), VT NH MA 1,304 3,100 29,097 and New York (37,944). WA MT ND SD MN WI MI NY CT RI 31,067 2,456 1,606 1,839 10,445 7,415 15,583 37,944 8,091 3,569 Figure 4.2.9 demonstrates what OR ID WY NE IA IL IN OH PA NJ percentage of a state’s total job 8,643 4,149 976 3,829 4,274 26,131 7,232 16,518 19,294 19,504 postings were AI-related. The top CA NV UT CO KS MO KY WV DC MD DE states according to this metric were 103,375 4,484 6,584 15,927 5,951 9,138 4,341 1,296 10,121 14,906 3,767 the District of Columbia (4.4%), AZ NM OK AR TN VA NC followed by Delaware (3.4%) and 12,939 3,617 4,512 4,707 9,184 31,186 18,916 Washington (3.3%). TX LA MS AL GA SC 57,785 3,770 2,877 6,876 20,260 5,362 HI FL 2,693 25,211 Figure 4.2.8 Percentage of US states job postings in AI, 2024 Source: Lightcast, 2024 | Chart: 2025 AI Index report AK ME 1.60% 1.57% VT NH MA 1.43% 1.16% 2.71% WA MT ND SD MN WI MI NY CT RI 3.27% 1.59% 1.22% 1.18% 1.46% 1.00% 1.51% 2.19% 1.64% 2.13% OR ID WY NE IA IL IN OH PA NJ 1.54% 1.91% 1.74% 1.34% 1.06% 1.87% 0.97% 1.19% 1.46% 2.07% CA NV UT CO KS MO KY WV DC MD DE 2.67% 1.18% 1.75% 1.78% 1.52% 1.26% 1.04% 1.13% 4.44% 2.29% 3.38% AZ NM OK AR TN VA NC 1.50% 1.30% 1.09% 1.86% 1.14% 2.77% 1.52% TX LA MS AL GA SC 1.86% 0.92% 1.37% 1.38% 1.82% 0.98% HI FL 1.44% 1.09% Figure 4.2.9 Table of Contents Chapter 4 Preview 230 Artificial Intelligence Index Report 2025 Chapter 4: Economy 4.2 Jobs Figure 4.2.10 examines which U.S. states Percentage of US AI job postings by state, 2024 Source: Lightcast, 2024 | Chart: 2025 AI Index report accounted for the largest proportion of AI job postings nationwide. In 2024, AK ME 15.7% of all AI job postings in the United 0.34% 0.38% States were for jobs based in California, VT NH MA 0.20% 0.47% 4.42% followed by Texas (8.8%) and New York (5.8%). WA MT ND SD MN WI MI NY CT RI 4.72% 0.37% 0.24% 0.28% 1.59% 1.13% 2.37% 5.76% 1.23% 0.54% OR ID WY NE IA IL IN OH PA NJ Figure 4.2.11 illustrates trends in four 1.31% 0.63% 0.15% 0.58% 0.65% 3.97% 1.10% 2.51% 2.93% 2.96% states with a significant number of AI CA NV UT CO KS MO KY WV DC MD DE job postings: Washington, California, 15.70% 0.68% 1.00% 2.42% 0.90% 1.39% 0.66% 0.20% 1.54% 2.26% 0.57% New York, and Texas. Each experienced AZ NM OK AR TN VA NC a notable increase in the share of total 1.96% 0.55% 0.69% 0.71% 1.39% 4.74% 2.87% AI-related job postings from 2023 to TX LA MS AL GA SC 8.77% 0.57% 0.44% 1.04% 3.08% 0.81% 2024. HI FL 0.41% 3.83% 3.00% 2.50% 2.00% 1.50% 1.00% 0.50% 0.00% 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 Table of Contents Chapter 4 Preview 231 IA ni sgnitsop boj ’setats SU fo egatnecreP Figure 4.2.10 Percentage of US states’ job postings in AI by select US state, 2010–24 Source: Lightcast, 2024 | Chart: 2025 AI Index report 3.27%, Washington 2.67%, California 2.19%, New York 1.86%, Texas Figure 4.2.11 Artificial Intelligence Index Report 2025 25% 20% 15% 10% 5% 0% 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 Table of Contents Chapter 4 Preview 232 sgnitsop boj IA setatS detinU fo egatnecreP Chapter 4: Economy 4.2 Jobs Figure 4.2.12 shows how AI-related job postings have been AI job postings—a particularly notable change in California distributed across the top four states over time. In 2024, all and New York, both of which had experienced decreases four states reversed multiyear declines in their proportion of since 2020. Percentage of US AI job postings by select US state, 2010–24 Source: Lightcast, 2024 | Chart: 2025 AI Index report 15.70%, California 8.77%, Texas 5.76%, New York 4.72%, Washington Figure 4.2.12 Artificial Intelligence Index Report 2025 Chapter 4: Economy 4.2 Jobs AI Hiring The hiring data presented in the AI Index is based on as the percentage of LinkedIn members who added a new LinkedIn’s Economic Graph, reflecting the jobs and skills employer in the same period the job began, divided by the of the platform’s 1+ billion members. As such, the data is total number of LinkedIn members in the corresponding influenced by how members choose to use the platform, location. Conversely, the relative AI talent hiring rate is the which can vary based on professional, social, and regional year-over-year change in AI hiring relative to the overall cultures, as well as overall site availability and accessibility. hiring rate in the same geographic area.4 Therefore, Figure The AI Index notes that Hungary, Indonesia, India, and South 4.2.13 illustrates AI hiring vibrancy in those regions that have Korea, included in the sample, have LinkedIn covering a experienced the most significant rise in AI talent recruitment lower portion of the labor force, so insights drawn about compared to the overall hiring rate. In 2024, the countries these countries should be interpreted with particular caution. with the greatest relative AI hiring rates year-over-year were India (33.4%), followed by Brazil (30.8%) and Saudi Arabia Figure 4.2.13 reports the relative AI hiring rate year-over-year (28.7%). This means, for example, that in 2024 in India, the ratio by geographic area. The overall hiring rate is computed ratio of AI talent hiring relative to overall hiring grew 33.4%. Relative AI hiring rate year-over-year ratio by geographic area, 2024 Source: LinkedIn, 2024 | Chart: 2025 AI Index report India 33.39% Brazil 30.83% Saudi Arabia 28.71% Slovenia 28.21% Romania 27.31% Finland 26.98% Argentina 26.39% Canada 26.13% Singapore 24.97% United Arab Emirates 24.88% United States 24.73% Ireland 24.58% South Africa 24.24% Mexico 24.02% Latvia 23.60% 0% 5% 10% 15% 20% 25% 30% 35% Relative AI hiring rate year-over-year ratio Figure 4.2.135 Figure 4.2.14 showcases the year-over-year ratio of AI hiring Chile have experienced notable upticks in AI hiring rates. by geographic areas over the past five years. Starting in 2024, Other countries that have recently experienced similar rises several South American countries like Argentina, Brazil, and include Canada, India, South Africa, and the United States. 4 For each month, LinkedIn calculates the AI hiring rate in the geographic area, divides the AI hiring rate by the overall hiring rate in that geographic area, calculates the year-over-year change of this ratio, and then takes the 12-month moving average using the last 12 months. 5 For brevity, the visualization only includes the top 15 countries for this metric. Table of Contents Chapter 4 Preview 233 Artificial Intelligence Index Report 2025 100% 100% 100% 100% 50% 50% 50% 50% 0% 0% 0% 0% 2018 2021 2024 2018 2021 2024 2018 2021 2024 2018 2021 2024 100% 100% 100% 100% 50% 50% 50% 50% 0% 0% 0% 0% 2018 2021 2024 2018 2021 2024 2018 2021 2024 2018 2021 2024 100% 100% 100% 100% 50% 50% 50% 50% 0% 0% 0% 0% 2018 2021 2024 2018 2021 2024 2018 2021 2024 2018 2021 2024 100% 100% 100% 100% 50% 50% 50% 50% 0% 0% 0% 0% 2018 2021 2024 2018 2021 2024 2018 2021 2024 2018 2021 2024 100% 100% 100% 100% 50% 50% 50% 50% 0% 0% 0% 0% 2018 2021 2024 2018 2021 2024 2018 2021 2024 2018 2021 2024 100% 100% 100% 100% 50% 50% 50% 50% 0% 0% 0% 0% 2018 2021 2024 2018 2021 2024 2018 2021 2024 2018 2021 2024 100% 100% 100% 100% 50% 50% 50% 50% 0% 0% 0% 0% 2018 2021 2024 2018 2021 2024 2018 2021 2024 2018 2021 2024 100% 100% 100% 100% 50% 50% 50% 50% 0% 0% 0% 0% 2018 2021 2024 2018 2021 2024 2018 2021 2024 2018 2021 2024 100% 100% 100% 100% 50% 50% 50% 50% 0% 0% 0% 0% 2018 2021 2024 2018 2021 2024 2018 2021 2024 2018 2021 2024 100% 100% 100% 100% 50% 50% 50% 50% 0% 0% 0% 0% 2018 2021 2024 2018 2021 2024 2018 2021 2024 2018 2021 2024 100% 100% 100% 100% 50% 50% 50% 50% 0% 0% 0% 0% 2018 2021 2024 2018 2021 2024 2018 2021 2024 2018 2021 2024 100% 100% 100% 50% 50% 50% 0% 0% 0% 2018 2021 2024 2018 2021 2024 2018 2021 2024 Figure 4.2.14 Table of Contents Chapter 4 Preview 234 oitar raey-revo-raey etar gnirih IA evitaleR Chapter 4: Economy 4.2 Jobs Relative AI hiring rate year-over-year ratio by geographic area, 2018–24 Source: LinkedIn, 2024 | Chart: 2025 AI Index report Argentina Australia Austria Belgium 26.39% 16.78% 16.23% 10.53% Brazil Canada Chile Costa Rica 30.83% 26.12% 22.18% 17.61% Croatia Cyprus Czech Republic Denmark 7.62% 6.86% 11.29% 20.47% Estonia Finland France Germany 17.40% 26.98% 5.75% 9.10% Greece Hong Kong Hungary India 14.52% 20.83% 22.34% 33.39% Indonesia Ireland Israel Italy 16.61% 24.58% 14.28% 19.78% Latvia Lithuania Luxembourg Mexico 23.59% 12.20% 9.15% 24.02% Netherlands New Zealand Norway Poland 8.57% 12.72% 13.33% 13.05% Portugal Romania Saudi Arabia Singapore 19.67% 27.31% 28.71% 24.97% Slovenia South Africa South Korea Spain 28.21% 24.24% 13.21% 18.22% Sweden Switzerland Turkey United Arab Emirates 19.12% 18.43% 20.36% 24.88% United Kingdom United States Uruguay 13.78% 24.73% 13.22% Artificial Intelligence Index Report 2025 Chapter 4: Economy 4.2 Jobs AI Skill Penetration Figure 4.2.15 and Figure 4.2.16 highlight relative AI skill penetration of AI skills among engineers is estimated to be penetration. The aim of this indicator is to measure the 8% (4/50). intensity of AI skills in a particular country or by industry or gender. The AI skill penetration rate signals the prevalence For the period from 2015 to 2024, the countries with the of AI skills across occupations or the intensity with which highest AI skill penetration rates were the United States (2.6) LinkedIn members utilize AI skills in their jobs. For example, and India (2.5). They were followed by the United Kingdom the top 50 skills for the occupation of engineer are calculated (1.4), Germany (1.3), and Brazil (1.3). In the United States, based on the weighted frequency with which they appear in therefore, the relative penetration of AI skills was 2.6 times LinkedIn member profiles. If, for instance, four of the skills greater than the global average across the same set of that engineers possess belong to the AI skill group, the occupations. Relative AI skill penetration rate by geographic area, 2015–24 Source: LinkedIn, 2024 | Chart: 2025 AI Index report United States 2.63 India 2.51 United Kingdom 1.40 Germany 1.32 Brazil 1.31 Canada 1.30 France 1.23 Spain 1.10 Indonesia 1.04 Global 1.00 Australia 0.95 Turkey 0.94 Netherlands 0.92 Italy 0.90 Israel 0.87 0.00 0.50 1.00 1.50 2.00 2.50 Relative AI skill penetration rate Figure 4.2.15 Table of Contents Chapter 4 Preview 235 Artificial Intelligence Index Report 2025 Chapter 4: Economy 4.2 Jobs Figure 4.2.16 disaggregates AI skill penetration rates by same set of occupations in the country. For all countries in gender across different countries or regions. A country’s the sample, with the exception of Saudi Arabia, the relative rate of 1.5 for women means female LinkedIn members in AI skill penetration rate is greater for men than women. India that country are 1.5 times more likely to list AI skills than the (1.9), United States (1.7), and Canada (1.0) have the highest average member in all countries pooled together across the reported relative AI skill penetration rates for women. Relative AI skill penetration rate across gender, 2015–24 Source: LinkedIn, 2024 | Chart: 2025 AI Index report India 2.38 1.91 United States 2.39 1.71 Canada 1.30 0.97 United Kingdom 1.29 0.90 Germany 1.34 0.89 France 1.25 0.83 Brazil 1.30 0.83 Israel 0.89 0.79 Spain 1.13 0.75 Netherlands 0.98 0.72 Australia 0.89 0.68 Italy 0.91 0.67 Turkey 0.96 0.66 Singapore 0.77 Male 0.64 Female Saudi Arabia 0.59 0.61 0.00 0.50 1.00 1.50 2.00 2.50 Relative AI skill penetration rate Figure 4.2.16 Table of Contents Chapter 4 Preview 236 Artificial Intelligence Index Report 2025 Chapter 4: Economy 4.2 Jobs AI Talent Figures 4.2.17 and 4.2.18 examine AI talent by country. A Figure 4.2.17 shows AI talent concentration in various LinkedIn member is considered to have AI talent if they geographic areas. In 2024, the countries with the highest have explicitly added AI skills to their profile, work or have concentrations of AI talent include Israel (2.0%), Singapore worked in AI. Counts of AI talent are used to calculate talent (1.6%), and Luxembourg (1.4%). Figure 4.2.18 looks at the concentration, or the portion of members who are AI talent. percent change in AI talent concentration for a selection of Note that concentration metrics may be influenced by countries since 2016. During that time period, several major LinkedIn coverage in these countries and should be used economies registered substantial increases in their AI talent with caution. pools. The countries showing the greatest increases are India (252%), Costa Rica (240%), and Portugal (237%). AI talent concentration by geographic area, 2024 Percentage change in AI talent concentration by Source: LinkedIn, 2024 | Chart: 2025 AI Index report geographic area, 2016 vs. 2024 Israel 1.98% Source: LinkedIn, 2024 | Chart: 2025 AI Index report India 252% Singapore 1.64% Costa Rica 240% Luxembourg 1.44% Portugal 237% Estonia 1.17% Cyprus 219% Switzerland 1.16% Brazil 217% Finland 1.13% Estonia 207% Ireland 1.11% Turkey 198% Germany 1.09% Croatia 192% Netherlands 1.07% Denmark 192% South Korea 1.06% Indonesia 191% Lithuania 1.06% Iceland 173% Poland 0.94% Uruguay 171% Canada 0.93% Argentina 170% Hungary 0.92% United Arab Emirates 168% Sweden 0.90% Canada 166% 0.00% 0.50% 1.00% 1.50% 2.00% 0% 40% 80% 120% 160% 200% 240% 280% AI talent concentration % change in AI talent concentration Figure 4.2.17 Figure 4.2.18 There are also notable gender differences in AI talent concentration of AI talent was higher among men than women concentration. For every country included in the analysis (Figure 4.2.19). Israel reported the highest concentration of sample, with the exception of India and Saudi Arabia, the female AI talent in 2024, at 1.6%. Table of Contents Chapter 4 Preview 237 Artificial Intelligence Index Report 2025 AI talent concentration by gender and geographic area, 2016–24 Source: LinkedIn, 2024 | Chart: 2025 AI Index report Argentina Australia Austria Belgium 0.40% 0.45% 1.00% 1.00% 1.00% 1.07% 1.00% 0.95% 0.20% 0.18% 0.50% 0.52% 0.50% 0.48% 0.50% 0.39% 0.00% 0.00% 0.00% 0.00% 2016 2020 2024 2016 2020 2024 2016 2020 2024 2016 2020 2024 Brazil Canada Chile Costa Rica 0.40% 0.37% 1.15% 0.60% 0.49% 1.00% 0.85% 1.00% 0.40% 0.20% 0.11% 0.50% 0.61% 0.20% 0.17% 0.50% 0.45% 0.00% 0.00% 0.00% 0.00% 2016 2020 2024 2016 2020 2024 2016 2020 2024 2016 2020 2024 Croatia Cyprus Czech Republic Denmark 1.00% 1.50% 0.83% 1.00% 1.27% 1.00% 1.14% 1.00% 1.07% 0.50% 0.46% 0.50% 0.59% 0.50% 0.47% 0.50% 0.44% 0.00% 0.00% 0.00% 0.00% 2016 2020 2024 2016 2020 2024 2016 2020 2024 2016 2020 2024 Estonia Finland France Germany 2.00% 1.69% 2.00% 1.71% 1.00% 1.06% 1.50% 1.38% 1.00% 0.81% 1.00% 0.75% 0.50% 0.53% 0 1. . 0 50 0% % 0.65% 0.00% 0.00% 0.00% 0.00% 2016 2020 2024 2016 2020 2024 2016 2020 2024 2016 2020 2024 Greece Hong Kong India Ireland 1.50% 1.38% 1.00% 1.05% 1.00% 0.92% 1.50% 1.40% 1.00% 0.89% 1.00% 0.50% 0.62% 0.50% 0.52% 0.50% 0.50% 0.75% 0.00% 0.00% 0.00% 0.00% 2016 2020 2024 2016 2020 2024 2016 2020 2024 2016 2020 2024 Israel Italy Latvia Lithuania 3.00% 2.88% 0.60% 0.55% 1.00% 0.95% 1.50% 1.47% 2 1. . 0 0 0 0% % 1.60% 0 0 . .4 20 0 % % 0.29% 0.50% 0.46% 0 1. . 0 50 0% % 0.74% 0.00% 0.00% 0.00% 0.00% 2016 2020 2024 2016 2020 2024 2016 2020 2024 2016 2020 2024 Luxembourg Mexico Netherlands New Zealand 1.00% 2.00% 1.86% 0.40% 0.39% 1.50% 1.38% 0.81% 1.00% 0.96% 0.20% 0.18% 0 1. . 0 5 0 0 % % 0.72% 0.50% 0.46% 0.00% 0.00% 0.00% 0.00% 2016 2020 2024 2016 2020 2024 2016 2020 2024 2016 2020 2024 Norway Poland Portugal Romania 1.00% 0.86% 1.50% 1.30% 1.00% 0.88% 0.75% 0.50% 0.44% 0 1. . 0 50 0 % % 0.59% 0.50% 0.36% 0.50% 0.47% 0.00% 0.00% 0.00% 0.00% 2016 2020 2024 2016 2020 2024 2016 2020 2024 2016 2020 2024 Saudi Arabia Singapore South Africa Spain 0.60% 0.60% 2.00% 1.91% 0.40% 0.40% 1.00% 0.86% 0 0 . .4 20 0 % % 0.40% 1.00% 1.35% 0.20% 0.24% 0.50% 0.37% 0.00% 0.00% 0.00% 0.00% 2016 2020 2024 2016 2020 2024 2016 2020 2024 2016 2020 2024 Sweden Switzerland Turkey United Arab Emirates 1.50% 2.00% 0.42% 0.59% 1.00% 1.21% 1.00% 1.55% 0.40% 0.33% 0 0 . . 6 40 0 % % 0.55% 0.50% 0.58% 0.70% 0.20% 0.20% 0.00% 0.00% 0.00% 0.00% 2016 2020 2024 2016 2020 2024 2016 2020 2024 2016 2020 2024 United Kingdom United States Uruguay 1.00% 1.08% 1.00% 0.99% 0.40% 0.45% Male 0.50% 0.56% 0.50% 0.51% 0.20% 0.15% Female 0.00% 0.00% 0.00% 2016 2020 2024 2016 2020 2024 2016 2020 2024 Table of Contents Chapter 4 Preview 238 noitartnecnoc tnelat IA Chapter 4: Economy 4.2 Jobs Figure 4.2.19 Artificial Intelligence Index Report 2025 80% 70% 60% 50% 40% 30% 20% 10% 0% 2016 2017 2018 2019 2020 2021 2022 2023 2024 Table of Contents Chapter 4 Preview 239 noitatneserper tnelat IA Chapter 4: Economy 4.2 Jobs LinkedIn also tracks the gender distribution of AI talent (Figure 4.2.20). In 2024, it estimates that 69.5% of AI professionals on the platform are male, while 30.5% are female. This ratio has remained remarkably stable over time. Global AI talent representation, 2016–24 Source: LinkedIn, 2024 | Chart: 2025 AI Index report 69.46%, Male 30.54%, Female Figure 4.2.20 LinkedIn’s data on AI talent can also be broken down by country. In every country in the sample, men proportionally outnumber women in AI roles (Figure 4.2.21). New Zealand and Romania have the most balanced gender distribution, while Brazil and Chile have the least. Artificial Intelligence Index Report 2025 Chapter 4: Economy 4.2 Jobs AI talent representation by gender and geographic area, 2016–24 Source: LinkedIn, 2024 | Chart: 2025 AI Index report Argentina Australia Austria Belgium 100% 100% 100% 100% 71.36% 68.61% 75.66% 75.87% 50% 50% 50% 50% 28.64% 31.39% 24.34% 24.13% 0% 0% 0% 0% 2016 2020 2024 2016 2020 2024 2016 2020 2024 2016 2020 2024 Brazil Canada Chile Costa Rica 100% 100% 100% 100% 77.11% 67.78% 77.11% 68.65% 50% 50% 50% 50% 22.89% 32.22% 22.89% 31.35% 0% 0% 0% 0% 2016 2020 2024 2016 2020 2024 2016 2020 2024 2016 2020 2024 Croatia Cyprus Czech Republic Denmark 100% 100% 100% 100% 65.08% 72.84% 73.66% 74.28% 50% 50% 50% 50% 34.92% 27.16% 26.35% 25.72% 0% 0% 0% 0% 2016 2020 2024 2016 2020 2024 2016 2020 2024 2016 2020 2024 Estonia Finland France Germany 100% 100% 100% 100% 67.10% 64.34% 68.95% 76.23% 50% 50% 50% 50% 32.90% 35.66% 31.05% 23.77% 0% 0% 0% 0% 2016 2020 2024 2016 2020 2024 2016 2020 2024 2016 2020 2024 Greece Hong Kong India Ireland 100% 100% 100% 100% 73.05% 68.23% 70.08% 68.31% 50% 50% 50% 50% 26.95% 31.77% 29.92% 31.69% 0% 0% 0% 0% 2016 2020 2024 2016 2020 2024 2016 2020 2024 2016 2020 2024 Israel Italy Latvia Lithuania 100% 100% 100% 100% 74.16% 65.94% 61.46% 66.63% 50% 50% 50% 50% 25.84% 34.05% 38.54% 33.37% 0% 0% 0% 0% 2016 2020 2024 2016 2020 2024 2016 2020 2024 2016 2020 2024 Luxembourg Mexico Netherlands New Zealand 100% 100% 100% 100% 72.42% 74.05% 71.68% 65.75% 50% 50% 50% 50% 27.58% 25.95% 28.32% 34.25% 0% 0% 0% 0% 2016 2020 2024 2016 2020 2024 2016 2020 2024 2016 2020 2024 Norway Poland Portugal Romania 100% 100% 100% 100% 72.61% 69.21% 72.51% 50% 50% 50% 50% 4 59 1. . 0 0 0 0 % % 27.39% 30.79% 27.49% 0% 0% 0% 0% 2016 2020 2024 2016 2020 2024 2016 2020 2024 2016 2020 2024 Saudi Arabia Singapore South Africa Spain 100% 100% 100% 100% 69.02% 62.91% 64.71% 72.21% 50% 50% 50% 50% 30.98% 37.09% 35.29% 27.79% 0% 0% 0% 0% 2016 2020 2024 2016 2020 2024 2016 2020 2024 2016 2020 2024 Sweden Switzerland Turkey United Arab Emirates 100% 100% 100% 100% 71.38% 74.94% 71.24% 70.61% 50% 50% 50% 50% 28.62% 25.06% 28.76% 29.39% 0% 0% 0% 0% 2016 2020 2024 2016 2020 2024 2016 2020 2024 2016 2020 2024 United Kingdom United States Uruguay 100% 100% 100% 70.50% 66.32% 73.50% 50% 50% 50% Male 29.50% 33.68% 26.50% Female 0% 0% 0% 2016 2020 2024 2016 2020 2024 2016 2020 2024 Figure 4.2.21 Table of Contents Chapter 4 Preview 240 noitatneserper tnelat IA Artificial Intelligence Index Report 2025 Chapter 4: Economy 4.2 Jobs LinkedIn data provides insights on the AI talent gained or lost the geographic area. Figure 4.2.22 examines net AI talent due to migration trends.6 Net flows are defined as total arrivals migration per 10,000 LinkedIn members by geographic area. minus departures within the given time period. A positive net The geographic areas that report the greatest per capita AI talent migration figure indicates that more talent is coming incoming migration of AI talent are Luxembourg (8.9), Cyprus into the geographic area than departing. A negative figure (4.7), and United Arab Emirates (4.1). indicates that more talent is departing than coming into Net AI talent migration per 10,000 LinkedIn members by geographic area, 2024 Source: LinkedIn, 2024 | Chart: 2025 AI Index report Luxembourg 8.92 Cyprus 4.67 United Arab Emirates 4.13 Switzerland 3.15 Ireland 2.17 Germany 2.13 Austria 2.09 Saudi Arabia 1.61 Australia 1.48 Finland 1.30 Singapore 1.26 Denmark 1.14 United States 1.07 Hong Kong 0.97 Poland 0.95 0.00 0.50 1.00 1.50 2.00 2.50 3.00 3.50 4.00 4.50 5.00 5.50 6.00 6.50 7.00 7.50 8.00 8.50 9.00 Net AI talent migration (per 10,000 LinkedIn members) Figure 4.2.22 Figure 4.2.23 documents AI talent migration data over time. flowing into these countries. Countries with rising talent In the last few years, Israel, the Netherlands, and Canada, flows include the United Arab Emirates, Saudi Arabia, and among other countries, have seen declining net AI talent Luxembourg. migration figures, suggesting that less AI talent has been 6 LinkedIn membership varies considerably among countries, which makes interpreting absolute movements of members from one country to another difficult. To compare migration flows between countries fairly, migration flows are normalized for the country of interest. For example, if country A is the country of interest, all absolute net flows into and out of country A (regardless of origin and destination countries) are normalized based on LinkedIn membership in country A at the end of each year and multiplied by 10,000. Hence, this metric indicates relative talent migration of all other countries to and from country A. Table of Contents Chapter 4 Preview 241 Artificial Intelligence Index Report 2025 Argentina Australia Austria* Belgium 1.48 3 1 1 2 2.09 1 1 0.63 0 -0.22 0 0 0 −1 −1 −1 −1 2020 2022 2024 2020 2022 2024 2020 2022 2024 2020 2022 2024 Brazil Canada* Chile Costa Rica 3 1 2 1 1 1 0.95 0 -0.09 0 0 -0.19 0 -0.28 −1 −1 −1 −1 2020 2022 2024 2020 2022 2024 2020 2022 2024 2020 2022 2024 Croatia Cyprus* Czech Republic Denmark 12 1 8 1 0.70 1 1.14 0 0.01 4 4.67 0 0 −1 0 −1 −1 2020 2022 2024 2020 2022 2024 2020 2022 2024 2020 2022 2024 Estonia* Finland France Germany* 6 3 4 1 1.30 1 2 2.13 2 0 0 0.34 1 0 0.13 0 −1 −1 −1 2020 2022 2024 2020 2022 2024 2020 2022 2024 2020 2022 2024 Greece Hong Kong Hungary* Iceland 1 1 0.97 1 1 0 0.51 0 -0.25 0 −1 -1.15 0 −1 −1 −2 −1 2020 2022 2024 2020 2022 2024 2020 2022 2024 2020 2022 2024 India* Indonesia Ireland* Israel* 3 1 1 2 2.17 2 0 1 0 − − 2 1 -1.55 0 -0.07 0 −2 -2.10 −1 −1 2020 2022 2024 2020 2022 2024 2020 2022 2024 2020 2022 2024 Italy Latvia Lithuania* Luxembourg* 3 12 1 1 0.66 2 8 8.92 1 0 -0.10 0 0 0.56 4 −1 −1 −1 0 2020 2022 2024 2020 2022 2024 2020 2022 2024 2020 2022 2024 Mexico Netherlands* New Zealand Norway 3 1 2 1 1 1 0.92 0.55 0 -0.10 0 0 -0.23 0 −1 −1 −1 −1 2020 2022 2024 2020 2022 2024 2020 2022 2024 2020 2022 2024 Poland Portugal Romania Saudi Arabia 1.61 1 0.95 1 1 1 0.42 0 0 0 0.06 0 −1 −1 −1 −1 2020 2022 2024 2020 2022 2024 2020 2022 2024 2020 2022 2024 Singapore* Slovenia South Africa South Korea 3 2 1 1 1 1 1.26 0.36 0 0 0 -0.22 0 -0.36 −1 −1 −1 −1 2020 2022 2024 2020 2022 2024 2020 2022 2024 2020 2022 2024 Spain Sweden Switzerland* Turkey 4 1 0.94 1 3 3.15 1 0.41 2 0 0 1 0 0 -0.49 −1 −1 −1 −1 2020 2022 2024 2020 2022 2024 2020 2022 2024 2020 2022 2024 United Arab Emirates* United Kingdom United States Uruguay 6 4 4.13 1 1 1.07 1 0.55 2 0 0 0 -0.05 0 −1 −1 −1 2020 2022 2024 2020 2022 2024 2020 2022 2024 2020 2022 2024 Table of Contents Chapter 4 Preview 242 )srebmem nIdekniL 000,01 rep( noitargim tnelat IA teN Chapter 4: Economy 4.2 Jobs Net AI talent migration per 10,000 LinkedIn members by geographic area, 2019–24 Source: LinkedIn, 2024 | Chart: 2025 AI Index report Figure 4.2.237 7 Asterisks indicate that a country’s y-axis label is scaled differently than the y-axis label for the other countries. Artificial Intelligence Index Report 2025 Chapter 4: Economy 4.2 Jobs Highlight: Measuring AI’s Current Economic Integration Analysis of over 4 million real-world AI interactions The analysis reveals that while all sectors make some provides comprehensive empirical evidence of how AI use of current AI, the dominant sectors are technical is being integrated across economic sectors. A recent and creative. As shown in Figure 4.2.24, computer and Anthropic study examined usage patterns of their AI mathematical occupations dominate, accounting for model classifying users via the U.S. Department of Labor’s 37.2% of all AI interactions. Arts, design, entertainment, O*NET occupational framework, offering concrete data sports, and media occupations follow at 10.3%, with on which industries and job functions are leveraging educational instruction and library occupations also AI. More specifically, the Anthropic team analyzed user showing significant adoption. conversations with their Claude.AI model to identify the tasks and occupations most frequently using AI. O�ce and administrative support 7.90% 12.20% Transportation and material moving 0.30% 9.10% Sales and related 2.30% 8.80% Food preparation and serving related 0.50% 8.70% Management 4.50% 6.90% Business and �nancial operations 5.90% 6.60% Healthcare practitioners and technical 2.60% 6.10% Production 2.90% 5.80% Educational instruction and library 5.80% 9.30% Healthcare support 0.30% 4.70% Construction and extraction 0.40% 4.10% Installation, maintenance, and repair 0.70% 3.90% Computer and mathematical 3.40% 37.20% Building and grounds cleaning and maintenance 0.10% 2.90% Protective service 0.40% 2.30% Personal care and service 0.50% 2.00% Architecture and engineering 1.70% 4.50% Community and social service 1.60% 2.10% Arts, design, entertainment, sports, and media 1.40% 10.30% Life, physical, and social science 0.90% 6.40% Legal 0.80% 0.90% % of Claude conversations Farming, �shing, and forestry 0.10% 0.30% % of US workers 0% 10% 20% 30% 40% Claude usage rate vs. US workforce distribution Figure 4.2.23 Table of Contents Chapter 4 Preview 243 noitapuccO Occupational representation in Claude usage data vs. US workforce distribution Source: Handa et al., 2025 | Chart: 2025 AI Index report Artificial Intelligence Index Report 2025 Chapter 4: Economy 4.2 Jobs Highlight: Measuring AI’s Current Economic Integration (cont’d) The AI usage patterns demonstrate a clear connection to (typically bachelor’s degree-level) show 50% higher usage wage levels and required skills. Figure 4.2.25 illustrates than their baseline workforce representation, while both that AI adoption peaks in occupations within the upper minimal-preparation and extensive-preparation roles wage quartile but drops significantly at both wage show lower adoption rates. extremes. Jobs requiring considerable preparation Computer programmers 6% 5% 4% Software developers, applications Bioinformatics technicians 3% 2% Tutors Copywriters 1% Obstetricians and gynecologists 0% 0 50 100 150 200 Median annual wage (in thousands of US dollars) Figure 4.2.25 Table of Contents Chapter 4 Preview 244 snoitasrevnoc edualC fo % Occupational usage of Claude by median annual wage Source: Handa et al., 2025 | Chart: 2025 AI Index report Artificial Intelligence Index Report 2025 Chapter 4: Economy 4.2 Jobs Highlight: Measuring AI’s Current Economic Integration (cont’d) The Anthropic study finds that approximately 36% of remains rare: Only about 4% of occupations show AI occupations use AI for at least a quarter of their associated usage across 75% or more of their tasks, suggesting that tasks (Figure 4.2.26), indicating substantial penetration wholesale automation of entire job categories is not yet beyond technical fields. However, deep integration occurring. Depth of AI usage across organizations Source: Handa et al., 2025 Figure 4.2.26 Table of Contents Chapter 4 Preview 245 Artificial Intelligence Index Report 2025 Chapter 4: Economy 4.2 Jobs Highlight: Measuring AI’s Current Economic Integration (cont’d) The analysis reveals how AI is being used within implementation tends toward complementing rather than organizations. As shown in Figure 4.2.27, 57% of AI replacing human workers. The study finds that cognitive interactions demonstrate augmentative patterns skills like critical thinking and writing show high presence (enhancing human capabilities) while 43% show in AI interactions, while physical and managerial skills automation patterns. This split suggests current AI show minimal presence (Figure 4.2.28). Percentage of Claude conversations by type of task execution Source: Handa et al., 2025 | Chart: 2025 AI Index report Validation Task iteration Learning Feedback loop Directive Augmentation 31.33% 23.27% Automation 14.80% 27.75% 0% 10% 20% 30% 40% 50% 60% % of Claude conversations Figure 4.2.27 Distribution of occupational skills exhibited by Claude in conversations Source: Handa et al., 2025 Figure 4.2.28 Table of Contents Chapter 4 Preview 246 Artificial Intelligence Index Report 2025 This section monitors AI investment trends, leveraging data from Quid, which analyzes investment data from more than 8 million companies worldwide, both public and private. Employing natural language processing, Quid 4.3 Investment sifts through vast unstructured datasets— including news aggregations, blogs, company records, and patent databases—to detect Corporate Investment patterns and insights. Additionally, Quid is Figure 4.3.1 illustrates the trend in global corporate AI investment from constantly expanding its database to include more companies, sometimes resulting in higher 2013 to 2024, including mergers and acquisitions, minority stakes, private reported investment volumes for specific years. investments, and public offerings. For the first time, this year’s investment section in the AI Index includes data on generative AI investments. In 2024, the total investment grew to $252.3 billion, an increase of 25.5% from 2023. The most significant upturn occurred in private investment, which rose by 44.5% compared with the previous year, while mergers and acquisitions increased by 12.1%. Over the past decade, AI-related investments have increased nearly thirteenfold. Merger/acquisition 360.73 Minority stake 350 Private investment Public o ering 300 175.36 253.25 252.33 250 221.87 200 39.83 201 92.19 121.39 82.26 150 88.19 103.27 145.4 100 79.62 36.43 150.79 53.72 21.89 73.79 113.01 104.34 50 33.82 24.68 25.43 43.1 58.18 14.57 19.04 25.72 20.06 37.32 0 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 Table of Contents Chapter 4 Preview 247 )srallod SU fo snoillib ni( tnemtsevni latoT Chapter 4: Economy 4.3 Investment Global corporate investment in AI by investment activity, 2013–24 Source: Quid, 2024 | Chart: 2025 AI Index report Figure 4.3.1 Artificial Intelligence Index Report 2025 Startup Activity Global Trends Global private AI investment increased 44.5% between 2023 This section analyzes private investment trends in AI startups and 2024, marking the first year-over-year growth since that have received over $1.5 million in investment since 2013. 2021 (Figure 4.3.2). Despite recent fluctuations, private AI investment globally has grown substantially in the last decade. 150.79 140 120 100 80 60 40 20 0 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 Table of Contents Chapter 4 Preview 248 )srallod SU fo snoillib ni( tnemtsevni latoT Chapter 4: Economy 4.3 Investment Global private investment in AI, 2013–24 Source: Quid, 2024 | Chart: 2025 AI Index report Figure 4.3.2 Artificial Intelligence Index Report 2025 Funding for generative AI continued to increase sharply times the investment of 2022. Furthermore, generative (Figure 4.3.3). In 2024, the sector attracted $33.9 billion, AI accounted for more than a fifth of all AI-related private representing an 18.7% increase from 2023 and over 8.5 investment in 2024. 35 33.94 30 25 20 15 10 5 0 2019 2020 2021 2022 2023 2024 Table of Contents Chapter 4 Preview 249 )srallod SU fo snoillib ni( tnemtsevni latoT Chapter 4: Economy 4.3 Investment Global private investment in generative AI, 2019–24 Source: Quid, 2024 | Chart: 2025 AI Index report Figure 4.3.3 Artificial Intelligence Index Report 2025 2,049 2,000 1,500 1,000 500 0 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 Table of Contents Chapter 4 Preview 250 seinapmoc fo rebmuN Number of newly funded AI companies in the world, 2013–24 Source: Quid, 2024 | Chart: 2025 AI Index report 214 200 150 100 50 0 2019 2020 2021 2022 2023 2024 seinapmoc fo rebmuN Chapter 4: Economy 4.3 Investment The number of newly funded AI companies in 2024 jumped of newly funded generative AI companies, with 214 new to 2,049, an 8.4% increase over the previous year (Figure startups receiving funding, compared to 179 in 2023, and 31 4.3.4). In addition, 2024 registered an increase in the number in 2019 (Figure 4.3.5). Figure 4.3.4 Number of newly funded generative AI companies in the world, 2019–24 Source: Quid, 2024 | Chart: 2025 AI Index report Figure 4.3.5 Artificial Intelligence Index Report 2025 Figure 4.3.6 visualizes the average size of AI private Figure 4.3.7 reports AI funding events disaggregated by investment events, calculated by dividing the total yearly size. In 2024, AI private investment events increased across AI private investment by the total number of AI private funding size categories exceeding $100 million and decreased investment events. From 2023 to 2024, the average increased or remained constant in smaller categories. In 2024, there significantly, growing from $31.6 million to $45.4 million. were 15 AI private investment events that involved funding sizes greater than $1 billion. 45.43 45 40 35 30 25 20 15 10 5 0 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 Table of Contents Chapter 4 Preview 251 )srallod SU fo snoillim ni( tnemtsevni egarevA Chapter 4: Economy 4.3 Investment Average size of global AI private investment events, 2013–24 Source: Quid, 2024 | Chart: 2025 AI Index report Figure 4.3.6 Global AI private investment events by funding size, 2023 vs. 2024 Source: Quid, 2024 | Table: 2025 AI Index report Funding size 2023 2024 Over 1 billion 9 15 500 million – 1 billion 9 20 100 million – 500 million 134 143 50 million – 100 million 200 196 Under 50 million 2,945 2,945 Undisclosed 680 207 Total 3,977 3,526 Figure 4.3.7 Artificial Intelligence Index Report 2025 Chapter 4: Economy 4.3 Investment Regional Comparison by Funding Amount The United States once again led the world in terms of total 24.1 times the amount invested in the United Kingdom ($4.5 AI private investment. In 2024, the $109.1 billion invested billion) (Figure 4.3.8). Other notable countries that rounded out in the United States was 11.7 times greater than the amount the top 15 in 2024 include Sweden ($4.3 billion), Austria ($1.5 invested in the next highest country, China ($9.3 billion), and billion), the Netherlands ($1.1 billion), and Italy ($0.9 billion). Global private investment in AI by geographic area, 2024 Source: Quid, 2024 | Chart: 2025 AI Index report United States 109.08 China 9.29 United Kingdom 4.52 Sweden 4.34 Canada 2.89 France 2.62 Germany 1.97 United Arab Emirates 1.77 Austria 1.51 Israel 1.36 South Korea 1.33 India 1.16 Netherlands 1.09 Japan 0.93 Italy 0.86 0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100 105 110 115 Total investment (in billions of US dollars) Figure 4.3.8 Table of Contents Chapter 4 Preview 252 Artificial Intelligence Index Report 2025 Chapter 4: Economy 4.3 Investment When aggregating private AI investments since 2013, the 4.3.9). Other countries that have attracted significant AI country rankings remain the same: The United States leads investment over the past decade include Israel ($15.0 billion), with $470.9 billion invested, followed by China with $119.3 Singapore ($7.3 billion), and Sweden ($7.3 billion). billion, and the United Kingdom with $28.2 billion (Figure Global private investment in AI by geographic area, 2013–24 (sum) Source: Quid, 2024 | Chart: 2025 AI Index report United States 470.92 China 119.32 United Kingdom 28.17 Canada 15.31 Israel 14.96 Germany 13.27 India 11.29 France 11.10 South Korea 8.96 Singapore 7.27 Sweden 7.27 Japan 5.89 Australia 3.99 Switzerland 3.90 United Arab Emirates 3.67 0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 380 400 420 440 460 480 Total investment (in billions of US dollars) Figure 4.3.9 Table of Contents Chapter 4 Preview 253 Artificial Intelligence Index Report 2025 Figure 4.3.10, which looks at AI private investment over China (-1.9%) and increased in Europe (+60%) since 2023, the time by geographic area, suggests that the gap in private United States has seen a significant increase (+50.7%) during investments between the United States and other regions is the same period—and a +78.3% increase since 2022. widening. While AI private investments have decreased in 100 80 60 40 20 0 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 Table of Contents Chapter 4 Preview 254 )srallod SU fo snoillib ni( tnemtsevni latoT Chapter 4: Economy 4.3 Investment Global private investment in AI by geographic area, 2013–24 Source: Quid, 2024 | Chart: 2025 AI Index report 109.08, United States 19.42, Europe 9.29, China Figure 4.3.10 Artificial Intelligence Index Report 2025 30 25 20 15 10 5 0 2019 2020 2021 2022 2023 2024 Table of Contents Chapter 4 Preview 255 )srallod SU fo snoillib ni( tnemtsevni latoT Chapter 4: Economy 4.3 Investment The disparity in regional AI private investment becomes outpaced the combined investments of China and Europe in particularly pronounced when examining generative AI- generative AI by approximately $21.8 billion (Figure 4.3.11). By related investments. For instance, in 2023, the United States 2024, this gap widened to $25.4 billion. Global private investment in generative AI by geographic area, 2019–24 Source: Quid, 2024 | Chart: 2025 AI Index report 29.04, United States 2.11, China 1.49, Europe Figure 4.3.11 Artificial Intelligence Index Report 2025 Chapter 4: Economy 4.3 Investment Regional Comparison by Newly Funded AI Companies This section examines the number of newly funded AI regions with 1,073 new AI companies, followed by the United companies across different geographic regions. Consistent Kingdom with 116, and China with 98 (Figure 4.3.12). with trends in private investment, the United States leads all Number of newly funded AI companies by geographic area, 2024 Source: Quid, 2024| Chart: 2025 AI Index report United States 1,073 United Kingdom 116 China 98 India 74 Germany 67 France 59 South Korea 52 Canada 51 Japan 42 Singapore 39 Israel 36 Netherlands 24 Australia 23 Switzerland 22 Spain 18 0 100 200 300 400 500 600 700 800 900 1,000 1,100 Number of companies Figure 4.3.12 Table of Contents Chapter 4 Preview 256 Artificial Intelligence Index Report 2025 Chapter 4: Economy 4.3 Investment A similar trend is evident in the aggregate data since 2013. In the last decade, the number of newly funded AI companies in the United States is around 4.3 times the amount in China, and 7.9 times the amount in the United Kingdom (Figure 4.3.13). Number of newly funded AI companies by geographic area, 2013–24 (sum) Source: Quid, 2024 | Chart: 2025 AI Index report United States 6,956 China 1,605 United Kingdom 885 Israel 492 Canada 481 France 468 India 434 Germany 394 Japan 388 South Korea 270 Singapore 239 Australia 178 Switzerland 154 Spain 117 Netherlands 116 0 500 1,000 1,500 2,000 2,500 3,000 3,500 4,000 4,500 5,000 5,500 6,000 6,500 7,000 Number of companies Figure 4.3.13 Table of Contents Chapter 4 Preview 257 Artificial Intelligence Index Report 2025 Figure 4.3.14 presents data on newly funded AI companies with Europe, has seen significant increases in the number of in specific geographic regions, highlighting a decade-long new AI companies, in contrast to China, which experienced a pattern in which the United States consistently surpasses second consecutive annual decline. both Europe and China. Since 2022, the United States, along 1,200 1,000 800 600 400 200 0 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 Figure 4.3.14 Table of Contents Chapter 4 Preview 258 seinapmoc fo rebmuN Chapter 4: Economy 4.3 Investment Number of newly funded AI companies by geographic area, 2013–24 Source: Quid, 2024 | Chart: 2025 AI Index report 1,143, United States 447, Europe 109, China Artificial Intelligence Index Report 2025 Chapter 4: Economy 4.3 Investment Focus Area Analysis Quid also disaggregates private AI investment by focus area. ($16.6 billion); and medical and healthcare ($11 billion). The Figure 4.3.15 compares global private AI investment by focus prominence of AI infrastructure, research, and governance area in 2024 versus 2023. The focus areas that attracted the reflects large investments in companies specifically building most investment in 2024 were AI infrastructure/research/ AI applications, such as OpenAI, Anthropic, and xAI. governance ($37.3 billion); data management and processing Global private investment in AI by focus area, 2023 vs. 2024 Source: Quid, 2024 | Chart: 2025 AI Index report AI infrastructure/research/governance Data management, processing Medical and health care AV Fintech Manufacturing Semiconductors NLP, customer support Cybersecurity, data protection Robotics Drones Energy, oil, and gas Marketing, digital ads Business operations Semantic search Supply chain Insurtech AR/VR Retail Ed tech Quantum computing IoT Agritech 2024 Content creation/translation 2023 Creative, music, video content 0 2 4 6 8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 Total investment (in billions of US dollars) Figure 4.3.15 Figure 4.3.16 presents trends over time in AI focus area investments. As noted earlier, most focus areas saw a boost in investments in the last year. While still substantial, investment in NLP, customer support peaked in 2021 and has since then declined. Table of Contents Chapter 4 Preview 259 Artificial Intelligence Index Report 2025 30 30 30 30 20 20 20 20 10 10 10 10 0 0 0 0 2018 2020 2022 2024 2018 2020 2022 2024 2018 2020 2022 2024 2018 2020 2022 2024 30 30 30 30 20 20 20 20 10 10 10 10 0 0 0 0 2018 2020 2022 2024 2018 2020 2022 2024 2018 2020 2022 2024 2018 2020 2022 2024 30 30 30 30 20 20 20 20 10 10 10 10 0 0 0 0 2018 2020 2022 2024 2018 2020 2022 2024 2018 2020 2022 2024 2018 2020 2022 2024 30 30 30 30 20 20 20 20 10 10 10 10 0 0 0 0 2018 2020 2022 2024 2018 2020 2022 2024 2018 2020 2022 2024 2018 2020 2022 2024 30 30 30 30 20 20 20 20 10 10 10 10 0 0 0 0 2018 2020 2022 2024 2018 2020 2022 2024 2018 2020 2022 2024 2018 2020 2022 2024 30 30 30 30 20 20 20 20 10 10 10 10 0 0 0 0 2018 2020 2022 2024 2018 2020 2022 2024 2018 2020 2022 2024 2018 2020 2022 2024 30 20 10 0 2018 2020 2022 2024 Table of Contents Chapter 4 Preview 260 )srallod SU fo snoillib ni( tnemtsevni latoT Chapter 4: Economy 4.3 Investment Global private investment in AI by focus area, 2018–24 Source: Quid, 2024 | Chart: 2025 AI Index report AI infrastructure/research/governance AR/VR AV Agritech 37.27 9.43 1.35 0.81 Business operations Content creation/translation Creative, music, video content Cybersecurity, data protection 1.52 0.76 0.75 3.73 Data management, processing Drones Ed tech Energy, oil, and gas 16.59 2.58 0.97 2.02 Fintech Insurtech IoT Manufacturing 6.88 6.58 1.36 0.84 Marketing, digital ads Medical and health care NLP, customer support Quantum computing 10.80 4.18 1.60 0.96 Retail Robotics Semantic search Semiconductors 5.53 1.17 3.29 1.43 Supply chain 1.40 Figure 4.3.16 Artificial Intelligence Index Report 2025 4.4 Corporate Activity This section examines the practical application of AI by corporations, highlighting industry usage trends, 4.4 Corporate Activity how businesses are integrating AI, the specific AI technologies deemed most beneficial, and the impact of AI Industry Usage usage on financial performance. This section incorporates insights from McKinsey’s publications on the state of AI alongside data from prior editions. The 2024 McKinsey analysis is based on two surveys spanning 2,854 respondents across various regions, industries, company sizes, functional areas, and tenures. Use of AI Capabilities Business use of AI increased significantly after stagnating between 2017 and 2023. The latest McKinsey report reveals that 78% of surveyed respondents say their organizations have begun to use AI in at least one business function, marking a significant increase from 55% in 2023 (Figure 4.4.1). Use of generative AI, which was covered for the first time in last year’s survey, more than doubled year over year, with 71% of respondents in 2024 saying their organizations regularly use the technology in at least one business function, compared to 33% in 2023. 80% 70% 60% 50% 40% 30% 20% 10% 0% 2017 2018 2019 2020 2021 2022 2023 2024 Table of Contents Chapter 4 Preview 261 stnednopser fo % Chapter 4: Economy Share of respondents who say their organization uses AI in at least one function, 2017–24 Source: McKinsey & Company Survey, 2024 | Chart: 2025 AI Index report 78%, AI 71%, GenAI Figure 4.4.1 Artificial Intelligence Index Report 2025 Chapter 4: Economy 4.4 Corporate Activity Figure 4.4.2 shows AI usage by industry and AI function in 2024. The greatest usage was in IT for tech (48%), followed by product and/or service development for tech (47%) and marketing and sales for tech (47%). Figure 4.4.28 8 “Advanced industries” comprises respondents from sectors such as advanced electronics, aerospace and defense, automotive and assembly, and semiconductors. “Energy and materials” encompasses respondents from agriculture, chemicals, electric power and natural gas, metals and mining, oil and gas, as well as paper, forest products, and packaging. Table of Contents Chapter 4 Preview 262 Artificial Intelligence Index Report 2025 Organizations have reported both cost reductions and supply chain and inventory management (43%), and software revenue increases where they have started using AI, but engineering (41%). For revenue gains, the functions that most most commonly at low levels (Figure 4.4.3). The areas where commonly benefited from their use of AI include marketing respondents most frequently reported that their use of AI and sales (71%), supply chain and inventory management has resulted in cost savings were service operations (49%), (63%), and service operations (57%). Decrease by <10% Decrease by 10–19% Decrease by ≥20% Increase by >10% Increase by 6–10% Increase by ≤5% Marketing and sales 34% 28% 23% 44% 71% Risk, legal, and compliance 34% 20% 9% Human resources 37% 21% 8% 8% Product or service development 23% 11% 8% 10% 16% 30% 56% Supply chain and inventory management 43% 29% 11% 10% 14% 39% 63% Service operations 49% 28% 16% 12% 10% 35% 57% IT 37% 22% 11% Software engineering 41% 20% 17% 11% 14% 19% 44% Other corporate functions 25% 15% 9% Table of Contents Chapter 4 Preview 263 noitcnuF Chapter 4: Economy 4.4 Corporate Activity Cost decrease and revenue increase from analytical AI use by function, 2024 Source: McKinsey & Company Survey, 2024 | Chart: 2025 AI Index report % of respondents Figure 4.4.3 Artificial Intelligence Index Report 2025 Chapter 4: Economy 4.4 Corporate Activity Figure 4.4.4 presents global AI usage by organizations, organizations’ reported use grew by 27 percentage points. segmented by regions. In 2024, surveyed respondents North America remains the leader in use of AI (82%), but in every region reported increased use of AI compared only by a small margin. Europe also experienced a significant with 2023. One of the most significant year-over-year increase in AI usage rates, growing by 23 percentage points growth rates in AI use was seen in Greater China, where to 80% since 2023. AI use by organizations in the world, 2023 vs. 2024 Source: McKinsey & Company Survey, 2024 | Chart: 2025 AI Index report 78% All geographies 55% 72% Asia-Paci c 58% 80% Europe 57% 82% North America 61% Greater China 75% (incl. Hong Kong, Taiwan, Macau) 48% Developing markets 2024 (incl. India, 77% 2023 Central/South America, 49% MENA) 0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% % of respondents Figure 4.4.4 Table of Contents Chapter 4 Preview 264 Artificial Intelligence Index Report 2025 Chapter 4: Economy 4.4 Corporate Activity Deployment of AI Capabilities How are organizations deploying AI? Figure 4.4.5 highlights The most common application is marketing strategy content the proportion of total surveyed respondents that report support (27%), followed by knowledge management (19%), using generative AI for a particular function. It is possible personalization (19%), and design development (14%). Most of for respondents to indicate that they deploy AI for multiple the leading reported use cases are within the marketing and purposes. sales function. A complementary survey of C-suite executives in developed markets found that only 1% described their generative AI rollouts as “mature.” Overall, most companies are still in the early stages of capturing value at scale from AI. Most common generative AI use cases by function, 2024 Source: McKinsey & Company Survey, 2024 | Chart: 2025 AI Index report Marketing strategy content support (i.e., drafting, generating ideas, and presenting relevant 27% knowledge for creating marketing strategy) Knowledge management 19% Personalization (e.g., personalized creative 19% content generation at scale) Design development 14% Code creation (i.e., using code assistants, leveraging natural-language-to-code translation, debugging, 13% development of tests) Automation of sales follow-up interactions 13% Integration of gen AI into the work�ow of human customer service representatives (e.g., providing real-time suggestions 12% for responses during human-to-human phone conversations) Sales lead identi�cation and prioritization 11% Service operations Accelerated early simulation/testing phases (i.e., re�ning R&D/product development and accelerating targeted customer research or 11% Marketing and sales interviews via gen AI’s synthesis and writing capabilities) Software engineering Scienti�c literature and research review 11% Other corporate functions 0% 5% 10% 15% 20% 25% % of respondents Figure 4.4.5 Table of Contents Chapter 4 Preview 265 Artificial Intelligence Index Report 2025 Chapter 4: Economy 4.4 Corporate Activity Figure 4.4.6 examines the proportion of respondents savings were supply chain and inventory management that report cost decreases and revenue increases from (61%), service operations (58%), and both human resources their organizations’ use of generative AI in each business and strategy and corporate finance (56%). For revenue function. Overall, respondents report both cost reductions gains, the functions most commonly reporting benefits and revenue increases across various functions as a result from generative AI include strategy and corporate finance of using generative AI, most commonly at low levels. The (70%), supply chain and inventory management (67%), and areas where respondents most frequently reported cost marketing and sales (66%). Decrease by ≤10% Decrease by 11–19% Decrease by ≥20% Increase by >10% Increase by 6–10% Increase by ≤5% Marketing and sales 47% 26% 11% 10% 8% 24% 34% 66% Risk, legal, and compliance 51% 29% 9% 13% Human resources 56% 32% 14% 10% Product or service development 43% 17% 7% 19% 12% 15% 25% 51% Supply chain and inventory management 61% 39% 15% 7% 19% 15% 32% 67% Service operations 58% 39% 11% 7% 18% 14% 31% 63% IT 44% 21% 12% 10% Software engineering 52% 23% 16% 13% 12% 13% 31% 57% Strategy and corporate nance 56% 35% 6% 15% 11% 12% 47% 70% Knowledge management and other 44% 16% 8% 19% internal functions Table of Contents Chapter 4 Preview 266 noitcnuF Cost decrease and revenue increase from generative AI use by function, 2024 Source: McKinsey & Company Survey, 2024 | Chart: 2025 AI Index report % of respondents Figure 4.4.6 Artificial Intelligence Index Report 2025 Chapter 4: Economy 4.4 Corporate Activity Figure 4.4.7 depicts the variation in generative AI usage (78%), which is shown in Figure 4.4.1. The use gap between among businesses across different regions of the world. AI overall and generative AI has contracted sharply from 22 Across all regions, reported use of generative AI in at least one percentage points in 2023 to 7 percentage points in 2024, business function reached 71% in 2024, more than doubling signaling an accelerated usage of generative AI capabilities. from 33% in 2023. This amount is just 7 percentage points North America (74%), Europe (73%), and Greater China (73%) lower than the percentage who reported using any form of AI lead in organizations’ use of generative AI. Generative AI use by organizations in the world, 2023 vs. 2024 Source: McKinsey & Company Survey, 2024 | Chart: 2025 AI Index report 71% All geographies 33% 67% Asia-Paci c 30% 73% Europe 31% 74% North America 40% Greater China 73% (incl. Hong Kong, Taiwan, and Macau) 31% Developing markets 2024 (incl. India, 68% 2023 Central/South America, 33% MENA) 0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% % of respondents Figure 4.4.79 9 This figure highlights AI use in at least one business function. Table of Contents Chapter 4 Preview 267 Artificial Intelligence Index Report 2025 2.97 3.00 2.60 2.50 2.00 1.50 1.00 0.50 0.00 Used AI Did not use AI Table of Contents Chapter 4 Preview 268 tnega troppus remotsuc rep stahc ylruoH Chapter 4: Economy 4.4 Corporate Activity AI’s Labor Impact Impact of AI on customer support agents Over the last six years, the growing integration of AI into Source: Brynjolfsson et al., 2023 | Chart: 2024 AI Index report the economy has sparked intense interest in its productivity potential. While early adoption showed promise, quantifying AI’s impact remained challenging until 2023, when the first wave of rigorous studies emerged. In 2024, a substantial body of empirical research established clear patterns of AI’s workplace effects across multiple domains and contexts. This section analyzes productivity impact data from five major academic studies, which together represent the first large- scale empirical investigation of AI’s workplace effects. The research, encompassing over 200,000 professionals across multiple industries and contexts, reveals consistent productivity gains ranging from 10% to 45%, with particularly strong effects in technical, customer support, and creative tasks. These studies employed diverse methodologies, including natural experiments, randomized controlled trials, and large-scale surveys, to measure AI’s impact across different organizational Figure 4.4.8 contexts. Productivity Trends One of the most reputable studies on AI’s impact on productivity, particularly generative AI, was published by Erik Brynjolfsson, Danielle Li, and Daniel Rock in April 2023.10 Analyzing data from 5,179 customer support agents, the study examined the staggered introduction of a generative AI- powered conversational assistant. The researchers found that AI adoption increased the number of issues resolved per hour by 14.2% (Figure 4.4.8). Moreover, the study uncovered that productivity gains emerged quickly after AI was introduced, and AI-exposed workers maintained higher efficiency even during AI outages. Other recently released research has confirmed the Brynjolfsson finding. A Microsoft workplace study established baseline productivity improvements in common workplace tasks, with document editing increasing by 10–13% and email processing time decreasing by 11%. Specialized roles showed Figure 4.4.9 This figure has been removed following a post-publication correction (October 2025). It referenced a paper that has been retracted. higher gains. For example, security professionals achieved 23% faster completion times with 7% higher accuracy, and sales teams demonstrated 39% faster response times with 25% higher accuracy. 10 The paper was published as NBER working paper 31161 in 2023 and then in the “Quarterly Journal of Economics” in 2025. Artificial Intelligence Index Report 2025 Chapter 4: Economy 4.4 Corporate Activity In the software development domain, two major studies developers experienced productivity increases of 21–40%, provided complementary evidence of AI’s impact. A field while senior developers saw more modest gains of 7–16%. experiment with 4,867 developers found that AI assistance This pattern was independently confirmed by other studies, increased task completion by 26.08% on average. This finding which found coding productivity increases of 14–27% for low- was reinforced by another natural experiment with 187,489 ability workers compared to 5–10% for high-ability workers. developers; it documented a 12.4% increase in core coding Moreover, their analysis showed AI increased exploration activities alongside a 24.9% decrease in time spent on project of new technologies by 21.8% and generated an average management tasks. potential salary increase of $1,683 per developer annually, suggesting AI tools are not just boosting productivity but Equalizing Effect actively enabling skill development. This research supports A consistent pattern across studies is AI’s equalizing effect earlier 2023 and 2024 studies showing that AI-driven on workplace performance (Figure 4.4.10). In software productivity gains vary based on workers’ initial skill levels. development contexts, new research has found that junior AI’s productivity equalizing effects Study Task Low-skill worker productivity gain High-skill worker productivity gain Brynjolfsson et al., 2023 Customer support 34% Indistinguishable from zero Dell’Acqua et al., 2023 Consulting 42.96% 16.5% Cui et al., 2024 Software engineering 21–40% 7–16% Hoffman et al., 2024 Software engineering 12–27% 5–10% Figure 4.4.10 Table of Contents Chapter 4 Preview 269 Artificial Intelligence Index Report 2025 Chapter 4: Economy 4.4 Corporate Activity Adoption and Integration The research reveals that productivity gains are strongly correlated with comprehensive AI integration and systematic 50% 46.78% implementation. A survey conducted by Romanian researchers of 233 employees found that organizations with 40% high AI integration showed a 72% probability of significant productivity improvements, compared to just 3.4% for those with minimal integration. Their analysis documented a clear 30% spectrum of productivity improvements across the entire 26.18% study sample, with 46.8% of respondents reporting gains of 0–20%, 26.2% seeing gains of 20–40%, and 18.4% achieving 20% 18.45% improvements of 40–60%. A smaller proportion saw even larger gains, with 7.7% reporting increases of 60–80% and 10% 7.73% 0.9% achieving improvements of 80–100% (Figure 4.4.11). 0.86% Workforce Impact 0% 0–20% 20–40% 40–60% 60–80% 80–100% The introduction of AI tools has led to significant shifts in both Productivity gains task allocation and team structures. The Microsoft workplace study found that AI automation enabled a 45% reduction in perceived mental demand (measured as 30/100 vs. 55/100 on their cognitive load scale), closed 84.6% of the accuracy gap for nonnative English speakers, and led to 49% more key information being included in professional reports. These improvements were particularly pronounced among “power users” (users who are intimately familiar with AI, as defined by using it at least several times a week) with 29% of AI users in this category saving more than 30 minutes per day. Research from the Harvard Business School documented that AI adoption led to reduced collaborative overhead, with projects requiring 79.3% fewer collaborators (team members) on average. These changes are reshaping professional roles in fundamental ways. Debates about AI, like those surrounding past technological advancements, often center on automation versus augmentation—whether AI will replace jobs or enhance human work. While concrete data on AI-driven workforce changes remains limited, research is shedding light on how people perceive its impact on employment. Table of Contents Chapter 4 Preview 270 stnednopser fo % Distribution of productivity gains from AI use Source: Necula et al., 2024 | Chart: 2025 AI Index report Figure 4.4.11 The Romanian survey data suggests varied expectations for AI’s impact on workforce size, with 43% of organizations anticipating decreases, 30% expecting little change, 15% projecting increases, and 12% remaining uncertain about long-term implications. A McKinsey survey of executives found that 31% expect AI to reduce workforce size, while only 19% foresee an increase (Figure 4.4.12). In spite of claims about the increase in productivity of software engineers due to generative AI, the survey shows that their number is expected to increase, consistent with the Jevons Paradox. Notably, the share predicting workforce reductions has declined from last year, suggesting business leaders are becoming less convinced that AI will shrink organizational workforces (Figure 4.4.13). Artificial Intelligence Index Report 2025 Chapter 4: Economy 4.4 Corporate Activity Expectations about the impact of generative AI on organizations’ workforces in the next 3 years, 2024 Source: McKinsey & Company Survey, 2024 | Chart: 2025 AI Index report Decrease by >20% Decrease by 11–20% Decrease by 3–10% Little or no change Increase by 3–10% Increase by 11–20% Increase by >20% Don’t know Overall 8% 9% 14% 38% 8% 6% 5% 12% Service operations 15% 17% 16% 19% 7% 4% 10% 12% Marketing and sales 10% 10% 10% 38% 7% 8% 6% 11% Supply chain/ 10% 19% 18% 15% 15% 4% 10% 9% inventory management Manufacturing 8% 15% 18% 20% 18% 7% 11% Human resources 8% 14% 24% 26% 6% 5% 4% 13% Software engineering 8% 9% 11% 25% 11% 11% 10% 15% Product and/or 7% 7% 9% 33% 16% 10% 8% 10% service development Strategy and 7% 13% 11% 29% 17% 5% 8% 9% corporate nance Risk, legal, and 6% 17% 14% 25% 13% 8% 15% compliance IT 5% 10% 10% 21% 17% 15% 9% 14% 0% 20% 40% 60% 80% 100% % of respondents Figure 4.4.12 Table of Contents Chapter 4 Preview 271 Artificial Intelligence Index Report 2025 Chapter 4: Economy 4.4 Corporate Activity 8% Increase by >20% 46% 3% >20% 38% 5% Increase by 11–20% 4% 17% Increase by 3–10% 10% 11–20% 8% 18% 31% Little or no change 30% 14% 6–10% 14% 17% Decrease by 3–10% 25% 10% 12% Decrease by 11–20% 10% ≤5% 20% 8% Decrease by >20% 8% 11% 2024 14% Don’t know 2023 Don’t know 8% 12% 0% 10% 20% 30% 40% 50% 0% 10% 20% 30% 40% 50% % of respondents % of respondents Table of Contents Chapter 4 Preview 272 seeyolpme fo rebmun eht ni egnahC dellikser eb ot detcepxe seeyolpme fo erahS Expectations about the impact of AI on organizations’ workforces in the next 3 years, 2023 vs. 2024 Source: McKinsey & Company Survey, 2023–24 | Chart: 2025 AI Index report Figure 4.4.13 Artificial Intelligence Index Report 2025 Chapter 4: Economy 4.5 Robot Deployments The deployment of robots equipped with AI-based software technologies offers a window into the real-world application of AI-ready infrastructure. This section draws on data from the 4.5 Robot Deployments International Federation of Robotics (IFR), a nonprofit organization dedicated to advancing the robotics Aggregate Trends industry. Annually, the IFR publishes the World Robotics Reports, which The following section includes data on the installation and operation of industrial track global robot installation trends.11 robots, which are defined as an “automatically controlled, reprogrammable, multipurpose manipulator, programmable in three or more axes, which can be either fixed in place or mobile for use in industrial automation applications.” Figure 4.5.1 reports the total number of industrial robots installed worldwide by year. In 2023, industrial robot installations decreased slightly, with 541,000 units marking a 2.2% decrease from 2022. This reflects the first year-over-year decrease since 2019. 541 500 400 300 200 100 0 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 11 Due to the timing of the IFR report, the most recent data is from 2023. Every year, the IFR revisits data collected for previous years and will occasionally update the data if more accurate figures become available. Therefore, some of the data reported in this year’s report might differ slightly from data reported in previous years. Table of Contents Chapter 4 Preview 273 )sdnasuoht ni( dellatsni stobor lairtsudni fo rebmuN Number of industrial robots installed in the world, 2012–23 Source: International Federation of Robotics (IFR), 2024 | Chart: 2025 AI Index report Figure 4.5.1 Artificial Intelligence Index Report 2025 Chapter 4: Economy 4.5 Robot Deployments The global operational stock of industrial robots reached 4,282,000 in 2023, up from 3,904,000 in 2022 (Figure 4.5.2). Since 2012, both the installation and utilization of industrial robots have steadily increased. 4,500 4,282 4,000 3,500 3,000 2,500 2,000 1,500 1,000 500 0 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 Table of Contents Chapter 4 Preview 274 )sdnasuoht ni( stobor lairtsudni fo rebmuN Operational stock of industrial robots in the world, 2012–23 Source: International Federation of Robotics (IFR), 2024 | Chart: 2025 AI Index report Figure 4.5.2 Artificial Intelligence Index Report 2025 Chapter 4: Economy 4.5 Robot Deployments Industrial Robots: Traditional vs. Collaborative Robots There is a distinction between traditional robots, which operate Figure 4.5.3 reports the number of industrial robots installed in place of humans, and collaborative robots, designed to work in the world by type. In 2017, collaborative robots accounted alongside them.12 The robotics community is increasingly for just 2.8% of all new industrial robot installations. By 2023, enthusiastic about collaborative robots due to their safety, the number rose to 10.5%. flexibility, scalability, and ability to learn iteratively. Traditional 553 541 Collaborative 526 500 424 400 400 387 389 300 495 484 484 405 200 389 366 363 100 58 57 42 0 2017 2018 2019 2020 2021 2022 2023 Table of Contents Chapter 4 Preview 275 )sdnasuoht ni( dellatsni stobor lairtsudni fo rebmuN Number of industrial robots installed in the world by type, 2017–23 Source: International Federation of Robotics (IFR), 2024 | Chart: 2025 AI Index report Figure 4.5.3 12 More detail on how the IFR defines collaborative robots can be found here. Artificial Intelligence Index Report 2025 Chapter 4: Economy 4.5 Robot Deployments By Geographic Area Country-level data on robot installations can suggest 46,100 and 7.3 times more than the United States’ 37,600 which nations prioritize the integration of robots into their (Figure 4.5.4). South Korea and Germany followed with economies. In 2023, China led the world with 276,300 31,400 and 28,400 installations, respectively. industrial robot installations, six times more than Japan’s Number of industrial robots installed by geographic area, 2023 Source: International Federation of Robotics (IFR), 2024 | Chart: 2025 AI Index report China 276.30 Japan 46.10 United States 37.60 South Korea 31.40 Germany 28.40 Italy 10.40 India 8.50 France 6.40 Mexico 5.80 Spain 5.10 Taiwan 4.40 Turkey 4.40 Canada 4.30 United Kingdom 3.80 Thailand 3.60 0 30 60 90 120 150 180 210 240 270 Number of industrial robots installed (in thousands) Figure 4.5.4 Table of Contents Chapter 4 Preview 276 Artificial Intelligence Index Report 2025 Chapter 4: Economy 4.5 Robot Deployments Since surpassing Japan in 2013 as the leading installer of industrial robots, China has significantly widened the gap with the nearest country. In 2013, China’s installations accounted for 20.8% of the global total, reaching 51.1% by 2023 (Figure 4.5.5). 300 250 200 150 100 50 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 Table of Contents Chapter 4 Preview 277 )sdnasuoht ni( dellatsni stobor lairtsudni fo rebmuN Number of new industrial robots installed in top 5 countries, 2011–23 Source: International Federation of Robotics (IFR), 2024 | Chart: 2025 AI Index report 276, China 46, Japan 38, United States 31, South Korea 28, Germany Figure 4.5.5 Artificial Intelligence Index Report 2025 Chapter 4: Economy 4.5 Robot Deployments Since 2021, China has installed more industrial robots than the rest of the world combined, but the margin decreased in 2023 compared to 2022 (Figure 4.5.6). Despite this year-over-year decline, the sustained trend underscores China’s dominance in industrial robot installations. 300 250 200 150 100 50 0 2016 2017 2018 2019 2020 2021 2022 2023 Table of Contents Chapter 4 Preview 278 )sdnasuoht ni( dellatsni stobor lairtsudni fo rebmuN Number of industrial robots installed (China vs. rest of the world), 2016–23 Source: International Federation of Robotics (IFR), 2024 | Chart: 2025 AI Index report 276, China 265, Rest of the world Figure 4.5.6 Artificial Intelligence Index Report 2025 Chapter 4: Economy 4.5 Robot Deployments According to the IFR report, seven countries reported an include India (59%), the United Kingdom (51%), and Canada annual increase in industrial robot installations from 2022 to (37%). The geographic areas with the steepest declines include 2023 (Figure 4.5.7). The countries with the highest growth rates Taiwan (-43%), France (-13%), and Japan and Italy (both -9%). Annual growth rate of industrial robots installed by geographic area, 2022 vs. 2023 Source: International Federation of Robotics (IFR), 2024 | Chart: 2025 AI Index report India 59% United Kingdom 51% Canada 37% Spain 31% Turkey 15% Thailand 9% Germany 7% South Korea -1% Mexico -3% United States -5% China -5% Italy -9% Japan -9% France -13% Taiwan -43% −40% −30% −20% −10% 0% 10% 20% 30% 40% 50% 60% Annual growth rate of industrial robots installed Figure 4.5.7 Table of Contents Chapter 4 Preview 279 Artificial Intelligence Index Report 2025 Chapter 4: Economy 4.5 Robot Deployments Country-Level Data on Service Robotics Another important class of robots is service robots, which professional cleaning. In 2023, more service robots were the International Organization for Standardization defines as installed for every application category than in 2022, with the a robot “that performs useful tasks for humans or equipment exception of medical robots (Figure 4.5.8). More specifically, excluding industrial automation applications.”13 Such robots the number of service robots installed in agricultural and can, for example, be used in medical settings and for hospitality settings increased 2.5 and 2.2 times, respectively. Number of service robots installed in the world by application area, 2022 vs. 2023 Source: International Federation of Robotics (IFR), 2024 | Chart: 2025 AI Index report 20 Agriculture 8 54 Hospitality 25 6 Medical and health care 9 12 Professional cleaning 2023 7 2022 113 Transportation and logistics 86 0 10 20 30 40 50 60 70 80 90 100 110 Number of service robots installed (in thousands) Figure 4.5.8 13 A more detailed definition can be accessed here. Table of Contents Chapter 4 Preview 280 AArrttiifificciiaall IInntteelllliiggeennccee IInnddeexx RReeppoorrtt 22002255 CHAPTER 5: Science and Medicine Table of Contents Chapter 5 Preview 281 Artificial Intelligence Index Report 2025 Chapter 5: Science and Medicine Overview 282 Diagnostic Reasoning With LLMs 304 Chapter Highlights 283 Highlight: LLMs Influence Diagnostic Reasoning 304 5.1 Notable Medical and Biological Management Reasoning and AI Milestones 285 Patient Care Decisions 304 Protein Sequence Optimization 285 Highlight: GPT-4 Assistance on Patient Care Tasks 305 Aviary 286 Ambient AI Scribes 306 AlphaProteo 287 Deployment, Implementation, Human Brain Mapping 287 Deimplementation 308 Virtual AI Lab 288 FDA Authorization of AI-Enabled GluFormer 289 Medical Devices 308 Evolutionary Scale Modeling v3 Successful Use Cases: (ESM3) 289 Stanford Health Care 308 AlphaFold 3 290 Screening for Peripheral Arterial Disease 309 5.2 The Central Dogma 291 Social Determinants of Health 310 Protein Sequence Analysis 291 Extracting SDoH From EHR and AI-Driven Protein Sequence Models 291 Clinical Notes 310 Public Databases for Protein Science 293 AI Adoption Across Medical Fields Research and Publication Trends 294 and the Integration of SDoH 311 AI-Driven Protein Science Synthetic Data 311 Publications 294 Clinical Risk Prediction 311 Image and Multimodal AI for Drug Discovery 312 Scientific Discovery 295 Data Generation Platforms 312 Electronic Health Record System 313 5.3 Clinical Care, Imaging 296 Clinical Decision Support 316 Data: Sources, Types, and Needs 296 Advanced Modeling Approaches 298 5.5 Ethical Considerations 317 Meta Review 317 5.4 Clinical Care, Non-Imaging 300 Clinical Knowledge 300 5.6 AI in Physics, Chemistry, MedQA 300 and Other Scientific Domains 320 Highlight: AI Doctors and Highlight: Notable Model Releases 320 Cost-Efficiency Considerations 301 Evaluation of LLMs for Healthcare Performance 302 ACCESS THE PUBLIC DATA Overview 302 Table of Contents 282 AArrttiifificciiaall IInntteelllliiggeennccee IInnddeexx RReeppoorrtt 22002255 CHAPTER 5: Science and Medicine Overview This chapter explores key trends in AI-driven science and medicine, reflecting the technology’s growing impact in these fields. It begins with notable AI milestones from 2024, followed by an analysis of AI in protein folding, an important area of scientific advancement. The chapter then examines AI’s role in clinical care, spanning both imaging and non-imaging applications. This includes a review of clinical knowledge capabilities in new language models, diagnostic and clinical management capabilities of AI systems, real-world AI deployments in medicine, synthetic data applications, and social determinants of health. Finally, the chapter concludes with an exploration of ethical trends in AI medical research. This chapter was prepared by RAISE Health (Responsible AI for Safe and Equitable Health), a collaboration between Stanford Medicine and the Stanford Institute for Human-Centered Artificial Intelligence (HAI). Since its launch in 2023, RAISE Health has worked to advance responsible AI innovation in biomedical research, education, and patient care, with a focus on ensuring that these technologies benefit everyone. Fostering collaborative research and knowledge sharing are central to RAISE Health’s mission. As part of that commitment, RAISE Health partnered with the AI Index Steering Committee to expand the group’s focus to include key developments in science and medicine. In 2024, this collaboration produced the inaugural chapter on science and medicine, highlighting major AI advancements at Stanford and beyond. The 2025 chapter builds on that foundation with contributions from members of the RAISE Health faculty research council, Stanford School of Medicine faculty, postdoctoral fellows, and undergraduate students from the schools of Medicine and Engineering. Table of Contents Chapter 5 Preview 283 AArrttiifificciiaall IInntteelllliiggeennccee IInnddeexx RReeppoorrtt 22002255 CHAPTER 5: Science and Medicine Chapter Highlights 1. Bigger and better protein sequencing models emerge. In 2024, several large-scale, high-performance protein sequencing models, including ESM3 and AlphaFold 3, were launched. Over time, these models have grown significantly in size, leading to continuous improvements in protein prediction accuracy. 2. AI continues to drive rapid advances in scientific discovery. AI’s role in scientific progress continues to expand. While 2022 and 2023 marked the early stages of AI-driven breakthroughs, 2024 brought even greater advancements, including Aviary, which trains LLM agents for biological tasks, and FireSat, which significantly enhances wildfire prediction. 3. The clinical knowledge of leading LLMs continues to improve. OpenAI’s recently released o1 set a new state- of-the-art 96.0% on the MedQA benchmark—a 5.8 percentage point gain over the best score posted in 2023. Since late 2022, performance has improved 28.4 percentage points. MedQA, a key benchmark for assessing clinical knowledge, may be approaching saturation, signaling the need for more challenging evaluations. 4. AI outperforms doctors on key clinical tasks. A new study found that GPT-4 alone outperformed doctors—both with and without AI—in diagnosing complex clinical cases. Other recent studies show AI surpassing doctors in cancer detection and identifying high-mortality-risk patients. However, some early research suggests that AI-doctor collaboration yields the best results, making it a fruitful area of further research. 5. The number of FDA-approved, AI-enabled medical devices skyrockets. The FDA authorized its first AI-enabled medical device in 1995. By 2015, only six such devices had been approved, but the number spiked to 223 by 2023. 6. Synthetic data shows significant promise in medicine. Studies released in 2024 suggest that AI-generated synthetic data can help models better identify social determinants of health, enhance privacy-preserving clinical risk prediction, and facilitate the discovery of new drug compounds. Table of Contents Chapter 5 Preview 284 AArrttiifificciiaall IInntteelllliiggeennccee IInnddeexx RReeppoorrtt 22002255 CHAPTER 5: Science and Medicine Chapter Highlights (cont’d) 7. Medical AI ethics publications are increasing year over year. The number of publications on ethics in medical AI quadrupled from 2020 to 2024, rising from 288 in 2020 to 1,031 in 2024. 8. Foundation models come to medicine. In 2024, a wave of large-scale medical foundation models were released, ranging from general-purpose multimodal models like Med-Gemini to specialized models such as EchoCLIP for echocardiology and ChexAgent for radiology. 9. Publicly available protein databases grow in size. Since 2021, the number of entries in major public protein science databases has grown significantly, including UniProt (31%), PDB (23%), and AlphaFold (585%). This expansion has important implications for scientific discovery. 10. AI research wins two Nobel Prizes. In 2024, AI-driven research received top honors, with two Nobel Prizes awarded for AI-related breakthroughs. Google DeepMind’s Demis Hassabis and John Jumper won the Nobel Prize in Chemistry for their pioneering work on protein folding with AlphaFold. Meanwhile, John Hopfield and Geoffrey Hinton received the Nobel Prize in Physics for their foundational contributions to neural networks. Table of Contents Chapter 5 Preview 285 Artificial Intelligence Index Report 2025 Chapter 5: Science and Medicine 5.1 Notable Medical and Biological AI Milestones This section highlights significant AI-related medical and biological breakthroughs in 2024 as chosen by the RAISE Health AI Index Workgroup and AI Index Steering Committee. 5.1 Notable Medical and Biological AI Milestones Protein Sequence Optimization LLMs optimize protein sequence optimization Single-objective optimization results for LLMs have recently, albeit unintentionally, gained a new fitness optimization Source: Wang et al., 2024 biological capability: optimizing protein sequences. Traditionally, protein engineering requires extensive lab studies to refine sequences for improved functionality. However, a recent study found that LLMs—without fine- tuning—are becoming remarkably effective at this task. In other words, this is a hidden strength of existing LLMs, exemplified in this case by an adapted version of Llama- 3.1-8B-Instruct. Using a directed evolutionary approach, researchers demonstrated that LLMs can generate protein sequences that outperform conventional algorithms across both synthetic and experimental fitness landscapes. Figure 5.1.1 illustrates the researchers’ findings. The objective in this case is to maximize the fitness value, with higher scores indicating better performance. The researchers compared their proposed method’s fitness score against that of the default evolutionary algorithm (EA) approach.1 The study revealed that this optimization extends beyond single- objective tasks to include constrained, budget-limited, and multiobjective scenarios. This compelling finding highlights the emergent properties of state-of-the-art LLMs, suggesting Figure 5.1.1 that as these general-purpose models continue to improve, their impact on scientific fields will only grow. 1 Evolutionary algorithms (EA) simulate key aspects of biological evolution within a computer program to tackle complex problems—especially those without precise or fully satisfactory solutions—by finding approximate answers. Table of Contents Chapter 5 Preview 286 Artificial Intelligence Index Report 2025 Aviary Training LLM agents for biological tasks Sonnet model, which attempts tasks without environmental As AI systems become increasingly useful, particularly for access, with models integrated into agent frameworks within scientific use cases, one challenge has been designing the Aviary environment. Across nearly all tasks, the agentic language models that can interact with tools as they reason models outperform the baseline. This research demonstrates through complex tasks. Aviary introduces a structured that (1) although general-purpose LLMs perform well at many framework for training language agents for three particularly scientific tasks, fine-tuning models alongside domain experts challenging scientific tasks: DNA manipulation (for molecular often helps models yield superior results, and (2) AI-driven cloning), answering research questions (through accessing scientific research can be accelerated not only by model size scientific papers), and engineering protein stability. Figure but also through interaction with external tools, capabilities 5.1.2 compares the performance of different models across now commonly referred to as “agentic AI.” various Aviary environments. It contrasts a baseline Claude 3.5 Claude 3.5 Sonnet Claude 3.5 Sonnet agent Claude 3.5 Sonnet agent pass @16 GPT-4o EI agent Llama 3.1 8B EI agent Llama 3.1 8B EI agent majority vote @32 1.00 0.89 0.86 0.83 0.80 0.79 0.81 0.80 0.76 0.73 0.72 0.72 0.61 0.59 0.60 0.55 0.49 0.40 0.25 0.20 0.14 0.15 0.00 GSM8K hotpotQA SeqQA LitQA2 Protein stability Task Table of Contents Chapter 5 Preview 287 etar ssaP Chapter 5: Science and Medicine 5.1 Notable Medical and Biological AI Milestones Performance of LLMs and language agents to solve tasks using Aviary environments Source: Narayanan et al., 2024 | Chart: 2025 AI Index report Figure 5.1.2 Artificial Intelligence Index Report 2025 Chapter 5: Science and Medicine 5.1 Notable Medical and Biological AI Milestones AlphaProteo AI for novel, high-affinity protein binders AlphaProteo is Google DeepMind’s model focused on AlphaProteo generating successful binders creating novel, high-affinity protein binders that attach to Source: Google DeepMind, 2024 Figure 5.1.3 specific target molecules. Figure 5.1.3 illustrates the predicted structures of seven target proteins for which AlphaProteo created successful binders. AlphaProteo has designed the first protein binders for many targets, including VEGF-A, a protein linked to cancer and diabetes. Many of the tool’s binding strengths are significantly better than current state- of-the-art solutions; in fact, the team estimates that some of their binders are up to 300 times more effective than anything currently available on the seven target proteins they tested. For the viral protein BHRF1, 88% of their designed binders successfully bound when tested in DeepMind’s wet lab. Based on the tested targets, AlphaProteo binders hold together roughly 10 times more strongly than those created using existing state-of-the-art design methods, making it a true bioengineering breakthrough. The model is being used for drug development, diagnostics, and biotech applications. Human Brain Mapping Synaptically reconstructing a small piece of the human brain visualizes the results: excitatory neurons on the left, inhibitory A team at Google’s Connectomics project has reconstructed neurons on the right. To process this massive dataset, the team a one-cubic-millimeter section of the human brain at the developed machine learning tools like flood-filling networks synaptic level—hailed by Wired as “the most detailed map (for neuron reconstruction without manual tracing), SegCLR of brain connections ever made.” The sample, taken from an (for cell type identification), and TensorStore (for managing epileptic patient’s left anterior temporal lobe during surgery, the multidimensional dataset). The dataset is publicly available was imaged with a multibeam scanning electron microscope. via Neuroglancer, a web-based exploration tool; and CAVE, Over 5,000 ultra-thin slices (30 nanometers each) captured a Neuroglancer extension for annotation refinement. This around 57,000 cells—including neurons, glial cells, and project marks a major step in understanding neural circuitry blood vessels—along with 150 million synapses. Figure 5.1.4 and could inform future neurological treatments. 3D brain map images Source: Google Research, 2024 Figure 5.1.4 Table of Contents Chapter 5 Preview 288 Artificial Intelligence Index Report 2025 Chapter 5: Science and Medicine 5.1 Notable Medical and Biological AI Milestones Virtual AI Lab Virtual AI lab supercharges biomedical research in validation studies. The virtual lab was structured similar to a AI’s role in science is shifting from a passive tool to an active computational biology lab, comprising a principal investigator collaborator. A recent Stanford study introduced a virtual AI (PI), a scientific critic AI, and three discipline-specific laboratory, where multiple AI-powered scientists (technically scientists specializing in immunology, computational biology, LLMs) specialize in different disciplines and autonomously and machine learning (Figure 5.1.5). The PI model created collaborate as agents. In one experiment, human researchers these expert scientists and guided their research. Tools like tasked this AI-driven lab with designing nanobodies— AlphaFold and Rosetta were used for protein design, but the antibody fragments—capable of binding to SARS-CoV-2, real significance of this study lies not in its specific findings, the virus that causes COVID-19. The lab generated 92 but in demonstrating that an entirely autonomous, LLM- nanobodies, with over 90% successfully binding to the virus powered lab can generate meaningful scientific discoveries. Workflow in AI-based lab Source: FreeThink, 2025 Figure 5.1.5 Table of Contents Chapter 5 Preview 289 Artificial Intelligence Index Report 2025 GluFormer Continuous glucose monitoring with AI GluFormer, a foundation model developed by Nvidia Tel Aviv, the Weizmann Institute, and others, analyzes continuous glucose monitoring (CGM) data to predict long-term health outcomes. Trained on over 10 million glucose measurements from nearly 11,000 individuals—most without diabetes—it forecasts health trajectories up to four years in advance. For instance, GluFormer can identify individuals at risk of developing diabetes or worsening glycemic control long before symptoms appear. In a 12-year study of 580 adults, it accurately flagged 66% of new-onset diabetes cases and 69% of cardiovascular-related deaths within their respective top- risk quartiles. The model’s results have also generalized across 19 external cohorts (n=6,044) in five countries and diverse health conditions. GluFormer often outperforms standard CGM-based metrics like the glucose management indicator (GMI) (Figure 5.1.6). In the near and long term, models like GluFormer will shift diabetes care from reactive treatment to proactive prevention, enabling earlier clinical intervention. Evolutionary Scale Modeling v3 (ESM3) Simulating evolutionary processes to generate novel proteins EvolutionaryScale’s ESM3 is a groundbreaking model 0.75 Base Preference-tuned designed to generate novel proteins by simulating evolutionary processes. The model was trained on 2.78 billion protein sequences, and hosts 98 billion parameters. Like many other AI models, it is available in three sizes (small, medium, 0.50 and large) and is available both via API and their partners’ platforms. Perhaps ESM3’s most notable achievement is designing esmGFP, a new artificial green fluorescent protein which the company estimates would take nature 500 million 0.25 years to develop. This was done through human-led chain-of- thought prompting. Figure 5.1.7 illustrates the performance of various ESM3 models in generating proteins that satisfy atomic coordination prompts. The results show that larger 0.00 ESM3 models solve twice as many tasks. ESM3 is also open- 1.4B 7B 98B Model sourced, promoting collaboration in synthetic biology and protein engineering projects which hope to use code and data from the project—with applications in drug discovery, materials science, and environmental engineering. Table of Contents Chapter 5 Preview 290 devlos sksat fo noitcarF Chapter 5: Science and Medicine 5.1 Notable Medical and Biological AI Milestones GluFormer versus glucose management indicator Source: Lutsker et al., 2024 Figure 5.1.6 ESM3 models evaluated on protein generation from atomic coordination prompts Source: ESM3, 2024 | Chart: 2025 AI Index report Figure 5.1.7 Artificial Intelligence Index Report 2025 AlphaFold 3 Predicting the structure and interactions of all of life’s important measure of docking accuracy.2 3 AlphaFold 3 is molecules competitive with previous state-of-the-art methods and Google and Isomorphic Lab’s latest in the AlphaFold series, particularly effective when the binding pocket is predefined, AlphaFold 3, goes beyond predicting protein structures meaning that the docking algorithm is given prior knowledge to more accurately modeling their interactions with key about the specific region on the protein where the small biomolecules (DNA, RNA, ligands, antibodies). Figure 5.1.8 molecule (ligand) is expected to bind. AlphaFold 3 can compares AlphaFold 3’s accuracy in predicting protein- accelerate drug development by modeling small molecule- ligand interactions against other top docking tools (e.g., protein interactions, which is important for disease research. Vina and Gnina) based on the percentage of predictions Moreover, AlphaFold 3’s open-source access empowers with a root mean square deviation (RMSD) below 2 Å, an scientists globally. 100 RMSD < 2 and PB-valid RMSD < 2 93.20 79.50 80.50 84.40 80 70.10 70.50 77.30 73.10 67.20 68.20 59.70 60 58.10 40 20 0 Vina Vina + Conf. Ensemble Gnina Gnina + Conf. Ensemble AF3 AF3 Pocket Speci ed Method Figure 5.1.8 Table of Contents Chapter 5 Preview 291 Å2 < DSMR % Chapter 5: Science and Medicine 5.1 Notable Medical and Biological AI Milestones AlphaFold 3 vs. baselines for protein-ligand docking Source: ESM3, 2024 | Chart: 2025 AI Index report 2 A docking tool, like Vina, is a computational program used in molecular docking—a process that predicts how small molecules (such as drugs) interact with target proteins. These tools help scientists model and visualize how a molecule might bind to a protein’s active site, which is crucial in drug discovery. 3 The chart uses two shades of bars to represent different accuracy criteria in molecular docking predictions. The lighter bars indicate the percentage of docking results with a root mean square deviation (RMSD) below 2 Å, meaning the predicted pose is structurally accurate. The darker bars apply a stricter criterion, showing the proportion of predictions that are not only within 2 Å RMSD but also correctly positioned within the binding pocket (PB-valid). This distinction highlights the difference between general docking accuracy and more precise, biologically relevant binding predictions. Artificial Intelligence Index Report 2025 Chapter 5: Science and Medicine 5.2 The Central Dogma AI has transformed numerous scientific fields, with protein science being one of 5.2 The Central Dogma the most impacted areas. Understanding protein sequences is fundamental to biology, influencing drug discovery, Protein Sequence Analysis synthetic biology, and disease research. Recent AI advancements have enabled scientists to analyze and predict protein AI-Driven Protein Sequence Models functions, structures, and interactions with unprecedented accuracy. As the The past year has witnessed remarkable progress in AI models applied to protein field evolves, these developments will sequences. Large-scale machine learning models have improved our ability to affect healthcare, biotechnology, and predict protein properties, accelerating research in structural biology and molecular regulatory frameworks. This section engineering. As noted above, several notable protein sequencing models, like highlights key advancements in AI- driven protein analysis over the past AlphaFold, ESM2, and ESM3, have recently been released. year, focusing on public databases, research trends, and emerging policy ESM3 integrates multimodal inputs—sequence, structure, and interaction data— considerations. while its larger parameter size improves representativeness and predictive accuracy. As the ESM family has expanded in scale, protein prediction performance has improved. Newer models, such as ESM C, released in 2024, have achieved greater accuracy in predicting protein structures in the Critical Assessment of Structure Prediction (CASP15) challenge (Figure 5.2.1). Emergent structure prediction success, CASP15 Source: EvolutionaryScale, 2024 Figure 5.2.1 Table of Contents Chapter 5 Preview 292 Artificial Intelligence Index Report 2025 Other significant advancements include ProGen, a generative 5.2.2 showcases key protein sequencing models and their AI model that, in demonstrating the ability to design parameter sizes, arranged by release date. As noted earlier, functional protein sequences, has highlighted the potential of there is a clear trend toward increasingly larger models trained AI-assisted protein engineering. Similarly, transformer-based on ever-expanding datasets. These AI-driven approaches models such as ProtT5 leverage deep learning to predict have transformed protein science by minimizing reliance on protein function and interactions directly from sequence costly, time-intensive experimental methods, enabling rapid data, advancing the field of computational biology. Figure exploration of protein function and design. 100 98.00 80 60 40 20 15.00 6.40 1.20 0.42 1.20 0 ProGen ProtBert ProGen2 ProtT5 ESM2 ESM3 2020 2022 2023 2024 Model (sorted by release date) Table of Contents Chapter 5 Preview 293 )snoillib ni( sretemarap fo rebmuN Chapter 5: Science and Medicine 5.2 The Central Dogma Size of protein sequencing models, 2020–24 Source: RAISE Health, 2025 | Chart: 2025 AI Index report Figure 5.2.2 Artificial Intelligence Index Report 2025 Chapter 5: Science and Medicine 5.2 The Central Dogma Public Databases for Protein Science The expansion of public databases has been crucial for AI sequences, enhancing their predictive power. Figure applications in protein science. Well-curated, large-scale 5.2.3 provides information on several key protein science datasets enable AI models to train on diverse biological databases and their release date. Key protein science databases Source: AI Index, 2025 Dataset Release date Description Protein Data Bank (PDB) 1971 A database of experimentally solved protein structures. When first released, it was the first open-access digital resource in the biological sciences. Pfam 1995 A comprehensive database of protein families, providing annotations and multiple sequence alignments generated through hidden Markov models. STRING 2000 Dataset offering valuable information on protein interactions and evolutionary relationships. UniProt 2002 Still the gold standard for protein sequence and function annotation, with AI-assisted curation improving accuracy. PDBbind 2004 A subset of the PDB that contains protein biomolecular complexes, including protein-ligand, protein-protein, and protein-nucleic acid complexes. AlphaFold Database 2021 An essential resource for structural biology, now integrating AI-driven models to predict missing experimental data. Figure 5.2.3 The number of entries in various public protein science databases has also steadily grown over time (Figure 5.2.4). The increasing availability of AI-generated protein insights UniProt AlphaFold DB PDB has made these databases indispensable tools for researchers and industry professionals. However, maintaining data quality and preventing biases in AI models remain ongoing 100M challenges. 10M 1M 100K 2019 2020 2021 2022 2023 2024 2025 Table of Contents Chapter 5 Preview 294 )elacs gol( seititne fo rebmuN Growth of public protein science databases, 2019–25 Source: RAISE Health, 2025 | Chart: 2025 AI Index report Figure 5.2.4 Artificial Intelligence Index Report 2025 Function prediction 8.40% Protein structure prediction 7.60% Protein-drug interactions 3.00% Synthetic protein design 0.70% 0% 1% 2% 3% 4% 5% 6% 7% 8% AI-driven publications in the biological sciences (% of total) Table of Contents Chapter 5 Preview 295 aera hcraeseR Chapter 5: Science and Medicine 5.2 The Central Dogma Research and Publication Trends AI-Driven Protein Science Publications AI applications in protein science have gained significant new drugs from scratch that can target specific proteins. traction in academic research, as evidenced by an increase in Both of these tasks are crucial for drug discovery and drug AI-driven studies on PubMed and bioRxiv preprints over the development. Furthermore, AI-generated proteins with novel past year. These studies focus on several key areas. Protein functions are emerging, particularly in enzyme engineering structure prediction has become more accessible due to and therapeutic applications, marking a significant step advances in machine learning, providing deeper structural forward in synthetic protein design. Figure 5.2.5 illustrates insights. AI models now infer biochemical functions from raw the proportion of protein AI-driven research within biological sequence data with greater accuracy, enhancing function sciences in 2024. The most researched topic was function prediction. In addition, AI models are being developed prediction (8.4%), followed by protein structure prediction that can predict protein-drug interactions and even create (7.6%) and protein-drug interactions (3.0%) Proportion of AI-driven protein research in the biological sciences, 2024 Source: RAISE Health, 2025 | Chart: 2025 AI Index report Figure 5.2.5 Artificial Intelligence Index Report 2025 Chapter 5: Science and Medicine 5.2 The Central Dogma Image and Multimodal AI for Scientific Discovery Advances in cryo-electron microscopy, high-throughput fluorescence microscopy, and whole-slide imaging allow scientists to examine and analyze atomic, subcellular context and tissue-level structures with high precision to Fluorescence Electron Light reveal new insights into complex biological processes. 8 8 To achieve this, researchers interpret and contextualize image findings with existing scientific knowledge to link 7 observations to biological functions and disease relevance. 6 Given the rise of high-throughput microscopy, active research has increasingly focused on the intersection of 5 vision, vision-language, and, more recently, vision-omics 4 4 4 foundation models. The number of microscopy foundation 4 models has increased over time across various techniques 3 (Figure 5.2.6). Light-based models doubled from four to eight in 2024, and, while no electron or fluorescence 2 models were released in 2023, four models for each technique emerged in 2024. Overall, foundation models 1 for microscopy are increasing as more data is collected 0 0 0 and made publicly available. 2023 2024 Table of Contents Chapter 5 Preview 296 sledom noitadnuof fo rebmuN Number of foundation models per microscopy techniques, 2023–24 Source: RAISE Health, 2025 | Chart: 2025 AI Index report Figure 5.2.6 Artificial Intelligence Index Report 2025 Chapter 5: Science and Medicine 5.3 Clinical Care, Imaging 5.3 Clinical Care, Imaging Data: Sources, Types, and Needs AI in medical imaging is rapidly evolving, expanding into available histopathology cohorts rarely exceed 10,000 patient new data modalities, and addressing increasingly complex samples, with The Cancer Genome Atlas (TCGA) providing clinical questions. More than 80% of FDA-cleared machine one of the most comprehensive collections—comprising learning software targets the analysis of medical images. 11,125 patient samples with matched clinical annotations, Currently, AI is predominantly applied to two-dimensional genomic sequencing, and protein expression data across 32 (2D) data settings, where conventional image-processing cancer types. As a result, histopathology AI models are often architectures, such as convolutional neural networks (CNNs) trained on fewer than 1,000 patient samples, particularly and transformers, can be effectively utilized. However, despite when genomic or proteomic data serve as labels. Limited a number of successes in this field, many AI applications in training sets increase the risk of data overfitting and poor medical imaging rely on highly limited training datasets. generalization. In histopathology, for example, while staining patient biopsies Figure 5.3.1 illustrates the geographic distribution of U.S. for histological analysis is routine, only a small fraction of cohorts used to train deep learning algorithms. Most cohorts these samples is digitized and made publicly available. Even originate from California, Massachusetts, and New York, fewer datasets contain the necessary matched annotations or raising concerns about the limited scope of the datasets used omics data required for advanced classification tasks. Publicly to train these algorithms. US patient cohorts used to train clinical machine learning algorithms by state, 2015 19 Source: Kaushal et al., 2020 | Chart: 2025 AI Index report AK ME 0 0 VT NH MA 1 2 15 WA MT ND SD MN WI MI NY CT RI 0 0 0 0 1 1 1 14 2 0 OR ID WY NE IA IL IN OH PA NJ 0 0 0 0 0 0 1 1 5 0 CA NV UT CO KS MO KY WV DC MD DE 22 0 0 2 0 0 0 0 0 4 0 AZ NM OK AR TN VA NC 0 0 0 0 0 0 2 TX LA MS AL GA SC 1 0 0 0 0 0 HI FL 0 0 Figure 5.3.1 Table of Contents Chapter 5 Preview 297 Artificial Intelligence Index Report 2025 These data limitations are more pronounced for three- Training accurate AI models requires large datasets: CNNs dimensional (3D) medical imaging. While AI has traditionally have succeeded with around 10,000 labeled images , but focused on 2D modalities such as chest X-rays, histopathology transformers need orders of magnitude more data. MIMIC- slides, and fundus photography, recent advancements have CXR (377,000 images) and CheXpert Plus (around 226,000 expanded its application to 3D imaging modalities, including frontal-view radiographs with aligned radiology reports and computed tomography (CT), magnetic resonance imaging patient metadata) are important resources but remain smaller (MRI), and 3D histopathology analysis. Three-dimensional than ImageNet (around 14 million images). Data completeness analysis provides richer data, enabling AI models to learn and bias issues remain key challenges. patterns from volumetric structures and complex surfaces that may not be apparent in 2D slices. Although promising Figure 5.3.2 illustrates the token volume in text and image approaches have been developed for the use of AI to analyze datasets used to train various leading medical language and 3D medical images, similar data limitations and needs imaging models, in comparison to various all-purpose text persist. Publicly available 3D datasets remain limited, with and image models. GatorTron, a large clinical LLM designed UK Biobank (around 100,000 MRI scans) and TCIA (around to extract patient information from unstructured electronic 50,000 studies) among the largest. Although 3D samples health records, was trained on 82 billion tokens. In contrast, are routinely collected in histopathology, 3D imaging is Llama 3 was trained on 15 trillion tokens—nearly 182 times not standard practice, resulting in an absence of publicly more. On the imaging side, RadImageNet, an open radiologic available 3D histopathology datasets. Standardization deep learning research dataset, contains 16 million image- challenges persist due to acquisition variability in pathology. equivalent tokens, while DALL-E, an early OpenAI image Differences in instrument settings, staining techniques, and generator, was trained on approximately 6 billion—roughly institutional practices introduce batch effects, which are 375 times more. further exacerbated by limited training datasets. Medical Nonmedical 20T 6B 10T 1B 1T 100M 100B 80B 20M GatorTron Llama 3 RadImageNet DALL-E Table of Contents Chapter 5 Preview 298 )elacs gol( snekot fo rebmuN )elacs gol( snekot fo rebmuN Chapter 5: Science and Medicine 5.3 Clinical Care, Imaging Training dataset token volumes: medical vs. nonmedical language and imaging models Source: RAISE Health, 2025 | Chart: 2025 AI Index report Figure 5.3.2 Artificial Intelligence Index Report 2025 Chapter 5: Science and Medicine 5.3 Clinical Care, Imaging Longitudinal imaging is important for modeling disease To train and validate robust medical imaging AI models, progression but remains underrepresented. ADNI (around larger, more comprehensive, and multicohort collections of 2,000 participants over 15-plus years) exemplifies such training data are required. By increasing the availability of efforts, but scalable multimodal longitudinal datasets are rare. high-quality, labeled training data, models can be expected Addressing these gaps requires privacy-preserving data- to achieve improved performance. Additionally, better sharing (e.g., federated learning), synthetic data generation, validation practices will bolster confidence in these models, and improved annotation strategies. facilitating their transition into clinical practice. Advanced Modeling Approaches Figure 5.3.3 presents leading clinical imaging modeling approaches, notable releases per approach, and key challenges associated with each. Imaging modeling approaches and notable AI models Source: AI Index, 2025 Modeling approach Notable releases Advantages Challenges Diffusion models 1. RoentGen (2022) Generate synthetic medical images for Dataset biases, hallucinated enhanced training, privacy, and pathol- artifacts, diagnostic uncer- 2. RNA-CDM (2023) ogy-specific augmentation. Outperform tainty. 3. XReal (2024) GANs in stability and diversity. Large vision-language 1. CheXagent (2024) Integrate medical images with text for Data scarcity, generalization models (LVLMs) improved diagnosis, segmentation, to low-resource settings, 2. Merlin (2024) and report automation. LVLMs extend computational demands. 3. Med-Gemini (2024) multimodal capabilities. 4. PathChat (2024) 5. TITAN (2024) 6. PRISM (2025) 7. BiomedParse (2025) 2D vision-only foundation 1. CTransPath (2022) Pan-cancer detection, biomarker Domain generalization, models prediction, and image segmentation. cross-modal adaptability. 2. Virchow (2024) Reduce annotation burdens. 3. UNI (2024) 4. MedSAM(2024) Multiscale/slide-level 1. HIPT (2022) Enhance whole-slide imaging analysis Scalability, computational models using hierarchical transformers and efficiency, dataset variability. 2. MEGT (2023) graph-based models for spatial relation- 3. MG-Trans (2023) ships. Improve diagnostic fidelity and 4. HIGT (2023) interpretability. 5. Prov-GigaPath (2024) Figure 5.3.3 Table of Contents Chapter 5 Preview 299 Artificial Intelligence Index Report 2025 Chapter 5: Science and Medicine 5.3 Clinical Care, Imaging In recent years, there has been a notable rise in foundation years, the number of medical imaging foundation models has models being used for medical imaging purposes. Figure 5.3.4 risen sharply, with a particularly high concentration of newly categorizes notable models by medical discipline. In recent launched pathology models. Medical disciplines and notable AI models Source: AI Index, 2025 Discipline Notable releases Echocardiology 1. EchoCLIP (2024) Oncology 1. MUSK (2025) Ophthalmology 1. RETFound (2023) 2. VisionFM (2024) Pathology 1. CTransPath (2022) 2. CHIEF (2024) 3. Prov-GigaPath (2024) 4. PathChat (2024) 5. TITAN (2024) 6. Virchow (2024) 7. UNI (2024) Radiology 1. RoentGen (2022) 2. CheXagent (2024) 3. Merlin (2024) 4. PRISM (2025) Figure 5.3.4 Table of Contents Chapter 5 Preview 300 Artificial Intelligence Index Report 2025 100% 80% 60% 40% 20% 0% 2021 2022 2023 2024 Table of Contents Chapter 5 Preview 301 ycarucca tset AQdeM Chapter 5: Science and Medicine 5.4 Clinical Care, Non-Imaging 5.4 Clinical Care, Non-Imaging Clinical Knowledge The following section examines the performance of LLMs and doctors. AI performance on the MedQA benchmark has recent AI models on key medical knowledge benchmarks. advanced significantly. A team of Microsoft and OpenAI researchers recently tested o1, which achieved a new state- MedQA of-the-art score of 96.0%—a substantial 5.8 percentage Evaluating the clinical knowledge of AI models involves point improvement over the record set in 2023 (Figure determining the extent of their medical expertise, particularly 5.4.1). Since late 2022, performance on the benchmark has knowledge applicable in a clinical setting. increased by 28.4 percentage points. As with other general knowledge benchmarks discussed in Chapter 2, MedQA may Introduced in 2020, MedQA is a comprehensive dataset be approaching a saturation point, indicating the need for derived from professional medical board exams, featuring more challenging evaluations. over 60,000 clinical questions designed to challenge MedQA: test accuracy Source: RAISE Health, 2025 | Chart: 2025 AI Index report 96.00%, No ne-tuning 91.10%, Intensive ne-tuning Figure 5.4.1 Artificial Intelligence Index Report 2025 Some researchers argue that evaluating medical LLMs requires more comprehensive benchmarks than MedQA, those that span a broader range of medical domains. Relying solely on standard medical QA benchmarks like MedQA—while valuable—may overlook the complexities of real-world clinical applications. Alternatively, using multiple benchmarks can offer greater clinical relevance and a more robust assessment of model performance. This year, new research from UC Santa Cruz, the University of Edinburgh, and the National Institutes of Health has taken a more expansive approach to testing AI medical systems. The study evaluated five leading large language models, including the newly developed o1, which features chain-of- thought reasoning. The other models assessed were GPT-3.5, Llama 3-8B, GPT-4, and Meditron-70B—the last of which is a specialized medical model. These models were tested on a diverse set of medical benchmarks covering various tasks, including concept recognition, text summarization, knowledge-based QA, clinical decision support, and medical calculations. Figure 5.4.2 presents the average performance of these five LLMs across 19 medical datasets. The findings indicate that clinical knowledge performance in LLMs is improving, particularly for newer models like o1 equipped with real-time reasoning capabilities. However, persistent challenges remain, including issues with hallucinations and inconsistent multilingual performance. Previous research, cited in last year’s AI Index, demonstrated that prompting techniques like Medprompt can significantly enhance LLM performance on medical benchmarks without additional fine-tuning. OpenAI’s recently released o1 model incorporates some of these insights by employing runtime reasoning before generating final responses. Researchers found that o1 outperforms the GPT-4 series with Medprompt, even without specialized prompting techniques. However, their analysis also highlights the accuracy-cost trade-off associated with o1. While it achieves a 5.8 percentage point higher score than GPT-4 Turbo with Medprompt, it is approximately 1.5 times more Table of Contents Chapter 5 Preview 302 5.3-TPG B07-nortideM 4-TPG B8-3amalL 1o 100% 80% 60% 40% 20% 0% 2022 2023 2024 ycarucca egarevA Chapter 5: Science and Medicine 5.4 Clinical Care, Non-Imaging Highlight: AI Doctors and Cost-Efficiency Considerations Performance of select LLMs on medical datasets Source: Xie et al., 2024 | Chart: 2025 AI Index report Figure 5.4.2 Enhanced pareto frontier: accuracy vs. cost Source: Nori et al., 2024 Figure 5.4.3 expensive. Figure 5.4.3 illustrates the cost versus accuracy trade-off on the MedQA benchmark. This trade-off highlights a key consideration for medical professionals deploying AI in clinical settings: the need to balance performance gains with computational costs. Artificial Intelligence Index Report 2025 Evaluation of LLMs for Healthcare Performance Overview There has been an explosion in interest in the evaluation of language model performance on healthcare tasks. A PubMed search for “large language model” returned 1,566 papers starting in 2019 with 1,210 published in 2024 alone (Figure 5.4.4). 1,210 1,200 1,000 800 600 400 353 200 1 0 0 2 0 2019 2020 2021 2022 2023 2024 Table of Contents Chapter 5 Preview 303 snoitacilbup fo rebmuN Chapter 5: Science and Medicine 5.4 Clinical Care, Non-Imaging Number of publications on large language models in PubMed, 2019–24 Source: RAISE Health, 2025 | Chart: 2025 AI Index report Figure 5.4.4 Artificial Intelligence Index Report 2025 Chapter 5: Science and Medicine 5.4 Clinical Care, Non-Imaging A systematic review in early 2024 identified over 500 papers 5.4.5). Most of the healthcare studies that evaluated the evaluating the performance of NLP on healthcare tasks performance of NLP systems focused on enhancing medical with a heavy emphasis on medical decision-making (Figure knowledge (419) and making diagnoses (178). Figure 5.4.54 4 The asterisks represent tasks in NLP and NLU. Table of Contents Chapter 5 Preview 304 Artificial Intelligence Index Report 2025 Highlight: LLMs Influence Diagnostic Reasoning A 2024 single-blind, randomized trial tested GPT-4 assistance against conventional resources in tackling complex clinical vignettes. The study involved 50 100 U.S.-licensed physicians and evaluated whether AI- 90 enhanced decision-making could improve diagnostic accuracy and efficiency. The results revealed no 80 significant improvement when physicians used GPT- 70 4 alongside traditional resources. In fact, physicians with AI assistance performed only slightly better (76%) 60 than those who relied solely on conventional tools 50 (74%). However, in a secondary analysis, GPT-4 alone outperformed both groups, achieving a 92% diagnostic 40 reasoning score, a 16-percentage-point increase over 30 physicians working without AI (Figure 5.4.6). Despite AI’s superior standalone performance, integrating it into 20 clinical workflows proved challenging. There was no clear 10 advantage in time efficiency, as case completion times 0 remained statistically unchanged across conditions. GPT-4 alone Physician + GPT-4 Physician + conventional resources only While purely autonomous AI outperformed physician- only efforts, simply giving doctors access to an LLM did not enhance their performance. This underscores a phenomenon seen in other AI-human collaborations: Bridging the gap between excellent model performance in isolation and effective synergy with clinicians requires rethinking workflows, user training, and interface design. Table of Contents Chapter 5 Preview 305 erocS Chapter 5: Science and Medicine 5.4 Clinical Care, Non-Imaging Diagnostic Reasoning With LLMs Diagnostic errors account for substantial patient harm, and many organizations are exploring AI as a tool to improve the diagnostic process. LLM performance in clinical diagnosis Source: Goh et al., 2024 | Chart: 2025 AI Index report Figure 5.4.6 Management Reasoning and Patient Care Decisions referred to as “management reasoning.” Researchers tested Beyond diagnosis, physicians must juggle treatment decisions, whether LLMs could improve these complex, context- risk-benefit trade-offs, and patient preferences—collectively dependent skills. Artificial Intelligence Index Report 2025 Highlight: GPT-4 Assistance on Patient Care Tasks A 2024–25 prospective, randomized, controlled trial evaluated the impact of GPT-4 assistance on complex clinical management decisions. The study involved 100 92 physicians, with half using GPT-4 alongside 90 standard resources and the other half relying solely on conventional references. Physicians assisted by GPT-4 80 outperformed the control group by approximately 6.5 70 percentage points (Figure 5.4.7). Interestingly, GPT-4 alone performed on par with GPT-4-assisted physicians, 60 suggesting that in certain well-defined scenarios, near- 50 autonomous AI-driven management support may be feasible. However, AI assistance came with a trade- 40 off, as physicians using GPT-4 spent slightly longer on 30 each scenario—a delay researchers attributed to deeper reflection and analysis. Generative AI can meaningfully 20 improve clinical decision-making, but its impact may be 10 qualitative rather than purely efficiency-driven. 0 GPT-4 alone Physicians + GPT-4 Physicians + conventional resources only Table of Contents Chapter 5 Preview 306 erocS Chapter 5: Science and Medicine 5.4 Clinical Care, Non-Imaging Impact of LLM assistance on clinical management Source: Goh et al., 2025 | Chart: 2025 AI Index report Figure 5.4.7 Artificial Intelligence Index Report 2025 Chapter 5: Science and Medicine 5.4 Clinical Care, Non-Imaging Ambient AI Scribes Clinical documentation has long been a source of clinician burden and burnout. Ambient scribe technology has rapidly evolved to integrate LLMs into the processing pipeline for physician-patient recordings. The first study, published in NEJM Catalyst, describes the launch of ambient AI scribe technology at Kaiser Permanente Northern California in late 2023. The technology was eventually adopted by thousands of clinicians before the end of the pilot (Figure 5.4.8). This was followed by a second study, published in JAMIA, that describes the pilot experience at Intermountain Health. Both studies were based on earlier versions of the technology that were not fully automated or integrated into the electronic health record (EHR). Source: Tierney et al., 2024 Figure 5.4.8 Table of Contents Chapter 5 Preview 307 Artificial Intelligence Index Report 2025 Researchers at Stanford conducted a two-part study on the approximately 30 seconds per note and reducing overall EHR use of ambient AI scribe technology, building on prior work time by about 20 minutes per day (Figure 5.4.9). Additionally, by testing a fully integrated, automated AI scribe system. physicians reported significant reductions in burden The study demonstrated improvements in both objective and burnout, with average decreases of 35% and 26%, measures, such as documentation time, and subjective respectively. These findings suggest that AI-powered scribe measures of physician experience. Adoption was strong, technology can meaningfully improve physician workflow with an average uptake of 55% among physicians. The AI and well-being, offering both time savings and relief from scribe provided notable efficiency gains, saving physicians administrative strain. 75 75 75 50 50 50 25 25 25 0 0 0 −25 −25 −25 −50 −50 −50 −75 −75 −75 −100 −100 −100 −125 −125 −125 −150 −150 −150 Table of Contents Chapter 5 Preview 308 )setunim( emit noitatnemucod yliad egareva ni egnahC )setunim( emit sruohretfa yliad egareva ni egnahC )setunim( emit RHE latot yliad egareva ni egnahC Chapter 5: Science and Medicine 5.4 Clinical Care, Non-Imaging Impact of AI Scribe on physician EHR usage Source: Ma et al., 2024 | Chart: 2025 AI Index report Figure 5.4.9 Investment in ambient scribe technology is reported to reach ambient listening technology in both outpatient and inpatient almost $300 million in 2024. While clinical documentation settings that will eventually support order placement, billing has been the starting point for the technology and the and coding, and real-time clinical decision support. evaluations performed to date, optimists envision ubiquitous Artificial Intelligence Index Report 2025 223 160 129 114 80 64 26 18 1 0 1 1 0 0 1 0 0 1 1 0 0 5 0 2 2 3 3 6 6 Table of Contents Chapter 5 Preview 309 5991 6991 7991 8991 9991 0002 1002 2002 3002 4002 5002 6002 7002 8002 9002 0102 1102 2102 3102 4102 5102 6102 7102 8102 9102 0202 1202 2202 3202 200 150 100 50 0 secived lacidem IA fo rebmuN Chapter 5: Science and Medicine 5.4 Clinical Care, Non-Imaging Deployment, Implementation, Deimplementation FDA Authorization of AI-Enabled Medical Devices The deployment of AI in clinical settings has grown The FDA authorized its first AI-enabled medical device in exponentially over the past decade, highlighted by the 1995. For the next two decades, annual approvals remained dramatic increase in the number of AI-enabled medical in the single digits. In 2015 alone, six AI medical devices were devices authorized by the U.S. Food and Drug Administration approved. Since then, the number of yearly approvals has (FDA). surged, peaking at 223 in 2023 (Figure 5.4.10). Number of AI medical devices approved by the FDA, 1995–2023 Source: FDA, 2024 | Chart: 2025 AI Index report Figure 5.4.10 Successful Use Cases: Stanford Health Care Reliable, Measurable) framework. Among the six AI use In practice, transitioning AI models into real-world use cases assessed, two have been successfully implemented: requires a framework that ensures fairness, utility, and (1) screening for peripheral arterial disease (PAD) and (2) reliability. Stanford Health Care has led the way by evaluating improving documentation and coding for inpatient care. This and implementing AI tools using its FURM (Fair, Useful, section details screening for peripheral arterial disease. Artificial Intelligence Index Report 2025 Chapter 5: Science and Medicine 5.4 Clinical Care, Non-Imaging Screening for Peripheral Arterial Disease Peripheral arterial disease (PAD) is a chronic vascular severe complications. By identifying high-risk patients, the condition that often goes undiagnosed in its early stages, model also helps optimize resource allocation, ensuring that leading to severe complications such as critical limb ischemia those most in need receive immediate follow-up and care. and amputation. To improve early detection and intervention, Stanford Health Care developed and implemented an AI- To integrate seamlessly into clinical workflows, the AI tool enabled PAD classification model designed to enhance was designed to automatically assess PAD risk and flag screening and optimize patient care. high-risk individuals for further evaluation. If the condition is confirmed, the patient is referred for a vascular consultation. The primary goal of the PAD screening tool is to facilitate Figure 5.4.11 illustrates the proposed model and workflow earlier diagnosis in primary care populations, allowing for details for integrating PAD screening into clinical workflows, medical or surgical intervention before the disease leads to including risk assessment, referrals, and patient follow-up. Proposed model and workflow for integrating PAD screening into clinical practice Source: Callahan et al., 2024 Figure 5.4.11 Following a successful pilot phase, the PAD screening tool independently without external funding. By increasing advanced to Stage 2 and was fully implemented at Stanford early PAD detection, reducing the likelihood of severe Health Care. The model is expected to impact approximately complications, and improving patient outcomes, this AI- 1,400 patients annually. Beyond its clinical benefits, the driven approach is reshaping the standard of care for PAD program has demonstrated financial sustainability, operating management. Table of Contents Chapter 5 Preview 310 Artificial Intelligence Index Report 2025 Social Determinants of Health The integration of LLMs and AI-based clinical decision Extracting SDoH From EHR and Clinical Notes support (CDS) systems is transforming medicine, though Fine-tuned multilabel classifiers (Flan-T5 XL) outperformed adoption varies by specialty. While some embrace LLMs, ChatGPT-family models in identifying SDoH in clinical notes others remain cautious. This review explores research and and were less sensitive to demographic descriptors. They also innovations, emphasizing the role of a strong evidence base. exhibited lower bias, with reduced discrepancies when race, A key aspect is addressing social determinants of health ethnicity, or gender was introduced. Figure 5.4.12 illustrates (SDoH), such as socioeconomic status and environment. In the performance of various models on SDoH identification 2024, AI advancements targeted SDoH, improving patient tasks in a radiotherapy test set. Newer, larger models like care and health equity. Flan-T5-XXL, augmented with synthetic and gold data (SDoH-labeled sentences), showed superior performance. As models have scaled and incorporated more data over time, their ability to identify SDoH has improved. 0.70 0.68 0.65 0.65 0.60 0.53 0.49 0.47 0.42 0.36 Table of Contents Chapter 5 Preview 311 esab-TREB dna dlog htiw atad citehtnys esab-TREB atad dlog htiw esab-5T-nalF atad dlog htiw esab-5T-nalF dna dlog htiw atad citehtnys egral-5T-nalF atad dlog htiw egral-5T-nalF dna dlog htiw atad citehtnys LX-5T-nalF atad dlog htiw LXX-5T-nalF atad dlog htiw LX-5T-nalF dna dlog htiw atad citehtnys LXX-5T-nalF dna dlog htiw atad citehtnys 1.00 0.80 0.60 0.40 0.20 0.00 2018 2020 2022 erocs 1F-orcaM Chapter 5: Science and Medicine 5.4 Clinical Care, Non-Imaging Model performance on in-domain RT test dataset (any SDoH) Source: RAISE Health, 2025 | Chart: 2025 AI Index report Figure 5.4.12 Extracting SDoH from EHRs helps healthcare providers documentation, resource allocation, and health equity while address social needs like housing instability or food insecurity. emphasizing the need for bias mitigation and robust synthetic These findings highlight LLMs’ potential to enhance SDoH data methods. Artificial Intelligence Index Report 2025 Chapter 5: Science and Medicine 5.4 Clinical Care, Non-Imaging AI Adoption Across Medical Fields and the Integration of SDoH Figure 5.4.13 highlights various medical fields and illustrates how AI integrates social determinants of health in each. Field Recent research Description of integration Oncology Istasy et al., 2024 In cancer care, AI-driven tools have been developed to consider SDoH in treatment planning. By incorporating factors such as a patient’s access to care and support systems, these tools assist oncologists in creating personalized treatment plans that are both effective and feasible for patients. Cardiology Snowdon et al., 2023 AI models in cardiology have been enhanced to include SDoH, improving the accuracy of risk assessments for conditions like hypertension and heart failure. This inclusion allows for more Quer et al., 2024 comprehensive patient evaluations and tailored management strategies. Psychiatry Stade et al., 2024 LLMs have been applied to analyze community-level SDoH data, aiding in the allocation of mental health resources. By identifying areas with high social risk factors, healthcare systems can prioritize interventions and support services in communities with the greatest need. Figure 5.4.13 Synthetic Data Synthetic data is revolutionizing healthcare by enhancing clinical risk prediction. Using ADSGAN, PATEGAN, and privacy-preserving analytics, clinical modeling, and AI DPGAN, researchers modeled lung cancer risk in ever- training. It optimizes workflows, simulates rare cases, smokers from the UK Biobank.5 The figure below compares and supports AI-driven innovations. However, scalability PCA eigenvalues, showing how ADSGAN and PATEGAN concerns, as noted in the first chapter of this year’s AI Index, closely match real data distributions, enabling reliable call for cautious adoption. clustering and feature selection (Figure 5.4.14). These findings demonstrate that synthetic datasets can preserve statistical Clinical Risk Prediction fidelity, support exploratory analysis, and develop predictive A recent study validated synthetic data for privacy-preserving models without real and identifiable patient data. Principal component analysis Source: Qian et al., 2024 Figure 5.4.14 5 An ever-smoker is someone who has smoked at least 100 cigarettes in their lifetime. Table of Contents Chapter 5 Preview 312 Artificial Intelligence Index Report 2025 Chapter 5: Science and Medicine 5.4 Clinical Care, Non-Imaging Drug Discovery Percolation threshold prediction and validation A recent Nature study introduced a based on AI-generated synthetic structures Source: Hornick et al., 2024 generative AI approach for in silico formulation optimization and particle engineering in drug development. Using an image generator guided by critical quality attributes, it creates digital formulations for analysis without extensive physical testing. The study validated this method by predicting the percolation threshold of microcrystalline cellulose (MCC) in oral tablets. Figure 5.4.15 compares the tortuosity calculations of real tablet volumes (green squares) with AI-synthesized Figure 5.4.15 volumes (red circles).6 Their close alignment suggests that synthetic data holds promise for modeling drug properties and improving AI-driven drug discovery. Data Generation Platforms Areas under the curve for evaluating synthetic heart disease datasets Platforms are necessary to demonstrate, Source: Rashidi et al., 2024 standardize, and automate the creation of synthetic data. Recently published research has demonstrated that large-scale synthetic data generation and validation is not only feasible but also capable of significantly enhancing AI applications in medicine with their synthetic tabular neural generator (STNG) framework. Figure 5.4.16 compares the area-under-the-curve values for real and synthetic heart disease datasets to evaluate the effectiveness of different synthetic data generation methods. In many cases, there is a fairly close overlap between the real datasets and the synthetic datasets, showing the Figure 5.4.16 ability of synthetic data to model complex health conditions closely. Advancements in synthetic data generation methodologies can improve data fidelity while minimizing privacy risks. 6 Tortuosity is a measure of how convoluted or twisted a path is compared to the shortest possible straight-line distance between two points. Table of Contents Chapter 5 Preview 313 Artificial Intelligence Index Report 2025 Chapter 5: Science and Medicine 5.4 Clinical Care, Non-Imaging Electronic Health Record System AI integration in electronic health records (EHRs) can ease A 2023 American Hospital Association IT survey found that healthcare burdens by streamlining administration, enhancing most hospitals using ML or predictive models in their EHRs clinical decision support, and improving patient care. With relied on a dominant vendor for inpatient care (Figure 5.4.17). major vendors—Epic, Oracle Health (formerly Cerner), Adoption was highest with Epic, Cerner, and Meditech. While Meditech, and TruBridge (formerly CPSI)—dominating the Epic, Cerner, and CPSI hospitals primarily used vendor- market, their AI tools can be widely adopted within their developed models, Meditech and others more often adopted networks. As of 2021, EHR adoption had approached 90% for third-party or in-house solutions (Figure 5.4.18). any system and 80% for certified EHR systems. Machine learning (ML) Other non-ML predictive model Neither/do not know 710 700 600 500 450 400 295 300 244 200 190 190 183 191 160 144 100 60 31 22 35 4 8 5 8 0 Epic Cerner Meditech CPSI/Evident Altera Other Vendor Figure 5.4.17 Table of Contents Chapter 5 Preview 314 slatipsoh fo rebmuN Predictive model use across primary inpatient EHR vendor Source: AHA survey, 2024 | Chart: 2025 AI Index report Artificial Intelligence Index Report 2025 In-house EHR developer A third-party developer Self-developed Public domain Do not know (ML development) 100% 95% 84% 81% 80% 75% 71% 68% 60% 53% 52% 54% 46% 46% 42% 41% 40% 33% 33% 30% 23% 20% 17% 8% 8% 9% 7% 5% 4% 0% 1% 2% 1% 0% 0% 0% Epic Cerner Meditech CPSI/Evident Altera Other Vendor AI integration into EHRs could streamline clinical workflows IT infrastructure, and EHR functionality constraints—key and enhance provider and patient experiences. However, it enablers of AI-driven healthcare. Additionally, it is important remains unclear whether AI-enabled health IT will benefit to assess whether AI tools are equitably developed for both underserved communities, which often struggle with basic and comprehensive EHR systems, as many resource- technological adoption. Rural areas, for example, face limited settings still rely on the former. barriers like limited broadband access, weak healthcare Table of Contents Chapter 5 Preview 315 slatipsoh fo % Chapter 5: Science and Medicine 5.4 Clinical Care, Non-Imaging Developer of predictive models across EHR vendor Source: AHA survey, 2024 | Chart: 2025 AI Index report Figure 5.4.18 Artificial Intelligence Index Report 2025 Chapter 5: Science and Medicine 5.4 Clinical Care, Non-Imaging Clinical Decision Support AI has transformed how healthcare providers diagnose, the COVID-19 pandemic—to proactive, data-driven clinical predict, and manage diseases with an increasing focus on decision-making with clinical trials increasing over the years. rigorous evaluation of AI-based systems in clinical trials. The number of clinical trials that have included mentions of The evolution of AI in clinical decision support (CDS) artificial intelligence is steadily rising (Figure 5.4.19). reflects a shift from reactive interventions—e.g., during 537 500 448 396 400 349 300 249 200 111 100 69 25 5 9 10 0 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 Figure 5.4.19 Table of Contents Chapter 5 Preview 316 slairt lacinilc fo rebmuN Number of clinical trials that have included mentions of AI, 2014–24 Source: RAISE Health, 2025 | Chart: 2025 AI Index report Artificial Intelligence Index Report 2025 Chapter 5: Science and Medicine 5.4 Clinical Care, Non-Imaging The COVID-19 pandemic accelerated AI adoption in triage, accuracy in gastrointestinal procedures. By 2023, AI in CDS resource allocation, and outcome prediction, showcasing the extended to medication safety and workflow optimization, as technology’s potential in real-time CDS. Post-pandemic, AI seen in Preventing Medication Dispensing Errors in Pharmacy expanded beyond emergency response to managing chronic Practice, which used AI to detect real-time medication errors. disease, optimizing procedures, and streamlining workflows. Globally, AI-driven clinical trials have sharply risen, with China Trials like the CERTAIN Study demonstrated how AI-driven (105 trials), the U.S. (97), and Italy (42) leading in 2024 (Figure real-time procedural support could improve diagnostic 5.4.20). 105 2024 100 97 2023 2022 2021 80 80 74 71 71 63 60 56 42 40 36 30 30 31 27 25 28 24 26 22 19 20 20 10 9 15 13 8 14 15 16 12 17 16 11 15 16 17 11 16 6 5 0 Germany Canada France Taiwan Spain United Kingdom Turkey Italy United States China Figure 5.4.20 Table of Contents Chapter 5 Preview 317 slairt lacinilc fo rebmuN Number of clinical trials that have included mentions of AI by select geographic areas, 2021–24 Source: RAISE Health, 2025 | Chart: 2025 AI Index report Artificial Intelligence Index Report 2025 1,031 1,000 800 674 600 523 397 400 288 200 0 2020 2021 2022 2023 2024 Table of Contents Chapter 5 Preview 318 snoitacilbup scihte IA lacidem fo rebmuN Chapter 5: Science and Medicine 5.5 Ethical Considerations The increasing integration of AI in medical research and clinical care as discussed in previous sections brings both promises and challenges. AI systems lean heavily on large amounts of data for training. The collection, use, and sharing of this data—especially in high-stakes domains such as healthcare—can raise various ethical concerns. 5.5 Ethical Considerations Meta Review For this section, the AI Index conducted a meta review of thousands of medical ethics studies to glean insights on the state of the field. The team’s methodology is highlighted in Figure 5.5.1. Attention to the ethical issues in medical AI has increased in each of the past five years. The number of publications related to ethics and medical AI increased fourfold from 2020 to 2024 (Figure 5.5.2). Figure 5.5.1 Number of medical AI ethics publications, 2020–24 Source: RAISE Health, 2025 | Chart: 2025 AI Index report Figure 5.5.2 Artificial Intelligence Index Report 2025 The focus of AI applications in medical ethics literature has evolved over time. Figure 5.5.3 illustrates the ethical issues discussed in AI medical papers from 2020 to 2024. In 2024, bias and privacy were the most frequently cited concerns, followed by equity. In contrast, privacy was a more prominent topic than bias in 2020, but this trend has since shifted. 2024 2023 2022 2021 2020 30% 25% 20% 15% 10% 5% 0% Bias Privacy Equity Transparency Trust Security Accessibility Stakeholders Fairness Safety Ethical concern Table of Contents Chapter 5 Preview 319 snoitacilbup scihte IA lacidem fo % Top 10 ethical concerns discussed in medical AI ethics publications, 2020–24 Source: RAISE Health, 2025 | Chart: 2025 AI Index report 2024 2023 2022 2021 2020 90 86 80 70 60 50 42 40 30 20 9 10 5 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 2 0 0 0 1 3 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 OpenAI GPT Series OpenAI Vision Google Meta Anthropic Mistral Cohere xAI (GPT-3, ChatGPT, (DALL-E, SORA) (LaMDA, PaLM, (BART, OPT, (Claude) (Grok) GPT-3.5, GPT-4, Gemini) LLaMA) GPT-4-Turbo) AI tool snoitacilbup scihte IA lacidem fo rebmuN Chapter 5: Science and Medicine 5.5 Ethical Considerations Figure 5.5.3 In terms of AI tools, much attention has been paid in medical ethics literature to OpenAI’s GPT series (e.g., ChatGPT) (Figure 5.5.4). This reflects an expanding interest in large-language models over the past few years. AI tools discussed in medical AI ethics publications, 2020–24 Source: RAISE Health, 2025 | Chart: 2025 AI Index report Figure 5.5.4 Artificial Intelligence Index Report 2025 Chapter 5: Science and Medicine 5.5 Ethical Considerations Figure 5.5.5 and Figure 5.5.6 show the number and total 337 in 2024 (Figure 5.5.5). Similarly, total funding soared from funding of NIH grants for medical AI ethics projects by fiscal $16 million in 2023 to $276 million in 2024—an almost 17-fold year. The number of grants skyrocketed from 25 in 2023 to increase in just one year. 350 337 300 250 200 150 100 50 25 2 3 7 0 2020 2021 2022 2023 2024 Fiscal year Table of Contents Chapter 5 Preview 320 stnarg HIN fo rebmuN Number of NIH grants for medical AI ethics by scal year, 2020–24 Source: RAISE Health, 2025 | Chart: 2025 AI Index report 300 276.00 250 200 150 100 50 19.20 16.30 2.50 1.70 0 2020 2021 2022 2023 2024 Fiscal year )srallod SU fo snoillim ni( gnidnuf tnarg HIN NIH grant funding for medical AI ethics by scal year, 2020–24 Source: RAISE Health, 2025 | Chart: 2025 AI Index report Figure 5.5.5 Figure 5.5.6 Artificial Intelligence Index Report 2025 Chapter 5: Science and Medicine 5.6 AI Foundation Models in Science This year, dozens of foundation models have been developed across various scientific fields. Some are refined large language models, adapted for specific domains using relevant publications; others are trained from scratch with specialized data, such as time series or weather data. These foundation models are then fine-tuned for targeted scientific tasks or applications. 5.6 AI Foundation Models in Science Highlight: Notable Model Releases AI has driven significant progress in other scientific analysis represents an initial effort by the AI Index, which domains, including physics, chemistry, and geosciences. aims to expand and deepen its coverage of AI-driven The table below highlights some of the most notable scientific progress across a broader range of disciplines in recent launches in these areas, alongside newly released the future. resources that further track these developments. This Date Name Domain Significance Image Feb 6, 2024 CrystalLLM Materials Researchers fine-tuned LLaMA-2 70B on science text-encoded atomistic data to generate stable materials, achieving nearly double the metastability rate of a leading diffusion model (49% vs. 28%) while maintaining physical plausibility. The approach enables flexible applications like unconditional generation, structure infilling, and text-guided design, with model scale enhancing symmetry Figure 5.6.1 awareness. Source: Gruver et al., 2024 Feb 14, 2024 LlaSMol Chemistry To address LLMs’ poor performance on chemistry tasks, researchers introduce SMolInstruct, a high-quality dataset with over 3 million samples across 14 tasks; and LlaSMol, a set of models fine-tuned on it. Among them, the Mistral-based Figure 5.6.2 LlaSMol outperforms GPT-4 and Claude Source: Yu et al., 2024 3 Opus by a wide margin, approaching task-specific model performance while tuning just 0.58% of parameters, demonstrating the power of domain- specific instruction tuning. Table of Contents Chapter 5 Preview 321 Artificial Intelligence Index Report 2025 Chapter 5: Science and Medicine 5.6 AI Foundation Models in Science Highlight: Notable Model Releases (cont’d) Apr 23, 2024 ORBIT Earth science Oak Ridge National Lab introduced ORBIT, a 113B-parameter vision transformer and the largest AI model ever built for climate science—1,000 times larger than prior models. Trained using a novel parallelism technique and tested on the Frontier supercomputer, ORBIT achieved up to 1.6 exaFLOPS of sustained performance. This breakthrough sets a new bar for AI- driven Earth system prediction. Figure 5.6.3 Source: Wang et al., 2024 May 20, 2024 Aurora Earth science Aurora is a large-scale foundation model trained on over a million hours of Earth system data, delivering state-of-the-art forecasts for air quality, ocean waves, cyclone tracks, and high-resolution weather. It outperforms traditional systems while operating at a fraction of the computational cost, and can be fine-tuned across domains with minimal resources—marking a major step toward accessible, AI-driven Earth system Figure 5.6.4 forecasting. Source: Bodnar et al., 2024 Jul 22, 2024 NeuralGCM Weather This study introduces NeuralGCM, forecasting a hybrid model that combines a differentiable, physics-based solver with machine learning components to simulate both weather and climate. It matches or exceeds leading ML and physics-based models in short- and Figure 5.6.5 medium-term forecasts, accurately Source: Kochkov et al., 2024 tracks climate metrics over decades, and captures complex phenomena like tropical cyclones—all while offering massive computational savings. Table of Contents Chapter 5 Preview 322 Artificial Intelligence Index Report 2025 Chapter 5: Science and Medicine 5.6 AI Foundation Models in Science Highlight: Notable Model Releases (cont’d) Aug 18, 2024 PhysBERT Physics Physics texts are notoriously difficult for NLP due to their specialized language and complex concepts. PhysBERT, the first physics-specific, text-embedding model, addresses this by outperforming general-purpose models on physics- specific tasks. Trained on 1.2 million arXiv Figure 5.6.6 papers and fine-tuned with supervised Source: Hellert et al., 2024 data, it significantly boosts performance in information retrieval and subdomain fine-tuning. Sep 16, 2024 FireSat Fire Google’s FireSat is a satellite-based prediction wildfire detection system that uses AI to identify fires as small as 5x5 meters within 20 minutes of ignition by analyzing real-time imagery and environmental data. Developed in partnership with Earth Fire Alliance and Muon Space, it not only enhances Figure 5.6.7 Source: Google, 2024 disaster response but also advances global wildfire research. Dec 4, 2024 GenCast Weather Google DeepMind’s GenCast is an AI- prediction powered weather model that delivers highly accurate 15-day forecasts using a diffusion-based approach, outperforming traditional systems like the ENS on nearly all metrics. It generates forecasts in minutes instead of hours and has broad applications in disaster response, Figure 5.6.8 Source: Google, 2024 renewable energy, and agriculture. Dec 9, 2024 AlphaQubit Quantum In late 2024, Google DeepMind and computing Google Quantum AI released AlphaQubit, an AI-based decoder with state-of-the-art quantum error detection. Soon after, they introduced Willow, the first quantum chip to achieve exponential error suppression and correction below the surface code threshold—a major milestone in the field. Willow also completed a benchmark task in under five minutes that would take the fastest supercomputer over 10 septillion years, longer than the age of the known Figure 5.6.9 Source: Google, 2024 universe. Table of Contents Chapter 5 Preview 323 Artificial Intelligence Index Report 2025 CHAPTER 6: Policy and Governance Artificial Intelligence Index Report 2025 Chapter 6: Policy and Governance Overview 325 Chapter Highlights 326 6.1 Major Global AI Policy News in 2024 327 6.2 AI and Policymaking 336 Global Legislative Records on AI 336 Overview 336 By Geographic Area 337 Highlight: A Closer Look at Global AI Legislation 338 US Legislative Records 339 Federal Level 339 State Level 340 Highlight: A Closer Look at State-Level AI Legislation 342 Highlight: Anti-deepfake Policymaking 343 Global AI Mentions 345 Overview 345 US Committee Mentions 348 US Regulations 349 Overview 349 By Agency 349 Highlight: A Closer Look at US Federal Regulations 351 6.3 Public Investment in AI 352 Total AI Public Investments 353 Spending Across Agencies and Sectors 360 Highlight: AI Grant Spending in the US 362 ACCESS THE PUBLIC DATA Table of Contents 325 AArrttiifificciiaall IInntteelllliiggeennccee IInnddeexx RReeppoorrtt 22002255 CHAPTER 6: Policy and Governance Overview AI’s advancing capabilities have captured policymakers’ attention, leading to an increase in AI-related policies worldwide. In recent years, nations and political bodies, including the United States and the European Union, have introduced significant regulations. More recently, many governments have announced major investments in AI infrastructure. This wave of policymaking reflects a growing recognition of the need to both regulate AI and harness its transformative potential. This chapter explores global AI governance, starting with a timeline of key AI policymaking events in 2024. It then examines global and U.S. legislative efforts, analyzes AI-related mentions in legislative discussions, and reviews how U.S. regulatory agencies have approached AI. The chapter concludes with an analysis of public investment in AI in the U.S., with most data sourced independently by the AI Index. Table of Contents Chapter 6 Preview 326 AArrttiifificciiaall IInntteelllliiggeennccee IInnddeexx RReeppoorrtt 22002255 CHAPTER 6: Policy and Governance Chapter Highlights 1. U.S. states are leading the way on AI legislation amid slow progress at the federal level. In 2016, only one state-level AI-related law was passed, increasing to 49 by 2023. In the past year alone, that number more than doubled to 131. While proposed AI bills at the federal level have also increased, the number passed remains low. 2. Governments across the world invest in AI infrastructure. Canada announced a $2.4 billion AI infrastructure package, while China launched a $47.5 billion fund to boost semiconductor production. France committed €109 billion to AI infrastructure, India pledged $1.25 billion, and Saudi Arabia’s Project Transcendence represents a $100 billion AI investment initiative. 3. Across the world, mentions of AI in legislative proceedings keep rising. Across 75 major countries, AI mentions in legislative proceedings increased by 21.3% in 2024, rising to 1,889 from 1,557 in 2023. Since 2016, the total number of AI mentions has grown more than ninefold. 4. AI safety institutes expand and coordinate across the globe. In 2024, countries worldwide launched international AI safety institutes. The first emerged in November 2023 in the U.S. and the U.K. following the inaugural AI Safety Summit. At the AI Seoul Summit in May 2024, additional institutes were pledged in Japan, France, Germany, Italy, Singapore, South Korea, Australia, Canada, and the European Union. 5. The number of U.S. AI-related federal regulations skyrockets. In 2024, 59 AI-related regulations were introduced—more than double the 25 recorded in 2023. These regulations came from 42 unique agencies, twice the 21 agencies that issued them in 2023. 6. U.S. states expand deepfake regulations. Before 2024, only five states—California, Michigan, Washington, Texas, and Minnesota—had enacted laws regulating deepfakes in elections. In 2024, 15 more states, including Oregon, New Mexico, and New York, introduced similar measures. Additionally, by 2024, 24 states had passed regulations targeting deepfakes. Table of Contents Chapter 6 Preview 327 Artificial Intelligence Index Report 2025 Chapter 6: Policy and Governance 6.1 Major Global AI Policy News in 2024 This chapter begins with an overview of some of the most significant AI-related policy events in 2024, as selected by the AI Index Steering Committee. 6.1 Major Global AI Policy News in 2024 Singapore plans to invest $1B in AI over 5 years Feb. 21, 2024 In his budget speech on February 16, Deputy Prime Minister and Finance Minister Lawrence Wong announced that the government will allocate over $1 billion over the next five years to support AI computation, talent development, and industry growth. Source: The Straits Times, 2024 Figure 6.1.1 Mar. 11, 2024 Abu Dhabi launches $100B AI investment firm In March 2024, Abu Dhabi established MGX Fund Management Limited, a state-owned investment firm specializing in AI technologies, with a target of managing $100 billion in assets. This initiative aligns with the UAE’s strategic objective to position itself as a global leader in AI innovation and technology. Source: Bloomberg, 2024 Figure 6.1.2 Mar. 13, 2024 Artificial Intelligence Act is passed by European Parliament The landmark EU AI Act, the first of its kind, was passed by the European Parliament three months after a provisional agreement on the bill was reached. The legislation introduces sweeping provisions around AI systems, including transparency and reporting obligations, risk-based regulations, and bans on certain applications including social scoring, human manipulation, and biometric categorization that uses “sensitive characteristics.” Most of the Act’s provisions will Source: Time, 2023 Figure 6.1.3 come into effect in 2026 after a two-year implementation period. The Act is significant for its restrictive nature, building on the already stringent EU privacy regulations. It takes a unique approach to regulating generative AI, differing from other proposed legislation, and has been met with resistance from the industry. Table of Contents Chapter 6 Preview 328 Artificial Intelligence Index Report 2025 Chapter 6: Policy and Governance 6.1 Major Global AI Policy News in 2024 India drops plan to require government approval for Mar. 15, 2024 launch of new AI models Less than a month after issuing an advisory requiring tech firms to obtain government approval before launching new AI models, India releases revised guidelines for companies’ self-regulation, following backlash from entrepreneurs and investors. Under the new guidelines, firms must inform users if their models are undertested or unreliable. India’s IT Ministry retained its emphasis that AI models should not Source: TechCrunch, 2024 Figure 6.1.4 undermine electoral integrity or promote bias and discrimination. India launches IndiaAI Mission with $1.25B investment Mar. 17, 2024 In March 2024, India launched the IndiaAI Mission to strengthen its AI ecosystem. The $1.25 billion initiative aims to build 10,000-plus GPUs via public-private partnerships, develop a national nonpersonal data platform, and support homegrown AI models and deep-tech startups. It also prioritizes ethical AI governance and expanding AI labs beyond major cities to democratize access. Source: Nature, 2024 Figure 6.1.5 French government fines Google 250 million euros over Mar. 20, 2024 use of copyrighted information France’s competition watchdog, the Autorité de la Concurrence, took a harsh stance toward negligent model training when it fined Google 250 million euros for using French news content to train Bard, now Gemini, the company’s AI-powered chatbot—without notifying media companies. The government cited the offense as a breach of EU intellectual property rules, and claimed it prevented Source: NBC News, 2024 Figure 6.1.6 publishers and press agencies from negotiating fair prices. Google accepted the settlement and proposed a series of measures to mitigate scraping issues. Table of Contents Chapter 6 Preview 329 Artificial Intelligence Index Report 2025 Chapter 6: Policy and Governance 6.1 Major Global AI Policy News in 2024 U.N. General Assembly adopts resolution promoting Mar. 21, 2024 “safe, secure, and trustworthy” AI Backed by more than 120 member states, the U.N. General assembly adopted a “historic” U.S.-led resolution (although not officially legally binding) on the promotion of “safe, secure, and trustworthy” artificial intelligence systems. The assembly called on stakeholders to ensure that artificial intelligence systems be used in compliance with human rights laws, recognizing the role these systems may Source: UN News, 2024 Figure 6.1.7 play in accelerating progress toward reaching the U.N.’s Sustainable Development Goals. The resolution was supported by more than 120 states, including China, and endorsed without a vote by all 193 U.N. member states. Canada pledges CA$2.4B investment to ensure country’s Apr. 7, 2024 AI advantage The Canadian Federal Budget for 2024 featured a CA$2.4 billion package of measures to “secure Canada’s AI advantage” in the midst of an intensifying global race for AI development and adoption. Funding would be directed toward a range of initiatives, including increasing capabilities and infrastructure for researchers and developers, boosting AI startups, helping small and medium Source: Center for International Governance Innovation, 2024 businesses increase productivity through AI, supporting workers Figure 6.1.8 impacted by AI, and creating a new Canadian AI Safety Institute. U.K. AI Safety Institute launches open-source tool for May 11, 2024 assessing AI model safety The agency released a toolset, called Inspect, designed to assess AI models’ capabilities in a range of areas, including core knowledge, ability to reason, and autonomous capabilities. The Institute claimed it was the first time an AI safety testing platform had been spearheaded by a government-backed body, and made available for public use under an open-source license in order to benefit industry, Source: TechCrunch, 2024 Figure 6.1.9 research organizations, and academia. Table of Contents Chapter 6 Preview 330 Artificial Intelligence Index Report 2025 Chapter 6: Policy and Governance 6.1 Major Global AI Policy News in 2024 U.K. and South Korea cohost AI safety summit in Seoul May 21, 2024 At the AI Seoul Summit, attending countries shared the safety measures they adopted in line with the Bletchley Declaration, which was signed the year prior at the U.K. AI Safety Summit. The declaration emphasizes the ethical and responsible development of AI. Building on the progress made at the U.K. summit, countries have since launched or announced plans for AI safety institutes. In Seoul, Source: Center for Strategic and these nations took another step forward by signing a letter of intent International Studies, 2024 to establish a collaborative network of institutes, highlighting the Figure 6.1.10 importance of global cooperation in advancing AI safety. China creates country’s largest-ever state-backed May 27, 2024 investment fund to back its semiconductor industry China launched a fund worth $47.5 billion to boost semiconductor production. The launch marks the third phase of China’s “Big Fund,” which has supported the industry’s development since 2014, including crucial investments into the country’s two largest chip foundries. The move comes amid rising U.S. export controls on critical technologies like semiconductors that underpin hardware Source: Reuters, 2024 Figure 6.1.11 components like GPUs used to train AI systems. European Commission establishes AI Office May 28, 2024 Over three years after the EU AI Act was proposed, the European Commission unveils its cornerstone. The AI Office will play a key role in implementing the Act, enforcing standards for general-purpose AI models, coordinating the development of codes of practice, and applying sanctions for offenses under the Act. With over 140 staff members, the body consists of five units dedicated to different AI- related goals, including promoting societal good through AI and Source: Center for Strategic and International Studies, 2024 pursuing excellence in AI and robotics. Figure 6.1.12 Table of Contents Chapter 6 Preview 331 Artificial Intelligence Index Report 2025 Chapter 6: Policy and Governance 6.1 Major Global AI Policy News in 2024 U.S. NIST unveils framework to help organizations Jun. 26, 2024 identify and mitigate GenAI risks The National Institute of Standards and Technology (NIST) launches a voluntary framework to help organizations identify unique risks posed by generative AI and recommends a series of actions for mitigating those risks. The framework extends the NIST AI Risk Management Framework released in 2023. Recommended actions include determining AI risk tolerance and respective risk Source: FedScoop, 2024 Figure 6.1.13 management needs, establishing clear responsibilities for managing AI risks, and involving nondeveloper experts in regular assessment and updates. The framework followed the release of a NIST document on adversarial machine learning outlining a taxonomy of attack types, the effects of such attacks, and mitigation strategies. U.S. State Department releases AI Risk Management Jul. 25, 2024 Profile for Human Rights The U.S. State Department designed the Risk Management Profile for Artificial Intelligence and Human Rights as a guide for governments, businesses, and civil society to align AI risk management with human rights protections. Built on the NIST AI Risk Management Framework, the Profile outlines four key functions—govern, map, measure, and manage—to assess and mitigate AI risks, from bias to misuse for surveillance. By bridging AI governance and human rights, it provides a globally applicable tool for responsible AI development Source: U.S. Department of State, 2024 Figure 6.1.14 and deployment. U.K. withdraws £1.3B promised for technology and Aug, 2, 2024 AI infrastructure The U.K.’s Labour government canceled £1.3 billion in funding promised for technology and AI projects, explaining that the commitments made by the previous government had been “underfunded.” Announced in 2023, the projects included £500 million for the AI Research Resource, which funds computing power, and £800 million for the creation of the University of Edinburgh’s Source: BBC, 2024 Figure 6.1.15 exascale supercomputer. Table of Contents Chapter 6 Preview 332 Artificial Intelligence Index Report 2025 Chapter 6: Policy and Governance 6.1 Major Global AI Policy News in 2024 U.S. White House launches task force on AI data center Sep. 13, 2024 infrastructure A White House meeting brought together federal officials and technology executives to discuss securing power sources for robust data center infrastructure critical to AI models. Executives from OpenAI, Anthropic, Amazon Web Services, Nvidia, and Alphabet were present. A White House press release emphasized that advancing AI development in the U.S. is vital for national security Source: FedScoop, 2024 Figure 6.1.16 and ensuring AI systems are safe, secure, and trustworthy. The newly formed AI data center infrastructure task force will identify opportunities and work with agencies to prioritize the development of AI data centers. California governor signs three bills on AI and elections Sep. 17, 2024 communications Ahead of the 2024 San Francisco mayoral election, Governor Gavin Newsom announced the signing of three bills into law aimed at combating deepfake election content. AB 2655, AB 2839, and AB 2355 require large online platforms to remove or label digitally Source: The Wall Street Journal, 2024 altered election content during specified periods, expand the time Figure 6.1.17 frame for prohibiting the distribution of deceptive AI-generated election content, and mandate that electoral ads using AI-generated or altered content include appropriate disclosures, respectively. United Nations adopts Global Digital Compact to ensure Sep. 22, 2024 an inclusive and secure digital future During the Summit of the Future, U.N. member states adopted the Global Digital Compact, aiming to establish an inclusive, open, sustainable, fair, safe, and secure digital future for all. The Compact emphasizes objectives such as closing digital divides, expanding benefits from the digital economy, fostering a digital space that respects human rights, advancing equitable data governance, and Source: United Nations, 2024 enhancing international governance of artificial intelligence. Guided Figure 6.1.18 by principles anchored in international law and human rights, the Compact seeks to harness digital technologies to accelerate progress toward the Sustainable Development Goals. Table of Contents Chapter 6 Preview 333 Artificial Intelligence Index Report 2025 Chapter 6: Policy and Governance 6.1 Major Global AI Policy News in 2024 California governor vetoes expansive AI legislation Sep. 29, 2024 Governor Gavin Newsom vetoed California’s AI safety bill, which would have set a national precedent for AI regulation, given the state’s role as home to many leading AI companies. The bill sought to mandate safety testing for frontier AI models before their public release and would have allowed the state attorney general to sue companies over AI-related harm. Supporters argued it was a nec- Source: Financial Times, 2024 essary step to ensure AI safety and accountability, while critics con- Figure 6.1.19 tended it was overly restrictive and could stifle AI development, es- pecially of the open-weight AI ecosystem. Given California’s status as the world’s fifth-largest economy, the bill’s impact could have extended beyond state borders, akin to the Brussels effect, shaping AI governance nationally and internationally. Newsom defended his veto, arguing the bill imposed excessive standards. U.S. judge blocks new California AI law over Oct. 2, 2024 Kamala Harris deepfake A federal judge in California issued a temporary injunction on one of the state’s new AI laws just two weeks after it was signed. In his ruling, Judge Mendez cited the law’s vague definition of “harmful” depictions as a potential threat to constitutionally protected speech. The law had been used to prosecute an X user after he had posted a deepfake featuring Kamala Harris. Source: Los Angeles Times, 2024 Figure 6.1.20 Saudi Arabia announces “Project Transcendence” Nov. 8, 2024 In November 2024, Saudi Arabia announced Project Transcendence, a $100 billion AI initiative aimed at establishing the kingdom as a global tech hub. Spearheaded by the Public Investment Fund, the project includes a partnership with Alphabet, Google’s parent company, involving an investment between $5 billion and $10 Source: Telecom Review, 2024 billion to develop Arabic-language AI models. This initiative aligns Figure 6.1.21 with Saudi Arabia’s Vision 2030, which focuses on diversifying the region’s economy beyond oil and becoming a meaningful hub of AI. Table of Contents Chapter 6 Preview 334 Artificial Intelligence Index Report 2025 Chapter 6: Policy and Governance 6.1 Major Global AI Policy News in 2024 European Commission AI Office releases first draft of Nov. 14, 2024 Code of Practice for General-Purpose AI The European AI Office issued the first of four drafts for the General- Purpose AI Code of Practice. This code was developed by four working groups of independent experts, focusing on transparency and copyright, risk identification and assessment, risk mitigation, and internal governance. Once finalized, the code will complement Source: European Union, 2024 the AI Act, allowing AI model providers to demonstrate compliance Figure 6.1.22 until a finalized standard is published. U.S. launches international AI safety network with Nov. 25, 2024 global partners In November 2024, the U.S. Department of Commerce and the U.S. Department of State cohosted the inaugural meeting of the International Network of AI Safety Institutes in San Francisco. This initiative aims to improve global coordination on safe AI innovation, focusing on managing synthetic content risks, testing foundation models, and conducting risk assessments for advanced AI systems. Source: AP, 2024 The United States serves as the inaugural chair, with initial members Figure 6.1.23 including Australia, Canada, the European Union, France, Japan, Kenya, the Republic of Korea, Singapore, and the United Kingdom. The network has secured over $11 million in global research funding commitments to support its efforts. U.S. increases export controls of semiconductor Dec. 2, 2024 manufacturing equipment and software to China The U.S. Department of Commerce’s Bureau of Industry and Security further limited China’s ability to produce advanced semiconductors by announcing new export controls. These measures include restrictions on 24 types of semiconductor manufacturing equipment, three types of software tools, and additional limitations. Source: CNBC, 2024 Figure 6.1.24 The secretary of commerce emphasized the importance of these measures in safeguarding U.S. national security. Table of Contents Chapter 6 Preview 335 Artificial Intelligence Index Report 2025 Chapter 6: Policy and Governance 6.1 Major Global AI Policy News in 2024 U.N. Security Council debates uses of AI in conflicts and Dec. 19, 2024 calls for global framework On Dec. 19, 2024, the United Nations Security Council convened to address the challenges posed by AI in military contexts. Secretary- General António Guterres emphasized that AI’s rapid evolution is outpacing current governance frameworks, potentially undermining human control over weapons systems. He called for “international Source: Berkeley Political Review, 2016 guardrails” to ensure AI’s safe and inclusive use. These discussions Figure 6.1.25 continue amid reports of widespread autonomous drone and robot use in the ongoing war in Ukraine. Table of Contents Chapter 6 Preview 336 Artificial Intelligence Index Report 2025 Chapter 6: Policy and Governance 6.2 AI and Policymaking 6.2 AI and Policymaking Global Legislative Records on AI Overview The AI Index analyzed legislation containing the term AI-related laws enacted since 2016. The total number of “artificial intelligence” in 114 countries from 2016 to 2024.1 AI-related laws passed rose from 30 in 2023 to 40 in 2024, Of these, 39 countries have enacted at least one AI-related making 2024 the second-highest year on record after 2022. law (Figure 6.2.1).2 In total, the countries have passed 204 Since 2016, the number of AI-related laws passed has grown AI-related laws. Figure 6.2.2 illustrates the annual count of from just one to 40. Number of AI-related bills passed into law by country, 2016–24 Source: AI Index, 2025 | Chart: 2025 AI Index report 0 1–5 6–10 11–15 16–30 No available data Figure 6.2.1 1 The analysis may undercount the number of actual laws passed, given that large bills that are proposed can include multiple sections related to AI. For example, the National Defense Authorization Act is introduced as a single omnibus bill but includes a collection of smaller bills that were originally proposed individually and later consolidated into one single comprehensive bill. 2 The AI Index monitored AI-related laws passed in Hong Kong and Macao, despite these not being officially recognized countries. Thus, the Index covers a total of 116 geographic areas. Laws passed by Hong Kong and Macao were counted in the overall tally of AI-related laws. This year, the Index decreased its country sample compared to previous years, due to issues accessing the legislative databases of certain nations. As a result, there is a difference between the number of AI-related laws reported this year and those in prior reports. Table of Contents Chapter 6 Preview 337 Artificial Intelligence Index Report 2025 Chapter 6: Policy and Governance 6.2 AI and Policymaking 45 40 35 30 25 20 15 10 5 0 2016 2017 2018 2019 2020 2021 2022 2023 2024 Table of Contents Chapter 6 Preview 338 dessap sllib detaler-IA fo rebmuN Number of AI-related bills passed into law in 116 select geographic areas, 2016–24 Source: AI Index, 2025 | Chart: 2025 AI Index report 40 Figure 6.2.2 By Geographic Area Figure 6.2.3 highlights the number of AI-related laws enacted each. Figure 6.2.4 displays the total number of AI-related in 2024 across the top 15 geographic areas. Russia led with laws passed since 2016, with the United States leading at 27, seven laws, followed by Belgium and Portugal with five followed by Portugal and Russia, each with 20.3 Number of AI-related bills passed into law in select Number of AI-related bills passed into law in select geographic areas, 2024 geographic areas, 2016–24 (sum) Source: AI Index, 2025 | Chart: 2025 AI Index report Source: AI Index, 2025 | Chart: 2025 AI Index report Russia 7 United States 27 Belgium 5 Portugal 20 Portugal 5 Russia 20 United States 4 Belgium 18 Hong Kong 2 South Korea 13 Latvia 2 Spain 11 South Korea 2 Italy 10 United Kingdom 2 United Kingdom 10 Australia 1 France 9 Austria 1 Austria 7 Bahamas 1 Philippines 6 Barbados 1 China 4 China 1 Germany 4 France 1 Japan 4 Germany 1 Andorra 3 0 1 2 3 4 5 6 7 0 2 4 6 8 10 12 14 16 18 20 22 24 26 28 Number of AI-related bills passed Number of AI-related bills passed Figure 6.2.3 Figure 6.2.4 3 For concision, Figure 6.2.3 and Figure 6.2.4 display data for the top 15 geographic areas by count. Complete country-level totals will be available in the summer 2025 update of the Global AI Vibrancy Tool. For immediate access, please contact the AI Index team. Artificial Intelligence Index Report 2025 Chapter 6: Policy and Governance 6.2 AI and Policymaking Highlight: A Closer Look at Global AI Legislation The following subsection delves into some of the AI-related legislation passed into law during 2024. Figure 6.2.5 samples five countries’ laws covering a range of AI-related issues. Country Bill name Description Austria Federal law amending the This act establishes a Service Center for Artificial Intelligence KommAustria Act and the to support, advise, and coordinate AI governance in the media, Telecommunications Act 2021 telecommunications, and postal sectors. It mandates an AI advisory board to monitor AI developments, advise the government, and help shape national AI policy. The Service Center must maintain an information portal on AI projects, particularly publicly funded ones. It also provides guidance on AI regulation, cybersecurity, and compliance. To fund these activities, €700,000 is allocated annually, with future adjustments based on inflation. Belgium Royal decree establishing an This act creates a federal AI steering committee to advise the orientation committee on artificial government on AI-related policies and serve as the primary point intelligence of contact for AI governance. The committee, composed of representatives from ministries and public institutions, meets regularly to provide recommendations and coordinate AI policy across Belgium. France LAW No. 2021-1382 of October This law establishes the Regulatory Authority for Audiovisual and 25, 2021, relating to the regulation Digital Communication (ARCOM) by merging the Higher Audiovisual and protection of access to cultural Council (CSA) and the High Authority for the Distribution of Works works in the digital age4 and the Protection of Rights on the Internet (HADOPI). It strengthens measures against online piracy and enhances the regulation of digital platforms to safeguard access to cultural content in the digital space. The law also references artificial intelligence as a tool ARCOM can use to monitor and regulate digital platforms, particularly for detecting copyright infringements and combating online piracy. Latvia Amendments to the Pre-election This act regulates the use of AI in political advertising, requiring clear Campaigning Law disclosure for AI-generated content in paid campaign materials. It also bans the use of automated systems with fake or anonymous social media profiles for election campaigns. Russia On Amendments to the Federal This act establishes a framework for processing and sharing Law “On Personal Data” and the anonymized personal data to support AI development in government Federal Law “On Conducting an operations. It regulates AI-driven decision making, sets security Experiment to Establish Special standards for biometric data, and restricts foreign access to sensitive Regulations for Creating Necessary AI-related datasets. Conditions for the Development and Implementation of Artificial Intelligence Technologies in the Constituent Entity of the Russian Federation – the Federal City of Moscow,” and on Amendments to Articles 6 and 10 of the Federal Law “On Personal Data” Figure 6.2.5 4 Law No. 2024-449, passed in 2024, amends Law No. 2021-1382—originally enacted in 2021 and updated in 2024 to include AI—by broadening its scope to cover artificial intelligence and authorizing ARCOM to utilize AI. Table of Contents Chapter 6 Preview 339 Artificial Intelligence Index Report 2025 US Legislative Records Federal Level Figure 6.2.6 illustrates the total number of passed versus has almost tripled. Still, of all AI-related bills being proposed, proposed AI-related bills in the U.S. Congress and relatively few are passed. The significant increase in U.S. demonstrates a significant increase in proposed legislation.5 In AI-related legislative activity likely reflects policymakers’ the last year, the count of proposed AI-related bills continued response to the increasing public awareness and capabilities to rise, increasing from 171 in 2023 to 221 in 2024. Since of AI technologies, particularly generative AI.6 2022, the number of proposed U.S. federal AI-related bills 210 180 150 120 90 60 30 0 2016 2017 2018 2019 2020 2021 2022 2023 2024 Table of Contents Chapter 6 Preview 340 sllib detaler-IA fo rebmuN Chapter 6: Policy and Governance 6.2 AI and Policymaking Number of congressional AI-related proposed bills and passed laws in the United States, 2016–24 Source: AI Index, 2025 | Chart: 2025 AI Index report 221, Proposed 4, Passed Figure 6.2.6 5 A bill is passed when it successfully clears both chambers of Congress: the House and the Senate. 6 This section covers only congressional bills. However, U.S. AI policymaking extends beyond Congress to other bodies, including the Executive Branch—such as President Donald Trump’s Stargate announcement—and rules coming from regulatory agencies like the FTC. Artificial Intelligence Index Report 2025 Chapter 6: Policy and Governance 6.2 AI and Policymaking State Level Number of AI-related bills passed into law in select US states, 2024 The AI Index also tracks data on the enactment of AI- Source: AI Index, 2025 | Chart: 2025 AI Index report related legislation at the state level. Figure 6.2.7 highlights California 22 the number of AI-related laws enacted by U.S. states in Utah 12 2024. According to the AI Index tracking methodology, Maryland 8 Virginia 6 California leads with 22 laws, followed by Utah with 12 and Illinois 5 Maryland with eight. Figure 6.2.8 displays the total amount New Hampshire 5 of legislation passed by states from 2016 to 2024. California New York 5 again tops the ranking with 42 bills, followed by Maryland Alabama 4 (17), Virginia (17), and Utah (17). Arizona 4 Colorado 4 Florida 4 Massachusetts 4 Mississippi 4 Tennessee 4 Idaho 3 0 2 4 6 8 10 12 14 16 18 20 22 Number of AI-related bills passed Figure 6.2.7 Number of state-level AI-related bills passed into law in the United States by state, 2016 24 (sum) Source: AI Index, 2025 | Chart: 2025 AI Index report AK ME 0 1 VT NH MA 7 6 11 WA MT ND SD MN WI MI NY CT RI 11 0 3 1 4 2 7 8 3 0 OR ID WY NE IA IL IN OH PA NJ 2 4 1 1 4 11 4 2 3 3 CA NV UT CO KS MO KY WV MD DE 42 2 17 7 0 0 2 4 17 1 AZ NM OK AR TN VA NC 5 3 0 0 4 17 6 TX LA MS AL GA SC 5 4 6 7 3 1 HI FL 4 9 Figure 6.2.8 Table of Contents Chapter 6 Preview 341 Artificial Intelligence Index Report 2025 Since 2016, the number of state-level AI-related laws has rapidly increased. Only one such bill was passed in 2016, rising to 49 by 2023. In the past year alone, that number more than doubled to 131 (Figure 6.2.9). 140 120 100 80 60 40 20 0 2016 2017 2018 2019 2020 2021 2022 2023 2024 Table of Contents Chapter 6 Preview 342 dessap sllib detaler-IA fo rebmuN Chapter 6: Policy and Governance 6.2 AI and Policymaking Number of AI-related bills passed into law by all US states, 2016–24 Source: AI Index, 2025 | Chart: 2025 AI Index report 131 Figure 6.2.9 Artificial Intelligence Index Report 2025 Chapter 6: Policy and Governance 6.2 AI and Policymaking Highlight: A Closer Look at State-Level AI Legislation The following subsection highlights some of the AI-related legislation passed into law at the state level during 2024. The Index profiles legislation from states like California and New York, major hubs for AI companies, alongside states like Alabama and Colorado, which play a smaller role in the industry. This approach highlights the diverse concerns shaping AI legislation at the state level (Figure 6.2.10). State Bill name Description Alabama Relating to elections; to provide This bill prohibits the distribution of AI-generated deceptive media that distribution of materially within 90 days of an election if intended to mislead voters or harm a deceptive media is a crime candidate, with penalties ranging from a misdemeanor to a felony for repeat offenses. Exceptions apply for media with clear disclaimers, news reporting, and satire, while violations can result in misdemeanor or felony charges, and affected parties may seek legal action. California California AI Transparency Act This act requires large AI providers to offer free AI detection tools and ensure AI-generated content includes clear, permanent disclosures. Violations result in a $5,000 fine per instance, with enforcement by the attorney general or local authorities. Colorado Consumer Protections for This bill establishes consumer protections for interactions with Artificial Intelligence7 high-risk AI systems, requiring developers and deployers to prevent algorithmic discrimination. AI systems must provide transparency, allow consumers to correct or appeal AI-driven decisions, and undergo regular impact assessments. Massachusetts An Act to Provide for the Future This act allocates $1.26 billion to modernize information technology, Information Technology Needs of cybersecurity, and broadband infrastructure across Massachusetts. Massachusetts It includes $25 million to integrate AI and machine learning into state government operations, enhancing automation, efficiency, and cybersecurity. New York An Act to Amend the General This act requires social media companies to publicly disclose Business Law, in Relation to their terms of service for each platform they own or operate in a Requiring Disclosure of Certain clear and accessible manner. It also mandates submitting terms of Social Media Terms of Service service reports to the attorney general and imposes penalties for noncompliance. Figure 6.2.10 7 This bill is colloquially known as the “Colorado AI Act.” Table of Contents Chapter 6 Preview 343 Artificial Intelligence Index Report 2025 Chapter 6: Policy and Governance 6.2 AI and Policymaking Highlight: Anti-deepfake Policymaking States in the U.S. have been particularly active in passing when states enacted laws to regulate AI deepfakes legislation to combat deepfakes. A deepfake is AI- in elections. Before 2024, five states—California, generated synthetic media that manipulates or replaces Washington, Texas, Michigan, and Minnesota—had a person’s likeness in video, audio, or images, often passed such laws. In 2024, 12 more states, including creating realistic but deceptive content. Deepfakes Oregon, New Mexico, and New York, introduced similar can be used to manipulate election outcomes, as regulations. discussed in Chapter 3 of this year’s AI Index, or to generate explicit images. The nonprofit Public Citizen State-level regulations against intimate deepfakes maintains a database tracking AI deepfake regulations, are far more widespread than those against election covering both election-related misuse and intimate misuse. A total of 25 states have enacted laws covering image misuse. Figure 6.2.11 illustrates the number of all individuals, while five states have passed regulations state-level laws passed in the United States over time, that apply only to minors (Figure 6.2.13). Wyoming and encompassing anti-deepfake regulations related to Ohio are the only states yet to implement any form of elections and intimate images.8 Figure 6.2.12 highlights intimate deepfake regulation. 35 30 25 20 15 10 5 0 2019 2020 2021 2022 2023 2024 Figure 6.2.11 Table of Contents Chapter 6 Preview 344 detcane swal level-etats fo rebmuN Number of state-level laws enacted on AI-generated deepfakes in intimate imagery and elections in the United States, 2019–24 Source: Public Citizen, 2025 | Chart: 2025 AI Index report 36, Intimate imagery 20, Elections 8 In some cases, the AI Index could not verify the enactment dates of certain state-level AI-related anti-deepfake laws tracked by Public Citizen. Figure 6.2.11 includes only those bills with confirmed passage dates. Artificial Intelligence Index Report 2025 Chapter 6: Policy and Governance 6.2 AI and Policymaking Highlight: Anti-deepfake Policymaking (cont’d) State-level laws regulating AI-generated deepfakes in elections in the US by state and status as of 2024 Source: Public Citizen, 2025 | Chart: 2025 AI Index report AK ME VT NH MA WA MT ND SD MN WI MI NY CT RI OR ID WY NE IA IL IN OH PA NJ CA NV UT CO KS MO KY WV MD DE AZ NM OK AR TN VA NC TX LA MS AL GA SC HI FL Enacted pre-2024 Enacted in 2024 Legislation pending No legislation enacted Figure 6.2.12 State-level laws regulating AI-generated deepfakes in intimate imagery in the US by state and status as of 2024 Source: Public Citizen, 2025 | Chart: 2025 AI Index report AK ME VT NH MA WA MT ND SD MN WI MI NY CT RI OR ID WY NE IA IL IN OH PA NJ CA NV UT CO KS MO KY WV MD DE AZ NM OK AR TN VA NC TX LA MS AL GA SC HI FL Enacted (covers everyone) Enacted (covers minors only) Legislation pending (covers everyone) Legislation pending (covers minors only) No legislation enacted Figure 6.2.13 Table of Contents Chapter 6 Preview 345 Artificial Intelligence Index Report 2025 1,800 1,600 1,400 1,200 1,000 800 600 400 200 0 2016 2017 2018 2019 2020 2021 2022 2023 2024 Table of Contents Chapter 6 Preview 346 snoitnem fo rebmuN Chapter 6: Policy and Governance 6.2 AI and Policymaking Global AI Mentions Another barometer of legislative interest is the number Overview of mentions of artificial intelligence in governmental and Figure 6.2.14 shows the total number of legislative sessions parliamentary proceedings. The AI Index conducted worldwide that have mentioned AI since 2016. In the past an analysis of the minutes or proceedings of legislative year, AI mentions rose by 21.3%, increasing from 1,557 in sessions in 73 countries that contain the keyword “artificial 2023 to 1,889. Since 2016, the total number of AI mentions intelligence” from 2016 to 2024.9 has grown more than ninefold. Number of mentions of AI in legislative proceedings in 75 select geographic areas, 2016–24 Source: AI Index, 2025 | Chart: 2025 AI Index report 1,889 Figure 6.2.14 9 The full list of analyzed countries is available in the Appendix. The AI Index research team aimed to review governmental and parliamentary proceedings worldwide, but publicly accessible databases were not available for all countries. This year, the Index slightly adjusted its tracking methodology, resulting in minor differences from previous totals. More specifically, mentions are counted by session, so multiple mentions of AI in the same legislative session count as one mention. The full methodology is detailed in the Appendix. Additionally, the AI Index tracked mentions in Macao and Hong Kong. While not officially countries, their mentions were included in the tally presented in Figure 6.2.14. In total, the Index tracked AI mentions across 75 geographic areas. Artificial Intelligence Index Report 2025 Chapter 6: Policy and Governance 6.2 AI and Policymaking In 2024, Spain led in AI mentions within its legislative proceedings (314), followed by Ireland (145) and Australia (123) (Figure 6.2.15). Of the 75 geographic areas analyzed, 57 referenced AI in at least one legislative proceeding in 2024. Number of mentions of AI in legislative proceedings by country, 2024 Source: AI Index, 2025 | Chart: 2025 AI Index report 0 1–55 56–120 121–250 251–315 No available data Figure 6.2.15 When legislative mentions are aggregated from 2016 to 2024, a somewhat similar trend emerges (Figure 6.2.16). Spain is first with 1,200 mentions, followed by the United Kingdom (710) and Ireland (659). Number of mentions of AI in legislative proceedings by country, 2016–24 (sum) Source: AI Index, 2025 | Chart: 2025 AI Index report 0 1–220 221–440 441–660 661–890 891–1,200 Figure 6.2.16 No available data Table of Contents Chapter 6 Preview 347 Artificial Intelligence Index Report 2025 25 United States Portugal 20 Russia Belgium 15 Spain South Korea Italy United Kingdom 10 France Philippines 5 Hong Kong Japan Brazil Canada Australia India 0 Iceland 0 100 200 300 400 500 600 700 800 900 1,000 1,100 1,200 Number of AI mentions Table of Contents Chapter 6 Preview 348 wal otni dessap sllib detaler-IA fo rebmuN Chapter 6: Policy and Governance 6.2 AI and Policymaking Drawing on data from select countries, Figure 6.2.17 compares discussion of AI correlates with more AI legislation—although AI mentions in parliamentary discussions with the number some countries, such as Belgium, Portugal, and Russia, of AI-related bills passed. In general, greater parliamentary deviate from this trend. Mentions of AI in legislative proceedings vs. AI-related bills passed into law in select countries, 2016–24 Source: AI Index, 2025 | Table: 2025 AI Index report China Germany Barbados Liechtenstein Andorra Latvia Slovenia Panama Figure 6.2.17 Artificial Intelligence Index Report 2025 140 120 100 80 60 40 20 0 107th 108th 109th 110th 111th 112th 113th 114th 115th 116th 117th 118th (2001–02) (2003–04) (2005–06) (2007–08) (2009–10) (2011–12) (2013–14) (2015–16) (2017–18) (2019–20) (2021–22) (2023–24) Table of Contents Chapter 6 Preview 349 snoitnem fo rebmuN Chapter 6: Policy and Governance 6.2 AI and Policymaking US Committee Mentions Mentions of artificial intelligence in committee reports by Figure 6.2.18 tracks AI mentions in U.S. committee reports House and Senate committees serve as another indicator by legislative session from 2001 to 2024. The 118th session of legislative interest in AI in the United States. Typically, recorded the highest count to date, with 136 mentions—up these committees focus on legislative and policy issues, 83.8% from the 117th session. investigations, and internal matters. Mentions of AI in US committee reports by legislative session, 2001–24 Source: AI Index, 2025 | Chart: 2025 AI Index report 136 Figure 6.2.18 Artificial Intelligence Index Report 2025 60 50 40 30 20 10 0 2016 2017 2018 2019 2020 2021 2022 2023 2024 Table of Contents Chapter 6 Preview 350 snoitaluger detaler-IA fo rebmuN Chapter 6: Policy and Governance 6.2 AI and Policymaking US Regulations The advent of AI has garnered significant attention from This section examines AI-related regulations enacted by regulatory agencies—federal bodies tasked with regulating American regulatory agencies between 2016 and 2024. It sectors of the economy and steering the enforcement of provides an analysis of the total number of regulations, as laws. This section examines AI regulations within the United well as their topics, scope, regulatory intent, and originating States. Unlike legislation, which establishes legal frameworks agencies. To compile this data, the AI Index performed a within nations, regulations are detailed directives crafted keyword search for “artificial intelligence” on the Federal by executive authorities to enforce legislation. In the Register, a comprehensive repository of government United States, prominent regulatory agencies include documents from nearly all branches of the American the Environmental Protection Agency (EPA), Food and government, encompassing more than 436 agencies. Drug Administration (FDA), and Federal Communications Commission (FCC). Since the specifics of legislation often Overview manifest through regulatory actions, understanding the AI The number of AI-related regulations has risen sharply over regulatory landscape is essential to developing a deeper the past six years, with a particularly noticeable increase in understanding of AI policymaking. the last year (Figure 6.2.19). In 2024, 59 AI-related regulations were introduced—more than double the 25 recorded in 2023. Number of AI-related regulations in the United States, 2016–24 Source: AI Index, 2025 | Chart: 2025 AI Index report 59 Figure 6.2.19 By Agency Figure 6.2.20 looks at the number of AI-related regulations Medicare and Medicaid Services (7) and the Commerce in the United States that have been released by different Department (7). AI regulations came from a record 42 unique American regulatory agencies since 2016.10 In 2024, the departments, up from 21 in 2023 and 17 in 2022. This trend Department of Health and Human Services issued the most reflects a growing interest in AI across a wider range of U.S. AI-related regulations (14), followed by the Centers for regulators. 10 Regulations can originate from multiple agencies, so the totals in Figure 6.2.20 do not fully align with those in Figure 6.2.19. Figure 6.2.20 refers to departments as agencies, consistent with the terminology used by the Federal Register, the source of the data. Artificial Intelligence Index Report 2025 Chapter 6: Policy and Governance 6.2 AI and Policymaking Figure 6.2.20 Table of Contents Chapter 6 Preview 351 Artificial Intelligence Index Report 2025 Chapter 6: Policy and Governance 6.2 AI and Policymaking Highlight: A Closer Look at US Federal Regulations The following section highlights some of the AI-related regulations passed as rules and executive orders at the federal level during 2024 (Figure 6.2.21). Agency Regulation Description Executive Office of Preventing Access to Americans’ This executive order identifies AI use by countries of concern as a the President Bulk Sensitive Personal Data significant national security threat. It specifically warns of foreign and United States Government– adversaries exploiting bulk sensitive personal and U.S. government– Related Data by Countries of related data to refine AI algorithms for espionage, cyber Concern operations, and influencing campaigns. To counter this risk, the order implements measures to safeguard sensitive data, including restrictions or bans on data transactions with these countries and strengthened network infrastructure security. Industry and Foreign-Produced Direct Product This rule amends the U.S. Export Administration Regulations to Security Bureau Rule Additions, and Refinements tighten controls on semiconductor manufacturing equipment and to Control for Advanced supercomputer exports, particularly to China. It introduces additional Computing and Semiconductor restrictions on semiconductor production, revises existing measures, Manufacturing Items and implements “Red Flags” to identify risks of unauthorized exports. These changes aim to counter China’s efforts to circumvent previous restrictions and limit its ability to develop advanced computing and AI systems that could threaten U.S. national security. Consumer Financial Consumer Financial Protection This rule mandates that employers cannot base employment Protection Bureau Circular 2024–06: Background decisions on background dossiers, algorithmic scores, or third-party Dossiers and Algorithmic Scores reports without complying with the Fair Credit Reporting Act. It for Hiring, Promotion, and Other reinforces key obligations, particularly for AI-driven systems, such as Employment Decisions obtaining a worker’s consent before procuring a consumer report. By doing so, the rule sets clear limits on the use of algorithmic scoring in hiring and employment decisions. Federal Election Fraudulent Misrepresentation of This interpretive rule offers supplemental guidance on the Federal Commission Campaign Authority Election Campaign Act (FECA) in response to the rise of AI- generated content. It reaffirms that FECA is “technology neutral” and focuses on whether a person or entity engages in election-related misrepresentation rather than specifically addressing AI misuse. Office of Provisions Pertaining to U.S. This final rule implements Executive Order 14105, mandating that Investment Security, Investments in Certain National U.S. persons notify the Treasury Department of transactions with Department of the Security Technologies and entities in countries of concern involved in sensitive technologies Treasury Products in Countries of Concern that threaten national security. It also prohibits certain transactions with these entities. Issued in 2023, the order targets U.S. investments in high-risk technologies, including AI, semiconductors, and quantum computing, recognizing them as critical sectors where such investments could heighten security threats from adversarial nations. Figure 6.2.21 Table of Contents Chapter 6 Preview 352 Artificial Intelligence Index Report 2025 Chapter 6: Policy and Governance 6.3 Public Investment in AI 6.3 Public Investment in AI11 As AI continues to drive innovation in critical sectors such as The AI Index cautions against making direct country-to- healthcare, transportation, and defense, public funding has country comparisons based on the public spending data become essential for nations to realize their AI strategies. presented in this section. While this analysis includes Understanding how much governments invest in AI research data on government contracts from a range of countries, and development (R&D) is important for understanding it only covers grant-level spending for the United States. the broader AI geopolitical landscape, yet tracking these This asymmetry stems from the complexity and difficulty investments presents significant challenges. While national of collecting comparable grant data from other countries budgets may outline AI-related spending, these allocations and regions, such as the European Union and China. do not always translate directly into expenditures. Moreover, However, as the U.S. case demonstrates, a significant share AI investments are often embedded within broader of government spending on AI occurs through grants. In scientific or technological initiatives. As a result, pinpointing 2023 alone, the AI Index estimates that the U.S. government AI-specific funding can be difficult. awarded approximately $830 million in AI-related public tenders, compared to $4.5 billion in AI-related grants. Given To address this, the AI Index leveraged natural language the current limitations in cross-national data availability and processing (NLP) techniques to analyze public tenders and consistency, comparative analysis of public AI spending contracts and to identify AI-related government spending in across countries remains premature. This analysis is countries across the world.12 Examining tenders provides a intended as an initial step toward more comprehensive more direct measure of investment trends and offers insight global coverage. The AI Index is committed to expanding into how governments allocate resources over time. Because this work and welcomes collaboration from researchers, the AI Index only analyzed countries for which public contract institutions, and governments interested in improving the and tenders data was publicly available, some countries scope and quality of this data. could not be analyzed.13 This section also presents an analysis of total AI grant spending in the United States. 11 The analysis in this section was led by Lapo Santarlasci. 12 The full methodology behind this analytical approach is detailed in the Appendix. Due to reporting lags that may result in incomplete data for 2024, the most up-to-date analysis is available for the end of 2023. 13 Some major government AI contract-granting regions, such as the EU (at the aggregate level) and China, were excluded from this analysis due to data limitations. The AI Index is committed to expanding its scope to include these and other regions in future editions. Table of Contents Chapter 6 Preview 353 Artificial Intelligence Index Report 2025 Chapter 6: Policy and Governance 6.3 Public Investment in AI Total AI Public Investments Figure 6.3.1 summarizes key figures on the number of AI- contracts (Figure 6.3.1 and Figure 6.3.2). In Europe, the related contracts and their value at the country level.14 From United Kingdom, Germany, and France stand out with the 2013 to 2023, the United States was the leading nation, highest total contract values awarded, accounting for 56% of with about $5.2 billion distributed across 2,678 unique AI European public investments in AI. Public spending on AI-related contracts in select countries, 2013–23 (sum) Source: AI Index, 2025 | Chart: 2025 AI Index report United States 5,233.10 United Kingdom 568.48 Germany 278.07 France 190.10 Spain 99.71 Belgium 83.54 Denmark 74.40 Finland 71.25 Poland 55.92 Greece 50.02 Romania 46.37 Italy 44.30 Czech Republic 40.71 Hungary 36.56 Ireland 29.42 0 500 1,000 1,500 2,000 2,500 3,000 3,500 4,000 4,500 5,000 5,500 Public spending on AI-related contracts (in millions of US dollars) Figure 6.3.1 14 The results and figures presented are subject to missing values ratios of the specific sample of matched tenders: 0.16% for NAICS code, and 26.8% for U.S. dollar values. It is important to note that the sample does not include Northern Ireland tenders, as their offices do not offer an API service or bulk download option for large-scale data collection. Table of Contents Chapter 6 Preview 354 Artificial Intelligence Index Report 2025 Chapter 6: Policy and Governance 6.3 Public Investment in AI Number of AI-related contracts in select countries, 2013–23 (sum) Source: AI Index, 2025 | Chart: 2025 AI Index report United States 2,678 United Kingdom 555 Germany 409 France 139 Poland 136 Spain 121 Czech Republic 75 Finland 69 Bulgaria 49 Romania 48 Hungary 40 Italy 38 Denmark 32 Belgium 29 Greece 28 0 200 400 600 800 1,000 1,200 1,400 1,600 1,800 2,000 2,200 2,400 2,600 Number of AI-related contracts Figure 6.3.2 Median value of public AI-related contracts in select countries, 2013–23 Source: AI Index, 2025 | Chart: 2025 AI Index report Switzerland 3.05 Turkey 2.81 Ireland 1.42 Luxembourg 1.15 Denmark 1.07 Italy 1.03 Belgium 1.01 Austria 0.92 Finland 0.67 Malta 0.65 Norway 0.63 Portugal 0.60 Estonia 0.57 Latvia 0.56 Greece 0.55 0.00 0.50 1.00 1.50 2.00 2.50 3.00 Median value of public AI-related contracts (in millions of US dollars) Figure 6.3.3 Table of Contents Chapter 6 Preview 355 Artificial Intelligence Index Report 2025 Chapter 6: Policy and Governance 6.3 Public Investment in AI Which governments spent the most on AI per capita over the past decade? The United States leads with $1.58 million per 100,000 inhabitants, followed by Finland ($1.3 million) and Denmark ($1.3 million) (Figure 6.3.4). Public spending on AI-related contracts per 100,000 inhabitants in select countries, 2013–23 (sum) Source: AI Index, 2025 | Chart: 2025 AI Index report United States 1.58 Finland 1.29 Denmark 1.27 United Kingdom 0.84 Belgium 0.72 Luxembourg 0.60 Ireland 0.56 Greece 0.48 Norway 0.47 Czech Republic 0.38 Hungary 0.38 Lithuania 0.38 Germany 0.33 Slovenia 0.33 Austria 0.32 0.00 0.30 0.60 0.90 1.20 1.50 Public spending on AI-related contracts per 100,000 inhabitants (in millions of US dollars) Figure 6.3.4 Table of Contents Chapter 6 Preview 356 Artificial Intelligence Index Report 2025 Chapter 6: Policy and Governance 6.3 Public Investment in AI Figure 6.3.5 illustrates public investment in AI in 2023. The ranked lower—such as Romania, Greece, Hungary, and U.S. led with $831.0 million, followed by the United Kingdom at Poland—broke into the top 10. This shift suggests a more $262.6 million. While Germany, Spain, and the U.K. remained balanced distribution of AI-related funding across Europe. among Europe’s top investors, countries that historically Public spending on AI-related contracts in select countries, 2023 Source: AI Index, 2025 | Chart: 2025 AI Index report United States 830.98 United Kingdom 262.59 Spain 49.59 Germany 49.55 Greece 36.89 Romania 31.13 Ireland 26.08 Poland 22.98 France 18.44 Hungary 16.84 Italy 10.48 Austria 10.14 Belgium 8.35 Czech Republic 5.78 Sweden 4.77 0 50 100 150 200 250 300 350 400 450 500 550 600 650 700 750 800 850 Public spending on AI-related contracts (in millions of US dollars) Figure 6.3.5 Table of Contents Chapter 6 Preview 357 Artificial Intelligence Index Report 2025 Chapter 6: Policy and Governance 6.3 Public Investment in AI Figure 6.3.6 illustrates the trends in public AI investment increases in investment, with a 400% year-over-year increase over time across two significant regions of AI investment, the in 2017, followed by another major spike of 200% year-over- United States and Europe. Both regions have seen substantial year in 2019—a year that also saw a peak in the number of growth in AI-related spending over the past decade. Notably, national AI strategies released globally. This sustained upward Europe’s total AI investment in 2023 was approximately 67 trend illustrates how government interest and commitment times higher than in 2013, compared to a fifteenfold increase to AI is growing in monetary terms. in the United States. Europe experienced particularly sharp 1000 800 600 400 200 0 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 Table of Contents Chapter 6 Preview 358 )srallod SU fo snoillim ni( stcartnoc detaler-IA no gnidneps cilbuP Public spending on AI-related contracts in the United States and Europe, 2013–23 Source: AI Index, 2025 | Chart: 2025 AI Index report 830.98, United States 581.38, Europe Figure 6.3.6 Artificial Intelligence Index Report 2025 Figure 6.3.7 charts the investment gap between Europe and indicating that European nations are closing the gap in total the U.S. over time. The disparity in AI investment widened AI-related public spending. until 2020 but has narrowed over the past three years, 800 700 600 500 400 300 200 100 0 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 Table of Contents Chapter 6 Preview 359 )srallod SU fo snoillim ni( stcartnoc detaler-IA no gnidneps cilbuP Chapter 6: Policy and Governance 6.3 Public Investment in AI Di erence in public spending on AI-related contracts between the United States and Europe, 2013–23 Source: AI Index, 2025 | Chart: 2025 AI Index report 249.60 Figure 6.3.7 Artificial Intelligence Index Report 2025 Figure 6.3.8 documents public investment trends from 2013 public investment in both 2021 and 2023. These investments to 2023 across the top five European countries—Belgium, followed the proposition of a national AI strategy by the AI France, Germany, Spain, and the U.K. The data reveals a Council—an independent expert committee established steady increase in investment, marked by periodic peaks. in 2019 to advise the government and provide high-level Germany experienced substantial growth, particularly in leadership of the AI ecosystem. Meanwhile, Belgium, France, 2019, following the launch of its national AI strategy in and Spain exhibited more modest but consistent growth. November 2018. The U.K. saw sharp increases in AI-related 300 250 200 150 100 50 0 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 Table of Contents Chapter 6 Preview 360 )srallod SU fo snoillim ni( stcartnoc detaler-IA no gnidneps cilbuP Chapter 6: Policy and Governance 6.3 Public Investment in AI Public spending on AI-related contracts in top 5 European countries, 2013–23 Source: AI Index, 2025 | Chart: 2025 AI Index report 262.77, United Kingdom 49.59, Spain 49.55, Germany 18.44, France 8.35, Belgium Figure 6.3.8 Artificial Intelligence Index Report 2025 Spending Across Agencies and Sectors The distribution of public tender investments in AI reflects Department of Veterans Affairs (6.8%) and the Department of stark contrasts between the U.S. and Europe, driven by the Treasury (5.3%). differing strategic priorities and institutional structures. As shown in Figure 6.3.9, the U.S. has allocated the majority of AI While the Department of Veterans Affairs may seem like an contracts since 2013 to the Department of Defense. This fact outlier, it has made significant investments in recent years— is unsurprising given the central role the American defense in areas that include the use of AI for diagnosis, robotic sector has played in American technological innovation. In prostheses, and mental health. 2023, the Department of Defense (75.0%) was followed by the 80% 70% 60% 50% 40% 30% 20% 10% 0% 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 Table of Contents Chapter 6 Preview 361 )latot fo %( stcartnoc detaler-IA no gnidneps cilbuP Chapter 6: Policy and Governance 6.3 Public Investment in AI Public spending on AI-related contracts (% of total) in the United States by funding agency, 2013–23 Source: AI Index, 2025 | Chart: 2025 AI Index report 75.04%, Department of Defense 6.83%, Department of Veterans A airs 5.34%, Department of the Treasury 3.98%, Department of Health and Human Services 2.30%, Department of Homeland Security 2.08%, Department of Commerce 1.57%, Other 0.97%, Department of Justice 0.80%, Department of Transportation 0.69%, National Aeronautics and Space Administration 0.32%, General Services Administration 0.05%, Department of Education 0.03%, Department of State Figure 6.3.9 Artificial Intelligence Index Report 2025 In Europe, AI investment through public tenders follows public services, education, and health—collectively account a markedly different pattern. Given the lack of aggregated for around 84% of total public AI investments in 2023. In the data comparable to that of the U.S., the AI Index categorized same year, defense accounted for only 0.84% of all European European funding entities by their central activity. As shown AI-related public tenders. This stands in stark contrast to the in Figure 6.3.10, there is a more balanced distribution of U.S., where defense overwhelmingly dominates AI funding. investments in Europe. The top funding areas—general 80% 70% 60% 50% 40% 30% 20% 10% 0% 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 Table of Contents Chapter 6 Preview 362 )latot fo %( stcartnoc detaler-IA no gnidneps cilbuP Chapter 6: Policy and Governance 6.3 Public Investment in AI Public spending on AI-related contracts (% of total) in Europe by funding agency activity, 2013–23 Source: AI Index, 2025 | Chart: 2025 AI Index report 64.05%, General public services 12.26%, Education 7.58%, Other 7.43%, Health 5.35%, Government 1.63%, Local authority 0.87%, Economic and �nancial a�airs 0.84%, Defense Figure 6.3.10 Artificial Intelligence Index Report 2025 Highlight: AI Grant Spending in the US US AI-related grants, 2013–23 Public grants also represent a key avenue through which Source: AI Index, 2025 | Table: 2025 AI Index report governments allocate resources to AI-related projects Grant statistics Value and initiatives. Public institutions can directly invest in Number of grants 18,399 AI-related projects such as enhancing X-ray angiography Total (in millions $) 19,748.44 interpretation, building AI-driven unmanned aircraft Median (in thousands $) 247.53 systems for automated soil monitoring, or developing tools Average (in thousands $) 1,073.34 for interpretable machine learning. Research grants can Total per 100,000 inhabitants (in thousands $) 5,967.69 be disbursed to organizations like the National Science Foundation or the Department of Health and Human Services (which includes NIH) to conduct AI-focused research. In this section, the AI Index examined data on grants in the U.S. allocated to AI-specific endeavors. As in the previous section, the AI Index employed NLP methodologies to identify AI-related grants.15 Figure 6.3.11 displays aggregate data on AI-related grant spending in the U.S. from 2013 to 2023. In that period, a total of roughly $19.7 billion was allocated by the U.S. government for AI-related grants. 4.49 4.50 4.00 3.50 3.00 2.50 2.00 1.50 1.00 0.50 0.00 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 15 The full methodology behind this approach can be found in the Appendix. Table of Contents Chapter 6 Preview 363 )srallod SU fo snoillib ni( stnarg detaler-IA no gnidneps cilbuP Chapter 6: Policy and Governance 6.3 Public Investment in AI Figure 6.3.11 Figure 6.3.12 illustrates the steady rise in AI-related grant funding over time. Between 2013 and 2023, total AI grant funding in the U.S. grew nearly nineteenfold, from $230 million to $4.5 billion. From 2014 to 2020, investments saw an average annual growth rate of 40%. This rapid expansion coincided with major advancements in AI technologies— such as deep learning, natural language processing, and computer vision—which likely fueled demand for public- sector AI applications and drove increased funding for related projects. Public spending on AI-related grants in the United States, 2013–23 Source: AI Index, 2025 | Chart: 2025 AI Index report Figure 6.3.12 Artificial Intelligence Index Report 2025 Highlight: AI Grant Spending in the US (cont’d) Department of Health and 43.57% Human Services National Science Foundation 27.91% Others 16.06% Department of Commerce 5.38% Department of Defense 2.62% Department of Agriculture 1.87% Department of Energy 1.47% National Aeronautics and 1.12% Space Administration 0% 5% 10% 15% 20% 25% 30% 35% 40% 45% Public spending on AI-related grants (% of total) Table of Contents Chapter 6 Preview 364 ycnega gnidnuF Chapter 6: Policy and Governance 6.3 Public Investment in AI Figure 6.3.13 illustrates the distribution of AI contract the Department of Health and Human Services (43.6%), values by funding agencies in the U.S. from 2013 to 2023. followed by the National Science Foundation (27.9%) and The greatest share of AI-related grants was allocated to the Department of Commerce (5.4%). Public spending on AI-related grants (% of total) by funding agency, 2013–23 Source: AI Index, 2025 | Chart: 2025 AI Index report Figure 6.3.13 Artificial Intelligence Index Report 2025 CHAPTER 7: Education Artificial Intelligence Index Report 2025 Chapter 7: Education Overview 366 Chapter Highlights 367 7.1 Background 368 7.2 K–12 CS and AI Education 369 United States 369 Foundational Computer Science 369 Advanced Computer Science 373 Education Standards and Guidance 376 Teacher Perspectives 377 Global 379 Access 379 Guidance 380 7.3 Postsecondary CS and AI Education 382 Degree Graduates 382 United States 382 Global 388 Guidance 392 7.4 Looking Ahead 393 ACCESS THE PUBLIC DATA Table of Contents 366 AArrttiifificciiaall IInntteelllliiggeennccee IInnddeexx RReeppoorrtt 22002255 CHAPTER 7: Education Overview AI has entered the public consciousness through generative AI’s impact on work— enhancing efficiency and automating tasks—but it has also driven innovation in education and personalized learning. Still, while AI promises benefits, it also poses risks—from hallucinating false outputs to reinforcing biases and diminishing critical thinking. With the AI education market expected to grow substantially, ethical concerns about the technology’s misuse—AI tools have already falsely accused marginalized students of cheating—are mounting, highlighting the need for responsible creation and deployment. Addressing these challenges requires both technical literacy and critical engagement with AI’s societal impact. Expanding AI expertise must begin in K–12 and higher education in order to ensure that students are prepared to be responsible users and developers. AI education cannot exist in isolation—it must align with broader computer science (CS) education efforts. This chapter examines the global state of AI and CS education, access disparities, and policies shaping AI’s role in learning. This chapter was a collaboration prepared by the Kapor Foundation, CSTA, PIT-UN and the AI Index. The Kapor Foundation works at the intersection of racial equity and technology to build equitable and inclusive computing education pathways, advance tech policies that mitigate harms and promote equitable opportunity, and deploy capital to support responsible, ethical, and equitable tech solutions. The CSTA is a global membership organization that unites, supports, and empowers educators to enhance the quality, accessibility, and inclusivity of computer science education. The Public Interest Technology University Network (PIT-UN) fosters collaboration between universities and colleges to build the PIT field and nurture a new generation of civic- minded technologists. Table of Contents Chapter 7 Preview 367 AArrttiifificciiaall IInntteelllliiggeennccee IInnddeexx RReeppoorrtt 22002255 CHAPTER 7: Education Chapter Highlights 1. Access to and enrollment in high school CS courses in the U.S. has increased slightly from the previous school year, but gaps remain. Student participation varies by state, race/ethnicity, school size, geography, income, gender, and disability. 2. CS teachers in the U.S. want to teach AI but do not feel equipped to do so. Despite 81% of CS teachers agreeing that using AI and learning about AI should be included in a foundational CS learning experience, less than half of high school CS teachers felt equipped to teach AI. 3. Two-thirds of countries worldwide offer or plan to offer K–12 CS education. This fraction has doubled since 2019, with African and Latin American countries progressing the most. However, students in African countries have the least access to CS education due to schools’ lack of electricity. 4. Graduates who earned their master’s degree in AI in the U.S. nearly doubled between 2022 and 2023. While increased attention on AI will be slower to emerge in the number of bachelor’s and PhD degrees, the surge in master’s degrees could indicate a future trend for all degree levels. 5. The U.S. continues to be a global leader in producing information, technology, and communications (ICT) graduates at all levels. Spain, Brazil, and the United Kingdom follow the U.S. as the top producers at various levels, while Turkey boasts the best gender parity. Table of Contents Chapter 7 Preview 368 Artificial Intelligence Index Report 2025 Chapter 7: Education 7.1 Background 7.1 Background To expand our understanding of the current state of AI risks of using it. AI education encompasses AI literacy plus education, it is imperative to differentiate between AI in students’ proficiency in the technical skills required to build education, AI literacy, and AI education (see Figure 7.1.1). AI (data analyses undergirding AI technologies, identifying AI in education is the usage of AI tools in the teaching and and mitigating data biases, etc.). For the purposes of this learning process while AI literacy refers to the foundational chapter, the data presented covers AI education. understanding of AI—how it works, how to use it, and the Figure 7.1.1 Table of Contents Chapter 7 Preview 369 Artificial Intelligence Index Report 2025 Chapter 7: Education 7.2 K–12 CS and AI Education The world faces significant challenges in developing a robust and diverse workforce when disparities in infrastructure, access to resources and courses, and participation in high quality 7.2 K–12 CS and AI Education1 coursework continue to exacerbate vast inequities in K–12 students’ ability United States to contribute to a technology-enabled future. While it is difficult to accurately To begin exploring the prevalence and quality of AI education within the United estimate the extent of the problem due to the unstandardized nature of data States, it is important to start with the CS education landscape in its earliest stages collection and metrics development, almost a decade ago. With the launch of President Barack Obama’s “Computer this section focuses on the earliest Science for All” initiative in 2016, billions in investments were provided to ensure that stage in the computing pipeline by all K–12 students learn CS to become creators in the digital economy and responsible examining the current status of K–12 CS and AI education with existing citizens of a technology-driven society. The federal funding was dedicated to global data. enhancing professional learning efforts, improving instructional resources, and building effective regional partnerships toward expanding CS education access. The National Science Foundation also led the development and implementation of two new computing courses (Exploring Computer Science and AP Computer Science Principles) aimed at engaging a broader group of students in computing. At the same time, the technology industry and philanthropy invested millions in national efforts to introduce millions of students across the country to CS. Public high schools teaching foundational CS (% of total in state), Foundational Computer Science 2024 In the past decade, educational Source: Code.org, CSTA, and ECEP Alliance, 2024 | Chart: 2025 AI Index report advocates have implored policymakers AK ME to adopt legislation to improve access 51% 63% to CS education. These efforts have VT NH MA 72% 95% 83% paid off. In the 2017–18 academic year, 35% of U.S. high schools offered CS, WA MT ND SD MN WI MI NY CT RI 50% 31% 47% 51% 36% 52% 54% 52% 84% 83% which increased to 60% of U.S. high schools in 2023–24. However, national OR ID WY NE IA IL IN OH PA NJ 60% 46% 74% 52% 84% 60% 91% 61% 75% 86% trends can obscure the reality that CA NV UT CO KS MO KY WV DC MD DE prioritization of CS education varies 52% 95% 81% 59% 35% 58% 76% 78% 53% 100% 61% by state. For example, 100% of high AZ NM OK AR TN VA NC schools in Arkansas and Maryland offer 43% 54% 64% 100% 61% 68% 69% CS, compared to only 31% in Montana TX LA MS AL GA SC (Figure 7.2.1). 56% 39% 85% 94% 78% 92% HI FL 72% 38% Figure 7.2.1 1 Since AI has historically been studied under CS, this chapter references CS education data when AI-specific data is unavailable. Table of Contents Chapter 7 Preview 370 Artificial Intelligence Index Report 2025 100% 91.18% 80% 76.40% 60% 43.12% 40% 20% 0% Small Medium Large Table of Contents Chapter 7 Preview 371 sloohcs fo % Schools o ering foundational CS courses by size, 2024 Source: Code.org, CSTA, and ECEP Alliance, 2024 | Chart: 2025 AI Index report 100% 80% 67.00% 65.01% 60.00% 60% 50.03% 40% 20% 0% <25% 25–49% 50–75% >75% % of students on free and reduced lunch sloohcs fo % 100% 80% 70.13% 60% 58.15% 56.05% 40% 20% 0% Urban Suburban Rural Schools o ering foundational CS courses by free and reduced lunch student population, 2024 Source: Code.org, CSTA, and ECEP Alliance, 2024 | Chart: 2025 AI Index report sloohcs fo % Chapter 7: Education 7.2 K–12 CS and AI Education Significant gaps remain in equitable access to CS education, lunch (FRL); those in small schools; students living in urban with some student groups left behind. In the 2023–24 and rural areas; and Native students were less likely to have academic year, students eligible for free or reduced-price access to CS education (Figures 7.2.2, 7.2.3, 7.2.4, and 7.2.5). Schools o ering foundational CS courses by geographic area, 2024 Source: Code.org, CSTA, and ECEP Alliance, 2024 | Chart: 2025 AI Index report Figure 7.2.2 Figure 7.2.3 Figure 7.2.4 Artificial Intelligence Index Report 2025 100% 91.55% 82.46% 82.98% 83.27% 79.74% 80.39% 80% 66.34% 60% 40% 20% 0% Native American Black Hispanic/Latino White Two+ races Native Hawaiian Asian Public high school enrollment in CS (% of students), 2024 Data about participation in CS Source: Code.org, CSTA, and ECEP Alliance, 2024 | Chart: 2025 AI Index report across 41 states indicates lags in student engagement with courses. AK ME In the 2020–21 academic year, - - only 5.1% of high school students VT NH MA participated in CS, with a marginal 4% - 8% increase to 6.4% in 2023–24. Similar WA MT ND SD MN WI MI NY CT RI 5% 4% 5% - 2% 4% - 5% 9% 18% to CS access, CS participation varies highly between states—with OR ID WY NE IA IL IN OH PA NJ 7% 2% 9% 4% 5% 7% 7% - 6% 9% 26% of high school students in South Carolina enrolled in CS but CA NV UT CO KS MO KY WV DC MD DE - - 13% - 3% 3% 11% 4% - 16% 5% only 2% enrolled in Florida, Arizona, and Idaho (Figure 7.2.6). AZ NM OK AR TN VA NC 2% 3% 5% 20% 6% 5% 5% TX LA MS AL GA SC 6% 3% 11% 8% 7% 26% HI FL 4% 2% Table of Contents Chapter 7 Preview 372 stneduts fo % Chapter 7: Education 7.2 K–12 CS and AI Education Access to foundational CS courses by race/ethnicity, 2024 Source: Code.org, CSTA, and ECEP Alliance, 2024 | Chart: 2025 AI Index report Figure 7.2.5 Figure 7.2.6 Artificial Intelligence Index Report 2025 Chapter 7: Education 7.2 K–12 CS and AI Education An analysis of CS enrollment by race and ethnicity shows underrepresented relative to their share of the K–12 population. that efforts to expand access have resulted in near or above Additionally, Hispanic and Native Hawaiian/Pacific Islander proportional representation for Black, Native American/ students, students with individualized education programs Alaskan, and white students at the national level (Figure (IEPs), those eligible for free or reduced-price lunch, and 7.2.7). However, data gaps—particularly from nine states— English language learners remain underrepresented nationally warrant caution in viewing these trends as complete. Girls are (Figure 7.2.7 and Figure 7.2.8). Public high school enrollment in CS vs. national demographics by race/ethnicity, 2024 Source: Code.org, CSTA, and ECEP Alliance, 2024 | Chart: 2025 AI Index report Asian 2.60 Black/African American 1.13 Hispanic/Latino/Latina/Latinx 0.69 Native American/Alaskan 1.00 Native Hawaiian/Paci c Islander 0.75 Two or more races 0.80 White 1.00 0 1 2 3 Ratio of enrollment in CS to national demographics Figure 7.2.7 Table of Contents Chapter 7 Preview 373 Artificial Intelligence Index Report 2025 Chapter 7: Education 7.2 K–12 CS and AI Education Public high school enrollment in CS vs. national demographics by subgroup, 2024 Source: Code.org, CSTA, and ECEP Alliance, 2024 | Chart: 2025 AI Index report Economically disadvantaged 0.72 English language learners 0.64 Girls 0.65 Students with 504 plans 1.33 Students with IEPs 0.67 0.00 0.50 1.00 1.50 Ratio of enrollment in CS to national demographics Figure 7.2.82 Advanced Computer Science In order to build students’ AI competencies, it is essential participating in the AP CS exam (Figure 7.2.9), students to offer access to advanced coursework in addition to do not participate in proportion to their racial and ethnic foundational courses. While AI is not specifically covered in representation in the general student body (Figure 7.2.10 Advanced Placement (AP) CS A, AP CS Principles (AP CS and Figure 7.2.11). Asian students, white boys, and multiracial P) does address some AI content areas. Because AP CS P students are overrepresented in the population of students was designed to attract a broader class of students, the who take AP CS exams, while all other student groups are potential exists to expose a diverse student population to AI underrepresented (Figure 7.2.12). topics. Yet, despite the growth in raw numbers of students 2 A student with a 504 plan receives accommodations under Section 504 of the Rehabilitation Act of 1973, a U.S. civil rights law that prohibits discrimination against individuals with disabilities. A student with an IEP (individualized education program) receives special education services under the Individuals with Disabilities Education Act. An IEP is a legally binding document that outlines a learning plan for a student with a disability designed to meet their unique needs and improve educational outcomes. Table of Contents Chapter 7 Preview 374 Artificial Intelligence Index Report 2025 Chapter 7: Education 7.2 K–12 CS and AI Education 250 243.18 201.61 200 179.19 181.04 158.56 150 130.90 99.87 100 54.38 50 46.34 37.33 29.55 24.78 19.39 19.83 20.96 19.39 21.14 0 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 Table of Contents Chapter 7 Preview 375 )sdnasuoht ni( nekat smaxe ecneics retupmoc PA fo rebmuN Number of AP computer science exams taken, 2007–23 Source: Code.org, CSTA, and ECEP Alliance, 2024 | Chart: 2025 AI Index report 90,000 80,000 70,000 60,000 50,000 40,000 30,000 20,000 10,000 0 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 nekat smaxe ecneics retupmoc PA fo rebmuN Figure 7.2.9 AP computer science exams taken by race/ethnicity, 2007–23 Source: Code.org, CSTA, and ECEP Alliance, 2024 | Chart: 2025 AI Index report 91,216, White 69,695, Asian 43,083, Hispanic/Latino/Latina 16,351, Black/African American 11,238, Two or more races 801, Native American/Alaskan 321, Native Hawaiian/Paci c Islander 0, Other Figure 7.2.10 Artificial Intelligence Index Report 2025 Chapter 7: Education 7.2 K–12 CS and AI Education 60% 50% 40% 30% 20% 10% 0% 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 Table of Contents Chapter 7 Preview 376 )stneduts gnidnopser latot fo %( nekat smaxe ecneics retupmoc PA AP computer science exams taken (% of total responding students) by race/ethnicity, 2007–23 Source: Code.org, CSTA, and ECEP Alliance, 2024 | Chart: 2025 AI Index report 37.50%, White 28.70%, Asian 17.70%, Hispanic/Latino/Latina 6.70%, Black/African American 4.60%, Two or more races 0.30%, Native American/Alaskan 0.10%, Native Hawaiian/Paci c Islander 0.00%, Other Figure 7.2.11 AP computer science exam participation vs. national demographics by race/ethnicity, 2023 Source: Code.org, CSTA, and ECEP Alliance, 2024 | Chart: 2025 AI Index report Asian Black/African American Hispanic/Latino/Latina/Latinx Native American/Alaskan Native Hawaiian/Paci c Islander Two or more races Male White Female 0 1 2 3 4 5 6 7 8 Ratio of AP CS exam participation to national demographics Figure 7.2.12 Artificial Intelligence Index Report 2025 Chapter 7: Education 7.2 K–12 CS and AI Education Education Standards and Guidance Federal guidance issued thus far has focused on AI in only two standards at the advanced high school level that education rather than AI education. The U.S. Department specifically require AI knowledge. However, existing CS of Education’s Office of Educational Technology released a standards support foundational AI knowledge and skills, series of reports about AI in education in 2023 and 2024. One covering topics such as perception, data structures, and of the reports focuses on recommendations for educational algorithms. The U.S. state-adopted K–12 CS standards technology developers, and two of them are intended for averaged 97% coverage of the same subconcepts as the educators, educational leaders, and policymakers. The most CSTA standards, indicating strong national coherence in CS recent report, from October 2024, offers guidance on the instruction. Among the 44 states that have adopted K–12 CS safe and effective implementation of AI in K–12 schools. standards, 33 have AI-specific standards, which are generally minimal, aligned to the CSTA standards, and focused on high As of January 2025, 26 states have issued guidance on AI in school grades (Figure 7.2.13).3 Four of these states recently education. And while there is considerable overlap between adopted more significant AI-specific standards that span CS and AI education content and what teachers currently grades K–12: Colorado (2024), Florida (2024), Ohio (2022), cover in the classroom, K–12 CS standards contain minimal and Virginia (2024), while Arkansas has defined standards for AI content. The Computer Science Teachers Association a high school AI and machine learning course. (CSTA) K–12 standards, last published in 2017, contain Adoption of AI-specific K 12 computer science standards by US state Source: CSTA and IACE, 2024 | Chart: 2025 AI Index report AK ME VT NH MA WA MT ND SD MN WI MI NY CT RI OR ID WY NE IA IL IN OH PA NJ CA NV UT CO KS MO KY WV DC MD DE AZ NM OK AR TN VA NC TX LA MS AL GA SC HI FL CS standards with significant AI-specific content CS standards with minimal AI-specific content CS standards with no AI-specific content No CS standards Figure 7.2.13 3 This project is supported by the National Science Foundation (NSF) under Grant No. 2311746. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the NSF. Table of Contents Chapter 7 Preview 377 Artificial Intelligence Index Report 2025 50% 46% 44% 40% 34% 30% 20% 10% 0% Elementary school Middle school High school 4 This project is supported by the National Science Foundation (NSF) under Grant No. 2118453. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the NSF. Survey responses may not total 100%, as some questions allowed respondents to select multiple options. 5 The percentages in the figure do not sum to 100% because respondents could select multiple options if they taught more than one grade level. Table of Contents Chapter 7 Preview 378 srehcaet fo % Percentage of teachers who feel equipped to teach AI by grade level Source: Computer Science Teacher Landscape Survey, 2024 | Chart: 2025 AI Index report Elementary school Middle school High school 100% 96% 96% 92% 93% 94% 84% 88% 86%85% 90% 87% 89% 82% 80% 75% 72% 74% 73% 65% 61% 60% 56% 51% 40% 20% 0% Algorithms Arti cial Intelligence Computing systems Computational Data and analysis Impacts and ethics Programming (AI) (e.g., hardware/ thinking of computing software) Concept srehcaet fo % Chapter 7: Education 7.2 K–12 CS and AI Education Teacher Perspectives To examine the perspectives and practices of CS teachers as it relates to AI education, the Computer Science Teacher Landscape Survey collected data from 2,901 pre-K through 12 CS teachers nationally (33% of respondents were elementary school teachers, 36% taught middle school, and 51% taught high school).4,5 As AI education gains importance for future workforce readiness, it is important to understand the preparedness of the current educator workforce. While 81% of CS teachers believe AI should be included in foundational CS education, less than half feel equipped to teach it—46% in high school, 44% in middle school, and just 34% in elementary school (Figure 7.2.14). When asked to identify the CS-related topics they cover in Figure 7.2.14 class, over two-thirds of middle and high school CS teachers stated they cover AI specifically, despite the lack of explicit of CS teachers said they include components of AI, such as definition in CS standards; fewer elementary teachers (65%) algorithms, computing systems, computational thinking, and reported covering AI (Figure 7.2.15). Greater proportions programming. AI concepts taught in CS classrooms by grade level Source: Computer Science Teacher Landscape Survey, 2024 | Chart: 2025 AI Index report Figure 7.2.15 Artificial Intelligence Index Report 2025 Elementary school Middle school High school 100% 80% 70% 60% 48% 42% 40% 35% 33% 22% 20% 17% 13% 6% 5% 6% 2% 0% 1–2 hours 3–5 hours 6–19 hours 20+ hours Time When asked to name the greatest benefits of using AI in To equip students to use AI responsibly, the educator the classroom, teachers most commonly said improving workforce must be upskilled. In a 2024 survey of 364 CS their productivity, differentiating student learning, providing teachers, 88% identified the need for more resources for AI- improved academic support to students, and preparing related professional development. When asked to identify students for the future. When asked about the greatest risks, specific resources, CS teachers said they needed to gain teachers’ greatest concerns were the misuse of AI (often more AI literacy (e.g., how AI works, how to use AI, and the related to academic integrity); that AI use could limit student ethical impacts of AI). learning or engagement; overreliance on the technology; that AI could generate misinformation and replicate biases; and other ethical concerns, including student privacy. Table of Contents Chapter 7 Preview 379 srehcaet fo % Chapter 7: Education 7.2 K–12 CS and AI Education Of the 2,245 teachers who did spend class time on AI content, the majority spent fewer than five hours per course. Elementary school teachers spent the least amount of time, with 70% spending only one to two hours (Figure 7.2.16). Time spent learning AI in CS classrooms by grade level Source: Computer Science Teacher Landscape Survey, 2024 | Chart: 2025 AI Index report Figure 7.2.16 Artificial Intelligence Index Report 2025 Chapter 7: Education 7.2 K–12 CS and AI Education Global Thus far, very few countries (e.g., Ghana, South Korea, Access Netherlands) include AI education in their curricula In 2024, approximately two-thirds of the world’s countries explicitly; countries more often flag the importance of AI offered or planned to offer CS education (Figure 7.2.17). education in the national education strategy conversation CS education is mandatory in primary and/or secondary without providing a detailed implementation plan. Because schools in 30% of countries, with Europe home to the highest AI education has historically been subsumed under CS concentration of these countries. In the past five years, or information and communications technology (ICT) all geographic regions have made progress in offering CS education, tracking CS and/or ICT education will serve as a education, with Africa and Latin America registering the largest proxy for tracking AI education in this analysis. Similar to the increases (Figure 7.2.18). Still, students in African countries are challenges inherent in tracking CS education in the United the least likely to have access to CS education. This is likely States, caution is called for when interpreting global metrics due to infrastructure challenges; in 2023, only 34% of primary because CS and ICT education are sometimes conflated schools in sub-Saharan Africa had access to electricity, with digital or computer literacy.6 hindering schools’ ability to teach students computer literacy skills, let alone providing them with CS and AI education. Availability of CS education by country, 2024 Source: Raspberry Pi Computing Education Research Centre, 2024 | Chart: 2025 AI Index report CS mandatory in primary and secondary CS mandatory in primary or secondary only CS as an elective course everywhere CS in some schools/districts CS cross curricular CS planned No CS Figure 7.2.17 6 Digital literacy is the “ability to use information and communication technologies to find, evaluate, create, and communicate information, requiring both cognitive and technical skills,” whereas computer literacy is the “general use of computers and programs, such as productivity software.” Table of Contents Chapter 7 Preview 380 Artificial Intelligence Index Report 2025 Globally, the lack of standardized data collection makes it challenging to track progress in AI education. Language barriers and infrequent updates on implementation further complicate accurate monitoring across countries. Africa 9.40% 49.05% (+39.65 pp) Asia 24.50% 57.89% (+33.39 pp) Europe 63.49% 88.88% (+25.39 pp) 2019 2024 LAC 29.54% 70.45% (+40.91 pp) 0% 20% 40% 60% 80% 100% % of countries o ering CS education Table of Contents Chapter 7 Preview 381 tnenitnoC Chapter 7: Education 7.2 K–12 CS and AI Education Change in access to CS education by continent, 2019 vs. 2024 Source: Raspberry Pi Computing Education Research Centre, 2024 | Chart: 2025 AI Index report Figure 7.2.18 Guidance Countries on a global scale have been quicker to develop to harnessing technologies toward ensuring “inclusive and guidance and policies for the use of AI in education as equitable quality education and promoting lifelong learning opposed to developing national standards for teaching AI. opportunities for all” (See Sustainable Development Goal As of November 2024, 10 countries have issued guidance 4). Since then, UNESCO published the Beijing Consensus on on AI in education: Australia, Belgium, Canada, Japan, New Artificial Intelligence and Education (in 2019) to offer specific Zealand, South Korea, Ukraine, the United Kingdom, the guidance on how to integrate AI technologies to ensure U.S., and Uruguay. This is not surprising given the decade- all people have access to quality education by 2030 (See long conversation across countries about developing Education 2030 Agenda). Within this set of recommendations, guidelines and policy recommendations for AI in education. there were four implementation and policy adoption guidelines As early as 2015, United Nations Educational, Scientific, and that touch upon AI concepts in K–12 education. Cultural Organization (UNESCO) member states committed Artificial Intelligence Index Report 2025 Chapter 7: Education 7.2 K–12 CS and AI Education Similar to the AI4K12 initiative, which released a set AI4K12 guidelines organized around 5 Big Ideas in AI of K–12 AI education standards organized around Source: AI4K12, 2024 “Five Big Ideas in AI” (Figure 7.2.19), international organizations are also developing AI curricular frameworks for countries to use. Last year, UNESCO published AI competency frameworks for students and teachers. The student framework includes four core competencies: a human-centered mindset, ethics of AI, AI techniques and applications, and AI system design. In each competency, students progress from understanding to applying to creating. In the European Union, many countries rely on DigComp 2.2, a framework for developing citizens’ digital competence, along with CS learning objectives for students. The most recent version has guidance on recommended knowledge, skills, and attitudes for interacting with AI, though it does not explicitly include guidance on teaching citizens to build AI systems. Figure 7.2.19 Table of Contents Chapter 7 Preview 382 Artificial Intelligence Index Report 2025 Chapter 7: Education 7.3 Postsecondary CS and AI Education The role AI will play in the U.S. labor force and the economic future is yet to be fully understood, but its impact is expected to be substantial. The technology workforce already contributes significantly to the U.S. economy, with 9.6 million working as tech employees across industries. While there are strong concerns about displaced employment as a result of automation, projected demands for AI-related roles, such as database management and data infrastructure solutions, are likely to increase. Therefore, a global commitment to ensure postsecondary institutions are equipped to train the future workforce and expand the computing pipeline is essential. 7.3 Postsecondary CS and AI Education Degree Graduates United States Data on U.S. postsecondary CS and AI education trends in offering certificate and both associate and bachelor’s degree this section comes from the National Center for Education programs in AI and related fields (Figure 7.3.2). Notable Statistics (NCES). Notably, the Classification of Instructional examples include Maricopa Community Colleges, Houston Programs (CIP), a national standard for classifying academic Community College, Miami Dade College, and several programs, was developed by NCES under the U.S. Department schools in the Bay Area Community College Consortium. of Education. In 2016, AI-specific curricula were designated under CIP code 11.0102, which covers programs focused The number of graduates with bachelor’s degrees in on “symbolic inference, representation, and simulation by computing has increased 22% over the last 10 years (Figure computers and software of human learning and reasoning 7.3.1). In 2023, the top five producers of CS bachelor’s processes and capabilities, and the computer modeling graduates were Western Governors University, University of of human motor control and motion. Includes instruction California–Berkeley, Southern New Hampshire University, in computing theory, cybernetics, human factors, natural University of Texas at Dallas, and University of Michigan.7 language processing, and applicable aspects of engineering, While the increased attention on AI will be slower to show technology, and specific end-use applications.” at the bachelor’s degree level, given its four-year cycle, AI’s explosive growth has already become visible in master’s While the number of students earning associate degrees in degrees, with a 26% increase in CS graduates between 2022 CS has largely remained stable over the past decade, several and 2023, and an overall increase of 83% in the last decade. community colleges are also pioneering AI education, 7 Western Governors University and Southern New Hampshire University are primarily online institutions. Table of Contents Chapter 7 Preview 383 Artificial Intelligence Index Report 2025 Male Female 100% 80% 68% 60% 77% 78% 76% 40% 20% 32% 23% 22% 24% 0% Associate Bachelor’s Master’s PhD Table of Contents Chapter 7 Preview 384 setaudarg yradnocestsop fo % 90,000 80,000 70,000 60,000 50,000 40,000 30,000 20,000 10,000 0 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 CS postsecondary graduates in the United States by gender, 2023 Source: National Center for Education Statistics’ Integrated Postsecondary Education Data System, 2013–23 | Chart: 2025 AI Index report setaudarg SC wen fo rebmuN Chapter 7: Education 7.3 Postsecondary CS and AI Education New CS postsecondary graduates in the United States, 2013–23 Source: National Center for Education Statistics’ Integrated Postsecondary Education Data System, 2013–23 | Chart: 2025 AI Index report 87,435, Bachelor’s 52,107, Master’s 20,725, Associate 2,540, PhD Figure 7.3.1 Despite the fact that women graduate from college at higher rates than men, degree completion data shows an underrepresentation of women in CS (Figure 7.3.2). Figure 7.3.2 Artificial Intelligence Index Report 2025 Chapter 7: Education 7.3 Postsecondary CS and AI Education Black students account for 8% of bachelor’s degrees, 8% of degrees and over half (52%) of PhDs in computing; and master’s degrees, and 7% of PhDs in computing (Figure 7.3.3). Asian students are overrepresented in the postsecondary Hispanic students account for 13% of bachelor’s degrees, computing space, accounting for 23% of bachelor’s degrees, 8% of master’s degrees, and 4% of PhDs in computing. By 28% of master’s degrees, and 17% of PhDs. contrast, white students account for 46% of bachelor’s CS vs. all postsecondary graduates in the United States by race/ethnicity (US residents only), 2023 Source: National Center for Education Statistics’ Integrated Postsecondary Education Data System, 2013–23 | Chart: 2025 AI Index report Native American/Alaskan Black Hispanic NHPI Two or more Asian White Unknown All 12% 27% 4% 6% 47% 4% Associate CS 12% 20% 4% 13% 44% 6% All 10% 18% 4% 9% 56% 3% Bachelor’s CS 8% 13% 4% 23% 46% 5% All 12% 13% 3% 8% 57% 6% Master’s CS 8% 8% 3% 28% 40% 12% All 10% 10% 3% 12% 58% 6% PhD CS 7% 4% 3% 17% 52% 15% 0% 20% 40% 60% 80% 100% % of postsecondary graduates Figure 7.3.3 The majority of students in computing-related graduate of the 95,130 international master’s students and 60% of the programs are from countries outside of the U.S.—a percentage 13,070 international PhD students) (Figure 7.3.4 and Figure that has steadily grown over the years. In 2023, nonresidents 7.3.5). accounted for 67% of master’s degree graduates and 60% of PhD graduates. Between 2022 and 2023, international The number of institutions in the U.S. that offer an AI-specific CS master’s students increased more than twofold, growing bachelor’s degree nearly doubled between 2022 and 2023, from 15,811 to 34,850 (IPEDS). Students from India and China while the number of institutions offering an AI-specific make up the vast majority of this graduate student body (93% master’s degree has sharply increased as well (Figure 7.3.6). Table of Contents Chapter 7 Preview 385 Artificial Intelligence Index Report 2025 Chapter 7: Education 7.3 Postsecondary CS and AI Education Number of international CS master’s students enrolled in US universities, 2022 Source: National Science Board; National Science Foundation, 2023 | Chart: 2025 AI Index report India 72.02 China 13.19 Taiwan 1.18 Nepal 0.99 Bangladesh 0.88 Nigeria 0.86 South Korea 0.53 Pakistan 0.48 Vietnam 0.29 Saudi Arabia 0.26 Turkey 0.23 Canada 0.23 Ghana 0.18 Brazil 0.14 Iran 0.14 Colombia 0.10 Japan 0.09 United Kingdom 0.08 France 0.07 Mexico 0.06 Other locations 3.14 0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 Number of international CS master’s students (in thousands) Figure 7.3.4 Number of international CS PhD students enrolled in US universities, 2022 Source: National Science Board; National Science Foundation, 2023 | Chart: 2025 AI Index report China 5,130 India 2,760 Bangladesh 980 Iran 660 South Korea 380 Saudi Arabia 370 Nepal 250 Pakistan 240 Taiwan 220 Nigeria 190 Vietnam 190 Turkey 160 Canada 130 Sri Lanka 80 Brazil 50 Ghana 50 Egypt 50 Colombia 40 Italy 40 Mexico 30 Other locations 1,060 0 300 600 900 1,200 1,500 1,800 2,100 2,400 2,700 3,000 3,300 3,600 3,900 4,200 4,500 4,800 5,100 Number of international CS PhD students Figure 7.3.5 Table of Contents Chapter 7 Preview 386 Artificial Intelligence Index Report 2025 45 40 35 30 25 20 15 10 5 0 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 Table of Contents Chapter 7 Preview 387 snoitutitsni fo rebmuN Chapter 7: Education 7.3 Postsecondary CS and AI Education Number of institutions o ering AI bachelor’s and master’s degrees in the US, 2013–23 Source: National Center for Education Statistics’ Integrated Postsecondary Education Data System, 2013–23 | Chart: 2025 AI Index report 45, Master’s 19, Bachelor’s Figure 7.3.6 There was a sharp increase in students graduating with graduates; meanwhile, Pennsylvania State University had its master’s degrees in AI between 2022 and 2023 (Figure first graduating class in 2022 (Figure 7.3.8). Until recently, 7.3.7). Carnegie Mellon University, which graduated more Carnegie Mellon was one of the only universities to offer AI majors than any other institution, doubled its number of dedicated programs in AI. 800 600 400 200 0 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 setaudarg IA wen fo rebmuN New AI bachelor’s and master’s graduates in the United States, 2013–23 Source: National Center for Education Statistics’ Integrated Postsecondary Education Data System, 2013–23 | Chart: 2025 AI Index report 935, Master’s 104, Bachelor’s Figure 7.3.7 Artificial Intelligence Index Report 2025 Chapter 7: Education 7.3 Postsecondary CS and AI Education Top postsecondary institutions graduating students in AI in 2023 by degree type8 Source: National Center for Education Statistics’ Integrated Postsecondary Education Data System, 2023 Graduates in AI Bachelor’s Programs Carnegie Mellon University 32 Full Sail University 19 Concordia University Wisconsin 16 University of Advancing Technology 10 Pennsylvania State University-Main Campus 7 Graduates in AI Master’s Programs Carnegie Mellon University 178 University of Pennsylvania 98 University of North Texas 76 Northeastern University 55 San Jose State University 52 Graduates in AI PhD Programs Carnegie Mellon University 28 Capitol Technology University 4 University of Pittsburgh-Pittsburgh Campus 1 Figure 7.3.8 8 This list includes only universities that use the AI-specific CIP code for their programs, rather than general CS. However, many students studying AI worldwide are likely enrolled in broader CS programs. Table of Contents Chapter 7 Preview 388 Artificial Intelligence Index Report 2025 Chapter 7: Education 7.3 Postsecondary CS and AI Education Global No single dataset provides a fully standardized accounting digital information, including computers, computerised of AI or CS postsecondary education across all countries. networks (including the Internet), microelectronics, However, the Organization for Economic Cooperation multimedia, software and programming.” and Development has compiled data covering its member countries and several non-OECD nations.9 The International The U.S. remains a global leader in ICT-related fields, Standard Classification of Education is used to compare producing more graduates at each of the associate, education statistics relied on by the OECD to evaluate global bachelor’s, master’s, and PhD levels than any other country progress. Information and communications technologies, or included in the sample (Figures 7.3.9 to 7.3.12). Notably, the ICT, includes such areas of study as “informatics, information U.S. graduates more than twice as many associate, master’s, and communication technologies, or CS. These subjects and PhD students—and nearly twice as many bachelor’s include a wide range of topics concerned with the new students—as the next highest country (Figure 7.3.9). technologies used for the processing and transmission of New ICT short-cycle tertiary graduates by country, 2022 Source: OECD, 2022 | Chart: 2025 AI Index report United States 38,746 Spain 17,764 Turkey 16,464 Canada 16,275 Colombia 12,852 France 10,820 United Kingdom 9,425 Australia 7,249 South Korea 6,983 Mexico 3,720 Chile 2,946 Sweden 2,885 Israel 2,157 New Zealand 1,889 Austria 1,273 0 3,000 6,000 9,000 12,000 15,000 18,000 21,000 24,000 27,000 30,000 33,000 36,000 39,000 Number of new ICT short-cycle tertiary graduates Figure 7.3.9 9 While this dataset provides insights across some country lines, it omits a number of countries likely to have large numbers of ICT graduates. The exclusion of India, China, and countries in Africa highlights the need for global standardized data collection to ensure inclusion of countries that have made significant investments in computing education and make up a significant proportion of the global majority. There is also a significant lag in collecting and reporting global data on education; as a result, the most recent year for which data is available is 2022. Table of Contents Chapter 7 Preview 389 Artificial Intelligence Index Report 2025 Chapter 7: Education 7.3 Postsecondary CS and AI Education New ICT bachelor’s graduates by country, 2022 Source: OECD, 2022 | Chart: 2025 AI Index report United States 116,401 Brazil 61,760 Mexico 32,738 Germany 21,365 United Kingdom 20,435 South Korea 19,603 Australia 14,584 Peru 13,054 Canada 13,053 Poland 12,817 France 10,472 Spain 6,650 Romania 6,256 Turkey 6,023 Chile 5,090 0 8,000 16,000 24,000 32,000 40,000 48,000 56,000 64,000 72,000 80,000 88,000 96,000 104,000 112,000 120,000 Number of new ICT bachelor’s graduates Figure 7.3.10 New ICT master’s graduates by country, 2022 Source: OECD, 2022 | Chart: 2025 AI Index report United States 55,706 United Kingdom 21,688 France 13,940 Germany 12,500 Australia 9,716 Poland 4,164 Canada 4,044 Ireland 3,728 Mexico 3,373 Spain 3,214 Colombia 2,982 Korea 2,910 Netherlands 2,452 Italy 2,403 Romania 2,200 0 4,000 8,000 12,000 16,000 20,000 24,000 28,000 32,000 36,000 40,000 44,000 48,000 52,000 56,000 Number of new ICT master’s graduates Figure 7.3.11 Table of Contents Chapter 7 Preview 390 Artificial Intelligence Index Report 2025 Chapter 7: Education 7.3 Postsecondary CS and AI Education New ICT PhD graduates by country, 2022 Source: OECD, 2022 | Chart: 2025 AI Index report United States 2,759 United Kingdom 1,156 Germany 1,008 France 733 South Korea 617 Australia 425 Brazil 374 Canada 309 Spain 247 Italy 194 Mexico 144 Switzerland 142 Finland 140 Sweden 122 Netherlands 120 0 150 300 450 600 750 900 1,050 1,200 1,350 1,500 1,650 1,800 1,950 2,100 2,250 2,400 2,550 2,700 2,850 Number of new ICT PhD graduates Figure 7.3.12 Gender parity in AI-related fields continues to be a challenge one-third of graduates. Turkey is among the countries that globally (Figure 7.3.13). On average, women comprise fare best with respect to gender parity, with women there approximately one-quarter of ICT postsecondary graduates comprising at least half of all graduates at the associate, at the associate, bachelor’s, and PhD levels. Women fare bachelor’s, master’s, and PhD levels. slightly better at the master’s level, comprising closer to Table of Contents Chapter 7 Preview 391 Artificial Intelligence Index Report 2025 Percentage of new ICT postsecondary graduates who are female by country, 2022 Source: OECD, 2022 | Chart: 2025 AI Index report 100% Australia 100% Austria 100% Belgium 100% Brazil 50% 24% 23% 33% 34% 50% 10% 19% 21% 13% 50% 10% 14% 17% 50% 15% 19% 19% NA NA 0% 0% 0% 0% SC B M PhD SC B M PhD SC B M PhD SC B M PhD 100% Bulgaria 100% Canada 100% Chile 100% Colombia 50% 35% 40% 25% 50% 29% 22% 31% 24% 50% 13% 12% 22% 50% 25% 18% 28% 38% NA NA 0% 0% 0% 0% SC B M PhD SC B M PhD SC B M PhD SC B M PhD 100% Costa Rica 100% Croatia 100% Czech Republic 100% Denmark 50% 31% 21% 18% 50% 26% 25% 50% 16% 19% 18% 50% 10% 19% 35% NA NA NA NA NA 0% 0% 0% 0% SC B M PhD SC B M PhD SC B M PhD SC B M PhD 100% Estonia 100% Finland 100% France 100% Germany 50% 24% 45% 38% 50% 25% 30% 21% 50% 14% 17% 22% 26% 50% 21% 24% 20% NA NA NA 0% 0% 0% 0% SC B M PhD SC B M PhD SC B M PhD SC B M PhD 100% Greece 100% Hungary 100% Iceland 100% Ireland 50% 30% 42% 22% 50% 12% 18% 18% 17% 50% 28% 9% 50% 37% 27% 36% 35% NA NA NA 0% 0% 0% 0% SC B M PhD SC B M PhD SC B M PhD SC B M PhD 100% Israel 100% Italy 100% South Korea 100% Latvia 56% 50% 32% 18% 28% 50% 17% 17% 25% 28% 50% 26% 32% 23% 15% 50% 20% 21% 28% NA 0% 0% 0% 0% SC B M PhD SC B M PhD SC B M PhD SC B M PhD 100% Lithuania 100% Luxembourg 100% Mexico 100% Netherlands 50% 16% 34% 50% 13% 17% 42% 23% 50% 27% 27% 33% 33% 50% 13% 15% 29% 14% NA NA 0% 0% 0% 0% SC B M PhD SC B M PhD SC B M PhD SC B M PhD 100% New Zealand 100% Norway 100% Peru 100% Poland 50% 36% 29% 34% 35% 50% 27% 23% 29% 43% 50% 31% 50% 23% 19% 12% NA NA NA NA 0% 0% 0% 0% SC B M PhD SC B M PhD SC B M PhD SC B M PhD 100% Portugal 100% Romania 100% Slovakia 100% Slovenia 50% 37% 50% 33% 42% 35% 50% 50% 6% 20% 11% NA NA 18% 17% 11% 13% 21% 23% 15% 0% 0% 0% 0% SC B M PhD SC B M PhD SC B M PhD SC B M PhD 100% Spain 100% Sweden 100% Switzerland 100% Turkey 55% 50% 51% 53% 50% 12% 14% 22% 23% 50% 30% 36% 41% 33% 50% 11% 17% 19% 50% NA 0% 0% 0% 0% SC B M PhD SC B M PhD SC B M PhD SC B M PhD 100% United Kingdom 100% United States Short-cycle (SC) Bachelor’s (B) 50% 24% 18% 31% 28% 50% 24% 24% 35% 26% Master’s (M) 0% 0% PhD SC B M PhD SC B M PhD Figure 7.3.13 Table of Contents Chapter 7 Preview 392 setaudarg yradnocestsop TCI elamef fo % Chapter 7: Education 7.3 Postsecondary CS and AI Education Artificial Intelligence Index Report 2025 Chapter 7: Education 7.3 Postsecondary CS and AI Education Guidance Most existing university policies and guidance around AI are the most impacted by AI, almost all institutional policies pertain to how students use AI for assignments; guidance on are affected by technology policies (e.g., purchasing AI tools AI education itself tends to be relegated to the department using university resources, respecting intellectual property/ level (primarily in computing departments). copyright laws, using AI to create malware or viruses)—from cybersecurity and data privacy to online learning and data AI is being used across campuses by both students and and analytics. faculty at high rates: 86% of students use AI in their studies, and 61% of faculty use AI in their teaching. Yet the guidelines In addition to the K–12 guidance UNESCO provided in the 2019 around usage still lack clarity and standardization across Beijing Consensus on Artificial Intelligence and Education, it universities. As of early 2025, 39% of institutions have an AI- offered specific guidance that is relevant for both K–12 and related acceptable use policy, an increase of 16 percentage postsecondary settings with an eye toward achieving the points from 2024. Larger universities (10,000-plus students) Education 2030 agenda goals via AI technologies. The 2019 are more likely to have a policy than smaller institutions (fewer report includes five implementation and policy guidelines than 5,000 students). Although teaching and learning policies pertaining to AI education in postsecondary settings. Table of Contents Chapter 7 Preview 393 Artificial Intelligence Index Report 2025 Chapter 7: Education 7.4 Looking Ahead 7.4 Looking Ahead The intentional design of an equitable AI educational future. There are already CS-based infrastructure, policies, ecosystem will be critical for the responsible development and implementation strategies that offer opportunities to and deployment of future technological innovations. The integrate AI education more seamlessly. As AI innovations current systems in which AI has proliferated have led to rapidly evolve, transforming education is urgent so that detrimental outcomes, such as mis/disinformation campaigns future creators of these technologies are made aware of to influence national political outcomes, development of AI- potential harms and have the competencies to mitigate enabled weapons, and infringement of copyright-protected negative impacts. Academic institutions around the world intellectual property. The pressing need to prioritize a must continue to progress (and monitor their progress) on better approach to building AI is evident. To do so, it is creating AI pathways, adopt policies to expand access to necessary to reimagine an educational program where AI relevant courses, and implement strategies to upskill the competencies, inclusive of building a lens interrogating educator workforce and engage students to participate and the ethics of AI in addition to technical creation, are seen build competencies equitably. as core to preparing students for a technology-powered Table of Contents Chapter 7 Preview 394 AArrttiifificciiaall IInntteelllliiggeennccee IInnddeexx RReeppoorrtt 22002255 CHAPTER 8: Public Opinion Text and analysis by Emily Capstick Table of Contents Chapter 8 Preview 395 Artificial Intelligence Index Report 2025 Chapter 8: Public Opinion Overview 396 Chapter Highlights 397 8.1 Public Opinion 399 Global Public Opinion 399 AI Products and Services 399 AI and Jobs 405 AI and Livelihood 407 Highlight: Self-Driving Cars 409 8.2 US Policymaker Opinion 410 ACCESS THE PUBLIC DATA Table of Contents 396 AArrttiifificciiaall IInntteelllliiggeennccee IInnddeexx RReeppoorrtt 22002255 CHAPTER 8: Public Opinion Overview As AI continues to permeate broad swaths of society, it is becoming increasingly important to understand public sentiment around the technology. Insights into how people perceive AI can help anticipate its societal impact and reveal how adoption varies across countries and demographic groups. Early data suggests growing public anxiety about AI, with some regions expressing significantly more pessimism than others. As the technology continues to advance, will these trends persist? This chapter explores public opinion on AI through global, national, demographic, and ethnic perspectives. It draws on multiple data sources, including longitudinal Ipsos surveys tracking global AI attitudes, American Automobile Association surveys on self- driving vehicles, and recent research into local U.S. policymakers’ views on AI. Table of Contents Chapter 8 Preview 397 AArrttiifificciiaall IInntteelllliiggeennccee IInnddeexx RReeppoorrtt 22002255 CHAPTER 8: Public Opinion Chapter Highlights 1. The world grows cautiously optimistic about AI products and services. Among the 26 nations surveyed by Ipsos in both 2022 and 2024, 18 saw an increase in the proportion of people who believe AI products and services offer more benefits than drawbacks. Globally, the share of individuals who see AI products and services as more beneficial than harmful has risen from 52% in 2022 to 55% in 2024. 2. The expectation and acknowledgment of AI’s impact on daily life is rising. Around the world, two thirds of people now believe that AI-powered products and services will significantly impact daily life within the next three to five years—an increase of six percentage points since 2022. Every country except Malaysia, Poland, and India saw an increase in this perception since 2022, with the largest jumps in Canada (17%) and Germany (15%). 3. Skepticism about the ethical conduct of AI companies is growing, while trust in the fairness of AI is declining. Globally, confidence that AI companies protect personal data fell from 50% in 2023 to 47% in 2024. Likewise, fewer people today believe that AI systems are unbiased and free from discrimination compared to last year. 4. Regional differences persist regarding AI optimism. First reported in the 2023 AI Index, significant regional differences in AI optimism endure. A large majority of people believe AI-powered products and services offer more benefits than drawbacks in countries like China (83%), Indonesia (80%), and Thailand (77%), while only a minority share this view in Canada (40%), the United States (39%), and the Netherlands (36%). 5. People in the United States remain distrustful of self-driving cars. A recent American Automobile Association survey found that 61% of people in the U.S. fear self-driving cars, and only 13% trust them. Although the percentage who express fear has declined from its 2023 peak of 68%, it remains higher than in 2021 (54%). 6. There is broad support for AI regulation among local U.S. policymakers. In 2023, 73.7% of local U.S. policymakers—spanning township, municipal, and county levels—agreed that AI should be regulated, up significantly from 55.7% in 2022. Support was stronger among Democrats (79.2%) than Republicans (55.5%), though both registered notable increases over 2022. Table of Contents Chapter 8 Preview 398 AArrttiifificciiaall IInntteelllliiggeennccee IInnddeexx RReeppoorrtt 22002255 CHAPTER 8: Public Opinion Chapter Highlights (cont’d) 7. AI optimism registers sharp increase among countries that previously showed the most skepticism. Globally, optimism about AI products and services has increased, with the sharpest gains in countries that were previously the most skeptical. In 2022, Great Britain (38%), Germany (37%), the United States (35%), Canada (32%), and France (31%) were among the least likely to view AI as having more benefits than drawbacks. Since then, optimism has grown in these countries by 8%, 10%, 4%, 8%, and 10%, respectively. 8. Workers expect AI to reshape jobs, but fear of replacement remains lower. Globally, 60% of respondents agree that AI will change how individuals do their job in the next five years. However, a smaller subset of respondents, 36%, believe that AI will replace their jobs in the next five years. 9. Sharp divides exist among local U.S. policymakers on AI policy priorities. While local U.S. policymakers broadly support AI regulation, their priorities vary. The strongest backing is for stricter data privacy rules (80.4%), retraining for the unemployed (76.2%), and AI deployment regulations (72.5%). However, support drops significantly for a law enforcement facial recognition ban (34.2%), wage subsidies for wage declines (32.9%), and universal basic income (24.6%). 10. AI is seen as a time saver and entertainment booster, but doubts remain on its economic impact. Global perspectives on AI’s impact vary. While 55% believe it will save time, and 51% expect it will offer better entertainment options, fewer are confident in its health or economic benefits. Only 38% think AI will improve health, whilst 36% think AI will improve the national economy, 31% see a positive impact on the job market, and 37% believe it will enhance their own jobs. Table of Contents Chapter 8 Preview 399 Artificial Intelligence Index Report 2025 Chapter 8: Public Opinion 8.1 Public Opinion 8.1 Public Opinion Global Public Opinion This section explores global differences in opinions on AI In 2024, 67% of respondents report a good understanding of through surveys conducted by Ipsos in 2022, 2023, and what AI is, and 66% anticipate that AI will profoundly change 2024. These surveys reveal that public perceptions of AI vary their daily life in the near future. The proportion of the global widely across countries and demographic groups. population that perceives AI-powered products and services as having more benefits than drawbacks has increased AI Products and Services modestly, rising from 52% in 2022 to 55% in 2024. In 2024, Ipsos ran a survey on global attitudes toward AI. The survey consisted of interviews with 23,685 adults across 32 Figure 8.1.1 also highlights respondents’ growing concerns. countries.1 In the last year, there has been a three percentage point decrease in those who trust that companies using AI will Figure 8.1.1 shows the percentage of respondents who agree protect their personal data and a two percentage point with specific statements. The increase in public awareness of decrease in respondents’ trust that AI will not discriminate or AI between 2022 and 2024 has remained relatively consistent. show bias toward any group of people. Global opinions on products and services using AI (% of total), 2022–24 Source: Ipsos, 2022–24 | Chart: 2025 AI Index report I have a good understanding of what 67% 67% arti cial intelligence is 64% I know which types of products and 52% 51% services use arti cial intelligence 50% Products and services using arti cial 50% intelligence have profoundly changed 49% my daily life in the past 3–5 years 49% Products and services using arti cial 66% intelligence will profoundly change 66% my daily life in the next 3–5 years 60% Products and services using arti cial 55% intelligence have more bene ts than 54% drawbacks 52% I trust people not to discriminate or 45% show bias toward any group of people I trust arti cial intelligence to not 54% discriminate or show bias toward 56% any group of people I trust that companies that use 47% 2024 arti cial intelligence will protect 50% my personal data 2023 Products and services using arti cial 50% 2022 52% intelligence make me nervous 39% 0% 10% 20% 30% 40% 50% 60% 70% % of respondents that “Agree” Figure 8.1.1 1 See Appendix for more details about the survey methodology. The survey was conducted from April to May, 2024. Table of Contents Chapter 8 Preview 400 Artificial Intelligence Index Report 2025 Chapter 8: Public Opinion 8.1 Public Opinion Perceptions of AI’s benefits versus drawbacks vary AI sentiment appears to be warming, particularly in countries considerably by country, according to the Ipsos survey. In that were once the most skeptical. Among the 26 nations general, respondents in Asia and Latin America believe that AI surveyed by Ipsos in both 2022 and 2024, 18 saw an increase will have more benefits than drawbacks: 83% of Chinese, 70% in the proportion of people who believe AI products and of Mexican, and 62% of Indian respondents view AI products services offer more benefits than drawbacks. In 2022, France and services as more beneficial than harmful (Figure 8.1.2). (31%), Canada (32%), the United States (35%), Germany (37%), In contrast, in Europe and the Anglosphere, respondents are Australia (37%), and Great Britain (38%) ranked among the more skeptical. For example, 46% of British, 44% of Australian, least optimistic about AI. By 2024, the percentages in all these 40% of Canadian, and 39% of American respondents believe countries had risen. that AI will have more benefits than drawbacks. Figure 8.1.2 Table of Contents Chapter 8 Preview 401 Artificial Intelligence Index Report 2025 Chapter 8: Public Opinion 8.1 Public Opinion Figure 8.1.3 shows responses to Ipsos’ survey on AI products to five years. Conversely, just 58% of American respondents and services by country. On average, survey respondents thought that AI would profoundly change their life in the in China had the highest level of awareness, trust, and next three to five years, and 34% reported that products and excitement about AI’s use in products and services: 81% of services using AI made them excited. respondents in China knew what products and services use AI, 80% reported that those products and services made Concerns about the privacy of personal data appear to be them excited, 76% trusted AI to not discriminate or show bias, strongest in Japan and Canada, while concerns about AI and overall 86% believed that products and services using discriminating against certain groups was highest in Sweden AI would profoundly change their daily life in the next three and Belgium. Figure 8.1.3 Table of Contents Chapter 8 Preview 402 Artificial Intelligence Index Report 2025 Figure 8.1.4 illustrates respondents’ answers to whether they the highest levels of nervousness and the lowest excitement are excited about AI and whether they are nervous about it. about AI. In contrast, several Asian countries, including Notable cross-country trends emerge. As previously noted, China, South Korea, and Indonesia, exhibit higher excitement many Anglosphere nations—such as the United Kingdom, the and lower nervousness levels, with Japan standing as an United States, Canada, Australia, and New Zealand—report exception to this trend. 100% 90% 80% 70% Ireland New Zealand United States Australia 60% Canada Singapore Sweden Switzerland Global Peru Turkey Thailand 50% Belgium Spain Brazil Indonesia Netherlands Colombia South Korea 40% Germany China Poland 30% Japan 20% 10% 0% 0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% Excited (% of respondents that “Agree”) Table of Contents Chapter 8 Preview 403 )”eergA“ taht stnednopser fo %( suovreN Chapter 8: Public Opinion 8.1 Public Opinion Global opinions about products and services using AI by country, 2024 Source: Ipsos, 2024 | Chart: 2025 AI Index report Great Britain India Chile Mexico South Africa France Hungary Argentina Malaysia Italy Figure 8.1.4 Artificial Intelligence Index Report 2025 Chapter 8: Public Opinion 8.1 Public Opinion A majority of the countries surveyed by Ipsos in 2023 were Brazil and Malaysia saw the sharpest average decline in surveyed again in 2024, enabling cross-year comparisons. awareness, trust, and excitement about AI. In both countries, Figure 8.1.5 highlights the year-over-year change in answers that negative trend was led by sharp declines in respondents to particular AI-related questions. Overall, the AI Index who trust AI companies to protect their personal data. observes slightly rising concerns about the use of AI, with an average 0.6% decrease in positive responses. This is South Africa and Ireland saw the sharpest average increases in largely driven by a 3% decrease in trust that companies that awareness, trust, and excitement about AI. Ireland’s positive use AI will protect personal data, and a 2% decrease in trust trend appears to be led by positive user experiences, since it that AI will not discriminate or show bias toward any group reports the highest increase across countries in respondents of people.2 who say their daily lives have been profoundly impacted by products and services using AI. Figure 8.1.5 2 Average global responses to the question “Products and services using AI make me nervous” are excluded from this average because this is the only question where a positive score would yield a normatively negative result. Table of Contents Chapter 8 Preview 404 Artificial Intelligence Index Report 2025 Chapter 8: Public Opinion 8.1 Public Opinion Figure 8.1.6 compares responses from the 2022 and 2024 the next three to five years has risen by 6%. Every country Ipsos surveys, highlighting shifts in sentiment since the except India, Malaysia, and Poland saw an increase in this launch of ChatGPT. Globally, the belief that AI-powered perception since 2022, with the largest jumps in Canada products and services will profoundly change daily life within (17%) and Germany (15%). Figure 8.1.6 Table of Contents Chapter 8 Preview 405 Artificial Intelligence Index Report 2025 Chapter 8: Public Opinion 8.1 Public Opinion AI and Jobs This year’s Ipsos survey included more questions about how Year-over-year comparisons for this question are challenging people perceive AI’s impact on their current jobs. Figure because in 2023 the survey did not differentiate between 8.1.7 illustrates various global perspectives on the expected “very likely” and “somewhat likely.” Nevertheless, when the impact of AI on employment. Overall, 60% of respondents 2024 categories are aggregated and compared to the 2023 believe AI is likely to change how they do their job in the next results, the overall sentiment appears largely unchanged. In five years and 36%, or more than one in three, believe that AI 2023, 57% of respondents agreed that AI would change how is likely to replace their current job in the next five years. jobs are done, while 36% believed AI was likely to replace their job within five years. Global opinions on the perceived impact of AI on current jobs, 2024 Source: Ipsos, 2024 | Chart: 2025 AI Index report Very likely Somewhat likely Don’t know Not very likely Not at all likely AI will change how you do your 21% 39% 8% 22% 10% current job in the next 5 years AI will replace your current job 11% 25% 8% 33% 23% in the next 5 years 0% 20% 40% 60% 80% 100% % of respondents Figure 8.1.7 Table of Contents Chapter 8 Preview 406 Artificial Intelligence Index Report 2025 Chapter 8: Public Opinion 8.1 Public Opinion Opinions on whether AI will significantly impact an Across 2023 and 2024, all generations increasingly agree individual’s job vary across demographic groups (Figure that AI will change how they do their jobs over the next five 8.1.8). Younger generations, such as Gen Z and millennials, years. Interestingly, of the 3% who believe AI will change are more inclined to agree that AI will change how they do how they do their jobs, the greatest increase was among both their jobs compared to older generations like Gen X and baby millennials and baby boomers, perhaps indicating increasing boomers. Specifically, in 2024, 67% of Gen Z compared to cross-generational awareness. 49% of boomers agree with the statement that AI will likely affect their current jobs. Global opinions on whether AI will change how current jobs are done in the next ve years (% agreeing with statement), 2023 vs. 2024 Source: Ipsos, 2024 | Chart: 2025 AI Index report 67% Gen Z 66% 64% Millennial 61% 55% Gen X 53% Baby 49% 2024 boomer 46% 2023 0% 10% 20% 30% 40% 50% 60% 70% % of respondents Figure 8.1.8 Table of Contents Chapter 8 Preview 407 Artificial Intelligence Index Report 2025 Chapter 8: Public Opinion 8.1 Public Opinion AI and Livelihood The Ipsos survey also explored the impact that respondents Conversely, less than 25% of respondents in the Netherlands, believe AI will have on various aspects of their lives, such as the United States, Belgium, Sweden, and Canada believe that the economy, entertainment, and health. AI will improve the economy. Figure 8.1.9 shows that 55% of global respondents said Within each country, respondents with an optimistic outlook they believe AI will reduce the amount of time it takes them on AI’s impact on the economy tended to express optimism in to get things done, and 51% believe AI will improve their other areas. For example, countries that expressed the highest entertainment options. Opinions on the economy and the job expectation that AI will positively impact their economy also market were more skeptical. In these sectors, just 36% and tended to believe that AI will reduce the amount of time it 31% of respondents believe AI will have a positive impact. takes to get things done and that AI will improve health. Figure 8.1.9 also shows significant range in respondents As a global average, 38% of respondents believe AI will who believe AI will improve the economy in their country. improve health. Mexico reported the highest rates of Countries in Asia are the most optimistic about AI’s economic optimism, with 56% believing that AI will have a positive impact, with 72% of respondents in China saying they expect impact on health. Conversely only 19% of respondents in AI to improve the economy, followed by 54% in Indonesia. Japan had positive expectations of AI’s impact on health. Figure 8.1.9 Table of Contents Chapter 8 Preview 408 Artificial Intelligence Index Report 2025 100% 90% 80% 70% China 60% Indonesia Peru 50% South Afric C a olom T b ha ia iland Mexico Brazil India 40% Chile Singapore Malaysia Turkey Ireland Argentina Sweden 30% Belgium Switzerland Canada Hungary 20% Japan 10% 0% 0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% The job market (% of respondents) Table of Contents Chapter 8 Preview 409 )stnednopser fo %( sboj laudividnI Global opinion on the potential of AI to improve the job market vs. individual jobs, 2024 Source: Ipsos, 2024 | Chart: 2025 AI Index report France United States Australia New Zealand Italy Global Spain Germany South Korea Netherlands Poland Great Britain 100% 90% 80% 70% China 60% Indonesia Peru Thailand South Africa 50% Brazil Mal I a n y d s i i a a Turkey Colombia 40% Argentina Singapore Ireland GlobalChile New Zealand 30% Switzerland Netherlands Canada Hungary South Korea 20% Poland Japan 10% 0% 0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% Amount of time to get things done (% of respondents) )stnednopser fo %( sboj laudividnI Chapter 8: Public Opinion 8.1 Public Opinion Figure 8.1.10 and Figure 8.1.11 provide a correlative analysis of agreement, respectively. In contrast, sentiment is much more the preceding data, examining the extent to which responses positive in China, where 44% believe AI will enhance the job to certain questions are interrelated. Notably, there is a strong market, and 62% think it will improve their jobs. correlation between respondents’ agreement that AI will improve the job market and their belief that it will benefit their Similarly, countries where respondents believe AI will reduce own jobs. In some countries, such as Poland, optimism on both the time required to complete tasks are also more likely to fronts is low, with only 17% and 21% of respondents expressing report that AI will improve their individual jobs. Figure 8.1.10 Global opinion on the potential of AI to improve time to get things done vs. individual jobs, 2024 Source: Ipsos, 2024 | Chart: 2025 AI Index report France Mexico United States Australia Sweden Italy Spain Germany Belgium Great Britain Figure 8.1.11 Artificial Intelligence Index Report 2025 Afraid Unsure Trust 100% 9% 9% 14% 15% 13% 80% 23% 25% 26% 32% 30% 60% 40% 68% 66% 61% 54% 55% 20% 0% 2021 2022 2023 2024 2025 Table of Contents Chapter 8 Preview 410 stnednopser fo % Chapter 8: Public Opinion 8.1 Public Opinion Highlight: Self-Driving Cars As discussed in Chapter 2: Technical Performance, self- driving cars. The most recent survey, conducted in January driving cars have made significant advancements in both 2025, was designed to be representative of approximately capability and adoption. With companies like Waymo and 97% of U.S. households. Figure 8.1.12 presents the results, Zoox becoming more prominent, understanding American revealing that despite the gradual rollout of self-driving attitudes toward self-driving technology is more important cars on American roads, a majority of Americans (61%) than ever. remain fearful of the technology. Only 13% of respondents expressed trust in self-driving cars. While fear has declined The American Automobile Association (AAA) conducts slightly from its 2023 peak of 68%, it remains higher than in an annual survey to assess public sentiment toward self- 2021, when 54% of Americans reported being afraid. US driver attitude toward self-driving vehicles, 2021–25 Source: AAA, 2025 | Chart: 2025 AI Index report Figure 8.1.12 Artificial Intelligence Index Report 2025 Chapter 8: Public Opinion 8.2 US Policymaker Opinion 8.2 US Policymaker Opinion Understanding public sentiment toward AI requires not Figure 8.2.1 illustrates the extent to which local policymakers only assessing the views of the general public but also agree with the statement: AI should be regulated by the those of key stakeholders, such as policymakers, who play government. In 2023, 73.7% of local U.S. policymakers a critical role in shaping AI regulation and policy. This year, supported this view, a significant increase from 55.7% in 2022. an international team of researchers from Uppsala, Oxford, The launch of ChatGPT appears to have played a key role in Harvard, and Syracuse universities released one of the first shifting policymaker sentiment toward regulation. Support comprehensive studies on the perspectives of local U.S. for AI regulation was higher among Democrats (79.2%) than policymakers—spanning township, municipal, and county Republicans (55.5%), though both groups registered a notable levels—on AI’s future impact and regulation. Conducted in increase after 2022. two waves, in 2022 and 2023, the study gathered responses from approximately 1,000 policymakers. Its timing allowed researchers to compare how policymakers’ views on AI shifted before and after the launch of ChatGPT. Local US o cials’ support for government regulation of AI by party and year Source: Hatz et al., 2025 | Chart: 2025 AI Index report Agree Neither agree nor disagree Disagree All 64.50% 19.10% 16.40% 2023 73.70% 14.40% 12.00% 2022 55.70% 23.60% 20.70% Democrats 79.20% 15.10% 5.70% Republicans 55.50% 21.60% 22.90% Democrats in 2023 84.40% 11.60% Democrats in 2022 74.60% 18.30% 7.10% Republicans in 2023 67.90% 15.50% 16.60% Republicans in 2022 42.70% 28.00% 29.40% 0% 20% 40% 60% 80% 100% % of respondents Figure 8.2.1 Table of Contents Chapter 8 Preview 411 Artificial Intelligence Index Report 2025 Chapter 8: Public Opinion 8.2 US Policymaker Opinion Given that most local policymakers support some form of AI (Figure 8.2.2). In contrast, there is significantly less backing regulation, which specific policies do they favor? At 80.4%, for redistributive measures. Just 33.9% support wage the strongest support is for stricter data privacy regulations. subsidies to offset wage declines and just 24.6% support In addition, 76.2% support retraining programs for the universal basic income. unemployed, and 72.5% support AI deployment regulations Local US o�cials’ views on what AI policies would be bene�cial for 2025–50 Source: Hatz et al., 2025 | Chart: 2025 AI Index report Agree Neither agree nor disagree Disagree Stricter data privacy regulations 80.40% 9.50% 10.10% Retraining for unemployed 76.20% 14.00% 9.80% AI deployment regulations 72.50% 14.50% 13.00% Stronger antitrust 57.70% 24.50% 17.80% Parole and sentencing AI regulations 54.70% 20.20% 25.10% Bias audits for hiring and promotion AI 51.70% 18.30% 30.00% Stronger social safety net 46.40% 24.60% 29.00% Federal regulations on local government AI 45.60% 22.80% 31.70% Semiconductor and AI hardware subsidies 44.40% 27.40% 28.20% Higher corporate income taxes 42.90% 30.50% 26.60% Robot tax 42.40% 22.30% 35.30% Immigration reform for AI developers 39.10% 34.10% 26.80% Law enforcement facial recognition ban 34.20% 26.00% 39.80% Wage subsidies for wage declines 33.90% 27.00% 39.00% Universal basic income 24.60% 17.10% 58.30% 0% 20% 40% 60% 80% 100% % of respondents Figure 8.2.2 Table of Contents Chapter 8 Preview 412 Artificial Intelligence Index Report 2025 Chapter 8: Public Opinion 8.2 US Policymaker Opinion When it comes to AI policy, most local legislators do not agreement with this statement has increased from 32.2% believe they will have to take immediate action (Figure in 2022 to 36.6% in 2023. This reflects the impact of major 8.2.3). Only 34.3% believe they will need to act within the AI developments, such as the launch of ChatGPT, on next few years, compared to 56.5% who do not. However, policymakers’ perspectives. Local US o cials’ likelihood of making AI policy decisions by party and year Source: Hatz et al., 2025 | Chart: 2025 AI Index report Likely Don’t know Unlikely All 34.30% 9.20% 56.50% 2023 36.60% 9.10% 54.30% 2022 32.20% 9.20% 58.60% Democrats 35.50% 8.90% 55.60% Republicans 33.60% 8.80% 57.70% Democrats in 2023 40.50% 8.10% 51.40% Democrats in 2022 31.10% 9.70% 59.20% Republicans in 2023 34.10% 8.40% 57.40% Republicans in 2022 33.00% 9.10% 57.90% 0% 20% 40% 60% 80% 100% % of respondents Figure 8.2.3 Table of Contents Chapter 8 Preview 413 Artificial Intelligence Index Report 2025 Chapter 8: Public Opinion 8.2 US Policymaker Opinion Only 29.8% of locally elected officials feel adequately informed to make AI policy decisions (Figure 8.2.4). While confidence in AI- related policymaking has increased slightly across both parties from 2022 to 2023, it remains relatively low overall. Local US o cials’ feeling adequately informed to make decisions about AI by party and year Source: Hatz et al., 2025 | Chart: 2025 AI Index report Agree Neither agree nor disagree Disagree All 29.80% 17.90% 52.30% 2023 31.30% 14.90% 53.80% 2022 28.50% 20.80% 50.80% Democrats 26.80% 15.10% 58.10% Republicans 31.50% 19.80% 48.70% Democrats in 2023 29.50% 11.00% 59.50% Democrats in 2022 24.40% 18.80% 56.90% Republicans in 2023 31.80% 17.60% 50.70% Republicans in 2022 31.20% 22.10% 46.70% 0% 20% 40% 60% 80% 100% % of respondents Figure 8.2.4 Table of Contents Chapter 8 Preview 414 AArrttiifificciiaall IInntteelllliiggeennccee IInnddeexx RReeppoorrtt 22002255 APPENDIX Table of Contents 415 Artificial Intelligence Index Report 2025 Appendix Chapter 1 Research and Development 416 Chapter 2 Technical Performance 420 Chapter 3 Responsible AI 427 Chapter 4 Economy 431 Chapter 5 Science and Medicine 441 Chapter 6 Policy and Governance 451 Chapter 7 Education 454 Chapter 8 Public Opinion 455 Table of Contents 416 Artificial Intelligence Index Report 2025 Appendix Chapter 1: Research and Development Chapter 1: Research and Development Acknowledgments The AI Index would like to acknowledge Angelo Salatino for To analyze research trends, the AI Index used the CSO his contributions to AI publication classification, Ben Cottier Classifier—an unsupervised method that automatically for leading the analysis of machine learning inference costs, categorizes research papers based on CSO topics. The Lapo Santarlasci for leading the analysis of AI patents, and classifier follows a three-stage pipeline that processes Andrew Shi for leading the analysis of the environmental paper titles and abstracts: A syntactic module detects impact of AI models. direct mentions of CSO topics; a semantic module uses word embeddings to identify related concepts; and a AI Publication Analysis postprocessing module merges results, filters out irrelevant For this analysis, the AI Index used OpenAlex, an open scholarly topics, and adds broader categories for a more refined database with over 260 million research publications, as its classification. For this analysis, the AI Index extended the primary data source. OpenAlex classifies papers using its own CSO Classifier to focus specifically on artificial intelligence knowledge organization system, known as OpenAlex Topics—a and its subtopics. Since its initial release, the classifier has taxonomy of around 4,500 topics combining Scopus codes and gained significant and growing interest due to its versatility. CWTS classification. The system uses a deep learning model For example, Springer Nature uses it to routinely classify that considers titles, abstracts, journal names, and citation proceedings books, improving metadata quality. Beyond networks for classification. To identify AI-related topics more academic publishing, it has been successfully applied to precisely, the AI Index analyzed computer science publications categorize research software, YouTube videos, press releases, identified by OpenAlex and refined the classifications using the job ads, and IT museum collections. Computer Science Ontology and the CSO Classifier. Accurately categorizing research papers as either conference The Computer Science Ontology (CSO) is a large-scale, proceedings or journal articles is essential for this analysis. automatically generated ontology of research areas derived OpenAlex’s metadata fields—type, crossref_type, and from 16 million publications using the Klink-2 algorithm. It source_type—can sometimes conflict. To resolve these features a hierarchical structure with thousands of subtopics, inconsistencies, the AI Index mapped OpenAlex records to allowing for precise mapping of specific terms to broader DBLP, a leading bibliographic database for computer science research fields. Compared to general-purpose scholarly publications. Known for its high metadata quality, DBLP databases like OpenAlex, Scopus, and Web of Science, CSO continuously adds new publications through a rigorous, offers a more detailed and fine-grained representation of the semiautomated curation process and currently indexes 3.6 research landscape. As a result, it has been widely used for million conference papers and 3 million journal articles. The scholarly data exploration, analysis, modeling, and expert initial matching between OpenAlex and DBLP was performed identification and recommendation. Version 3.4.1—used in using DOIs. For remaining unmatched papers, the AI Index this analysis—includes approximately 15,000 topics and used a combination of title and publication year. To streamline 166,000 relationships within computer science. Released on this process, the AI Index built a title index to optimize search Jan. 17, 2025, this version introduces over 150 new research and ensure efficient mapping across the datasets. topics in artificial intelligence, bringing the total to 2,369 AI- related topics and 12,620 hierarchical relationships within the AI publications are aggregated based on several parameters AI domain alone. to provide a comprehensive analysis. Publications are Table of Contents Appendix 417 Artificial Intelligence Index Report 2025 Appendix Chapter 1: Research and Development grouped by year, considering the publication date of the Patent-level bibliographic data is sourced from PATSTAT most recent versions. Additionally, the AI Index groups Global, a comprehensive database issued by the European publications by geographic areas or World Bank regions Patent Office (EPO). The analysis focuses on granted patents using the affiliations of authors. This means a single paper can from 2010 onward, aggregated at the DOCDB family level to contribute to multiple counts if coauthored by researchers avoid duplicate counting of the same invention.1 Patents are from different countries, with each country receiving a count. attributed to countries based on the publication authority of When authors’ affiliations are missing, these publications are the earliest recorded grant publication. mapped as “Unknown.” Furthermore, sectors are associated with publications through authors’ affiliations when available, Patent abstracts and titles originally published in languages which may lead to a publication being counted for multiple other than English were translated using the deep-translator sectors. Citation counts are included when available; those tool, Google Translate engine, and the Meta NLLB-200 without citation data are classified as “Unknown.” machine translation model. Post-translation, patent texts were processed using natural language processing (NLP) Top 100 Publications Analysis techniques. These included the removal of stop words The AI Index conducted a comprehensive analysis of and special characters, part-of-speech (POS) tagging to influential AI publications by collecting and analyzing citation retain key grammatical categories, lowercase conversion, data from multiple sources including OpenAlex, Google lemmatization, and replacement of numerical measures with Scholar, and Semantic Scholar. Initially gathering the top 150 a <NUM> tag. most-cited papers per publication year from OpenAlex, the list was refined to 100 publications through careful review. AI-related patents are identified by searching for relevant terms in patent titles and abstracts using regular expressions (regex). The methodology attributes publications to all countries and An AI-specific keyword dictionary was developed through regions represented by authors’ affiliations, meaning a single a structured multistep process, incorporating keywords paper can contribute to multiple counts. For instance, a paper generated by AI models, expanded using established AI coauthored by researchers from the United States and China lexicons such as those from Yamashita et al. (2021), and refined counts once for each country. This approach may result in through Word2Vec-based synonym identification. Further overlapping totals in aggregate statistics. Publication years validation was conducted using BERTopic topic modeling and are based on the most recent versions, whether in journals, DeBERTA-based zero-shot classification, with manual checks conferences, or repositories like arXiv. To maintain accuracy, applied to reduce false positives. organizational affiliations were verified and standardized, with countries assigned according to headquarters’ locations. In addition to keyword-based classification, AI-related patents were identified using International Patent Classification The full list of the top 100 AI publications is available here. (IPC) and Cooperative Patent Classification (CPC) codes. A curated list of AI-relevant codes was compiled through a combination of AI model analysis, regex-based searches, and AI Patent Analysis prior research, including classifications from Pairolero et al. The AI Index identifies AI-related patents using a hybrid (2023) and WIPO (2024). The final dataset was constructed classification approach, combining keyword-based text by merging results from both approaches, balancing coverage analysis with classification-code-based identification. and accuracy. 1 Despite this aggregation procedure, duplicates occasionally appear in marginal cases where applications within the same DOCDB family share the same earliest filing date. The AI Index removes duplicate values with respect to the aggregation variables (e.g., counting by year) when presenting analytics. Table of Contents Appendix 418 Artificial Intelligence Index Report 2025 Appendix Chapter 1: Research and Development Epoch Notable Models Analysis Training Cost Analysis The AI forecasting research group Epoch AI maintains a dataset To create the dataset of cost estimates, the Epoch database of landmark AI and ML models, along with accompanying was filtered for models released during the large-scale ML information about their creators and publications, such as era2 that were in the top 10 of training compute at the time the list of their authors, number of citations, type of AI task of release. This filtered for the largest-scale ML models. accomplished, and amount of compute used in training. The Transformer model was added to this set of models for further context. The nationalities of the authors of these papers have important implications for geopolitical AI forecasting. As For the selected ML models, the training time and the type, various research institutions and technology companies start quantity, and hardware utilization rate were determined producing advanced ML models, the global distribution of from the publication, press release, or technical reports, as AI development may shift or concentrate in certain places, applicable. Cloud rental prices for the computing hardware which in turn affects the geopolitical landscape because AI is used by these models were collected from online historical expected to become a crucial component of economic and archives of cloud vendors’ websites.3 military power in the near future. Training costs were estimated from the hardware type, To track the distribution of AI research contributions on quantity, and time by multiplying the hourly cloud rental rates landmark publications by country, the Epoch dataset is coded (at the time of training)4 by the quantity of hardware hours. according to the following methodology: However, some developers purchased hardware rather than renting cloud compute, and cloud prices vary by vendor 1. A snapshot of the dataset was taken in March 2025. and by rental commitment, so the true costs incurred by the This includes papers about landmark models, selected developers may vary. using the inclusion criteria of importance, relevance, and uniqueness, as described in the Compute Trends Various challenges were encountered while estimating the dataset documentation. training cost of these models. Often, the developers did not 2. The authors are attributed to countries based on their disclose the duration of training or the hardware that was affiliation credited on the paper. For international used. In other cases, cloud compute pricing was not available organizations, authors are attributed to the country for the hardware. The investigation of training cost trends is where the organization is headquartered, unless a more thoroughly detailed in a separate report by Epoch AI. more specific location is indicated. 3. All of the landmark publications are aggregated within AI Conference Attendance time periods (e.g., monthly or yearly) and the national contributions compiled to determine the extent of The AI Index reached out to the organizers of various AI each country’s contribution to landmark AI research conferences in 2024 and asked them to provide information during each time period. on total attendance. For conferences that posted their 4. The contributions of different countries are compared attendance totals online, the AI Index used those reported over time to identify any trends. totals and did not reach out to the conference organizers. 2 The selected cutoff date was Sept. 1, 2015, in accordance with Compute Trends Across Three Eras of Machine Learning (Epoch, 2022). 3 Historic prices were collected from archived snapshots of Amazon Web Services, Microsoft Azure, and Google Cloud Platform price catalogs viewed through the Internet Archive Wayback Machine. 4 The chosen rental rate was the most recent published price for the hardware and cloud vendor used by the developer of the model, at a three-year commitment rental rate, after subtracting the training duration and two months from the publication date. If this price was not available, the most analogous price was used—either the same hardware and vendor at a different date, or the same hardware from a different cloud vendor. If a three-year commitment rental rate was unavailable, this was imputed from other rental rates based on the empirical average discount for the given cloud vendor. If the exact hardware type was not available (e.g., Nvidia A100 SXM4 40GB), a generalization was used (e.g., Nvidia A100). Table of Contents Appendix 419 Artificial Intelligence Index Report 2025 Appendix Chapter 1: Research and Development GitHub The calculator’s accuracy was verified against published emission values. Calculator inputs included hardware Identifying AI Projects type, GPU hours, provider, and compute region. For newer In partnership with researchers from Harvard Business hardware like the H100 GPU (released in 2022), the A100 School, Microsoft Research, and Microsoft’s AI for Good SXM4 80GB was used as a substitute in calculations. Provider Lab, GitHub identifies public AI repositories following the selection was based on known partnerships (e.g., Google methodologies of Gonzalez, Zimmerman, and Nagappan models using GCP, OpenAI using Azure), while compute (2020) and Dohmke, Iansiti, and Richards (2023), using topic regions were determined by team locations. labels related to AI/ML and generative AI, respectively, along with other relevant keywords identified through snowball Special consideration was given to models trained on sampling, such as “machine learning,” “deep learning,” and custom hardware, such as BLOOM’s use of the Jean “artificial intelligence.” GitHub further augments the dataset Zay supercomputer in France. In these cases, private with repositories that have a dependency on the PyTorch, infrastructure calculations incorporated carbon efficiency TensorFlow, OpenAI, Transformers, XGBoost, scikit-learn, (kg/kWh) and offset percentages. and SciPy libraries for Python. The study evaluated 50 models in total: 34 industry language Mapping AI Projects to Geographic Areas models (2018–24), eight industry vision models (2019– Public AI projects are mapped to geographic areas using IP 23), four academic language models (2020–23), and four address geolocation to determine the mode location of a academic vision models (2011–22), selecting particularly project’s owners each year. Each project owner is assigned influential models in their respective domains. a location based on their IP address when interacting with GitHub. If a project owner changes locations within a year, the location for the project would be determined by the mode location of its owners sampled daily in the year. Additionally, the last known location of the project owner is carried forward on a daily basis even if no activities were performed by the project owner that day. For example, if a project owner performed activities within the United States and then became inactive for six days, that project owner would be considered to be in the United States for that seven-day span. Environmental Impact Analysis The AI Index estimated the carbon emissions of training language and vision models using a calculator proposed by Lacoste et al. (2019). The analysis focused on the training stage emissions, excluding embodied hardware production, idle infrastructure, and deployment emissions. The study examined four model categories: industry language models, academic language models, industry vision models, and academic vision models. Table of Contents Appendix 420 Artificial Intelligence Index Report 2025 Appendix Chapter 2: Technical Performance Chapter 2: Technical Performance Acknowledgments The AI Index would like to acknowledge Andrew Shi for 6. Chatbot Arena: Data on Chatbot Arena was taken his work generating sample Midjourney and Pika video from the Chatbot Arena leaderboard in February generations and Armin Hamrah for his work identifying 2025. To learn more about Chatbot Arena, please read significant AI technical advancements for the timeline. the original paper. 7. FrontierMath: Data on FrontierMath was taken from Benchmarks the FrontierMath paper and OpenAI video in February In this chapter, the AI Index reports on benchmarks, recognizing 2025. To learn more about FrontierMath, please read their importance in tracking AI’s technical progress. As a the original paper. The visual was supplemented with standard practice, the Index sources benchmark scores from benchmark data from OpenAI’s o3 model, sourced leaderboards, public repositories such as Papers With Code from a YouTube video announcing its launch in and RankedAGI, as well as company papers, blog posts, and December 2025. product releases. The Index operates under the assumption 8. GAIA: Data on GAIA was taken from the GAIA that the scores reported by companies are accurate and leaderboard in February 2025. To learn more about factual. The benchmark scores in this section are current as GAIA, please read the original paper. of mid-February 2025. However, since the publication of the 9. GPQA: Data on GPQA was taken from the GPQA AI Index, newer models may have been released that surpass paper and OpenAI video in February 2025. To learn current state-of-the-art scores. more about GPQA, please read the original paper. 10. GSM8K: Data on GSM8K was taken from the GSM8K 1. ARC-AGI: Data on ARC-AGI was taken from the ARC- Papers With Code leaderboard in February 2025. To AGI paper and OpenAI video in February 2025. To learn learn more about GSM8K, please read the original more about ARC-AGI, please read the original paper. paper. 2. Arena-Hard-Auto: Data on Arena-Hard-Auto was 11. HELMET: Data on HELMET (How to Evaluate Long- taken from the LMSYS leaderboard in February 2025. Context Models Effectively and Thoroughly) was To learn more about Arena-Hard-Auto, please read taken from the HELMET paper in February 2025. To the original paper. learn more about HELMET, please read the original 3. Bench2Drive: Data on Bench2Drive was taken from paper. the Bench2Drive paper in February 2025. To learn more 12. HLE: Data on Humanity’s Last Exam (HLE) was taken about Bench2Drive, please read the original paper. from the HLE paper in February 2025. To learn more 4. Berkeley Function Calling: Data on Berkeley Function about HLE, please read the original paper. Calling was taken from the Berkeley Function Calling 13. HumanEval: Data on HumanEval was taken from leaderboard in February 2025. To learn more about the HumanEval Papers With Code leaderboard in Berkeley Function Calling, please read the original February 2025. To learn more about HumanEval, work. please read the original paper. 5. BigCodeBench: Data on BigCodeBench was taken 14. LRS2: Data on Oxford-BBC Lip Reading Sentences from the BigCodeBench leaderboard in February 2 (LRS2) was taken from the LRS2 Papers With Code 2025. To learn more about BigCodeBench, please read leaderboard in February 2025. To learn more about the original work. LRS2, please read the original paper. Table of Contents Appendix 421 Artificial Intelligence Index Report 2025 Appendix Chapter 2: Technical Performance 15. MATH: Data on MATH was taken from the MATH 27. VAB: Data on VisualAgentBench (VAB) was taken Papers With Code leaderboard in February 2025 from the VAB leaderboard in February 2025. To learn and the o3-mini model launch. To learn more about more about VAB, please read the original paper. MATH, please read the original paper. 28. VCR: Data on VCR was taken from the VCR 16. MixEval: Data on MixEval was taken from the MixEval leaderboard in February 2025. To learn more about leaderboard in February 2025. To learn more about VCR, please read the original paper. MixEval, please read the original paper. 29. WildBench: Data on WildBench was taken from the 17. MMLU: Data on MMLU was taken from the MMLU WildBench leaderboard in February 2025. To learn Papers With Code leaderboard in February 2025. more about WildBench, please read the original To learn more about MMLU, please read the original paper. paper. 18. MMLU-Pro: Data on MMLU-Pro was taken from the MMLU-Pro leaderboard in February 2025. To learn more about MMLU-Pro, please read the original paper. 19. MMMU: Data on MMMU was taken from the MMMU leaderboard in February 2025. To learn more about MMMU, please read the original paper. 20. MTEB: Data on Massive Text Embedding Benchmark (MTEB) was taken from the MTEB leaderboard in February 2025. To learn more about MTEB, please read the original paper. 21. MVBench: Data on MVBench was taken from the MVBench leaderboard in February 2025. To learn more about MVBench, please read the original paper. 22. PlanBench: Data on PlanBench was taken from the PlanBench paper in February 2025. To learn more about PlanBench, please read the original paper. 23. RE-Bench: Data on RE-Bench was taken from the RE- Bench paper in February 2025. To learn more about RE-Bench, please read the original paper 24. RLBench: Data on RLBench was taken from the RLBench Papers With Code leaderboard in February 2025. To learn more about RLBench, please read the original paper. 25. Ruler: Data on Ruler was taken from the Ruler repository in February 2025. To learn more about Ruler, please read the original paper. 26. SWE-bench: Data on SWE-bench was taken from the SWE-bench leaderboard in February 2025. To learn more about SWE-bench, please read the original paper. Table of Contents Appendix 422 Artificial Intelligence Index Report 2025 Appendix Chapter 2: Technical Performance Works Cited Akter, S. N., Yu, Z., Muhamed, A., Ou, T., Bäuerle, A., Cabrera, Á. A., Dholakia, K., Xiong, C., & Neubig, G. (2023). An In-Depth Look at Gemini’s Language Abilities (arXiv:2312.11444). arXiv. https://doi.org/10.48550/arXiv.2312.11444 Bairi, R., Sonwane, A., Kanade, A., C, V. D., Iyer, A., Parthasarathy, S., Rajamani, S., Ashok, B., & Shet, S. (2023). CodePlan: Repository-Level Coding Using LLMs and Planning (arXiv:2309.12499). arXiv. https://doi.org/10.48550/arXiv.2309.12499 Bauza, M., Chen, J. E., Dalibard, V., Gileadi, N., Hafner, R., Martins, M. F., Moore, J., Pevceviciute, R., Laurens, A., Rao, D., Zambelli, M., Riedmiller, M., Scholz, J., Bousmalis, K., Nori, F., & Heess, N. (2024). DemoStart: Demonstration-Led Auto-Curriculum Applied to Sim-to-Real With Multi-fingered Robots (arXiv:2409.06613). arXiv. https://doi.org/10.48550/arXiv.2409.06613 Bommasani, R., Kapoor, S., Klyman, K., Longpre, S., Ramaswami, A., Zhang, D., Schaake, M., Ho, D. E., Narayanan, A., & Liang, P. (2024). “Considerations for Governing Open Foundation Models.” Science, 386(6718), 151–53. https://doi.org/10.1126/science. adp1848 Brohan, A., Brown, N., Carbajal, J., Chebotar, Y., Chen, X., Choromanski, K., ... & Zitkovich, B. (2023). RT-2: Vision-Language- Action Models Transfer Web Knowledge to Robotic Control. (arXiv:2307.15818). arXiv. https://arxiv.org/abs/2307.15818 Budagam, D., Kumar, A., Khoshnoodi, M., KJ, S., Jain, V., & Chadha, A. (2024). Hierarchical Prompting Taxonomy: A Universal Evaluation Framework for Large Language Models Aligned With Human Cognitive Principles (arXiv:2406.12644; Version 4). arXiv. https://doi.org/10.48550/arXiv.2406.12644 Cao, Z., Long, M., Wang, J., & Yu, P. S. (2017). HashNet: Deep Learning to Hash by Continuation (arXiv:1702.00758). arXiv. https://doi.org/10.48550/arXiv.1702.00758 Chen, M., Tworek, J., Jun, H., Yuan, Q., Pinto, H. P. de O., Kaplan, J., Edwards, H., Burda, Y., Joseph, N., Brockman, G., Ray, A., Puri, R., Krueger, G., Petrov, M., Khlaaf, H., Sastry, G., Mishkin, P., Chan, B., Gray, S., … Zaremba, W. (2021). Evaluating Large Language Models Trained on Code (arXiv:2107.03374). arXiv. https://doi.org/10.48550/arXiv.2107.03374 Chiang, W.-L., Zheng, L., Sheng, Y., Angelopoulos, A. N., Li, T., Li, D., Zhang, H., Zhu, B., Jordan, M., Gonzalez, J. E., & Stoica, I. (2024). Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference (arXiv:2403.04132). arXiv. https://doi. org/10.48550/arXiv.2403.04132 Chollet, F., Knoop, M., Kamradt, G., & Landers, B. (2025). ARC Prize 2024: Technical Report (arXiv:2412.04604). arXiv. https://doi. org/10.48550/arXiv.2412.04604 Chung, J. S., Senior, A., Vinyals, O., & Zisserman, A. (2017). “Lip Reading Sentences in the Wild.” 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 3444–53. https://doi.org/10.1109/CVPR.2017.367 Cobbe, K., Kosaraju, V., Bavarian, M., Chen, M., Jun, H., Kaiser, L., Plappert, M., Tworek, J., Hilton, J., Nakano, R., Hesse, C., & Schulman, J. (2021). Training Verifiers to Solve Math Word Problems (arXiv:2110.14168). arXiv. https://doi.org/10.48550/ arXiv.2110.14168 Table of Contents Appendix 423 Artificial Intelligence Index Report 2025 Appendix Chapter 2: Technical Performance Driess, D., Xia, F., Sajjadi, M. S. M., Lynch, C., Chowdhery, A., Ichter, B., Wahid, A., Tompson, J., Vuong, Q., Yu, T., Huang, W., Chebotar, Y., Sermanet, P., Duckworth, D., Levine, S., Vanhoucke, V., Hausman, K., Toussaint, M., Greff, K., … Florence, P. (2023). PaLM-E: An Embodied Multimodal Language Model (arXiv:2303.03378). arXiv. https://doi.org/10.48550/arXiv.2303.03378 Fang, H., Grotz, M., Pumacay, W., Wang, Y. R., Fox, D., Krishna, R., & Duan, J. (2025). SAM2Act: Integrating Visual Foundation Model With a Memory Architecture for Robotic Manipulation (arXiv:2501.18564). arXiv. https://doi.org/10.48550/arXiv.2501.18564 Fattorini, L., Maslej, N., Perrault, R., Parli, V., Etchemendy, J., Shoham, Y., & Ligett, K. (2024). The Global AI Vibrancy Tool (arXiv:2412.04486). arXiv. https://doi.org/10.48550/arXiv.2412.04486 Glazer, E., Erdil, E., Besiroglu, T., Chicharro, D., Chen, E., Gunning, A., Olsson, C. F., Denain, J.-S., Ho, A., Santos, E. de O., Järviniemi, O., Barnett, M., Sandler, R., Vrzala, M., Sevilla, J., Ren, Q., Pratt, E., Levine, L., Barkley, G., … Wildon, M. (2024). FrontierMath: A Benchmark for Evaluating Advanced Mathematical Reasoning in AI (arXiv:2411.04872). arXiv. https://doi. org/10.48550/arXiv.2411.04872 Hendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D., & Steinhardt, J. (2021). Measuring Massive Multitask Language Understanding (arXiv:2009.03300). arXiv. https://doi.org/10.48550/arXiv.2009.03300 Hendrycks, D., Burns, C., Kadavath, S., Arora, A., Basart, S., Tang, E., Song, D., & Steinhardt, J. (2021). Measuring Mathematical Problem Solving With the MATH Dataset (arXiv:2103.03874). arXiv. https://doi.org/10.48550/arXiv.2103.03874 Hsieh, C.-P., Sun, S., Kriman, S., Acharya, S., Rekesh, D., Jia, F., Zhang, Y., & Ginsburg, B. (2024). RULER: What’s the Real Context Size of Your Long-Context Language Models? (arXiv:2404.06654). arXiv. https://doi.org/10.48550/arXiv.2404.06654 Huang, Q., Vora, J., Liang, P., & Leskovec, J. (2024). MLAgentBench: Evaluating Language Agents on Machine Learning Experimentation (arXiv:2310.03302). arXiv. https://doi.org/10.48550/arXiv.2310.03302 Islam, P., Kannappan, A., Kiela, D., Qian, R., Scherrer, N., & Vidgen, B. (2023). FinanceBench: A New Benchmark for Financial Question Answering (arXiv:2311.11944). arXiv. https://doi.org/10.48550/arXiv.2311.11944 James, S., Ma, Z., Arrojo, D. R., & Davison, A. J. (2019). RLBench: The Robot Learning Benchmark & Learning Environment (arXiv:1909.12271; Version 1). arXiv. https://doi.org/10.48550/arXiv.1909.12271 Jia, X., Yang, Z., Li, Q., Zhang, Z., & Yan, J. (2024). Bench2Drive: Towards Multi-ability Benchmarking of Closed-Loop End-to-End Autonomous Driving (arXiv:2406.03877). arXiv. https://doi.org/10.48550/arXiv.2406.03877 Jimenez, C. E., Yang, J., Wettig, A., Yao, S., Pei, K., Press, O., & Narasimhan, K. (2024). SWE-bench: Can Language Models Resolve Real-World GitHub Issues? (arXiv:2310.06770). arXiv. https://doi.org/10.48550/arXiv.2310.06770 Jones, C. R., & Bergen, B. K. (2024). People Cannot Distinguish GPT-4 From a Human in a Turing Test (arXiv:2405.08007). arXiv. https://doi.org/10.48550/arXiv.2405.08007 Table of Contents Appendix 424 Artificial Intelligence Index Report 2025 Appendix Chapter 2: Technical Performance Karnchanachari, N., Geromichalos, D., Tan, K. S., Li, N., Eriksen, C., Yaghoubi, S., Mehdipour, N., Bernasconi, G., Fong, W. K., Guo, Y., & Caesar, H. (2024). Towards Learning-Based Planning: The nuPlan Benchmark for Real-World Autonomous Driving (arXiv:2403.04133). arXiv. https://doi.org/10.48550/arXiv.2403.04133 Kusupati, A., Bhatt, G., Rege, A., Wallingford, M., Sinha, A., Ramanujan, V., Howard-Snyder, W., Chen, K., Kakade, S., Jain, P., & Farhadi, A. (2024). Matryoshka Representation Learning (arXiv:2205.13147). arXiv. https://doi.org/10.48550/arXiv.2205.13147 Leal, I., Choromanski, K., Jain, D., Dubey, A., Varley, J., Ryoo, M., Lu, Y., Liu, F., Sindhwani, V., Vuong, Q., Sarlos, T., Oslund, K., Hausman, K., & Rao, K. (2023). SARA-RT: Scaling Up Robotics Transformers With Self-Adaptive Robust Attention (arXiv:2312.01990). arXiv. https://doi.org/10.48550/arXiv.2312.01990 Li, K., Wang, Y., He, Y., Li, Y., Wang, Y., Liu, Y., Wang, Z., Xu, J., Chen, G., Luo, P., Wang, L., & Qiao, Y. (2024). MVBench: A Comprehensive Multi-modal Video Understanding Benchmark (arXiv:2311.17005). arXiv. https://doi.org/10.48550/arXiv.2311.17005 Li, T., Chiang, W.-L., Frick, E., Dunlap, L., Wu, T., Zhu, B., Gonzalez, J. E., & Stoica, I. (2024). From Crowdsourced Data to High- Quality Benchmarks: Arena-Hard and BenchBuilder Pipeline (arXiv:2406.11939). arXiv. https://doi.org/10.48550/arXiv.2406.11939 Li, X., Mata, C., Park, J., Kahatapitiya, K., Jang, Y. S., Shang, J., Ranasinghe, K., Burgert, R., Cai, M., Lee, Y. J., & Ryoo, M. S. (2025). LLaRA: Supercharging Robot Learning Data for Vision-Language Policy (arXiv:2406.20095). arXiv. https://doi.org/10.48550/ arXiv.2406.20095 Liu, X., Yu, H., Zhang, H., Xu, Y., Lei, X., Lai, H., Gu, Y., Ding, H., Men, K., Yang, K., Zhang, S., Deng, X., Zeng, A., Du, Z., Zhang, C., Shen, S., Zhang, T., Su, Y., Sun, H., … Tang, J. (2023). AgentBench: Evaluating LLMs as Agents (arXiv:2308.03688). arXiv. https:// doi.org/10.48550/arXiv.2308.03688 Liu, X., Zhang, T., Gu, Y., Iong, I. L., Xu, Y., Song, X., Zhang, S., Lai, H., Liu, X., Zhao, H., Sun, J., Yang, X., Yang, Y., Qi, Z., Yao, S., Sun, X., Cheng, S., Zheng, Q., Yu, H., … Tang, J. (2024). VisualAgentBench: Towards Large Multimodal Models as Visual Foundation Agents (arXiv:2408.06327). arXiv. https://doi.org/10.48550/arXiv.2408.06327 Mialon, G., Fourrier, C., Swift, C., Wolf, T., LeCun, Y., & Scialom, T. (2023). GAIA: A Benchmark for General AI Assistants (arXiv:2311.12983). arXiv. https://doi.org/10.48550/arXiv.2311.12983 Mitchell, M. (2024). “The Turing Test and Our Shifting Conceptions of Intelligence.” Science, 385(6710), eadq9356. https://www. science.org/doi/10.1126/science.adq9356 Muennighoff, N., Tazi, N., Magne, L., & Reimers, N. (2023). MTEB: Massive Text Embedding Benchmark (arXiv:2210.07316). arXiv. https://doi.org/10.48550/arXiv.2210.07316 Ni, J., Xue, F., Yue, X., Deng, Y., Shah, M., Jain, K., Neubig, G., & You, Y. (2024). MixEval: Deriving Wisdom of the Crowd From LLM Benchmark Mixtures (arXiv:2406.06565). arXiv. https://doi.org/10.48550/arXiv.2406.06565 Table of Contents Appendix 425 Artificial Intelligence Index Report 2025 Appendix Chapter 2: Technical Performance O’Neill, A., Rehman, A., Gupta, A., Maddukuri, A., Gupta, A., Padalkar, A., Lee, A., Pooley, A., Gupta, A., Mandlekar, A., Jain, A., Tung, A., Bewley, A., Herzog, A., Irpan, A., Khazatsky, A., Rai, A., Gupta, A., … Lin, Z. (2024). Open X-Embodiment: Robotic Learning Datasets and RT-X Models (arXiv:2310.08864). arXiv. https://doi.org/10.48550/arXiv.2310.08864 Phan, L., Gatti, A., Han, Z., Li, N., Hu, J., Zhang, H., Zhang, C. B. C., Shaaban, M., Ling, J., Shi, S., Choi, M., Agrawal, A., Chopra, A., Khoja, A., Kim, R., Ren, R., Hausenloy, J., Zhang, O., Mazeika, M., … Hendrycks, D. (2025). Humanity’s Last Exam (arXiv:2501.14249). arXiv. https://doi.org/10.48550/arXiv.2501.14249 Rein, D., Hou, B. L., Stickland, A. C., Petty, J., Pang, R. Y., Dirani, J., Michael, J., & Bowman, S. R. (2023). GPQA: A Graduate-Level Google-Proof Q&A Benchmark (arXiv:2311.12022). arXiv. https://doi.org/10.48550/arXiv.2311.12022 Reuel, A., Hardy, A., Smith, C., Lamparth, M., Hardy, M., & Kochenderfer, M. J. (2024). BetterBench: Assessing AI Benchmarks, Uncovering Issues, and Establishing Best Practices (arXiv:2411.12990). arXiv. https://doi.org/10.48550/arXiv.2411.12990 Turing, A. M. (2009). Computing Machinery and Intelligence. In Epstein, R., Roberts, G., & Beber, G., eds., Parsing the Turing Test: Philosophical and Methodological Issues in the Quest for the Thinking Computer (23–65). Springer Netherlands. https://doi. org/10.1007/978-1-4020-6710-5_3 Valmeekam, K., Stechly, K., & Kambhampati, S. (2024). LLMs Still Can’t Plan; Can LRMs? A Preliminary Evaluation of OpenAI’s o1 on PlanBench (arXiv:2409.13373). arXiv. https://doi.org/10.48550/arXiv.2409.13373 Wijk, H., Lin, T., Becker, J., Jawhar, S., Parikh, N., Broadley, T., Chan, L., Chen, M., Clymer, J., Dhyani, J., Ericheva, E., Garcia, K., Goodrich, B., Jurkovic, N., Kinniment, M., Lajko, A., Nix, S., Sato, L., Saunders, W., … Barnes, E. (2024). RE-Bench: Evaluating Frontier AI R&D Capabilities of Language Model Agents Against Human Experts (arXiv:2411.15114). arXiv. https://doi.org/10.48550/ arXiv.2411.15114 Xia, Z., Li, J., Lin, Z., Wang, X., Wang, Y., & Yang, M.-H. (2024). OpenAD: Open-World Autonomous Driving Benchmark for 3D Object Detection (arXiv:2411.17761). arXiv. https://doi.org/10.48550/arXiv.2411.17761 Xu, C., Guan, S., Greene, D., & Kechadi, M.-T. (2024). Benchmark Data Contamination of Large Language Models: A Survey (arXiv:2406.04244). arXiv. https://doi.org/10.48550/arXiv.2406.04244 Yang, X., Sun, K., Xin, H., Sun, Y., Bhalla, N., Chen, X., Choudhary, S., Gui, R. D., Jiang, Z. W., Jiang, Z., Kong, L., Moran, B., Wang, J., Xu, Y. E., Yan, A., Yang, C., Yuan, E., Zha, H., Tang, N., … Dong, X. L. (2024). CRAG—Comprehensive RAG Benchmark (arXiv:2406.04744). arXiv. https://doi.org/10.48550/arXiv.2406.04744 Yen, H., Gao, T., Hou, M., Ding, K., Fleischer, D., Izsak, P., Wasserblat, M., & Chen, D. (2025). HELMET: How to Evaluate Long- Context Language Models Effectively and Thoroughly (arXiv:2410.02694). arXiv. https://doi.org/10.48550/arXiv.2410.02694 Yue, X., Ni, Y., Zhang, K., Zheng, T., Liu, R., Zhang, G., Stevens, S., Jiang, D., Ren, W., Sun, Y., Wei, C., Yu, B., Yuan, R., Sun, R., Yin, M., Zheng, B., Yang, Z., Liu, Y., Huang, W., … Chen, W. (2024). MMMU: A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI (arXiv:2311.16502). arXiv. https://doi.org/10.48550/arXiv.2311.16502 Table of Contents Appendix 426 Artificial Intelligence Index Report 2025 Appendix Chapter 2: Technical Performance Zellers, R., Bisk, Y., Farhadi, A., & Choi, Y. (2019). From Recognition to Cognition: Visual Commonsense Reasoning (arXiv:1811.10830). arXiv. https://doi.org/10.48550/arXiv.1811.10830 Zhang, H., Da, J., Lee, D., Robinson, V., Wu, C., Song, W., Zhao, T., Raja, P., Zhuang, C., Slack, D., Lyu, Q., Hendryx, S., Kaplan, R., Lunati, M., & Yue, S. (2024). A Careful Examination of Large Language Model Performance on Grade School Arithmetic (arXiv:2405.00332). arXiv. https://doi.org/10.48550/arXiv.2405.00332 Table of Contents Appendix 427 Artificial Intelligence Index Report 2025 Appendix Chapter 3: Responsible AI Chapter 3: Responsible AI Acknowledgments The AI Index would like to acknowledge Andrew Shi for his data breach, data ethics, data governance, data integrity, work spearheading the analysis of responsible AI (RAI)– data privacy, data protection, data transparency, differential related conference submissions. The AI Index acknowledges privacy, inference privacy, machine unlearning, privacy by that the Global State of Responsible AI analysis was design, privacy-preserving, secure data storage, trustworthy conducted in collaboration with Accenture. It specifically data curation. highlights the contributions of Accenture’s Chief Responsible AI Officer, Arnab Chakraborty, and the Accenture Research Security: adversarial attack, adversarial learning, AI incident, team, including Patrick Connolly, Jakub Wiatrak, Dikshita attacks, audits, cybersecurity, ethical hacking, forensic Venkatesh, and Shekhar Tewari, to the data collection and analysis, fraud detection, red teaming, safety, security, analysis. The AI Index acknowledges the McKinsey team— security ethics, threat detection, vulnerability assessment. specifically, Medha Bankhwal, Emily Capstick, Katherine Ottenbreit, Brittany Presten, Roger Roberts, and Cayla Transparency and explainability: algorithmic transparency, Volandes—for their collaboration on the survey of the audit, auditing, causal reasoning, causality, explainability, responsible AI ecosystem. explainable AI, explainable models, human-understandable decisions, interpretability, interpretable models, model Conference Submissions Analysis explainability, outcome explanation, transparency, xAI. For the analysis on responsible AI-related conference Accenture Global State of submissions, the AI Index examined the number of responsible AI–related academic submissions at the following Responsible AI Survey conferences: AAAI, AIES, FAccT, ICML, ICLR, and NeurIPS. Researchers from Stanford conducted the second iteration of Specifically, the team scraped the conference websites or the Global State of Responsible AI survey in collaboration with repositories of conference submissions for papers containing Accenture. Responses from 1,500 organizations, each with relevant keywords indicating they could fall into a particular total revenues of at least $500 million, were collected from responsible AI category. The papers were then manually 20 countries and 19 industries. The survey was conducted in verified by a human team to confirm their categorization. January–February 2025. The objective of the Global State It is possible that a single paper could belong to multiple of Responsible AI survey was to understand the challenges responsible AI categories. of adopting RAI principles and practices and to allow for a comparison of organizational and operational RAI activities The keywords searched include: across 10 dimensions over time. Fairness and bias: algorithmic fairness, bias detection, bias The survey covers a total of 10 RAI dimensions: reliability; mitigation, discrimination, equity in AI, ethical algorithm privacy and data governance; fairness and nondiscrimination; design, fair data practices, fair ML, fairness and bias, group transparency and explainability; human interaction; societal fairness, individual fairness, justice, nondiscrimination, and environmental well-being; accountability; leadership/ representational fairness, unfair, unfairness. principles/culture; lawfulness and compliance; and organizational governance. Details about the methodology Privacy and data governance: anonymity, confidentiality, can be found here. Table of Contents Appendix 428 Artificial Intelligence Index Report 2025 Appendix Chapter 3: Responsible AI McKinsey Responsible AI Survey A recent survey by McKinsey & Company of more than 750 leaders across 38 countries provides insights into the current state of RAI in enterprises. These leaders represent various industries, from technology to healthcare, and include professionals from legal, data/AI, engineering, risk, and finance roles. Leaders were asked about their organization’s experience with RAI and assessed using the McKinsey RAI Maturity Model, a responsible AI framework that encompasses four dimensions of RAI—strategy, risk management, data and technology, and operating model— with 21 subdimensions. RAI maturity was ranked across four levels, ranging from the development of foundational RAI practices to having a comprehensive and proactive program in place. Table of Contents Appendix 429 Artificial Intelligence Index Report 2025 Appendix Chapter 3: Responsible AI Works Cited Alanazi, S., & Asif, S. (2024). “Exploring Deepfake Technology: Creation, Consequences and Countermeasures.” Human- Intelligent Systems Integration, 6(1), 49–60. https://doi.org/10.1007/s42454-024-00054-8 Bai, X., Wang, A., Sucholutsky, I., & Griffiths, T. L. (2024). Measuring Implicit Bias in Explicitly Unbiased Large Language Models (arXiv:2402.04105). arXiv. https://doi.org/10.48550/arXiv.2402.04105 Birhane, A., Dehdashtian, S., Prabhu, V. U., & Boddeti, V. (2024). “The Dark Side of Dataset Scaling: Evaluating Racial Classification in Multimodal Models.” The 2024 ACM Conference on Fairness, Accountability, and Transparency, 1229–44. https://doi. org/10.1145/3630106.3658968 Bommasani, R., Klyman, K., Kapoor, S., Longpre, S., Xiong, B., Maslej, N., & Liang, P. (2025). The 2024 Foundation Model Transparency Index (arXiv:2407.12929). arXiv. https://doi.org/10.48550/arXiv.2407.12929 Gabriel, I., Manzini, A., Keeling, G., Hendricks, L. A., Rieser, V., Iqbal, H., Tomašev, N., Ktena, I., Kenton, Z., Rodriguez, M., El- Sayed, S., Brown, S., Akbulut, C., Trask, A., Hughes, E., Bergman, A. S., Shelby, R., Marchal, N., Griffin, C., … Manyika, J. (2024). The Ethics of Advanced AI Assistants (arXiv:2404.16244). arXiv. https://doi.org/10.48550/arXiv.2404.16244 Germani, F., Spitale, G., & Biller-Andorno, N. (2024). The Dual Nature of AI in Information Dissemination: Ethical Considerations. Jmir Ai, 3, e53505. https://doi.org/10.2196/53505 Gu, X., Zheng, X., Pang, T., Du, C., Liu, Q., Wang, Y., Jiang, J., & Lin, M. (2024). Agent Smith: A Single Image Can Jailbreak One Million Multimodal LLM Agents Exponentially Fast (arXiv:2402.08567). arXiv. https://doi.org/10.48550/arXiv.2402.08567 Laffier, J., & Rehman, A. (2023). “Deepfakes and Harm to Women.” Journal of Digital Life and Learning, 3(1), Article 1. https://doi. org/10.51357/jdll.v3i1.218 Li, J., Cheng, X., Zhao, W. X., Nie, J.-Y., & Wen, J.-R. (2023). HaluEval: A Large-Scale Hallucination Evaluation Benchmark for Large Language Models (arXiv:2305.11747). arXiv. https://doi.org/10.48550/arXiv.2305.11747 Liebowitz, J., ed. (2024). Regulating Hate Speech Created by Generative AI. Auerbach Publications. https://doi. org/10.1201/9781032654829 Lin, S., Hilton, J., & Evans, O. (2022). TruthfulQA: Measuring How Models Mimic Human Falsehoods (arXiv:2109.07958). arXiv. https://doi.org/10.48550/arXiv.2109.07958 Longpre, S., Mahari, R., Chen, A., Obeng-Marnu, N., Sileo, D., Brannon, W., Muennighoff, N., Khazam, N., Kabbara, J., Perisetla, K., Wu, X., Shippole, E., Bollacker, K., Wu, T., Villa, L., Pentland, S., & Hooker, S. (2023). The Data Provenance Initiative: A Large Scale Audit of Dataset Licensing and Attribution in AI (arXiv:2310.16787). arXiv. https://doi.org/10.48550/arXiv.2310.16787 Longpre, S., Mahari, R., Lee, A., Lund, C., Oderinwale, H., Brannon, W., Saxena, N., Obeng-Marnu, N., South, T., Hunter, C., Klyman, K., Klamm, C., Schoelkopf, H., Singh, N., Cherep, M., Anis, A., Dinh, A., Chitongo, C., Yin, D., … Pentland, S. (2024). Consent in Crisis: The Rapid Decline of the AI Data Commons (arXiv:2407.14933). arXiv. https://doi.org/10.48550/arXiv.2407.14933 Table of Contents Appendix 430 Artificial Intelligence Index Report 2025 Appendix Chapter 3: Responsible AI Mazeika, M., Phan, L., Yin, X., Zou, A., Wang, Z., Mu, N., Sakhaee, E., Li, N., Basart, S., Li, B., Forsyth, D., & Hendrycks, D. (2024a). HarmBench: A Standardized Evaluation Framework for Automated Red Teaming and Robust Refusal (arXiv:2402.04249). arXiv. https://doi.org/10.48550/arXiv.2402.04249 Parrish, A., Chen, A., Nangia, N., Padmakumar, V., Phang, J., Thompson, J., Htut, P. M., & Bowman, S. R. (2022). BBQ: A Hand- Built Bias Benchmark for Question Answering (arXiv:2110.08193). arXiv. https://doi.org/10.48550/arXiv.2110.08193 Qi, X., Panda, A., Lyu, K., Ma, X., Roy, S., Beirami, A., Mittal, P., & Henderson, P. (2024). Safety Alignment Should Be Made More Than Just a Few Tokens Deep (arXiv:2406.05946). arXiv. https://doi.org/10.48550/arXiv.2406.05946 Reuel, A., Connolly, P., Meimandi, K. J., Tewari, S., Wiatrak, J., Venkatesh, D., & Kochenderfer, M. (2024). Responsible AI in the Global Context: Maturity Model and Survey (arXiv:2410.09985). arXiv. https://doi.org/10.48550/arXiv.2410.09985 Röttger, P., Kirk, H. R., Vidgen, B., Attanasio, G., Bianchi, F., & Hovy, D. (2024). XSTest: A Test Suite for Identifying Exaggerated Safety Behaviours in Large Language Models (arXiv:2308.01263). arXiv. https://doi.org/10.48550/arXiv.2308.01263 Ruan, Y., Dong, H., Wang, A., Pitis, S., Zhou, Y., Ba, J., Dubois, Y., Maddison, C. J., & Hashimoto, T. (2024). Identifying the Risks of LM Agents with an LM-Emulated Sandbox (arXiv:2309.15817). arXiv. https://doi.org/10.48550/arXiv.2309.15817 Sheshadri, A., Ewart, A., Guo, P., Lynch, A., Wu, C., Hebbar, V., Sleight, H., Stickland, A. C., Perez, E., Hadfield-Menell, D., & Casper, S. (2024). Latent Adversarial Training Improves Robustness to Persistent Harmful Behaviors in LLMs (arXiv:2407.15549). arXiv. https://doi.org/10.48550/arXiv.2407.15549 Simchon, A., Edwards, M., & Lewandowsky, S. (2024). The Persuasive Effects of Political Microtargeting in the Age of Generative Artificial Intelligence. PNAS Nexus, 3(2), pgae035. https://doi.org/10.1093/pnasnexus/pgae035 Spivak, R. (2018). “Deepfakes”: The Newest Way to Commit One of the Oldest Crimes. Georgetown Law Technology Review, 3, 339. https://georgetownlawtechreview.org/wp-content/uploads/2019/05/3.1-Spivak-pp-339-400.pdf Vaccari, C., & Chadwick, A. (2020). Deepfakes and Disinformation: Exploring the Impact of Synthetic Political Video on Deception, Uncertainty, and Trust in News. Social Media + Society, 6(1), 2056305120903408. https://doi.org/10.1177/2056305120903408 Vidgen, B., Scherrer, N., Kirk, H. R., Qian, R., Kannappan, A., Hale, S. A., & Röttger, P. (2024). SimpleSafetyTests: A Test Suite for Identifying Critical Safety Risks in Large Language Models (arXiv:2311.08370). arXiv. https://doi.org/10.48550/arXiv.2311.08370 Wei, J., Karina, N., Chung, H. W., Jiao, Y. J., Papay, S., Glaese, A., Schulman, J., & Fedus, W. (2024). Measuring Short-Form Factuality in Large Language Models (arXiv:2411.04368). arXiv. https://doi.org/10.48550/arXiv.2411.04368 Zeng, Y., Yang, Y., Zhou, A., Tan, J. Z., Tu, Y., Mai, Y., Klyman, K., Pan, M., Jia, R., Song, D., Liang, P., & Li, B. (2024). AIR-Bench 2024: A Safety Benchmark Based on Risk Categories From Regulations and Policies (arXiv:2407.17436). arXiv. https://doi.org/10.48550/ arXiv.2407.17436 Table of Contents Appendix 431 Artificial Intelligence Index Report 2025 Appendix Chapter 4: Economy Chapter 4: Economy International Federation of United States. The primary source of government data on U.S. job postings is the Job Openings and Labor Turnover Survey Robotics (IFR) (JOLTS) program, conducted by the Bureau of Labor Statistics. Data presented in the Robot Installations section was sourced Based on comparisons between JOLTS and Lightcast, the from the World Robotics 2024 report. labor market demand captured by Lightcast data represents over 99% of the total labor demand. Jobs not posted online Lightcast are usually in small businesses (e.g., “Help Wanted” signs in Prepared by Vishy Kamalapuram and Elena Magrini restaurant windows) and union hiring halls. Lightcast delivers job market analytics that empower Measuring Demand for AI employers, workers, and educators to make data-driven To measure the demand by employers of AI skills, Lightcast decisions. The company’s artificial intelligence technology uses its skills taxonomy of over 33,000 skills.1 These skills are analyzes hundreds of millions of job postings and real- organized hierarchically in over 400 skills clusters and 32 life career transitions to provide insight into labor market skills categories. The list of AI skills from Lightcast are shown patterns. This real-time strategic intelligence offers crucial below, with associated skills clusters. For the purposes of this insights, such as what jobs are most in demand, the specific report, all skills below were considered AI skills. A posting was skills employers need, and the career directions that offer considered an AI job if it mentioned any of these skills in the the highest potential for workers. For more information, visit text of the listing. https://lightcast.io. AI ethics, governance, and regulation: ethical AI, data Job Postings Data sovereignty, AI security, artificial intelligence risk. To support these analyses, Lightcast mined its dataset of millions of job postings collected since 2010. Lightcast Artificial intelligence: agentic systems, AI/ML inference, collects postings from over 51,000 online job sites to AIOps (artificial intelligence for IT operations), AI develop a comprehensive, real-time portrait of labor market personalization, AI testing, applications of artificial intelligence, demand. It aggregates job postings, removes duplicates, artificial general intelligence, artificial intelligence, artificial and extracts data from job postings text. This includes intelligence development, Artificial Intelligence Markup information on job title, employer, industry, and region, Language (AIML), artificial intelligence systems, automated as well as required experience, education, and skills. data cleaning, Azure Cognitive Services, Baidu, cognitive automation, cognitive computing, computational intelligence, Job postings are useful for understanding trends in the labor Cortana, Data Version Control (DVC), Edge Intelligence, market because they allow for a detailed, real-time look at embedded AI, expert systems, explainable AI (XAI), intelligent the skills employers seek. To assess the representativeness of control, intelligent systems, interactive kiosk, IPSoft Amelia, job postings data, Lightcast conducts a number of analyses knowledge distillation, knowledge engineering, knowledge- to compare the distribution of job postings to the distribution based configuration, knowledge-based systems, knowledge of official government and other third-party sources in the representation, multi-agent systems, neuro-symbolic AI, 1 https://lightcast.io/open-skills Table of Contents Appendix 432 Artificial Intelligence Index Report 2025 Appendix Chapter 4: Economy Open Neural Network Exchange (ONNX), OpenAI Gym, ai, hidden Markov model, hyperparameter optimization, operationalizing AI, PineCone, Qdrant, reasoning systems, incremental learning, inference engine, k-means clustering, swarm intelligence, synthetic data generation, Watson kernel methods, Kubeflow, LIBSVM, loss functions, machine Conversation, Watson Studio, Weka Weaviate. learning, machine learning algorithms, machine learning methods, machine learning model monitoring and evaluation, Autonomous driving: advanced driver-assistance systems, machine learning model training, Markov chain, matrix autonomous cruise control systems, autonomous system, factorization, meta learning, Microsoft Cognitive Toolkit autonomous vehicles, dynamic routing, guidance navigation (CNTK), MLflow, MLOps (machine learning operations), and control systems, light detection and ranging (LiDAR), mlpack (C++ library), ModelOps, Naive Bayes Classifier, object tracking, OpenCV, path analysis, path finding, remote neural architecture compression, neural architecture search sensing, scene understanding, unmanned aerial systems (NAS), objective function, Oracle Autonomous Database, (UAS). Perceptron, Predictionio, predictive modeling, programmatic media buying, Pydata, PyTorch (machine learning library), Generative AI: Adobe Sensei, ChatGPT, CrewAI, DALL-E PyTorch Lightning, Random Forest Algorithm, recommender image generator, generative adversarial networks, generative systems, reinforcement learning, Scikit-Learn (Python AI agents, generative artificial intelligence,Google Bard, package), semi-uupervised learning, soft computing, sorting image inpainting, image super-resolution, LangGraph, algorithm, supervised learning, support vector machines large language modeling, Microsoft Copilot, multimodal (SVM), t-SNE (t-distributed Stochastic Neighbor Embedding), learning, multimodal models, prompt engineering, retrieval- test datasets, topological data analysis (TDA), Torch (machine augmented generation, Stable Diffusion, text summarization, learning), training datasets, transfer learning, transformer text to speech (TTS), variational autoencoders (VAEs). (machine learning model), unsupervised learning, Vowpal Wabbit, Xgboost, Theano (software). Machine learning: AdaBoost (adaptive boosting), adversarial machine learning, Apache MADlib, Apache Mahout, Apache Natural language processing: AI copywriting, Amazon SINGA, Apache Spark, association rule learning, attention Alexa, Amazon Textract, ANTLR, Apache OpenNLP, mechanisms, AutoGen, automated machine learning, BERT (NLP Model), chatbot, computational linguistics, autonomic computing, AWS SageMaker, Azure Machine conversational AI, DeepSpeech, dialog systems, fastText, Learning, bagging techniques, Bayesian belief networks, fuzzy logic, handwriting recognition, Hugging Face (NLP Boltzmann Machine, boosting, Chi-Squared Automatic framework), Hugging Face Transformers, intelligent agent, Interaction Detection (CHAID), Classification and Regression intelligent virtual assistant, Kaldi, language model, latent Tree (CART), cluster analysis, collaborative filtering, concept Dirichlet allocation, Lexalytics, machine translation, Microsoft drift detection, confusion matrix, cyber-physical systems, LUIS, natural language generation (NLG), natural language Dask (Software), data classification, Dbscan, decision processing (NLP), natural language programming, natural models, decision-tree learning, dimensionality reduction, language toolkits, natural language understanding (NLU), distributed machine learning, Dlib (C++ library), embedded natural language user interface, nearest neighbour algorithm, intelligence, ensemble methods, evolutionary programming, Nuance Mix, optical character recognition (OCR), screen expectation maximization algorithm, feature engineering, reader, semantic analysis, semantic interpretation for speech feature extraction, feature learning, feature selection, recognition, semantic kernel, semantic parsing, semantic federated learning, game AI, Gaussian process, genetic search, sentence transformers, sentiment analysis, Seq2Seq, algorithm, Google AutoML, Google Cloud ML Engine, Shogun, small language model, speech recognition, speech gradient boosting, gradient boosting machines (GBM), H2O. recognition software, speech synthesis, statistical language Table of Contents Appendix 433 Artificial Intelligence Index Report 2025 Appendix Chapter 4: Economy acquisition, summarization methods, text mining, text LinkedIn retrieval systems, text to speech (TTS), tokenization, Vespa, Prepared by Rosie Hood, Akash Kaura, and Mar Carpanelli voice assistant technology, voice interaction, voice user interface, word embedding, Word2Vec models. LinkedIn Data This body of work represents the world seen through LinkedIn Neural networks: Apache MXNet, artificial neural data, drawn from the anonymized and aggregated profile networks, autoencoders, Caffe (framework), Caffe2, information of LinkedIn’s more than 1 billion members around Chainer (Deep Learning Framework), convolutional neural the world. As such, it is influenced by how members choose networks (CNN), Cudnn, deep learning, deep learning to use the platform, which can vary based on professional, methods, Deeplearning4j, deep reinforcement learning social, and regional culture, as well as overall site availability (DRL), evolutionary acquisition of neural topologies, Fast. and accessibility. In publishing insights from LinkedIn’s AI, graph neural networks (GNNs), Keras (neural network Economic Graph, LinkedIn aims to provide accurate statistics library), Long Short-Term Memory (LSTM), neural ordinary while ensuring the privacy of LinkedIn’s members. As a result, differential equations, OpenVINO, PaddlePaddle, Pybrain, all data shows aggregated information for the corresponding recurrent neural network (RNN), reinforcement learning (RL), period following strict data quality thresholds that prevent residual networks (ResNet), sequence-to-sequence models disclosing any information about specific individuals. (seq2seq), spiking neural networks, TensorFlow. Country Sample Robotics: advanced robotics, bot framework, cognitive LinkedIn provides data on Argentina, Australia, Austria, robotics, meta-reinforcement learning, motion planning, Belgium, Brazil, Canada, Chile, Costa Rica, Croatia, Cyprus, Nvidia Jetson, OpenAI Gym environments, reinforcement Czechia, Denmark, Estonia, Finland, France, Germany, learning from human feedback (RLHF), robot framework, Greece, Hong Kong SAR, Hungary, Iceland, India, Indonesia, robot operating systems, robotic automation software, Ireland, Israel, Italy, Latvia, Lithuania, Luxembourg, Mexico, robotic liquid handling systems, robotic programming, robotic Netherlands, New Zealand, Norway, Poland, Portugal, systems, servomotor, SLAM algorithms (Simultaneous Romania, Saudi Arabia, Singapore, Slovenia, South Africa, Localization and Mapping). South Korea, Spain, Sweden, Switzerland, Turkey, United Arab Emirates, United Kingdom, United States, and Uruguay. Visual image recognition: 3D reconstruction, activity recognition, computer vision, contextual image classification, Skills Deck.gl, digital image processing, digital twin technology, eye LinkedIn members self-report their skills on their LinkedIn tracking, face detection, facial recognition, general-purpose profiles. Currently, more than 41,000 distinct, standardized computing on graphics processing units, gesture recognition, skills are identified by LinkedIn. image analysis, image captioning, image matching, image recognition, image segmentation, image sensor, ImageNet, LinkedIn categorizes AI skills into two mutually exclusive instance segmentation, machine vision, MNIST, motion groups: “AI Engineering” and “AI Literacy.” Broadly speaking, analysis, object recognition, OmniPage, pose estimation, AI Engineering skills refer to the technical expertise and RealSense, thermal imaging analysis. practical competencies required to design, develop, deploy, and maintain artificial intelligence systems, and AI Literacy skills refer to the knowledge, abilities, and critical thinking competencies needed to understand, evaluate, and effectively interact with artificial intelligence technologies. Table of Contents Appendix 434 Artificial Intelligence Index Report 2025 Appendix Chapter 4: Economy As skills are ever evolving, we maintain and refresh these METHODOLOGIES classifications on a periodic basis. For a list of skills included in this analysis, please see LinkedIn’s AI skills List below. 1. Top AI Skills These are the AI skills most frequently added by LinkedIn Industry members from 2015 onward. LinkedIn’s industry taxonomy is a collection of entities that share economic activities and contribute to a specific Interpretation: The most added AI Engineering skills globally product or service. An industry represents the products or are machine learning, AI, and deep learning. services that a company offers or sells. LinkedIn analyzes the following industries in the context of AI: education; 2. Fastest Growing AI Skills financial services; manufacturing; professional services; and The year-over-year growth rate for AI skills most frequently technology, information, and media. added by all members. Please note that LinkedIn implements thresholds to skill add volumes in the most recent year, which Gender are set at the 50th percentile of the most recent year’s AI skill LinkedIn recognizes that some LinkedIn members identify adds distribution by country. beyond the traditional gender constructs of “man” and “woman.” If not explicitly self-identified, LinkedIn has inferred Interpretation: The fastest growing AI Engineering skills the gender of members included in this analysis either by the globally are custom GPTs, AI productivity, and AI agents. pronouns used on their LinkedIn profiles or on the basis of first names. Members whose gender could not be inferred as 3. AI Talent Concentration either male or female were excluded from any gender analysis. The counts of AI talent are used to calculate talent Please note that LinkedIn filtered out countries where their concentration metric. In other words, to calculate the country- gender attribution algorithm did not have sufficient coverage. level AI talent concentration, LinkedIn uses the counts of AI talent in a particular country divided by the counts of LinkedIn AI Jobs or Occupations members in that country. Note that concentration metrics LinkedIn member titles are standardized and grouped into may be influenced by LinkedIn coverage in these countries over 16,000 occupations. These are not sector or country and should be utilized with caution. specific. An AI job requires AI skills to perform the job. Examples of such occupations include (but are not limited to): Interpretation: AI talent with AI Engineering skills represents machine learning engineer, artificial intelligence specialist, 0.78% of LinkedIn members in the United States. data scientist, and computer vision engineer. 4. Relative AI Talent Hiring Rate YoY Ratio AI Talent The LinkedIn hiring rate is a measure of hires normalized by A LinkedIn member is considered AI talent if they have LinkedIn membership. It is computed as the percentage of explicitly added at least two AI skills to their profile and/or LinkedIn members who added a new employer in the same they are or have been employed in an AI job. period the job began, divided by the total number of LinkedIn members in the corresponding location. The AI hiring rate is computed using the overall hiring rate methodology, but it only considers members classified as AI Table of Contents Appendix 435 Artificial Intelligence Index Report 2025 Appendix Chapter 4: Economy talent. The relative AI talent hiring rate YoY ratio is the year- AI SKILLS PENETRATION over-year change in the AI hiring rate relative to the overall The aim of this indicator is to measure the intensity of AI skills hiring rate in the same country. LinkedIn shares a 12-month in a given category using the following methodology: moving average. • LinkedIn computes frequencies for all self-added skills by LinkedIn members in a given entity (occupation, Interpretation: In the United States, the ratio of AI talent hiring industry, etc.) from 2015 onward. relative to overall hiring has grown 24.7% year over year. • LinkedIn reweights skill frequencies using a TF-IDF model to get the top 50 most representative skills in 5. Skill Penetration that entity. These 50 skills compose the “skill genome” of that entity. SKILLS GENOME • LinkedIn computes the share of skills that belong to the For any category (occupation, country, industry, etc.), the AI skill group out of the top skills in the selected entity. skills genome is an ordered list (a vector) of the 50 skills most characteristic of that category. These most characteristic Interpretation: The AI skills penetration rate signals the skills are determined using a TF-IDF algorithm, which down- prevalence of AI skills across occupations, or the intensity ranks ubiquitous skills that add little information about that with which LinkedIn members utilize AI skills in their jobs. For specific entity (e.g., Microsoft Word) and up-ranks skills example, the top 50 skills for the occupation of engineer are unique to that specific entity (e.g., artificial intelligence). calculated based on the weighted frequency with which they Further details are available at LinkedIn’s skills genome and appear in LinkedIn members’ profiles. If four of the skills that the LinkedIn–World Bank Methodology note. engineers possess belong to the AI skills group, this measure indicates that the penetration of AI skills is estimated to be As an example, Table 1 details the skills genome of the 8% among engineers (i.e., 4/50). technology, information, and media industry in the United States in 2024, displaying the top 10 skills ranked by TF-IDF. RELATIVE AI SKILLS PENETRATION To allow for skills penetration comparisons across countries, Skill name TF-IDF skill rank the skills genomes are calculated, and a relevant benchmark is selected (e.g., a global average). A ratio is then constructed Amazon Web Services (AWS) 1 between a country and the benchmark’s AI skills penetrations, Software as a Service (SaaS) 2 controlling for occupations. Artificial intelligence (AI) 3 Python (programming language) 4 Interpretation: If a country has a relative AI skills penetration of 1.5, that means AI skills are 1.5 times as frequent as in the Go-to-market strategy 5 benchmark, for an overlapping set of occupations. Customer success 6 Large language models (LLM) 7 GLOBAL COMPARISON Salesforce.com 8 For cross-country comparisons, LinkedIn presents the relative penetration rate of AI skills, measured as the sum of SQL 9 the penetration of each AI skill across occupations in a given Generative AI 10 country, divided by the average global penetration of AI skills across the overlapping occupations in a sample of countries. Table of Contents Appendix 436 Artificial Intelligence Index Report 2025 Appendix Chapter 4: Economy Interpretation: A relative penetration rate of 2 means the 7. AI Talent Migration average penetration of AI skills in that country is two times Data on migration comes from the World Bank Group– the global average across the same set of occupations. LinkedIn “Digital Data for Development” partnership (see https://linkedindata.worldbank.org/ and Zhu et al. (2018)). GLOBAL COMPARISON: BY INDUSTRY LinkedIn migration rates are derived from the self-identified The relative AI skills penetration by country for a given locations of LinkedIn member profiles. For example, when a industry provides an in-depth sectoral decomposition of AI LinkedIn member updates their location from Paris to London, skills penetration across industries and countries. this is counted as a migration. Migration data is available from 2019 onward. Interpretation: A country’s relative AI skill penetration rate of 2 in the education sector means the average penetration of LinkedIn data provides insights to countries on AI talent AI skills in that country is two times the global average across gained or lost due to migration trends. AI talent migration is the same set of occupations in that sector. considered for all members with AI skills/holding AI jobs at time “t” for country A as the country of interest and country GLOBAL COMPARISON: BY GENDER B as the source of inflows and destination for outflows. Thus, The relative AI skills penetration by gender provides a cross- net AI talent migration between country A and country B is country comparison of AI skills penetrations within a gender. calculated as: Since the global averages are distinct for each gender, this metric should only be used to compare country rankings within each gender, not for cross-gender comparisons within countries. Net flows are defined as total arrivals minus departures within a given time period. LinkedIn membership varies Interpretation: A country’s AI skills penetration for women between countries, which can prove challenging when of 1.5 means that female members in that country are 1.5 interpreting absolute movements of members from one times more likely to list AI skills than the average female country to another. Migration flows are therefore normalized member in all countries pooled together across the same set with respect to each country. For example, for country A, all of occupations that exist in the country-gender combination. absolute net flows into and out of country A, regardless of origin and destination countries, are normalized based on the GLOBAL COMPARISON: ACROSS GENDERS LinkedIn membership of country A at the end of each year The relative AI skills penetration across genders allows and multiplied by 10,000. Hence, this metric indicates relative for cross-gender comparisons within and across countries talent migration from all countries to and from country A. globally, since LinkedIn compares a country’s AI skills Please note that minimum thresholds have been applied such penetration by gender to the same global average regardless that transitions have a sufficient sample size. of gender. Interpretation: The United States had a positive net flow of 6. Female Representation in AI AI talent relative to its membership size at 1.07 net flow per This refers to the share of AI talent occupied by women. 10,000 members. Interpretation: Female representation within AI talent with 8. Career Transitions Into AI Jobs AI Engineering skills is 30.5% globally. LinkedIn considers the source occupations that feed AI occupations, analyzing the share of transitions into AI occupations pooled over a five-year period. Career transitions Table of Contents Appendix 437 Artificial Intelligence Index Report 2025 Appendix Chapter 4: Economy are computed by aggregating member-level job transitions representation and reasoning, LangChain, large language from one occupation to another occupation the member model operations (LLMOps), large language models (LLM), has not previously held. LinkedIn excludes first occupations machine learning, machine learning algorithms, machine added by new graduates and intra-occupation transitions. translation, Microsoft Azure Machine Learning, MLOps, model compression, model interpretation, model training, Interpretation: In the United States, 26.9% of transitions into music generation,nNatural language generation, natural AI engineer came from software engineer, followed by 13.3% language processing (NLP), natural language understanding, from data scientist. neural network architecture design, neural networks, NLTK, object recognition, ontologies, OpenAI API, OpenCV, parsing, THE LINKEDIN AI SKILLS LIST pattern recognition, predictive modeling, probabilistic generative models, probabilistic programming, prompt flow, AI Engineering PyTorch, question answering, random forest, RapidMiner, 3D reconstruction, AI agents, AI productivity, AI strategy, recommender systems, recurrent neural networks (RNN), algorithm analysis, algorithm development, Amazon Bedrock, reinforcement learning, responsible AI, Scikit-Learn, semantic Apache Spark ML, applied machine learning, artificial technologies, semantic web, sentiment analysis, speech intelligence (AI), artificial neural networks, association recognition, Spring AI, statistical inference, style transfer, rules, audio synthesis, autoencoders, automated clustering, StyleGAN, supervised learning, support vector machine automated feature engineering, automated machine learning (SVM), synthetic data generation, TensorFlow, text analytics, (AutoML), automated reasoning, autoregressive models, text classification, text generation, text mining, text-to-image Azure AI Studio, Caffe, chatbot development, chatbots, generation, Theano, time series forecasting, transformer classification, cognitive computing, computational geometry, models, unsupervised learning, variational autoencoders computational intelligence, computational linguistics, (VAEs), video generation, web mining, Weka, WordNet. concept drift adaptation, conditional generation, conditional image generation, convolutional neural networks (CNN), AI Literacy custom GPTs, decision trees, deep convolutional generative AI Builder, AI prompting, Anthropic Claude, ChatGPT, adversarial networks (DCGAN), deep convolutional neural DALL-E, generative AI, Generative AI Studio, generative AI nNetworks (DCNN), deep learning, deep neural networks tools, generative art, GitHub Copilot, Google Bard, Google (DNN), evolutionary algorithms, expert systems, facial Gemini, GPT-3, GPT-4, LLaMA, Microsoft Copilot, Microsoft recognition, feature extraction, feature selection, fuzzy Copilot Studio, Midjourney, multimodal prompting, prompt logic, generative adversarial imitation learning, generative engineering, Stable Diffusion. adversarial networks (GANs), generative AI, generative design optimization, generative flow models, generative Acknowledgments modeling, generative neural networks, generative LinkedIn gratefully acknowledges the contributions of Murat optimization, generative pre-training, generative query Erer and Carl Shan in developing these methodologies and networks (GQNs), generative replay memory, generative metrics, and the feedback from our collaborators at the synthesis, gesture recognition, Google Cloud AutoML, graph OECD.AI, Stanford Institute for Human-Centered AI, World embeddings, graph networks, hyperparameter optimization, Bank, and Centro Nacional de Inteligencia Artificial (Cenia). hyperparameter tuning, image generation, image inpainting, image processing, image synthesis, image-to-image translation, information extraction, intelligent agents, k-means clustering, Keras, knowledge discovery, knowledge Table of Contents Appendix 438 Artificial Intelligence Index Report 2025 Appendix Chapter 4: Economy Quid when investors’ names or funding amounts are not disclosed. Quid embeds Capital IQ data as a default and adds in data Quid insights prepared by Heather English and Hansen Yang from Crunchbase for the data points that are not captured in Capital IQ. This not only yields comprehensive and accurate Quid uses its own in-house LLM and other smart search data on all global organizations, but it also captures early- features, as well as traditional Boolean query, to search for stage startups and funding events data. focus areas, topics, and keywords within many datasets: social media, news, forums and blogs, companies, patents, as well as Search Parameters other custom feeds of data (e.g., survey data). Quid has many Boolean query is used to search for focus areas, topics, and visualization options and data delivery endpoints, including keywords within the archived company database and within network graphs based on semantic similarity, in-platform their business descriptions and websites. Quid can filter dashboarding capabilities, and programmatic PostgreSQL out the search results by HQ regions, investment amount, database delivery. Quid applies best-in-class AI and NLP to operating status, organization type (private/ public), and reveal hidden patterns in large datasets, enabling users to founding year. Quid then visualizes these companies by make data-driven decisions accurately, quickly, and efficiently. semantic similarity. If there are more than 7,000 companies from the search result, Quid selects the 7,000 most relevant Search, Data Sources, and Scope companies for visualization based on the language algorithm. Over 8 million global public and private company profiles Boolean search: “artificial intelligence” or “AI” or “machine from multiple data sources are indexed to search across learning” or “deep learning” company descriptions, while filtering and including metadata ranging from investment information to firmographic Companies information, such as founding year, headquarter location, and • Global AI and ML companies that have received more. Company information is updated on a weekly basis. investments (private, IPO, M&A) from Jan. 1, 2014, to The Quid algorithm reads a large amount of text data from Dec. 31, 2024. each document to make links between different documents • Global AI and ML companies that have received over based on their similar language. This process is repeated at $1.5 million for the past 10 years (Jan. 1, 2014, to Dec. an immense scale, which produces a network of different 31, 2024). clusters identifying distinct topics or focus areas. Trends are • Global data was also pulled for a generative AI query identified based on keywords, phrases, people, companies, (Boolean search: “generative AI” or “gen AI” OR and institutions that Quid identifies and other metadata that “generative artificial intelligence”) for companies that is put into the software. have received over $1.5 million for the past 10 years (Jan. 1, 2014, to Dec. 31, 2024). Data Target Event Definitions Companies • Private investment: A private placement is a private Organization data is embedded from Capital IQ and sale of newly issued securities (equity or debt) by a Crunchbase. These companies include every type of company to a select investor or group of investors. The organization (private, public, operating, operating as a stakes that buyers take in private placements are often subsidiary, out of business) throughout the world. The minority stakes (under 50%), although it is possible to investment data includes private investments, M&A, public take control of a company through a private placement offerings, minority stakes held by PE/ VCs, corporate venture as well, in which case the private placement would be arms, governments, and institutions both within and outside a majority stake investment. the United States. Some data is unavailable—for instance, Table of Contents Appendix 439 Artificial Intelligence Index Report 2025 Appendix Chapter 4: Economy • Minority investment: These refer to minority stake The second online survey of 2024 was in the field from July 16 acquisitions in Quid, which take place when the buyer to July 31, and garnered responses from 1,491 participants in acquires less than 50% of the existing ownership stake 101 nations representing the full range of regions, industries, in entities, asset products, and business divisions. company sizes, functional specialties, and tenures. Forty-two • M&A: This refers to a buyer acquiring more than percent of respondents said they work for organizations with 50% of the existing ownership stake in entities, asset more than $500 million in annual revenues. products, and business divisions. To adjust for differences in response rates, the data is weighted McKinsey & Company by the contribution of each respondent’s nation to global GDP. Data used in the “Corporate Activity” section was sourced from two McKinsey global surveys: “The State of AI in Early The AI Index also considered data from previous iterations of 2024: Gen AI Adoption Spikes and Starts to Generate Value” the McKinsey survey. These include: and “The State of AI: How Organizations Are Rewiring to The State of AI in 2023: Generative AI’s Breakout Year Capture Value.” The State of AI in 2022—and a Half Decade in Review The State of AI in 2021 The first online survey of 2024 was in the field from Feb. 22 The State of AI in 2020 to March 5, and garnered responses from 1,363 participants AI Proves Its Worth, But Few Scale Impact (2019) representing the full range of regions, industries, company AI Adoption Advances, But Foundational Barriers Remain sizes, functional specialties, and tenures. Among the (2018) respondents, 981 said their organizations had adopted AI in at least one business function, and 878 said their organizations were regularly using gen AI in at least one function. Table of Contents Appendix 440 Artificial Intelligence Index Report 2025 Appendix Chapter 4: Economy Works Cited Brynjolfsson, E., Li, D., & Raymond, L. (2025). Generative AI at Work. The Quarterly Journal of Economics, qjae044. https://doi. org/10.1093/qje/qjae044 Cui, Z. (Kevin), Demirer, M., Jaffe, S., Musolff, L., Peng, S., & Salz, T. (2025). The Effects of Generative AI on High-Skilled Work: Evidence From Three Field Experiments With Software Developers (SSRN Scholarly Paper 4945566). https://doi.org/10.2139/ ssrn.4945566 Dell’Acqua, F., McFowland, E., Mollick, E. R., Lifshitz-Assaf, H., Kellogg, K., Rajendran, S., Krayer, L., Candelon, F., & Lakhani, K. R. (2023). Navigating the Jagged Technological Frontier: Field Experimental Evidence of the Effects of AI on Knowledge Worker Productivity and Quality. SSRN Electronic Journal. https://doi.org/10.2139/ssrn.4573321 Handa, K., Tamkin, A., McCain, M., Huang, S., Durmus, E., Heck, S., Mueller, J., Hong, J., Ritchie, S., Belonax, T., Troy, K. K., Amodei, D., Kaplan, J., Clark, J., & Ganguli, D. (2025). Which Economic Tasks Are Performed with AI? Evidence From Millions of Claude Conversations (arXiv:2503.04761). arXiv. https://doi.org/10.48550/arXiv.2503.04761 Hoffmann, M., Boysel, S., Nagle, F., Peng, S., & Xu, K. (2024). Generative AI and the Nature of Work (No. 11479). CESifo Working Paper. https://www.econstor.eu/bitstream/10419/308375/1/cesifo1_wp11479.pdf Jaffe, S., Shah, N. P., Butler, J., Farach, A., Cambon, A., Hecht, B., Schwarz, M., & Teevan, J. (eEds.). (2024). Generative AI in Real-World Workplaces: The Second Microsoft Report on AI and Productivity Research. Microsoft. https://www.microsoft.com/ en-us/research/wp-content/uploads/2024/07/Generative-AI-in-Real-World-Workplaces.pdf Necula, S.-C., Fotache, D., & Rieder, E. (2024). Assessing the Impact of Artificial Intelligence Tools on Employee Productivity: Insights From a Comprehensive Survey Analysis. Electronics, 13(18), Article 18. https://doi.org/10.3390/electronics13183758 Table of Contents Appendix 441 Artificial Intelligence Index Report 2025 Appendix Chapter 5: Science and Medicine Chapter 5: Science and Medicine Acknowledgments model alleged to be a foundation model that had been trained on fewer than 1 million data points or not evaluated on The AI Index would like to acknowledge Armin Hamrah for multiple tasks was discarded. his work in surveying the literature on significant trends in AI- related science and medicine. FDA-Approved AI Medical Benchmarks Devices 1. MedQA: Data on MedQA was taken from the MedQA Data on FDA-approved AI medical devices was sourced Papers With Code leaderboard in February 2025. To learn from the FDA website, which tracks artificial intelligence and more about MedQA, please read the original paper. machine learning (AI/ML)–enabled medical devices. AI-Driven Protein Science Ethical Considerations Publications The AI Index used PubMedCentral’s API to query for English- language indexed articles published between Jan. 1, 2020, The AI Index used Dimensions’ AI document search function and Dec. 31, 2024, using search terms regarding artificial to measure the number of manuscripts published in a year. intelligence, medicine, and ethical issues. In order to obtain The searches were restricted to the 2024 publication year only articles at the intersection of those three topics, the AI and the biological sciences category (987,717 publications). Index further narrowed the articles to those with an abstract Then a search was conducted for each key term, which had to including a keyword related to: (a) artificial intelligence, (b) be present in both the title and the abstract. This requirement medicine, and (c) at least one ethical issue. After removing limited the number of manuscripts returned that might preprints, retracted articles, and articles that failed to satisfy only have mentioned the key term in passing, rather than the inclusion criteria, 2,916 articles remained. The AI Index describing research about the key term. Once the number used the frequency of ethical issues mentioned in abstracts of manuscripts was identified, the percent of total biological across this pool of articles to conduct its analysis. sciences manuscripts about each key term was calculated. Image and Multimodal AI for API query: (“artificial intelligence”[MeSH] OR “machine learning”[MeSH] Scientific Discovery OR “deep learning”[All Fields] OR “AI”[All Fields] OR The AI Index used Semantic Scholar and Google Scholar to “ML”[All Fields] OR “predictive analytics”[All Fields]) AND measure the number of manuscripts published from 2023 to ((“ethics”[MeSH] OR “ethical implications”[All Fields] OR 2025. A search was then performed for each key term (e.g., “fair*”[All Fields] OR “unfair*”[All Fields] OR “bias”[All Fields] “foundation models,” “microscopy,” “electron microscopy,” OR “accountability”[All Fields] OR “transparency”[All Fields] “fluorescence microscopy,” “light microscopy”) with the OR “explainability”[All Fields] OR “privacy”[All Fields] OR requirement that the terms be present in both the title “trustworthy AI”[All Fields]) OR (“bioethics”[MeSH] OR and the abstract. Furthermore, the search was refined to “ELSI”[All Fields] OR “autonomy”[All Fields] OR “equity”[All strictly comply with the definition of a foundation model— Fields] OR “equitab*”[All Fields] OR “justice”[All Fields] OR specifically, a model trained on vast datasets that can be “beneficence”[All Fields] OR “non-maleficence”[All Fields] applied across a wide range of use cases. To this end, any OR “independent review”[All Fields] OR “oversight”[All Table of Contents Appendix 442 Artificial Intelligence Index Report 2025 Appendix Chapter 5: Science and Medicine Fields] OR “racis*”[All Fields] OR “prejud*”[All Fields] OR • AI keywords: “artificial intelligence,” “ AI,” “algorithm,” “inequit*”[All Fields] OR “community engagement”[All “ML,” “machine learning,” “deep learning,” predictive Fields] OR “misuse”[All Fields] OR “dual use”[All Fields])) analytics. AND (“medicine”[MeSH] OR “medical AI”[All Fields] • Medicine keywords: “medicine,” “medical,” “health,” OR “clinical decision support”[All Fields] OR “health “healthcare.” informatics”[All Fields]) AND (“2020/01/01”[PubDate] : • Ethics keywords: “ethic*,” “fairness,” “bias,” “2024/12/31”[PubDate]) “accountability,” “transparency,” “explainability,” “privacy,” “trustworthy AI,” “bioethics,” “ELSI,” Date of search: 2/14/2025 “autonomy,” “equit*,” “justice,” “beneficence,” “non- maleficence,” “independent review,” “oversight,” Abstract inclusion criteria: “racism,” “inequit*,” community engagement, misuse, Therefore, includes only articles that discuss medicine, dual use. artificial intelligence, and at least one ethical issue within the abstract (N = 2,916). Table of Contents Appendix 443 Artificial Intelligence Index Report 2025 Appendix Chapter 5: Science and Medicine Works Cited Abramson, J., Adler, J., Dunger, J., Evans, R., Green, T., Pritzel, A., Ronneberger, O., Willmore, L., Ballard, A. J., Bambrick, J., Bodenstein, S. W., Evans, D. A., Hung, C.-C., O’Neill, M., Reiman, D., Tunyasuvunakool, K., Wu, Z., Žemgulytė, A., Arvaniti, E., … Jumper, J. M. (2024). Accurate Structure Prediction of Biomolecular Interactions With AlphaFold 3. Nature, 630(8016), 493– 500. https://doi.org/10.1038/s41586-024-07487-w Acharya, R., Abanin, D. A., Aghababaie-Beni, L., Aleiner, I., Andersen, T. I., Ansmann, M., Arute, F., Arya, K., Asfaw, A., Astrakhantsev, N., Atalaya, J., Babbush, R., Bacon, D., Ballard, B., Bardin, J. C., Bausch, J., Bengtsson, A., Bilmes, A., Blackwell, S., … Google Quantum AI and Collaborators. (2025). Quantum Error Correction Below the Surface Code Threshold. Nature, 638(8052), 920–26. https://doi.org/10.1038/s41586-024-08449-y Blankemeier, L., Cohen, J. P., Kumar, A., Veen, D. V., Gardezi, S. J. S., Paschali, M., Chen, Z., Delbrouck, J.-B., Reis, E., Truyts, C., Bluethgen, C., Jensen, M. E. K., Ostmeier, S., Varma, M., Valanarasu, J. M. J., Fang, Z., Huo, Z., Nabulsi, Z., Ardila, D., … Chaudhari, A. S. (2024). Merlin: A Vision Language Foundation Model for 3D Computed Tomography (arXiv:2406.06512). arXiv. https://doi.org/10.48550/arXiv.2406.06512 Bodnar, C., Bruinsma, W. P., Lucic, A., Stanley, M., Vaughan, A., Brandstetter, J., Garvan, P., Riechert, M., Weyn, J. A., Dong, H., Gupta, J. K., Thambiratnam, K., Archibald, A. T., Wu, C.-C., Heider, E., Welling, M., Turner, R. E., & Perdikaris, P. (2024). A Foundation Model for the Earth System (arXiv:2405.13063). arXiv. https://doi.org/10.48550/arXiv.2405.13063 Burley, S. K., Berman, H. M., Kleywegt, G. J., Markley, J. L., Nakamura, H., & Velankar, S. (2017). Protein Data Bank (PDB): The Single Global Macromolecular Structure Archive. Methods in Molecular Biology (Clifton, N.J.), 1607, 627–41. https://doi. org/10.1007/978-1-4939-7000-1_26 Callahan, A., McElfresh, D., Banda, J. M., Bunney, G., Char, D., Chen, J., Corbin, C. K., Dash, D., Downing, N. L., Jain, S. S., Kotecha, N., Masterson, J., Mello, M. M., Morse, K., Nallan, S., Pandya, A., Revri, A., Sharma, A., Sharp, C., … Shah, N. H. (2024). Standing on FURM Ground: A Framework for Evaluating Fair, Useful, and Reliable AI Models in Health Care Systems. NEJM Catalyst, 5(10), CAT.24.0131. https://doi.org/10.1056/CAT.24.0131 Campanella, G., Chen, S., Verma, R., Zeng, J., Stock, A., Croken, M., Veremis, B., Elmas, A., Huang, K., Kwan, R., Houldsworth, J., Schoenfeld, A. J., & Vanderbilt, C. (2024). A Clinical Benchmark of Public Self-Supervised Pathology Foundation Models (arXiv:2407.06508). arXiv. https://doi.org/10.48550/arXiv.2407.06508 Carrillo-Perez, F., Pizurica, M., Zheng, Y., Nandi, T. N., Madduri, R., Shen, J., & Gevaert, O. (2023). RNA-to-Image Multi- cancer Synthesis Using Cascaded Diffusion Models. bioRxiv: The Preprint Server for Biology, 2023.01.13.523899. https://doi. org/10.1101/2023.01.13.523899 Chambon, P., Bluethgen, C., Delbrouck, J.-B., Sluijs, R. V. der, Połacin, M., Chaves, J. M. Z., Abraham, T. M., Purohit, S., Langlotz, C. P., & Chaudhari, A. (2022). RoentGen: Vision-Language Foundation Model for Chest X-ray Generation (arXiv:2211.12737). arXiv. https://doi.org/10.48550/arXiv.2211.12737 Table of Contents Appendix 444 Artificial Intelligence Index Report 2025 Appendix Chapter 5: Science and Medicine Chambon, P., Delbrouck, J.-B., Sounack, T., Huang, S.-C., Chen, Z., Varma, M., Truong, S. Q., Chuong, C. T., & Langlotz, C. P. (2024). CheXpert Plus: Augmenting a Large Chest X-ray Dataset With Text Radiology Reports, Patient Demographics and Additional Image Formats (arXiv:2405.19538). arXiv. https://doi.org/10.48550/arXiv.2405.19538 Chen, R. J., Chen, C., Li, Y., Chen, T. Y., Trister, A. D., Krishnan, R. G., & Mahmood, F. (2022). Scaling Vision Transformers to Gigapixel Images via Hierarchical Self-Supervised Learning (arXiv:2206.02647). arXiv. https://doi.org/10.48550/arXiv.2206.02647 Chen, Z., Varma, M., Xu, J., Paschali, M., Veen, D. V., Johnston, A., Youssef, A., Blankemeier, L., Bluethgen, C., Altmayer, S., Valanarasu, J. M. J., Muneer, M. S. E., Reis, E. P., Cohen, J. P., Olsen, C., Abraham, T. M., Tsai, E. B., Beaulieu, C. F., Jitsev, J., … Langlotz, C. P. (2024). A Vision-Language Foundation Model to Enhance Efficiency of Chest X-ray Interpretation (arXiv:2401.12208). arXiv. https://doi.org/10.48550/arXiv.2401.12208 Christensen, M., Vukadinovic, M., Yuan, N., & Ouyang, D. (2024). Vision–Language Foundation Model for Echocardiogram Interpretation. Nature Medicine, 30(5), 1481–88. https://doi.org/10.1038/s41591-024-02959-y Clark, K., Vendt, B., Smith, K., Freymann, J., Kirby, J., Koppel, P., Moore, S., Phillips, S., Maffitt, D., Pringle, M., Tarbox, L., & Prior, F. (2013). The Cancer Imaging Archive (TCIA): Maintaining and Operating a Public Information Repository. Journal of Digital Imaging, 26(6), 1045–57. https://doi.org/10.1007/s10278-013-9622-7 Ding, S., Li, J., Wang, J., Ying, S., & Shi, J. (2023). Multi-scale Efficient Graph-Transformer for Whole Slide Image Classification (arXiv:2305.15773). arXiv. https://doi.org/10.48550/arXiv.2305.15773 Ding, T., Wagner, S. J., Song, A. H., Chen, R. J., Lu, M. Y., Zhang, A., Vaidya, A. J., Jaume, G., Shaban, M., Kim, A., Williamson, D. F. K., Chen, B., Almagro-Perez, C., Doucet, P., Sahai, S., Chen, C., Komura, D., Kawabe, A., Ishikawa, S., … Mahmood, F. (2024). Multimodal Whole Slide Foundation Model for Pathology(arXiv:2411.19666). arXiv. https://doi.org/10.48550/arXiv.2411.19666 Goh, E., Gallo, R., Hom, J., Strong, E., Weng, Y., Kerman, H., Cool, J. A., Kanjee, Z., Parsons, A. S., Ahuja, N., Horvitz, E., Yang, D., Milstein, A., Olson, A. P. J., Rodman, A., & Chen, J. H. (2024). Large Language Model Influence on Diagnostic Reasoning: A Randomized Clinical Trial. JAMA Network Open, 7(10), e2440969. https://doi.org/10.1001/jamanetworkopen.2024.40969 Goh, E., Gallo, R. J., Strong, E., Weng, Y., Kerman, H., Freed, J. A., Cool, J. A., Kanjee, Z., Lane, K. P., Parsons, A. S., Ahuja, N., Horvitz, E., Yang, D., Milstein, A., Olson, A. P. J., Hom, J., Chen, J. H., & Rodman, A. (2025). GPT-4 Assistance for Improvement of Physician Performance on Patient Care Tasks: A Randomized Controlled Trial. Nature Medicine, 1–6. https://doi.org/10.1038/ s41591-024-03456-y Gruver, N., Sriram, A., Madotto, A., Wilson, A. G., Zitnick, C. L., & Ulissi, Z. (2024). Fine-Tuned Language Models Generate Stable Inorganic Materials as Text (arXiv:2402.04379). arXiv. https://doi.org/10.48550/arXiv.2402.04379 Guevara, M., Chen, S., Thomas, S., Chaunzwa, T. L., Franco, I., Kann, B. H., Moningi, S., Qian, J. M., Goldstein, M., Harper, S., Aerts, H. J. W. L., Catalano, P. J., Savova, G. K., Mak, R. H., & Bitterman, D. S. (2024). Large Language Models to Identify Social Determinants of Health in Electronic Health Records. Npj Digital Medicine, 7(1), 1–14. https://doi.org/10.1038/s41746-023- 00970-0 Table of Contents Appendix 445 Artificial Intelligence Index Report 2025 Appendix Chapter 5: Science and Medicine Guo, Z., Zhao, W., Wang, S., & Yu, L. (2023). HIGT: Hierarchical Interaction Graph-Transformer for Whole Slide Image Analysis (arXiv:2309.07400). arXiv. https://doi.org/10.48550/arXiv.2309.07400 Haberle, T., Cleveland, C., Snow, G. L., Barber, C., Stookey, N., Thornock, C., Younger, L., Mullahkhel, B., & Ize-Ludlow, D. (2024). The Impact of Nuance DAX Ambient Listening AI Documentation: A Cohort Study. Journal of the American Medical Informatics Association, 31(4), 975–79. https://doi.org/10.1093/jamia/ocae022 Hashmi, A. U. R., Almakky, I., Qazi, M. A., Sanjeev, S., Papineni, V. R., Jagdish, J., & Yaqub, M. (2024). XReal: Realistic Anatomy and Pathology-Aware X-ray Generation via Controllable Diffusion Model (arXiv:2403.09240). arXiv. https://doi.org/10.48550/ arXiv.2403.09240 Hayes, T., Rao, R., Akin, H., Sofroniew, N. J., Oktay, D., Lin, Z., Verkuil, R., Tran, V. Q., Deaton, J., Wiggert, M., Badkundri, R., Shafkat, I., Gong, J., Derry, A., Molina, R. S., Thomas, N., Khan, Y. A., Mishra, C., Kim, C., … Rives, A. (2024). Simulating 500 Million Years of Evolution With a Language Model (p. 2024.07.01.600583). bioRxiv. https://doi.org/10.1101/2024.07.01.600583 Hellert, T., Montenegro, J., & Pollastro, A. (2024). PhysBERT: A Text Embedding Model for Physics Scientific Literature (arXiv:2408.09574). arXiv. https://doi.org/10.48550/arXiv.2408.09574 Hornick, T., Mao, C., Koynov, A., Yawman, P., Thool, P., Salish, K., Giles, M., Nagapudi, K., & Zhang, S. (2024). In Silico Formulation Optimization and Particle Engineering of Pharmaceutical Products Using a Generative Artificial Intelligence Structure Synthesis Method. Nature Communications, 15(1), 9622. https://doi.org/10.1038/s41467-024-54011-9 Istasy, P., Lee, W. S., Iansavichene, A., Upshur, R., Gyawali, B., Burkell, J., Sadikovic, B., Lazo-Langner, A., & Chin-Yee, B. (2022). The Impact of Artificial Intelligence on Health Equity in Oncology: Scoping Review. Journal of Medical Internet Research, 24(11), e39748. https://doi.org/10.2196/39748 Jiang, J. X., Qi, K., Bai, G., & Schulman, K. (2023). Pre-pandemic Assessment: A Decade of Progress in Electronic Health Record Adoption Among U.S. Hospitals. Health Affairs Scholar, 1(5), qxad056. https://doi.org/10.1093/haschl/qxad056 Jin, D., Pan, E., Oufattole, N., Weng, W.-H., Fang, H., & Szolovits, P. (2020). What Disease Does This Patient Have? A Large- Scale Open Domain Question Answering Dataset From Medical Exams (arXiv:2009.13081). arXiv. https://doi.org/10.48550/ arXiv.2009.13081 Johnson, A. E. W., Pollard, T. J., Berkowitz, S. J., Greenbaum, N. R., Lungren, M. P., Deng, C., Mark, R. G., & Horng, S. (2019). MIMIC-CXR, a De-identified Publicly Available Database of Chest Radiographs With Free-Text Reports. Scientific Data, 6(1), 317. https://doi.org/10.1038/s41597-019-0322-0 Kochkov, D., Yuval, J., Langmore, I., Norgaard, P., Smith, J., Mooers, G., Klöwer, M., Lottes, J., Rasp, S., Düben, P., Hatfield, S., Battaglia, P., Sanchez-Gonzalez, A., Willson, M., Brenner, M. P., & Hoyer, S. (2024). Neural General Circulation Models for Weather and Climate. Nature, 632(8027), 1060–66. https://doi.org/10.1038/s41586-024-07744-y Table of Contents Appendix 446 Artificial Intelligence Index Report 2025 Appendix Chapter 5: Science and Medicine Kudiabor, H. (2024). Virtual Lab Powered by ‘AI Scientists’ Super-Charges Biomedical Research. Nature, 636(8043), 532–33. https://doi.org/10.1038/d41586-024-01684-3 Kumar, A., Kriz, A., Havaei, M., & Arbel, T. (2025). PRISM: High-Resolution & Precise Counterfactual Medical Image Generation Using Language-Guided Stable Diffusion (arXiv:2503.00196). arXiv. https://doi.org/10.48550/arXiv.2503.00196 Lu, M. Y., Chen, B., Williamson, D. F. K., Chen, R. J., Zhao, M., Chow, A. K., Ikemura, K., Kim, A., Pouli, D., Patel, A., Soliman, A., Chen, C., Ding, T., Wang, J. J., Gerber, G., Liang, I., Le, L. P., Parwani, A. V., Weishaupt, L. L., & Mahmood, F. (2024). A Multimodal Generative AI Copilot for Human Pathology. Nature, 634(8033), 466–73. https://doi.org/10.1038/s41586-024-07618-3 Lutsker, G., Sapir, G., Shilo, S., Merino, J., Godneva, A., Greenfield, J. R., Samocha-Bonet, D., Dhir, R., Gude, F., Mannor, S., Meirom, E., Chechik, G., Rossman, H., & Segal, E. (2025). From Glucose Patterns to Health Outcomes: A Generalizable Foundation Model for Continuous Glucose Monitor Data Analysis (arXiv:2408.11876). arXiv. https://doi.org/10.48550/arXiv.2408.11876 Ma, J., He, Y., Li, F., Han, L., You, C., & Wang, B. (2024). Segment Anything in Medical Images. Nature Communications, 15(1), 654. https://doi.org/10.1038/s41467-024-44824-z Ma, S. P., Liang, A. S., Shah, S. J., Smith, M., Jeong, Y., Devon-Sand, A., Crowell, T., Delahaie, C., Hsia, C., Lin, S., Shanafelt, T., Pfeffer, M. A., Sharp, C., & Garcia, P. (2025). Ambient Artificial Intelligence Scribes: Utilization and Impact on Documentation Time. Journal of the American Medical Informatics Association, 32(2), 381–85. https://doi.org/10.1093/jamia/ocae304 Madani, A., Krause, B., Greene, E. R., Subramanian, S., Mohr, B. P., Holton, J. M., Olmos, J. L., Xiong, C., Sun, Z. Z., Socher, R., Fraser, J. S., & Naik, N. (2023). Large Language Models Generate Functional Protein Sequences Across Diverse Families. Nature Biotechnology, 41(8), 1099–1106. https://doi.org/10.1038/s41587-022-01618-2 Maier-Hein, L., Eisenmann, M., Reinke, A., Onogur, S., Stankovic, M., Scholz, P., Arbel, T., Bogunovic, H., Bradley, A. P., Carass, A., Feldmann, C., Frangi, A. F., Full, P. M., van Ginneken, B., Hanbury, A., Honauer, K., Kozubek, M., Landman, B. A., März, K., … Kopp-Schneider, A. (2018). Why Rankings of Biomedical Image Analysis Competitions Should Be Interpreted With Care. Nature Communications, 9(1), 5217. https://doi.org/10.1038/s41467-018-07619-7 Mei, X., Liu, Z., Robson, P. M., Marinelli, B., Huang, M., Doshi, A., Jacobi, A., Cao, C., Link, K. E., Yang, T., Wang, Y., Greenspan, H., Deyer, T., Fayad, Z. A., & Yang, Y. (2022). RadImageNet: An Open Radiologic Deep Learning Research Dataset for Effective Transfer Learning. Radiology: Artificial Intelligence, 4(5), e210315. https://doi.org/10.1148/ryai.210315 Narayanan, S., Braza, J. D., Griffiths, R.-R., Ponnapati, M., Bou, A., Laurent, J., Kabeli, O., Wellawatte, G., Cox, S., Rodriques, S. G., & White, A. D. (2024). Aviary: Training Language Agents on Challenging Scientific Tasks (arXiv:2412.21154). arXiv. https://doi. org/10.48550/arXiv.2412.21154 Nori, H., Lee, Y. T., Zhang, S., Carignan, D., Edgar, R., Fusi, N., King, N., Larson, J., Li, Y., Liu, W., Luo, R., McKinney, S. M., Ness, R. O., Poon, H., Qin, T., Usuyama, N., White, C., & Horvitz, E. (2023). Can Generalist Foundation Models Outcompete Special- Purpose Tuning? Case Study in Medicine (arXiv:2311.16452). arXiv. https://doi.org/10.48550/arXiv.2311.16452 Table of Contents Appendix 447 Artificial Intelligence Index Report 2025 Appendix Chapter 5: Science and Medicine Nori, H., Usuyama, N., King, N., McKinney, S. M., Fernandes, X., Zhang, S., & Horvitz, E. (2024). From Medprompt to o1: Exploration of Run-Time Strategies for Medical Challenge Problems and Beyond (arXiv:2411.03590). arXiv. https://doi.org/10.48550/ arXiv.2411.03590 Pokharel, S., Pratyush, P., Heinzinger, M., Newman, R. H., & Kc, D. B. (2022). Improving Protein Succinylation Sites Prediction Using Embeddings From Protein Language Model. Scientific Reports, 12(1), 16933. https://doi.org/10.1038/s41598-022-21366-2 Price, I., Sanchez-Gonzalez, A., Alet, F., Andersson, T. R., El-Kadi, A., Masters, D., Ewalds, T., Stott, J., Mohamed, S., Battaglia, P., Lam, R., & Willson, M. (2025). Probabilistic Weather Forecasting With Machine Learning. Nature, 637(8044), 84–90. https://doi.org/10.1038/s41586-024-08252-9 Qian, Z., Callender, T., Cebere, B., Janes, S. M., Navani, N., & van der Schaar, M. (2024). Synthetic Data for Privacy-Preserving Clinical Risk Prediction. Scientific Reports, 14(1), 25676. https://doi.org/10.1038/s41598-024-72894-y Qiu, J., Wu, J., Wei, H., Shi, P., Zhang, M., Sun, Y., Li, L., Liu, H., Liu, H., Hou, S., Zhao, Y., Shi, X., Xian, J., Qu, X., Zhu, S., Pan, L., Chen, X., Zhang, X., Jiang, S., … Yuan, W. (2024). Development and Validation of a Multimodal Multitask Vision Foundation Model for Generalist Ophthalmic Artificial Intelligence. NEJM AI, 1(12), AIoa2300221. https://doi.org/10.1056/AIoa2300221 Quer, G., & Topol, E. J. (2024). The Potential for Large Language Models to Transform Cardiovascular Medicine. The Lancet Digital Health, 6(10), e767–71. https://doi.org/10.1016/S2589-7500(24)00151-1 Rashidi, H. H., Albahra, S., Rubin, B. P., & Hu, B. (2024). A Novel and Fully Automated Platform for Synthetic Tabular Data Generation and Validation. Scientific Reports, 14(1), 23312. https://doi.org/10.1038/s41598-024-73608-0 Shah, S. J., Devon-Sand, A., Ma, S. P., Jeong, Y., Crowell, T., Smith, M., Liang, A. S., Delahaie, C., Hsia, C., Shanafelt, T., Pfeffer, M. A., Sharp, C., Lin, S., & Garcia, P. (2025). Ambient Artificial Intelligence Scribes: Physician Burnout and Perspectives on Usability and Documentation Burden. Journal of the American Medical Informatics Association, 32(2), 375–80. https://doi.org/10.1093/ jamia/ocae295 Shapson-Coe, A., Januszewski, M., Berger, D. R., Pope, A., Wu, Y., Blakely, T., Schalek, R. L., Li, P. H., Wang, S., Maitin-Shepard, J., Karlupia, N., Dorkenwald, S., Sjostedt, E., Leavitt, L., Lee, D., Troidl, J., Collman, F., Bailey, L., Fitzmaurice, A., … Lichtman, J. W. (2024). A Petavoxel Fragment of Human Cerebral Cortex Reconstructed at Nanoscale Resolution. Science, 384(6696), eadk4858. https://doi.org/10.1126/science.adk4858 Sheller, M. J., Edwards, B., Reina, G. A., Martin, J., Pati, S., Kotrotsou, A., Milchenko, M., Xu, W., Marcus, D., Colen, R. R., & Bakas, S. (2020). Federated Learning in Medicine: Facilitating Multi-institutional Collaborations Without Sharing Patient Data. Scientific Reports, 10(1), 12598. https://doi.org/10.1038/s41598-020-69250-1 Shi, J., Tang, L., Gao, Z., Li, Y., Wang, C., Gong, T., Li, C., & Fu, H. (2023). MG-Trans: Multi-scale Graph Transformer With Information Bottleneck for Whole Slide Image Classification. IEEE Transactions on Medical Imaging, 42(12), 3871–83. https://doi.org/10.1109/TMI.2023.3313252 Table of Contents Appendix 448 Artificial Intelligence Index Report 2025 Appendix Chapter 5: Science and Medicine Snel, B., Lehmann, G., Bork, P., & Huynen, M. A. (2000). STRING: A Web-Server to Retrieve and Display the Repeatedly Occurring Neighbourhood of a Gene. Nucleic Acids Research, 28(18), 3442–44. https://doi.org/10.1093/nar/28.18.3442 Snowdon, J. L., Scheufele, E. L., Pritts, J., Le, P.-T., Mensah, G. A., Zhang, X., & Dankwa-Mullan, I. (2023). Evaluating Social Determinants of Health Variables in Advanced Analytic and Artificial Intelligence Models for Cardiovascular Disease Risk and Outcomes: A Targeted Review. Ethnicity & Disease, 33(1), 33–43. https://doi.org/10.18865/1704 Stade, E. C., Stirman, S. W., Ungar, L. H., Boland, C. L., Schwartz, H. A., Yaden, D. B., Sedoc, J., DeRubeis, R. J., Willer, R., & Eichstaedt, J. C. (2024). Large Language Models Could Change the Future of Behavioral Healthcare: A Proposal for Responsible Development and Evaluation. Npj Mental Health Research, 3(1), 1–12. https://doi.org/10.1038/s44184-024-00056-z Sudlow, C., Gallacher, J., Allen, N., Beral, V., Burton, P., Danesh, J., Downey, P., Elliott, P., Green, J., Landray, M., Liu, B., Matthews, P., Ong, G., Pell, J., Silman, A., Young, A., Sprosen, T., Peakman, T., & Collins, R. (2015). UK Biobank: An Open Access Resource for Identifying the Causes of a Wide Range of Complex Diseases of Middle and Old Age. PLoS Medicine, 12(3), e1001779. https://doi.org/10.1371/journal.pmed.1001779 Tierney, A. A., Gayre, G., Hoberman, B., Mattern, B., Ballesca, M., Kipnis, P., Liu, V., & Lee, K. (2024). Ambient Artificial Intelligence Scribes to Alleviate the Burden of Clinical Documentation. NEJM Catalyst, 5(3), CAT.23.0404. https://doi.org/10.1056/ CAT.23.0404 Varadi, M., Anyango, S., Deshpande, M., Nair, S., Natassia, C., Yordanova, G., Yuan, D., Stroe, O., Wood, G., Laydon, A., Žídek, A., Green, T., Tunyasuvunakool, K., Petersen, S., Jumper, J., Clancy, E., Green, R., Vora, A., Lutfi, M., … Velankar, S. (2022). AlphaFold Protein Structure Database: Massively Expanding the Structural Coverage of Protein-Sequence Space With High-Accuracy Models. Nucleic Acids Research, 50(D1), D439–44. https://doi.org/10.1093/nar/gkab1061 Veitch, D. P., Weiner, M. W., Aisen, P. S., Beckett, L. A., Cairns, N. J., Green, R. C., Harvey, D., Jack, C. R., Jagust, W., Morris, J. C., Petersen, R. C., Saykin, A. J., Shaw, L. M., Toga, A. W., Trojanowski, J. Q., & Alzheimer’s Disease Neuroimaging Initiative. (2019). Understanding Disease Progression and Improving Alzheimer’s Disease Clinical Trials: Recent Highlights From the Alzheimer’s Disease Neuroimaging Initiative. Alzheimer’s & Dementia: The Journal of the Alzheimer’s Association, 15(1), 106–52. https://doi. org/10.1016/j.jalz.2018.08.005 Vorontsov, E., Bozkurt, A., Casson, A., Shaikovski, G., Zelechowski, M., Severson, K., Zimmermann, E., Hall, J., Tenenholtz, N., Fusi, N., Yang, E., Mathieu, P., van Eck, A., Lee, D., Viret, J., Robert, E., Wang, Y. K., Kunz, J. D., Lee, M. C. H., … Fuchs, T. J. (2024). A Foundation Model for Clinical-Grade Computational Pathology and Rare Cancers Detection. Nature Medicine, 30(10), 2924–35. https://doi.org/10.1038/s41591-024-03141-0 Wang, R., Fang, X., Lu, Y., & Wang, S. (2004). The PDBbind Database: Collection of Binding Affinities for Protein−Ligand Complexes With Known Three-Dimensional Structures. Journal of Medicinal Chemistry, 47(12), 2977–80. https://doi.org/10.1021/jm030580l Wang, X., Liu, S., Tsaris, A., Choi, J.-Y., Aji, A., Fan, M., Zhang, W., Yin, J., Ashfaq, M., Lu, D., & Balaprakash, P. (2024). ORBIT: Oak Ridge Base Foundation Model for Earth System Predictability (arXiv:2404.14712). arXiv. https://doi.org/10.48550/arXiv.2404.14712 Table of Contents Appendix 449 Artificial Intelligence Index Report 2025 Appendix Chapter 5: Science and Medicine Wang, X., Yang, S., Zhang, J., Wang, M., Zhang, J., Yang, W., Huang, J., & Han, X. (2022a). Transformer-Based Unsupervised Contrastive Learning for Histopathological Image Classification. Medical Image Analysis, 81, 102559. https://doi.org/10.1016/j. media.2022.102559 Wang, X., Yang, S., Zhang, J., Wang, M., Zhang, J., Yang, W., Huang, J., & Han, X. (2022b). Transformer-Based Unsupervised Contrastive Learning for Histopathological Image Classification. Medical Image Analysis, 81, 102559. https://doi.org/10.1016/j. media.2022.102559 Wang, X., Zhao, J., Marostica, E., Yuan, W., Jin, J., Zhang, J., Li, R., Tang, H., Wang, K., Li, Y., Wang, F., Peng, Y., Zhu, J., Zhang, J., Jackson, C. R., Zhang, J., Dillon, D., Lin, N. U., Sholl, L., … Yu, K.-H. (2024). A Pathology Foundation Model for Cancer Diagnosis and Prognosis Prediction. Nature, 634(8035), 970–78. https://doi.org/10.1038/s41586-024-07894-z Wang, Y., He, J., Du, Y., Chen, X., Li, J. C., Liu, L.-P., Xu, X., & Hassoun, S. (2025). Large Language Model Is Secretly a Protein Sequence Optimizer (arXiv:2501.09274). arXiv. https://doi.org/10.48550/arXiv.2501.09274 Xiang, J., Wang, X., Zhang, X., Xi, Y., Eweje, F., Chen, Y., Li, Y., Bergstrom, C., Gopaulchan, M., Kim, T., Yu, K.-H., Willens, S., Olguin, F. M., Nirschl, J. J., Neal, J., Diehn, M., Yang, S., & Li, R. (2025). A Vision–Language Foundation Model for Precision Oncology. Nature, 638(8051), 769–78. https://doi.org/10.1038/s41586-024-08378-w Xie, Y., Wu, J., Tu, H., Yang, S., Zhao, B., Zong, Y., Jin, Q., Xie, C., & Zhou, Y. (2024). A Preliminary Study of o1 in Medicine: Are We Closer to an AI Doctor? (arXiv:2409.15277). arXiv. https://doi.org/10.48550/arXiv.2409.15277 Xu, H., Usuyama, N., Bagga, J., Zhang, S., Rao, R., Naumann, T., Wong, C., Gero, Z., González, J., Gu, Y., Xu, Y., Wei, M., Wang, W., Ma, S., Wei, F., Yang, J., Li, C., Gao, J., Rosemon, J., … Poon, H. (2024). A Whole-Slide Foundation Model for Digital Pathology From Real-World Data. Nature, 630(8015), 181–88. https://doi.org/10.1038/s41586-024-07441-w Yang, L., Xu, S., Sellergren, A., Kohlberger, T., Zhou, Y., Ktena, I., Kiraly, A., Ahmed, F., Hormozdiari, F., Jaroensri, T., Wang, E., Wulczyn, E., Jamil, F., Guidroz, T., Lau, C., Qiao, S., Liu, Y., Goel, A., Park, K., … Golden, D. (2024). Advancing Multimodal Medical Capabilities of Gemini (arXiv:2405.03162). arXiv. https://doi.org/10.48550/arXiv.2405.03162 Yang, X., Chen, A., PourNejatian, N., Shin, H. C., Smith, K. E., Parisien, C., Compas, C., Martin, C., Flores, M. G., Zhang, Y., Magoc, T., Harle, C. A., Lipori, G., Mitchell, D. A., Hogan, W. R., Shenkman, E. A., Bian, J., & Wu, Y. (2022). GatorTron: A Large Clinical Language Model to Unlock Patient Information from Unstructured Electronic Health Records (arXiv:2203.03540). arXiv. https://doi.org/10.48550/arXiv.2203.03540 Yu, B., Baker, F. N., Chen, Z., Ning, X., & Sun, H. (2024). LlaSMol: Advancing Large Language Models for Chemistry With a Large-Scale, Comprehensive, High-Quality Instruction Tuning Dataset (arXiv:2402.09391). arXiv. https://doi.org/10.48550/ arXiv.2402.09391 Zambaldi, V., La, D., Chu, A. E., Patani, H., Danson, A. E., Kwan, T. O. C., Frerix, T., Schneider, R. G., Saxton, D., Thillaisundaram, A., Wu, Z., Moraes, I., Lange, O., Papa, E., Stanton, G., Martin, V., Singh, S., Wong, L. H., Bates, R., … Wang, J. (2024). De Novo Design of High-Affinity Protein Binders with AlphaProteo (arXiv:2409.08022). arXiv. https://doi.org/10.48550/arXiv.2409.08022 Table of Contents Appendix 450 Artificial Intelligence Index Report 2025 Appendix Chapter 5: Science and Medicine Zhao, T., Gu, Y., Yang, J., Usuyama, N., Lee, H. H., Kiblawi, S., Naumann, T., Gao, J., Crabtree, A., Abel, J., Moung-Wen, C., Piening, B., Bifulco, C., Wei, M., Poon, H., & Wang, S. (2025). A Foundation Model for Joint Segmentation, Detection and Recognition of Biomedical Objects Across Nine Modalities. Nature Methods, 22(1), 166–76. https://doi.org/10.1038/s41592-024-02499-w Zhou, Y., Chia, M. A., Wagner, S. K., Ayhan, M. S., Williamson, D. J., Struyven, R. R., Liu, T., Xu, M., Lozano, M. G., Woodward- Court, P., Kihara, Y., Altmann, A., Lee, A. Y., Topol, E. J., Denniston, A. K., Alexander, D. C., & Keane, P. A. (2023). A Foundation Model for Generalizable Disease Detection From Retinal Images. Nature, 622(7981), 156–63. https://doi.org/10.1038/s41586- 023-06555-x Table of Contents Appendix 451 Artificial Intelligence Index Report 2025 Appendix Chapter 6: Policy and Governance Chapter 6: Policy and Governance Acknowledgments Global Legislation Records on AI The AI Index would like to acknowledge Julia Betts Lotufo For AI-related bills passed into laws, the AI Index performed and Alexandra Rome for their efforts in collecting information searches for the keyword “artificial intelligence,” in respective on significant AI policy events. The AI Index would also like to languages and in the full text of bills, on the websites of acknowledge Lapo Santarlasci for leading the analysis of AI congresses or parliaments in 116 geographic areas. Note that public spending and U.S. grant-related AI spending. only laws passed by state-level legislative bodies and signed into law (e.g., by presidents or received royal assent) from 2016 to Global AI Mentions 2024 are included. Laws that were approved but then repealed For mentions of AI in AI-related legislative proceedings are not included in the analysis. For laws where AI-related around the world, the AI Index performed searches for the provisions were added or amended after initial enactment, keyword “artificial intelligence,” in respective languages, on the AI Index uses the year of inclusion rather than the original the websites of congresses or parliaments in 75 geographic passage year, when relevant. Future AI Index reports hope to areas, usually under sections named “minutes,” “hansard,” etc. include analysis on other types of legal documents, such as Mentions were counted by session, so multiple mentions of regulations and standards, adopted by state- or supranational- “artificial intelligence” in the same legislative session counted level legislative bodies, government agencies, etc. as one mention. The AI Index team surveyed the following databases: The AI Index team surveyed databases for the following geographic areas: Andorra, Armenia, Australia, Azerbaijan, Barbados, Belgium, Bermuda, Brazil, Canada, Cayman Islands, China,1 Czech Algeria, Andorra, Antigua and Barbuda, Argentina, Armenia, Republic, Denmark, Dominican Republic, Ecuador, El Australia, Austria, Azerbaijan, The Bahamas, Bahrain, Salvador, Estonia, Fiji, Finland, France, Germany, Gibraltar, Bangladesh, Barbados, Belarus, Belgium, Belize, Bermuda, Greece, Hong Kong, Iceland, India, Ireland, Isle of Man, Bhutan, Bolivia, Brazil, Brunei, Bulgaria, Cameroon, Canada, Italy, Japan, Kenya, Kosovo, Latvia, Lesotho, Liechtenstein, Chile, China, Croatia, Cuba, Curacao, Cyprus, Czech Luxembourg, Macao SAR, China, Madagascar, Malaysia, Republic, Denmark, Estonia, Faroe Islands, Fiji, Finland, France, Maldives, Malta, Mauritius, Mexico, Moldova, Netherlands, Germany, Gibraltar, Greece, Greenland, Grenada, Guam, New Zealand, Northern Mariana Islands, Norway, Pakistan, Guatemala, Guyana, Hong Kong, Hungary, Iceland, India, Iraq, Panama, Papua New Guinea, Philippines, Poland, Portugal, Ireland, Isle of Man, Israel, Italy, Jamaica, Japan, Kazakhstan, Romania, Russia, San Marino, Seychelles, Sierra Leone, Kenya, Kiribati, Republic of Korea, Kosovo, Kyrgyz Republic, Singapore, Slovenia, South Africa, South Korea, Spain, Sri Latvia, Liechtenstein, Lithuania, Luxembourg, Macao SAR Lanka, Sweden, Switzerland, Tanzania, Trinidad and Tobago, China, Malawi, Malaysia, Malta, Mauritius, Mexico, Monaco, Ukraine, United Kingdom, United States, Uruguay, Zambia, Montenegro, Morocco, Mozambique, Nauru, Netherlands, Zimbabwe New Zealand, Northern Marina Islands, Norway, Panama, Philippines, Poland, Portugal, Romania, Russia, Samoa, Saudi Arabia, Serbia, Seychelles, Sierra Leone, Singapore, 1 The National People’s Congress is held once per year and does not provide full legislative proceedings. Hence, the counts included in the analysis searched mentions of “artificial intelligence” in the only public document released from the congressional meetings, the Report on the Work of the Government, delivered by the premier. Table of Contents Appendix 452 Artificial Intelligence Index Report 2025 Appendix Chapter 6: Policy and Governance Slovak Republic, Slovenia, South Africa, Spain, St. Kitts and US Committee Mentions Nevis, Suriname, Sweden, Switzerland, Tajikistan, Tanzania, To research trends on the United States’ committee mentions Togo, Tongo, Turkey, Tuvalu, Uganda, Ukraine, United Arab of AI, the following search was conducted: Emirates, United Kingdom, United States, Uruguay, Vietnam, Website: Congress.gov Yemen, Zambia, Zimbabwe Keyword: artificial intelligence US State-Level AI Legislation Filters: Committee Reports For AI-related bills passed into law, the AI Index performed Public Investment in AI searches for the keyword “artificial intelligence” in the full The AI Index analyzed government AI spending across text of bills on the websites of all 50 U.S. states. Bills are only European countries and the United States, focusing on regions counted as passed into law if the keyword appears in the final where data is more accessible. It is important to note that version of the bill, not just the introduced version. Note that this analysis may not fully represent all countries or regions, only laws passed from 2015 to 2024 are included. The count as the availability and quality of data can vary significantly. for proposed laws includes both laws that were proposed Additionally, while this analysis includes data on government that were passed and laws that were proposed that have contracts from various countries, it only covers grant-level not been passed yet, or are now inactive. The AI Index team spending for the United States. This discrepancy is the result surveyed the following databases: of challenges in collecting comparable grant data from other countries and regions, such as the European Union and China. Alabama, Alaska, Arizona, Arkansas, California, Colorado, Nevertheless, the U.S. case illustrates that a substantial Connecticut, Delaware, Florida, Georgia, Hawaii, Idaho, portion of government spending on AI occurs through grants. Illinois, Indiana, Iowa, Kansas, Kentucky, Louisiana, Maine, Coverage will expand in future iterations of the AI Index as Maryland, Massachusetts, Michigan, Minnesota, Mississippi, more data becomes available, but discrepancies and gaps Missouri, Montana, Nebraska, Nevada, New Hampshire, New in the existing data may affect the comprehensiveness and Jersey, New Mexico, New York, North Carolina, North Dakota, accuracy of the findings. Ohio, Oklahoma, Oregon, Pennsylvania, Rhode Island, South Carolina, South Dakota, Tennessee, Texas, Utah, Vermont, Data Sources Virginia, Washington, West Virginia, Wisconsin, Wyoming For European countries, the AI Index collected public tender data from Tenders Electronic Daily (TED) (Publications Office For a more thorough review, the AI Index also included AI- of the European Union, 2024)—the online supplement to related state laws listed on the Multistate AI state legislation the official journal of the EU dedicated to European public tracker, even if they did not specifically reference “artificial procurement. While contracts are available in various formats, intelligence” as a keyword. the most detailed data comes from bulk XML downloads, US AI Regulation which include comprehensive information on tendering procedures, issuing entities, awarded contractors, lot values, This section examines AI-related regulations enacted by descriptions, award dates, and common procurement U.S. regulatory agencies from 2016 to 2024, analyzing the vocabulary (CPV) codes. TED publication is governed by total number of regulations and their originating agencies. EU law thresholds: Tenders above specific monetary values, To compile this data, the AI Index conducted a keyword deemed of cross-border interest, must be published on search for “artificial intelligence” on the Federal Register, a TED. However, some countries also report below-threshold comprehensive repository of government documents drawn procurements, leading to variations in coverage across from over 436 agencies and nearly every branch of the U.S. countries. government. Table of Contents Appendix 453 Artificial Intelligence Index Report 2025 Appendix Chapter 6: Policy and Governance For the United Kingdom, data sources include TED, Find a For ease of comparison, all monetary amounts were converted Tender, Contracts Finder, and Contracts Finder Archive. to U.S. dollars and adjusted for price level differences using Data from Scotland and Wales were accessed via the APIs the purchasing power parities (PPP) index. of their procurement websites, while Northern Ireland does not offer this service, necessitating its exclusion from the Classification analysis and potentially leading to an underestimation of Classifying AI-related contracts and grants was achieved public investments in AI for the U.K. Due to API limitations using full-text search with regular expressions. An restricting historical data access, the AI Index utilized the AI dictionary was compiled by generating AI-related Open Contracting Partnership’s data registry via Kingfisher expressions and incorporating “core” expressions from the Collect to obtain comprehensive data for Scotland and Wales. Yamashita et al. (2021) vocabulary. Additionally, a Word2Vec model expanded the dictionary with cosine-similar terms Data for the United States was sourced from the publicly for each baseline expression that were manually reviewed accessible USAspending platform, an official repository and included in the final vocabulary. This process provided that facilitates bulk downloads of information related to keywords and co-occurrence patterns crucial for identifying contract award notices and grant data. While this dataset AI content. encompasses a longer time frame than the TED dataset, it is important to note that data quality can vary. Additionally, The classification followed a multistep approach. Initially, a study by the U.S. Government Accountability Office (GAO, regular expression (regex) matching identified AI terms 2023) found that 49 agencies, including 25 in the executive within contract and grant awards. These documents were branch, did not report data to USAspending, accounting for then categorized as either “non AI-related” or “AI-related.” To over $5 billion in net outlays for fiscal year 2022. validate AI-related matches, BERTopic model and pretrained DeBERTA transformer were employed to assess probability Data Processing scores for specific AI-related topics. Awards with relevance Processing TED data posed significant challenges due to scores below 20% underwent manual review, while those inconsistent storage of contract descriptions, which varied with higher scores were confirmed as AI-related. To ensure by XML tag names based on release time and procurement additional accuracy, all high-value tenders were also manually type. Some files contained aggregated descriptions while reviewed. others detailed each awarded contract lot. To capture comprehensive information, the main descriptions of each competition call were combined with partial descriptions when available. The linguistic diversity in data from different countries required translation of all texts into English using the deep- translator tool and the Google Translator engine. Post- translation, tender texts were processed using natural language processing (NLP) techniques. These included the removal of stop words and special characters, part-of- speech (POS) tagging to retain key grammatical categories, lowercase conversion, lemmatization, and replacement of numerical measures with a <NUM> tag. Table of Contents Appendix 454 Artificial Intelligence Index Report 2025 Appendix Chapter 7: Education Chapter 7: Education Code.org, CSTA, ECEP Alliance Global K-12 AI Education State-Level Data The Raspberry Pi Computing Education Research Centre, based Appendix 2 of the State of Computer Science Education in the Department of Computer Science and Technology at the 2024 report includes a full description of the methodology University of Cambridge, compiled this dataset, expanding on used by Code.org, CSTA, and ECEP Alliance to collect their research conducted by the Brookings Institution for its 2021 data. The staff at Code.org also maintains a database of the report Building Skills for Life: How to Expand and Improve state of American K–12 education and, in this policy primer, Computer Science Education Around the World. We made provides a greater amount of detail on the state of American one change to their dataset to clarify that CS in the United K–12 education in each state. States is available in some schools/districts and not available everywhere as an elective course. For more information about AP Computer Science Data the methodology, please refer to their report. The AP Computer Science data is provided to Code.org as per an agreement the College Board maintains with Code.org. The IPEDS AP Computer Science data comes from the College Board’s national and state summary reports. The Integrated Postsecondary Education Data System (IPEDS) combines annual surveys conducted by the U.S. Access to Computer Science Education Department of Education’s National Center for Education Data on access to computer science education was drawn Statistics (NCES). IPEDS gathers information from every from Code.org, CSTA, and ECEP Alliance’s State of Computer college, university, and technical and vocational institution Science Education 2024 report. that participates in federal student financial aid programs. 2024 K-12 Computer Science Completion Data This chapter used data from the Completions survey, which Landscape Teacher Landscape collects data on the number of students who complete a Survey postsecondary education program. Graduates in AI-related fields were identified as those whose first major was either For more information or access to the dataset, please contact Computer and Information Sciences, General (11.01); Computer membership@csteachers.org. Programming (11.02); or Computer Science (11.07), according to the Classification of Instructional Programs (CIP) codes. The number of graduates in AI-related fields included in this State Standards Comparison year’s report differs from previous years because the AI Index CSTA and the Institute for Advancing Computing Education used multiple CIP codes. (IACE) published a State Standards Comparison report in December 2024. The dataset of approximately 10,000 state- OECD adopted K-12 standards is available as a spreadsheet, as well as a Python notebook that may be useful for data analysis. This chapter used data from the OECD Data Explorer, Colorado and Virginia’s standards were adopted in late 2024 specifically from the table “Number of enrolled students, and are not included in this dataset. graduates and new entrants by field of education.” The methodology for this dataset can be found in Education at a Glance 2024 Sources, Methodologies and Technical Notes. Table of Contents Appendix 455 Artificial Intelligence Index Report 2025 Appendix Chapter 8: Public Opinion Chapter 8: Public Opinion Ipsos For the sake of brevity, the 2025 AI Index opted not to republish the methodology used by the Ipsos survey featured in the report. More details about the Ipsos survey’s methodology can be found in the survey itself. Table of Contents Appendix 456