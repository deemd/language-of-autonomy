agent ai towards a holistic intelligence qiuyuanhuang naokiwake ℜ bidiptasarkar zanedurante rangong rohantaori yusukenoda demetriterzopoulos noborukuno adefamoti ashleyllorens johnlangford𭟋 hoivo lifei-fei katsuikeuchiℜ jianfenggao microsoftresearchcore redmond ℜmicrosoftappliedroboticsresearch redmond stanforduniversity universityofcalifornia losangeles microsoftgamingus msraccelerator 𭟋msraifrontiers newyork figure1 overviewofanagentaisystem thissystemisapplicableacrossmultipledomainsandprovidesafoundationmodel forinteractivemanipulationandembodiedoperations agentaioperatesinbothphysicalandvirtualworldsbyleveraging cross-modaldatathatisacquiredthroughinteractionsbetweendiverseenvironments agentaioffersapromisingapproachto unifyabroadrangeofapplicationsandcapabilitieswithininfrastructureandsystem furthermore itisemergingasapromising pathwaytowardsholisticintelligence hi abstract modeltoachieveembodiedintelligentbehav- ior the agent foundation model on top of recentadvancementsinlargefoundationmod- this idea we discuss how agent ai exhibits elshaveremarkablyenhancedourunderstand- remarkablecapabilitiesacrossavarietyofdo- ingofsensoryinformationinopen-worlden- mains andtasks challenging ourunderstand- vironments inleveragingthepoweroffoun- ing of learning and cognition furthermore dationmodels itiscrucialforairesearchto wediscussthepotentialofagentaifroman pivot away from excessive reductionism and interdisciplinaryperspective underscoringai towardanemphasisonsystemsthatfunction cognitionandconsciousnesswithinscientific as cohesive wholes specifically we empha- discourse we believe that those discussions sizedevelopingagentai anembodiedsys- serveasabasisforfutureresearchdirections temthatintegrateslargefoundationmodelsinto andencouragebroadersocietalengagement agentactions theemergingfieldofagentai spansawiderangeofexistingembodiedand agent-basedmultimodalinteractions including equal contribution project lead equal advisor robotics gaming andhealthcaresystems etc correspondingauthor workdonewhileinterningorre- inthispaper weproposeanovellargeaction searchingpart-timeatmicrosoftresearch redmond introduction activelyleveragingaction-basedlargefoundation modelsmakesourapproachuniquefordeveloping artificial intelligence ai was historically de- integratedaisystems fined at the dartmouth conference as ar- buildingupontheagentaiframework webe- tificial life forms capable of collecting informa- lievethattheaicommunitywillsteadilyaccumu- tion from their environment and taking effective lateinsightsandknowledgeessentialfortransition- actions within it minsky s group at mit devel- ing from ai models used for passive structured opedaroboticsystemin1970 knownasthe copy taskstothosecapableofdynamic interactiveroles demo thatobserved blocksworld scenesand in complex environments this is a critical step successfully reconstructed the observed polyhe- towardsthedevelopmentofartificialgeneralin- dral block structures winston the sys- telligence agi fig inthispaper weanalyze tem comprisingobservation planning andmanip- a new architecture for agent ai systems along- ulationmodules demonstratedthateachofthese side a review of recent literature in agent ai do- subproblemswashighlychallengingandnecessi- mainsincludingrobotics gaming andhealthcare tated further research consequently the field of furthermore weexplorethecognitiveaspectsof ai fragmented into specialized subfields while agent ai and introduce research areas impacted thesesubfieldshavemadesignificantprogressin- by agent ai to engage a broader community of dependently thisover-reductionismhasblurredthe researchersandactivelypromoteitsdevelopment overarchinggoalsofairesearch finally we discuss future research directions in- to advance beyond the current state towards cluding the ethical challenges that need to be ad- more sophisticated ai we emphasize the impor- dressed through these discussions we aim to tanceofembracingtheholisticphilosophyofaris- illustratehowthedevelopmentofthesetechnolo- totle which underscores the integration of com- gies is bringing ai agents closer to agi holistic ponents to surpass the sum of its parts recent intelligence advancementsinlargelanguagemodels llms andvisuallanguagemodels vlms haveshown agentaiparadigm greatpotentialinrecognizinglanguageandimages agentaifundamentals inanopen-worldcontext openai forex- ample theadvancedsemanticprocessingofllms wedefineagentaiasanintelligentagentcapable has been utilized to decompose human instruc- of autonomously executing appropriate and con- tionsintohigh-leveltasksforrobots wakeetal textuallyrelevantactionsbasedonsensoryinput 2023c d however these existing multimodal whetherinaphysical virtual ormixed-realityen- foundation models even for gpt-4v ision still vironment agent ai represents a new paradigm faceachallengeinachievingfine-grainedmanip- thatshedslightonembodiedintelligence empha- ulationthatnecessitatesactionprediction there- sizingtheimportanceofanintegratedapproachfor fore a new embodied agent foundation model interactiveagentsincomplexdynamics thisap- was proposed durante et al 2024b which inte- proachismotivatedbythebeliefthatintelligence grateslanguageproficiency visualcognition con- arisesfromtheintricateinterplaybetweenlearning textmemory intuitivereasoning andcanpredict memory action perception planning andcogni- theembodiedactionswithadaptability thisisthe tion fig firststudythatpretrainsafoundationmodelforthe learning agent ai can adapt to new environ- developmentofgeneral-purposeaiagentsbyus- mentsbyacquiringnewknowledgeandupdating ingembodieddatacollectedfromrobotics gaming itsskills tothisend theagentneedstoobserveits andhealthcaretasks environment understandtheimpactofitsactions an embodied agent is conceptualized as an in- onthatenvironment andlearnfromhumandemon- teractivesystemthatcommunicateswithhumans strations wakeetal forinstance byem- andinteractswithenvironmentsthroughitspercep- ployingreinforcementlearning rl techniquesor tualcapabilities employingactionsaligningwith supervised learning from human demonstrations humanintents thisisthereasonwhyweconsider e g imitationlearning il behaviorcloning the theadvanceoflargeembodiedfoundationmodels agentcanprogressivelyimproveitsbehavior asasignificantcontributiontoagentai enabling memory long-termmemoryenablestheagentto systemstoparseandinferhumanintentfromvari- rememberspecificoperationsadaptabletotheenvi- ousdomaininformation actions natural-language ronmentoruserpreference incontrast short-term instructions and multimodal contexts moreover memorypertainstothehistoryofactionstakenand figure2 anagentaiparadigmforsupportingembodiedmulti-modalgeneralistagentsystems therearefivemainmodules asshown agentinenvironmentandperceptionwithtask-planningandobservation agentlearning memory action and cognitionandconsciousness webelievethatthecohesiveintegrationofthesecomponentsfacilitatesthe developmentofaholisticintelligence akeydistinctionofourapproachfromsomepriorinteractivestrategiesisthat after training theagent sactionswilldirectlyinfluencetaskplanningwithouttheneedforreceivingfeedbackfromtheenvironment toplanitssubsequentactionsasthepreviousinteraciveparadigm perceptions observed during an operation short- orchestrationfunctionalityisreferredtoasthecog- term memory enables the system to replan and nitiveaspectofagentai considernext-stepactionsbasedonhistory action theactionsofagentaidonotnecessar- agentaiconsciousness ily have to be physical actions in the real world depending on the definition of the environment agent ai can go beyond a simple component or- actionsmayincludeinteractionsinvirtualreality chestration and potentially entail a type of con- vr environmentsorspeechdirectedathumans sciousness inrecentchallengingattemptstofind a suitable action is selected through a cognitive consciousness in ai based on neuroscientific in- processfromlearnedskills basedonmemory ad- sights neuroscientistshavediscussedagencyand ditionally real-world operations often cannot be embodimentasindicatorsofconsciousness butlin completedinoneshotandthusrequiremulti-round etal agencyreferstothecapacitytolearn interactions between humans or the environment from feedback make decisions to pursue goals andtheagent thisinteractionisalsoorchestrated and adapt to conflicting objectives it indicates byacognitiveprocessandmemory e g conversa- asystem scharacteristicofattemptingtoachieve tionhistory goalsthroughinteractionwithitsenvironment em- perception likehumans robustandmultimodal bodimentinvolvesunderstandingandutilizingthe perceptioniscrucialforagentstounderstandtheir relationship between actions and feedback from environment visualperceptionisoneofthemost theenvironmenttoaffectperceptionorcontrol it importantabilities enablingtheagenttocompre- emphasizes comprehending how one s body and hend the world e g images videos gameplay thesurroundingenvironmentcanbeleveragedin similarly audio perception is crucial for under- cognitiveprocesses standinghumanintent planning planningisanimportantaspectoflong- ouragentaipredictsoptimalactionsbasedon rangetasks suchasarobotmanipulatingobjects language i e textualinstructions sensoryinputs inanenvironmentforaspecificpurpose theplan- andactionhistory fulfillingagencybygenerating ningstrategytypicallydependsonthegoalofthe goal-directed actions it also learns from the re- task goal-orientedplanningenablesflexibleopera- lationship between its actions and environmental tionthatadaptstouncertaintiesduetoanyexternal outcomes fulfillingtheprincipleofembodiment andinternaldisturbances thus wecanpotentiallyquantifyaspectsofagent ai sconsciousness suggestingitspotentialacross cognitive aspects agent ai focuses not only disciplineslikeneuroscience biology physics bio- ontheperformanceofindividualcomponentsbut logicalphysics cognitivescience medicalhealth alsoontheutilityofthesystemasawhole con- andmoralphilosophy sider a scenario where a robot right after being unboxed beginstocommunicatewithanon-expert there are various approaches to developing userandswiftlyadaptstocarryoutdomestictasks agent ai in section we will introduce a spe- within the user s home setting realizing such a cific example of agent ai in section we will system is challenging and requires a mechanism discussthemainchallengesandnecessaryactions thatorchestrateseachagentaicomponents this includingethicalconcernsinagentairesearch agentfoundationmodel diversehistoricaldataintothetransformermodel includingbutnotlimitedtopreviouslow-levelfine- agent ai systems that interact with the environ- grainedactions agentinformation video images ment withhumans andamongstotheragents we audio language orhigh-levelinstruction ascon- consideragent-environmentinteractionsasencom- textduringpre-training asaresult foranygiven passingabroaderscopethanembodiedagents for timestep itcanpredictlow-levelmanipulation ac- instance ambientintelligencesystems whichde- tion tokens general agent types e g typechat spitenotonlyhavingaphysicalembodiment can ingaming orhigh-levelinstructions e g agent beembeddedintoandinteractwiththeirenviron- intention moreover theunifiedtransformercan ment theadvancementofagentsystemsthatin- alsoproducehigh-levelinstructionsbasedontext teract with humans is another area of keen inter- prompts visualcontext andpreviousactions this est for this area we strongly believe that mul- approach allows the model to take into account timodalinteractionsbetweenhumansandagents boththecurrentcontextandthehistoryofinterac- extendingbeyondhigh-levelintentioninstructions tions makingitabletorespondmoreaccuratelyto is a promising area of research and future direc- thetaskathand tion for low-level fine-grained actions manipula- tion with human-agent interactions we are also agentlearningstrategy interestedindevelopingsystemsforeffectiveagent reinforcementlearning rl tolearntheopti- toagentcommunicationandefficientcollaboration malrelationshipbetweenstatesandactionsbased within multi-agent infrastructures and exploring onrewards orpenalties receivedasaresultofits newagentparadigmandagentlearningstrategy actions we can use reinforcement learning rl inthissection weprovideanoverviewofagent is a highly scalable framework that has been ap- aisystemthatleveragesfoundationmodelswith pliedtonumerousapplications includingrobotics thelatestmachine-learningtechnologies thesys- formanyapplications itischallengingorcostly temiscomposedofthreecomponents i interac- tocollecthumandemonstrations suchaslearning tiveagenttransformer ii agentfoundationmodel policiesinautomaticallygeneratedvirtualenviron- learningstrategywithrlandil andiii selfim- ments rl is particularly effective in these sce- provement narios exemplified by the actor-critic algorithm agenttransformer ppo schulman et al additionally rl technology can be applied to model human-ai interactions which is a crucial aspect of interac- tiveagentai forinstance agentscanbetrained via rl from human feedback rlhf ouyang et al allowing humans to choose desired responseswithouthand-engineeringrewards imitation learning il il seeks to leverage demonstrationdatatomimictheactionsofhuman experts for example in robotics one of the ma- figure3 overviewofaninteractiveagentfoundationmodel jorframeworksbasedonilisbehavioralcloning framework the transformer is designed to process multi- modalinformationthatconveysvariouslevelsofabstraction bc bcisanapproachwherearobotistrainedto thisapproachfacilitatesacomprehensiveunderstandingofthe mimictheactionsofanhumanexpertbydirectly context thusenhancingcoherentactions throughlearning copyingthem inthisapproach theexpert sactions acrossavarietyoftaskdomainsandapplications inperformingspecifictasksarerecorded andthe weanalyzeatransformer-basedmultimodalen- robotistrainedtoreplicatetheseactionsinsimilar coder fig thatenablesaninteractiveagentto situations recentbc-basedmethodsoftenincor- takeactionsbasedonmultimodalinformation this porate technologies from llm vlms enabling modelisinitializedwiththreepre-trainedsubmod- more advanced end-to-end models for example ules namely the visual module the agent action brohanetal proposedrt- brohanetal moduleandthelanguagemodule andrt- brohanetal transformer-based to facilitate cross-modal information sharing modelsthatoutputanactionsequenceforarobot s duranteetal 2024b foundationmodelallowsthe base and arm taking a series of images and lan- agenttopredictactions oractiontokens tocom- guageasinput thesemodelsarereportedtoshow pletetheembodiedtasksinrobot gaming andin- high generalization performance as the result of teractivehealthcaredomains themodelalsofeed trainingonalargeamountsofdemonstrationdata traditional rgb learning intelligent agent be- selfimprovementfortransformers haviorleveragingimageinputshasbeenofinterest currently foundationmodelbasedaiagentshave for many years mnih et al the inherent the capacity to learn from multiple different data challengeofusingrgbinputisthecurseofdimen- sources whichallowformoreflexiblesourcesfor sionality tosolvethisproblem researcherseither datafortraining twokeyconsequencesofthisare use more data jang et al ha et al that userandhuman-basedinteractiondatacan orintroduceinductivebiasesintothemodeldesign beusedtofurtherrefineandimprovetheagentand toimprovesampleefficiency inparticular authors existingfoundationmodelsandmodelartifacts incorporate3dstructuresintothemodelarchitec- canbeusedtogeneratetrainingdata wediscuss tureformanipulations zengetal shridhar each of these in more detail in the following sec- et al goyal et al james and davi- tions butwenotethatsincecurrentaiagentsare son forrobotnavigation authors chaplot largelytiedtoexistingpretrainedfoundationmod- etal 2020a b leveragemapsasarepresentation els they generally do not learn from continuous mapscaneitherbelearnedfromaneuralnetwork interactionwiththeirenvironments wethinkthis aggregatingallpreviousrgbinputsorthrough3d isanexcitingfuturedirection andinitialworkby reconstruction methods such as neural radiance bousmalis et al has shown that self-improving fields rosinoletal agents for robotic control are able to continuous learnandimprovethroughenvironmentalinterac- optimizationintheagentsystem tions without supervision durante et al 2024b theoptimizationofagentsystemscanbedivided bousmalisetal intospatialandtemporalaspects spatialoptimiza- furthermore theiterativelearningprocesscan tion considers how agents operate within a phys- leveragehumanfeedback gongetal for ical space to execute tasks this includes inter- example inthecontextofrobotteaching agentai robotcoordination resourceallocation andkeep- understandswhatitneedstodofrommultimodalin- inganorganizedspace inordertoeffectivelyop- structionsprovidedbyhumans wakeetal timizeagentaisystems especiallysystemswith basedontheseinstructions itgeneratesimagesor large numbers of agents acting in parallel previ- scenesandmakesthemoperableinavirtualworld ousworkshavefocusedonusinglargebatchrein- thisprocessisrepeatedbyutilizinguserfeedback forcementlearning shacklettetal since allowingagentaitograduallyimproveandadapt datasets of multi-agent interactions for specific itselftotheenvironment tasksarerare self-playreinforcementlearningen- ablesateamofagentstoimproveovertime how- agentaicategorization ever thismayalsoleadtoverybrittleagentsthat canonlyworkunderself-playandnotwithhumans agentaiaimstodevelopagentsthatcanadeptly orotherindependentagentssincetheyover-fitto navigateandinteractwithachangingworld these the self-play training paradigm to address this agents are designed to learn and solve complex issue wecaninsteaddiscoveradiversesetofcon- tasks through direct engagement with their envi- ventions cuietal sarkaretal and ronment the field has been propelled forward trainanagentthatisawareofawiderangeofcon- by significant advancements in the development ventions foundation models can further help to ofgeneral-purposefoundationmodels leadingto establish conventions with humans or other inde- superhumanachievementsinvariousaidomains pendentagents enablingsmoothcoordinationwith previously deemed challenging these develop- newagents gongetal ments have significantly boosted the capabilities temporal optimization on the other hand fo- ofembodiedai researchersarenowrapidlyad- cusesonhowagentsexecutetasksovertime this vancingtowardscreatingintelligentagentsthatcan encompasses task scheduling sequencing and perceivetheirsurroundings engageinnaturallan- timeline efficiency for instance optimizing the guagedialogue understandandrespondtoauditory trajectory of a robot s arm is an example of effi- inputs navigateandmanipulatetheirenvironment cientlyoptimizingmovementbetweenconsecutive to achieve objectives and reason about the long- tasks zhou et al 2023b at the level of task termoutcomesoftheiractions weareinterestedin scheduling methods like llm-dp dagan et al particularwithsubmissionsthatfocusonthemulti- andreact yaoetal havebeenpro- modalaspectsofembodiedaisystemsanddevelop posedtosolveefficienttaskplanningbyincorpo- novelmethodsforsynthesizingmeaningfulagent ratingenvironmentalfactorsinteractively outputsfrommulti-sensoryinputs embodiedagentcategorization controllersthataretrainedusingconventionalmeth- odsrt- brohanetal andrt- brohan etal andagentfoundationmodel durante etal 2024b manipulationactioninvirtual environments thistypeofagentutilizesavirtualsimulatedenvi- ronment intheroboticsdomain themainobjec- tiveistotrainagentaithroughtrial-and-errorfor taskswherephysicaltrialsareimpracticalorrisky including the ability to predict user actions and devise plans for tasks within specific constraints ahn et al 2022b brohan et al durante et al 2024b gong et al in the case of gamingagents thegoalisnottoeventuallytransi- tiontothephysicalworld butthelearningwithin thesimulationenvironmentitselfisthemainobjec- tive parketal 2023c wangetal 2023b e baker figure4 overviewofthetwoaxesforagentsspaces embod- etal iedagentaiisclassifiedaccordingtotheextenttowhichit involveslow-levelfineactionmanipulations whichwerefer there have also been a number of works that to as manipulation actions e g action prediction in an demonstratetheabilityofgeneral-purposevisually- environment whetherrealorvirtual incontrast anagent s aligned large language models trained on large- actions may primarily aim at high-level information trans- missionforarobotorhuman sintentinstruction whichwe scale text image and video data to serve as a refer to as intention action e g general task planning foundation for creating multi-modal agents that anagent senvironmentcanbebroadlycategorizedbasedon areembodiedandcanactinvariousenvironments whetheritisthephysicalworldoravirtualone accordingto this wedivideembodiedandinteractiveagentintomainfour bakeretal driessetal brohanetal categories durante et al 2024b typically research agent ai refers to ai systems that integrate ontheseagentsinvolvessimulationplatformsfor largefoundationmodels consequently anumber objectrecognition kolveetal wangetal ofrecentaisystemsthatarebasedonllm vlms 2023d meesetal yangetal 2023a ehsani can be associated with agent ai subcategories etal szotetal puigetal car- specifically wecategorizeagentaibasedbythe roll et al li et al srivastava et al types of agent actions and their environments as mittal et al zhong et al liu illustrated in fig therefore agent ai can be andnegrut saitoetal huangetal broadlygroupedintofourcategories thissection 2022a reviewsrelatedresearch duranteetal 2024a and intentionalactioninphysical organizesthemaccordingtothesecategories we environment alsoexpandonsystemscombiningbothintention andmanipulationagentsinappendixa a typical example of interactive agents in this category is found in the healthcare domain such manipulationactioninphysical as applications in diagnostics and knowledge re- environments trieval lee et al peng et al in agents in this category are intended to work in a similar context several works have developed thephysicalworld withroboticsapplicationsbe- empathy-awareagentsforengagingdialogueand ingthetypicalexample ahnetal 2022a huang human-machine interactions chen et al etal 2022b liangetal driessetal maoetal wakeetal 2023a savvaetal brohanetal trainingagentsforphysical puig et al huang et al in manipulationinanend-to-endmanneristypically other cases agent ai s focus on knowledge and challengingduetothesignificantcostsassociated logicalreasoninginvolvesintegratingimplicitand withcollectingalargeamountofdatafortraining explicit knowledge sources this integration en- consequently recenttrendshaveshiftedtowards ables more accurate and contextually appropri- solvinghigher-ordertaskplanswithlargefounda- ateresponses brownetal openai tionmodelandintegratingthesewithlower-level lewis et al peng et al gao et al marcus and davis gao et al etal 2023b butnotlimitedtosimulationanden- wang et al 2023a chen et al park et al vironmentsagents puigetal generative 2023a lietal 2023b agents huangetal 2023b knowledgeandlogi- calinferenceagents lewisetal pengetal intentionalactioninvirtual wangetal 2023a guietal 2022b emo- environment tion agent chen et al neuro-symbolic studies on agent ai in this category have high- agents chen et al and agents for tradi- lighted the utility for the creation of interactive tionalmultimodaltasks multimodalagentsystems content in gaming and both vr and xr chen andinfrastructure andapplicationsofmultimodal etal maoetal huangetal 2023b agents agent navigation following instruacion is also a agentaiapplicationtasks representativetaskthatfallsinthiscategory tsoi etal deitkeetal similartogaming in section we categorized existing research agents for intentional action this type of agent within the realm of agent ai to offer a tangi- ai has shown super-human performance in spe- bleunderstandingofitsapplications weintroduce cificgames metafundamentalairesearchetal fourmission-criticaldomainswhereagentaican yaoetal recentroboticsresearch haveamajorimpact alsoleveragesllmstoperformtaskplanning ahn et al 2022a huang et al 2022b liang et al robotics by decomposing natural language instruc- robots are representative agents that necessitate tionintoasequenceofsubtasks eitherinthenatu- effectiveinteractionwiththeirenvironment inthis rallanguageformorinpythoncode thenusinga section we introduce key elements essential for low-levelcontrollertoexecutethesesubtasks efficientroboticoperation reviewresearchtopics wherethelatestlargefoundationmodelshavebeen multimodelagentcategorization applied andshareinsightsfromrecentstudies non-embodied multimodal systems recent research focuses thesecategoriesofagentsemphasizetheimpor- on developing end-to-end systems incorporating tanceofusingmultimodalinformationtotakeben- large foundation model technologies as encoders eficialnon-embodiedfromtheirrespectiveaspects forinputinformation guidingroboticactionsbased this indicates the necessity for agents to possess onlinguistic instructionsand visualcues huang highrecognitioncapabilitiesforbothlanguageand etal jiangetal brohanetal vision thereby strongly suggesting the effective- lietal 2023f ahnetal 2022b shahetal nessofleveraginglargefondationmodels multi- 2023b lietal 2023c modelagenthaveshownsignificantutilityacross task planning and skill training advanced a variety of tasks the advancements in large- languageprocessingabilitiesofllmsinterpretin- scale foundational models and interactive artifi- structions and decompose them into robot action cialintelligencehaveopenedupnovelcapabilities steps advancing task planning technologies ni for multimodel agent a number of works lever- et al li et al 2023a parakh et al age multi-modelagents toperform task planning wakeetal 2023b forskilltraining largefoun- huangetal 2022a wangetal 2023b yaoetal dationmodelsareusedfordesigningrewardfunc- lietal 2023b andleveragethelargemul- tions yuetal kataraetal maetal timodels large internet-scale domain knowledge generatingdataforpolicylearning kumar andzero-shotplanningabilitiestoperformagentic etal duetal oraspartofareward tasks like planning and reasoning additionally function sontakkeetal huang et al 2022b liang et al and on-siteoptimization thisinvolvesdynamically wangetal 2023e alsoincorporateenvironmen- adaptingandrefiningroboticskillsbyintegrating talfeedbacktoimprovetaskperformance taskplanswithreal-timeenvironmentaldata ahn nevertheless foragentaitobegenuinelybene- et al 2022b zhou et al 2023b raman et al ficial theymustofferintuitiveinteractionexperi- chenetal strategiesseektoachieve ences and adapt to a wide array of environments environment-groundedrobotexecutionbyadjust- contexts andmodalities topromoteresearchin ingtherobot sactionsatthetaskplanorcontroller thisarea weproposedabroadrangeofcategoriza- level tion relevant for multimodal agents without em- conversation agents llms contribute to natu- bodied action including gui et al 2022a park ral context-sensitiveinteractionswithhumansin conversationalrobots yeetal wakeetal immersion gongetal 2023d theyprocessandgenerateresponsesthat agent-basedanalysisofgaming gamingisan mimic human conversation and estimate concep- integralpartofdailylife estimatedtoengagehalf tual henseletal teshimaetal and oftheworld spopulation intelligence and emotionalattributes zhaoetal yangetal exhibitsapositiveimpactonmentalhealth granic 2023b wakeetal 2023a ofutterances et al contemporary game systems how- navigationagents robotnavigationfocuseson ever oftenexhibitdeficienciesininteractionswith coreaspectssuchasmap-basedpathplanningand human players due to primarily hand-crafted be- slam guimarãesetal recentworken- haviors by game developers in such a context ables robots to navigate in challenging environ- agentaiprovesvaluableasasystemthatanalyzes ments using object names chaplot et al 2020a in-gametextdata suchaschatlogsandplayerfeed- batra et al gervet et al ramakr- back to identify patterns of player behavior and ishnan et al zhang et al or zero- preferences aswellasanalyzesimageandvideo shotobjectnavigation gadreetal dorbala datafromgamingsessionstounderstanduserintent et al cai et al vision-language andactions navigation vln interprets sentences for navi- scene synthesis for gaming scene synthesis gation in unseen environments anderson et al isessentialforcreatingandenhancingimmersive shahetal 2023a zhouetal 2023a dor- gaming environments encompassing the genera- balaetal liangetal huangetal tionofthree-dimensional 3d scenes terraincre- 2023a vlninterpretssentencesratherthanob- ation objectplacement realisticlighting anddy- ject names it requires a higher functionality to namicweathersystems huangetal 2023b in parseinputtext wangetal modern games providing vast open-world envi- ronmentsnecessitatestheuseofproceduralorai- gaming driven techniques for automated terrain genera- gamesprovideauniquesandboxtotesttheagen- tion agentai utilizinglargefoundationmodels tic behavior of large foundation models pushing aidsscenedesignersbyformulatingnon-repeating theboundariesoftheircollaborativeanddecision- uniquelandscapedesignrulesbasedonthedesign- making abilities we describe three areas in par- ers desiresandthecurrentscene ensuringseman- ticular that highlight agent s abilities to interact ticconsistencyandvariabilityofthegeneratedas- with human players and other agents as well as sets thesemodelsexpediteobjectplacementand their ability to take meaningful actions within an assistincontentgeneration enhancingthedesign environment process npc behavior in modern gaming systems the interactivehealthcare behaviorofnon-playercharacters npcs ispre- dominantlydictatedbypredefinedscriptscrafted inhealthcare agentaicanhelpbothpatientsand bydevelopers thesescriptsencompassarangeof physicians by utilizing large foundation models reactionsandinteractionsbasedonvarioustriggers inunderstandingtheintentoftheuser retrieving orplayeractionswithinthegamingenvironment clinical knowledge and grasping the undergoing inlightofthissituation agentaiisattheforefront human-to-human interaction but not limited to ofrevolutionizingnpctechnologies byleverag- theseareas examplesofapplicationinclude inglargefoundationmodel agentaicanprovide diagnosticagents llmsasmedicalchatbotsfor dynamicdialoguesandrefinebehaviorsbasedon patient diagnosis have gained attention for their player feedback and in-game data significantly potentialtohelptriageanddiagnosepatients pro- contributing to the evolution of npc behavior in vidingequitablehealthcareaccesstodiversepopu- games lations lee et al they offer a pathway human-npcinteraction agentaiplaysacrit- to improve healthcare for millions understand- icalroleinenhancingtheinteractionbetweenhu- ing various languages cultures and health con- manplayersandnpcs offeringamoreimmersive ditions withinitialresultsshowingpromiseusing gamingexperience theconventionalinteraction healthcare-knowledgeablellmstrainedonlarge- paradigmisprimarilyone-dimensional withnpcs scalewebdata duranteetal 2024b a however reactinginapresetmannertoplayerinputs agent riskssuchashallucinationwithinmedicalcontexts ai utilizinglargefoundationmodels cananalyze arenotablechallenges and learn from human behavior providing more knowledgeretrievalagents inthemedicalcon- human-likeinteractionsandincreasingrealismand text model hallucinations can be dangerous po- tentially leading to serious patient harm or death image understanding to include dynamic content approaches using agents for reliable knowledge andrequiresagentstointeractwithvisual textual retrieval pengetal orretrieval-basedtext andaudiomodalities keytasksincludecaptioning generation guuetal arepromising pairing question answering and activity recognition fo- diagnosticagentswithmedicalknowledgeretrieval cusingontemporalalignment sequencehandling agents can reduce hallucinations and improve re- and complex activity interpretation agents also sponsequalityandpreciseness needtoprocessaudiocueslikespokenwordsand telemedicine and remote monitoring agent- background sounds to grasp a video s mood and basedaiintelemedicineandremotemonitoring nuances canenhancehealthcareaccess improvecommuni- parallel research explores generating scaled cationbetweenhealthcareprovidersandpatients datasets from large models then applying visual andincreasetheefficiencyofdoctor-patientinter- instructiontuning duranteetal 2024b a lietal actions amjad et al agents can assist 2023d zhu et al on the generated data in triaging messages from doctors patients and considerableaudio speech andvisualexpertper- healthcareproviders highlightingimportantcom- ception models are subsequently used to verbal- munications andrevolutionizingremotehealthcare ize videos speech is transcribed with automatic anddigitalhealthindustries speech recognition tools and video descriptions andrelateddataareproducedwithvarioustagging interactivemultimodaltasks grounding andcaptioningmodels lietal 2023e theintegrationofvisualandlinguisticunderstand- maaz et al chen et al wang et al ing is a fundamental of agent ai therefore the 2023c thesetechniquesdemonstratehowinstruc- development of agent ai is closely linked to the tion tuning video-language models on generated performanceofmultimodaltasks includingimage datasetsmayleadtoenhancedvideo-reasoningand captioning visual question answering video lan- communicationabilities guagegeneration andvideounderstanding here suchagentswouldbeabletounderstandthecon- aresometasksthathaverecentlygarneredsignifi- text of the video identify the key steps and gen- cantinterest erateacoherentsummaryoftheprocedure this imageandlanguageunderstandingandgen- wouldnotonlyenhancetheinterpretabilityofthe eration image-language understanding is a task modelbutalsoenableittoprovideusefulfeedback thatinvolvestheinterpretationofvisualcontentin orguidancetotheuser a given image with language and the generation weexpanduponmorecross-modalityandmix- of associated linguistic descriptions this task is reality topic discussion in appendix b ap- criticaltothedevelopmentofaiagentsthatcanin- pendixb 2andb teractwiththeworldinamorehuman-likemanner someofmostpopularonesareimagecaptioning deployingagentai linetal sharmaetal youngetal krishna et al referring expression we believe that in order to develop a system that yuetal karpathyetal andvisual incorporates these elements it is necessary to in- questionanswering antoletal renetal volveawiderangeofexpertsandpractitioners for singh et al this demands capabil- instance therearethefollowingimportantresearch ities beyond object recognition encompassing a areas deepunderstandingofspatialrelationships visual exploringnewparadigms thedevelopmentof semantics and integrating world knowledge for agentparadigmswithintegratedmodalities audio accuratedescriptiveandreasoningabilities image text sensor inputs may address common video-language understanding and genera- issuesinlarge-scalemodels suchashallucinations tion video captioning and storytelling involve and biases in their outputs which will enhance generating coherent sentences for video frames their recognition and response capabilities for a challengingduetotheneedforacomprehensiveun- widevarietyofapplications derstandingofeachframeandtheirinterrelations general-purposeend-to-endsystems versatile recentadvancesleveragelargefoundationmodels and adaptable ai solutions can be driven by the forimprovedvideo-languagegeneration emphasiz- developmentofend-to-endmodelsthataretrained ingthedevelopmentofagent-awaretextsynthesis withlarge-scaledata modelsforencodingsequencesandgeneratingco- methodologiesforgroundingmodalities byin- hesiveparagraphs videounderstandingbroadens tegratinginformationacrossvariousmodalities we canenhancethecoherenceandefficacyofdatapro- agentcopilotsbyusingadvancedhardware diverse cessing weexpandonthistopicinappendixb datasources andpowerfulsoftwarelibraries gong intuitivehumaninterface developingintuitive et al the rising prevalence of agent ai humaninterfacescanfacilitateeffectiveandmean- underscores the need for robust infrastructure to ingfulinteractionsbetweenhumansandagents facilitatetheirtraining evaluation anddeployment tamingllm vlms exploringnewapproaches inresponsetothisneed weareintroducingaded- canaddresscommonissuesinlarge-scalefounda- icatedtrackforagentresearchfocusingonthein- tion models such as hallucinations and biases in frastructureandmethodologiespertinenttothede- theiroutputs velopment evaluation and deployment of agent bridgingthegapbetweensimulationandreal ai we expect this track will attract a significant the sim-to-real problemhighlightsthechallenge numberofsubmissionscenteredontheefficiency ofdeployingaiagentstrainedinsimulationstothe and optimization of agent systems agent ai in- realworld wherediscrepanciesinconditionslike frastructureisintendedtoensurethatthebroader disturbancesandphysicalpropertiescandegrade community can readily access and benefit from performance totackletheseissues strategiesin- these contributions thereby fostering further ad- clude vancementsinthefield weexpandonbiasesandhallucinationsinap- domainrandomizationintroducingvariabil- pendixcanddrespectively ityinthesimulatedenvironmenttobetterpre- pare the model for real-world unpredictabil- challengesforagentai ity tobinetal saitoetal inthispaper weputspecialemphasisondiscover- domainadaptationbridgingsim-to-realgap ingthecurrentagentailimitation andwediscuss bytrainingonbothsimulatedandreal-world thechallengesaheadforadvancingtowardsdeeper data zhuetal 2017a raoetal ho andmorecomprehensiveversionsofagi includ- etal ingthepossibleneedforpursuinganewparadigm thatmovesbeyondnext-wordprediction improvementofsimulationenhancingsim- ulation fidelity through better replication of achievement of the agent ai still have some real-worldconditions zhuetal 2017b al- challenges especiallyconsideringthedynamicsys- levatoetal martinez-gonzalezetal temwithhighmodalityobservationsinthephysical müller et al shah et al world therestillexistanumberofchallengesthat sasabuchietal need to be addressed including but not limited to unstructured environments where current multi-agent agent ai interaction is currently visualinputsaffectbothhigh-levelintentsandlow- still a complex process that requires a combina- levelactionsoftheembodiedagentgiventhesame tionofmultipleskills thecurrenthuman-machine goalinstruction empathyforagent whenopen interactionsystemsinsidemulti-agentsareprimar- setsofobjects whichrequiretheagent sdecision- ilyeffectivenessofcooperationrule-based they makingmoduletousecommonsenseknowledge do have intelligent behaviors in response to hu- that is hard to encode manually multi-agent man user actions and possess web knowledge to interactionsandcollaborations whichrequirethe some extent gong et al the kind multi agenttounderstandandoperateonmorethanjust agentsinteractionsareveryimportantintheagent template-based commands but also a context of development to enable specific behaviors in the goals constraints andpartialplansexpressedinev- agentsystemdesign erydaylanguage toenableamorecomprehensive agentinfrastructureandsystem agent-based approach to these complex challenges the inclu- aiisalargeandfast-growingcommunitywithin sionofresearchersandpractitionersfromabroader thedomainsofentertainment research andindus- range of fields is critical emergent ability for try the development of large foundation mod- embodied large agent foundation model we as- elshassignificantlyimprovedtheperformanceof pire to broaden our collective understanding of agent ai systems however creating agents in the potential and limitations of agent paradigm this vein is limited by the increasing effort nec- byleveragingouruniqueanddiverseperspectives essary to create high-quality datasets and overall westronglybelievethatthisproposednewagent cost in industry building high-quality agent in- paradigmwillnotonlyenrichtheperspectivesof frastructurehassignificantlyimpactedmulti-modal individualpractitioners butwillalsoenhancethe community scollectiveknowledgeandpromotea gaming robotics healthcare andlong-videounder- holistic view that is more inclusive of the wide- standing specifically the development of multi- rangingchallengesfacedbyfutureagentai modalagentsingamingcouldleadtomoreimmer- siveandpersonalizedgamingexperiences thereby emergentabilities transformingthegamingindustry inrobotics the developmentofadaptivesystemscouldrevolution- despitethegrowingadoptionofinteractiveagent izeindustriesrangingfrommanufacturingtoagri- aisystems themajorityofproposedmethodsstill culture potentiallyaddressinglaborshortagesand face a challenge in terms of their generalization improvingefficiency inhealthcare theuseoflarge performance in unseen environments or scenar- foundation model as diagnostic agents or patient ios current modeling practices require develop- care assistants could lead to more accurate diag- ers to prepare large datasets for each domain to noses improved patient care and increased ac- finetune pretrainmodels however thisprocessis cessibilitytomedicalservices particularlyinun- costly and even impossible if the domain is new derservedareas furthermore theabilityofthese toaddressthisissue weproposebuildinginterac- models to interpret long-form videos could have tive agents that leverage the knowledge-memory far-reaching applications from enhancing online ofgeneral-purposefoundationmodels chatgpt learning to improving technical support services dall-e gpt- etc for novel scenarios specifi- ingeneral theagentaiframeworkwillhavesig- callyforgeneratingacollaborativespacebetween nificant downstream effects on a wide range of humans and agents we discover an emergent industriesandpeopleacrosstheworld mechanism whichwenamemixedrealitywith wemustalsohighlightthediverseandcomplex knowledgeinferenceinteraction thatfacilitates challengesthatcomewithimplementingaiagents collaboration with humans to solve challenging across a wide variety of environments and situ- tasks in complex real-world environments and ations for instance there are many limitations enables the exploration of unseen environments andpotentialhazardslinkedtoagenticaisystems for adaptation to virtual reality for this mecha- when they are developed for specialized sectors nism theagentlearnsi micro-reactionsincross- suchashealthcarediagnostics inthisdomain is- modality collectingrelevantindividualknowledge sueslikedangeroushallucinationsinaibehavior for each interaction task e g understanding un- canposesignificantrisks highlightingthecritical seenscenes fromtheexplicitwebsourceandby needformeticulousdesignandtesting however implicitly inferringfrom theoutput of pretrained these specific challenges may not be equally rel- models ii macro-behaviorinreality-agnostic im- evant or noticeable when considering ai agents proving interactive dimensions and patterns in crafted for the gaming industry in such recre- languageandmulti-modalitydomains andmake ationalfields developersmightinsteadprioritize changesbasedoncharacterizedroles certaintarget tacklingdifferenthurdles suchastheneedforai variable influenceddiversificationofcollaborative toperformmoreopen-endedgenerationandexhibit information in mixed-reality and llms we in- creativity adaptingdynamicallytounpredictable vestigatethetaskofknowledge-guidedinteractive gameplayscenariosandplayerinteractions synergisticeffectstocollaboratedscenegeneration withcombiningvariousopenaimodels andshow conclusion promisingresultsofhowtheinteractiveagentsys- temcanfurtherboostthelargefoundationmodels ourproposedagentaifocusesonadvancedmulti- inoursetting itintegratesandimprovesthedepth modalsystemsthatinteracteffectivelywithinboth ofgeneralization consciousandinterpretabilityof physicalandvirtualenvironmentsandfacilitateef- acomplexadaptiveaisystems fectiveinteractionwithhumans thispaperaimsto uniteresearcherstodeepenthediscourseonagent impactstatement ai cuttingacrossvariousaidisciplinesincluding agent paradigms foundation models infrastruc- agent ai paradigm is to create general-purpose tures andsystems ourgoalistoenrichthescien- agentsthatcanworkalongsidehumansinbothreal tific comprehension of agent ai and explore the andvirtualenvironments thisparadigmtherefore potential of embodied agents within the realm of intendstohaveaverybroadimpact possiblyaffect- holisticintelligenceresearch thisendeavorposi- ingall membersofsociety agentaiframework tionsustoleverageemergingfoundationalmodels emphasizestheintegrationofagentsintothewider effectively environment across a variety of settings such as ethicalconsideration limitations the main thesis of our work is that the agent ai agentaisystemshavemanyapplications inaddi- formulationhelpstobringthefieldofaibackto tiontointeractiveai groundedmultimodalmodels itsrootsinholisticintelligence however thereare couldhelpingeneratingtrainingdatasetsforrobots stillmanyunknownswithintheagentaiparadigm and ai agents and assist in productivity applica- existingfoundationmodelsexhibitbiasesandhal- tions helping to re-play or paraphrase scenario lucinations anditisunclearwhetherthesecanbe predict actions in novel scenarios or synthesize resolvedthroughscalingupmodelanddatasetsizes 3dor2dscenes fundamentaladvancesinagent orifthesearefundamentallimitationsofagentai ai help contribute towards these goals and many we also acknowledge that there are many ad- wouldbenefitfromagreaterunderstandingofhow ditional challenges in this field that we have not tomodelembodiedandempatheticbehaviorina coveredinsection7 asagrowingfieldwithapo- simulated environment or the real world there- tentialformajorimpact webelievethatthedevel- fore therearemanyapplicationsthathavepositive opmentofagentaimustincludeadiverserange benefits ofperspectivesacrossdisciplinestoensurethatit hasapositiveimpactonhumanity however thistechnologycouldalsobeusedby bad actors agent ai systems that generate con- tentcanbeusedtomanipulateordeceivepeople references therefore itisveryimportantthatthistechnology michael ahn anthony brohan noah brown yev- is developed in accordance with responsible ai genchebotar omarcortes byrondavid chelsea guidelines forexample explicitlycommunicating finn chuyuanfu keerthanagopalakrishnan karol tousersthatcontentisgeneratedbyanaisystem hausman alex herzog daniel ho jasmine hsu and providing the user with controls in order to julian ibarz brian ichter alex irpan eric jang customizesuchasystem itispossibletheagent rosario jauregui ruano kyle jeffrey sally jes- month nikhil joshi ryan julian dmitry kalash- aicouldbeusedtodevelopnewmethodstodetect nikov yuheng kuang kuang-huei lee sergey manipulativecontent-partlybecauseitisrichwith levine yao lu linda luu carolina parada pe- hallucinationsthatemergefromlargefoundation terpastor jornellquiambao kanishkarao jarek models-andthushelpaddressanotherrealworld rettinghouse diegoreyes pierresermanet nico- problem lassievers claytontan alexandertoshev vincent vanhoucke feixia tedxiao pengxu sichunxu forexample ethicaldeploymentoflargeagents mengyuan yan and andy zeng 2022a do as i foundationmodels especiallyinsensitivedomains canandnotasisay groundinglanguageinrobotic like healthcare is paramount ai agents trained affordances inarxivpreprintarxiv onbiaseddatacouldpotentiallyworsenhealthdis- michaelahn anthonybrohan noahbrown yevgen paritiesbyprovidinginaccuratediagnosesforun- chebotar omarcortes byrondavid chelseafinn derrepresentedgroups moreover thehandlingof keerthana gopalakrishnan karol hausman alex sensitive patient data by ai agents raises signifi- herzog et al 2022b do as i can not as i say cant privacy and confidentiality concerns in the grounding language in robotic affordances arxiv preprintarxiv gaming industry ai agents could transform the roleofdevelopers shiftingtheirfocusfromscript- jean-baptiste alayrac jeff donahue pauline luc ing non-player characters to refining agent learn- antoine miech iain barr yana hasson karel ingprocesses similarly adaptiveroboticsystems lenc arthurmensch katherinemillican malcolm reynolds etal flamingo avisuallanguage couldredefinemanufacturingroles necessitating model for few-shot learning advances in neural newskillsetsratherthanreplacinghumanworkers informationprocessingsystems navigatingthesetransitionsresponsiblyisvitalto minimizepotentialsocio-economicdisruptions adamallevato elaineschaertlshort mitchpryor and andrea thomaz tunenet one-shot resid- furthermore the agent ai focuses on learning ualtuningforsystemidentificationandsim-to-real collaborative policies in simulation and there is robottasktransfer inconferenceonrobotlearning some risk of directly applying the policy to the pages445 pmlr real world due to the distribution shift robust ayeshaamjad piotrkordel andgabrielafernandes testing and continuous safety monitoring mecha- areviewoninnovationinhealthcaresector nismsshouldbeputinplacetominimizerisksof telehealth through artificial intelligence sustain- unpredictablebehaviorsinreal-worldscenarios ability peter anderson qi wu damien teney jake bruce bridgingzero-shotobjectnavigationandfoundation markjohnson nikosünderhauf ianreid stephen modelsthroughpixel-guidednavigationskill arxiv gould and anton van den hengel vision- preprintarxiv and-language navigation interpreting visually- grounded navigation instructions in real environ- micahcarroll rohinshah markkho tomgriffiths ments in proceedings of the ieee conference on sanjitseshia pieterabbeel andancadragan computervisionandpatternrecognition pages3674 ontheutilityoflearningabouthumansforhuman-ai coordination advancesinneuralinformationpro- cessingsystems stanislawantol aishwaryaagrawal jiasenlu mar- garetmitchell dhruvbatra clawrencezitnick and devendrasinghchaplot dhirajprakashchandgandhi deviparikh vqa visualquestionanswering abhinav gupta and russ r salakhutdinov 2020a inproceedingsoftheieeeinternationalconference objectgoalnavigationusinggoal-orientedsemantic oncomputervision pages2425 exploration advances in neural information pro- cessingsystems bowen baker ilge akkaya peter zhokov joost huizinga jie tang adrien ecoffet brandon devendrasinghchaplot ruslansalakhutdinov abhi- houghton raul sampedro and jeff clune navgupta andsaurabhgupta 2020b neuraltopo- video pretraining vpt learning to act by watch- logicalslamforvisualnavigation inproceedingsof ing unlabeled online videos advances in neural theieee cvfconferenceoncomputervisionand informationprocessingsystems patternrecognition pages12875 dhruvbatra aarongokaslan aniruddhakembhavi guo chen yin-dong zheng jiahao wang jilan xu oleksandr maksymets roozbeh mottaghi mano- yifei huang junting pan yi wang yali wang lis savva alexander toshev and erik wijmans yu qiao tong lu and limin wang vide- objectnav revisited on evaluation of em- ollm modelingvideosequencewithlargelanguage bodiedagentsnavigatingtoobjects arxivpreprint models arxiv kezhenchen qiuyuanhuang danielmcduff xiang konstantinosbousmalis giuliavezzani dushyantrao gao hamidpalangi jianfengwang kennethfor- coline devin alex x lee maria bauza todor bus and jianfeng gao nice neural image davchev yuxiangzhou agrimgupta akhilraju commentingwithempathy inemnlp2021 et al robocat a self-improving founda- tionagentforroboticmanipulation arxivpreprint kezhen chen qiuyuan huang hamid palangi paul arxiv smolensky kenneth d forbus and jianfeng gao mappingnatural-languageproblemstoformal- anthonybrohan noahbrown justicecarbajal yevgen languagesolutionsusingstructuredneuralrepresen- chebotar xichen krzysztofchoromanski tianli tations inicml2020 ding dannydriess avinavadubey chelseafinn et al rt- vision-language-action models brandoncui andreilupu samuelsokota hengyuan transfer web knowledge to robotic control arxiv hu davidjwu andjakobnicolausfoerster preprintarxiv adversarialdiversityinhanabi intheeleventhin- ternationalconferenceonlearningrepresentations anthonybrohan noahbrown justicecarbajal yev- genchebotar josephdabis chelseafinn keerthana gautier dagan frank keller and alex lascarides gopalakrishnan karolhausman alexherzog jas- dynamicplanningwithallm arxivpreprint minehsu etal rt- roboticstransformer arxiv for real-world control at scale arxiv preprint mattdeitke winsonhan alvaroherrasti aniruddha arxiv kembhavi erickolve roozbehmottaghi jordisal- tom brown benjamin mann nick ryder melanie vador dustin schwenk eli vanderbilt matthew subbiah jareddkaplan prafulladhariwal arvind wallingford et al robothor an open neelakantan pranavshyam girishsastry amanda simulation-to-realembodiedaiplatform inproceed- askell etal languagemodelsarefew-shot ingsoftheieee cvfconferenceoncomputervision learners advancesinneuralinformationprocessing andpatternrecognition pages3164 systems vishnu sashank dorbala james f mullen jr and di- patrickbutlin robertlong ericelmoznino yoshua neshmanocha cananembodiedagentfind bengio jonathan birch axel constant george your cat-shapedmug llm-basedzero-shotobject deane stephenmfleming chrisfrith xuji etal navigation arxivpreprintarxiv consciousness in artificial intelligence in- sights from the science of consciousness arxiv vishnu sashank dorbala gunnar sigurdsson robin- preprintarxiv son piramuthu jesse thomason and gaurav s sukhatme clip-nav using clip for zero- wenzhecai siyuanhuang guangrancheng yuxing shotvision-and-languagenavigation arxivpreprint long penggao changyinsun andhaodong arxiv dannydriess feixia mehdismsajjadi coreylynch rangong qiuyuanhuang xiaojianma hoivo zane aakankshachowdhery brianichter ayzaanwahid durante yusuke noda zilong zheng song-chun jonathan tompson quan vuong tianhe yu et al zhu demetri terzopoulos li fei-fei et al palm-e anembodiedmultimodallanguage mindagent emergent gaming interaction arxiv model arxivpreprintarxiv preprintarxiv yilun du mengjiao yang pete florence fei xia ankitgoyal jiexu yijieguo valtsblukis yu-wei ayzaanwahid brianichter pierresermanet tianhe chao anddieterfox rvt roboticviewtrans- yu pieter abbeel joshua b tenenbaum et al former for 3d object manipulation arxiv preprint video language planning arxiv preprint arxiv arxiv isabelagranic adamlobel andrutgercmeengels zanedurante qiuyuanhuang naokiwake rangong thebenefitsofplayingvideogames ameri- jaesungpark bidiptasarkar rohantaori yusuke canpsychologist noda demetri terzopoulos yejin choi katsushi ikeuchi hoivo lifei-fei andjianfenggao 2024a liangke gui qiuyuan huang alex hauptmann agentai surveyingthehorizonsofmultimodalin- yonatanbisk andjianfenggao 2022a vlc train- teraction arxivpreprintarxiv ingvision-languagetransformersfromcaptions zane durante bidipta sarkar ran gong rohan liangkegui boruiwang qiuyuanhuang alexhaupt- taori yusuke noda paul tang ehsan adeli mann yonatanbisk andjianfenggao 2022b kat shrinidhikowshikalakshmikanth kevinschulman aknowledgeaugmentedtransformerforvision-and- arnoldmilstein demetriterzopoulos adefamoti language innaacl2022 longpaper oral noborukuno ashleyj llorens hoivo katsushi ikeuchi fei-feili jianfenggao naokiwake and rodrigo longhi guimarães andré schneider qiuyuanhuang 2024b agentfoundationmodel deoliveira joãoalbertofabro thiagobecker and nouha dziri andrea madotto osmar zaiane and vinícius amilgar brenner ros navigation avishekjoeybose neuralpathhunter re- concepts and tutorial robot operating system ducing hallucination in dialogue systems via path ros the complete reference volume pages grounding arxivpreprintarxiv kianaehsani winsonhan alvaroherrasti elivan- kelvinguu kentonlee zoratung panupongpasu- derbilt lucaweihs erickolve aniruddhakemb- pat andmingweichang retrievalaugmented havi androozbehmottaghi manipulathor languagemodelpre-training ininternationalconfer- aframeworkforvisualobjectmanipulation inpro- enceonmachinelearning pages3929 pmlr ceedingsoftheieee cvfconferenceoncomputer visionandpatternrecognition pages4497 huyha peteflorence andshuransong scaling upanddistillingdown language-guidedrobotskill samiryitzhakgadre mitchellwortsman gabrielil- acquisition arxivpreprintarxiv harco ludwig schmidt and shuran song cows on pasture baselines and benchmarks for laurabirkahensel nutchanonyongsatianchot parisa language-drivenzero-shotobjectnavigation inpro- torshizi elenaminucci andstacymarsella ceedingsoftheieee cvfconferenceoncomputer largelanguagemodelsintextualanalysisforgesture visionandpatternrecognition pages23171 selection ininternationalconferenceon multimodalinteraction pages378 jianfenggao baolinpeng chunyuanli jinchaoli shahin shayandeh lars liden and heung-yeung danielho kanishkarao zhuoxu ericjang mohi shum robustconversationalaiwithgrounded khansari and yunfei bai retinagan an textgeneration arxivpreprintarxiv object-aware approach to sim-to-real transfer in ieee international conference on robotics jianfeng gao chenyan xiong paul bennett and andautomation icra pages10920 ieee nick craswell neural approaches to con- versational information retrieval arxiv preprint chenguanghuang oiermees andyzeng andwol- arxiv framburgard 2023a visuallanguagemapsforrobot caelanreedgarrett rohanchitnis rachelholladay navigation in2023ieeeinternationalconference beomjoonkim tomsilver lesliepackkaelbling onroboticsandautomation icra pages10608 andtomáslozano-pérez integratedtaskand ieee motionplanning annualreviewofcontrol robotics andautonomoussystems qiuyuanhuang jaesungpark abhinavgupta paul bennett ran gong subhojit som baolin peng theophilegervet soumithchintala dhruvbatra jiten- owais khan mohammed chris pal yejin choi dramalik anddevendrasinghchaplot navi- et al 2023b ark augmented reality with knowl- gatingtoobjectsintherealworld sciencerobotics edge interactive emergent ability arxiv preprint eadf6991 arxiv qiuyuan huang pengchuan zhang oliver wu and ranjaykrishna yukezhu olivergroth justinjohn- leizhang turbolearningforcaptionbotand son kenji hata joshua kravitz stephanie chen drawingbot inneurips2018 yannis kalantidis li-jia li david a shamma michael bernstein and li fei-fei vi- wenlong huang pieter abbeel deepak pathak and sual genome connecting language and vision us- igor mordatch 2022a language models as zero- ing crowdsourced dense image annotations in shotplanners extractingactionableknowledgefor arxiv embodiedagents inproceedingsofthe39thinter- nationalconferenceonmachinelearning volume kniranjankumar irfanessa andsehoonha 162ofproceedingsofmachinelearningresearch wordsintoaction learningdiversehumanoidrobot pages9118 pmlr behaviorsusinglanguageguidediterativemotionre- finement arxivpreprintarxiv wenlonghuang feixia tedxiao harrischan jacky liang peteflorence andyzeng jonathantomp- peterlee sebastienbubeck andjosephpetro son igor mordatch yevgen chebotar pierre ser- benefits limits andrisksofgpt-4asanaichatbot manet noah brown tomas jackson linda luu for medicine new england journal of medicine sergey levine karol hausman and brian ichter 2022b inner monologue embodied reasoning through planning with language models in arxiv patricklewis ethanperez aleksandrapiktus fabio preprintarxiv petroni vladimirkarpukhin namangoyal hein- richküttler mikelewis wen-tauyih timrock- dfcintelligence globalvideogameaudience täschel etal retrieval-augmentedgeneration reaches3 7billion forknowledge-intensivenlptasks inneurips bal-video-game-audience-reaches---bil lion accessed -- boyili philippwu pieterabbeel andjitendrama- lik 2023a interactivetaskplanningwithlanguage stephen james and andrew j davison q- models arxivpreprintarxiv attention enablingefficientlearningforvision-based roboticmanipulation ieeeroboticsandautoma- chengshuli feixia robertomartín-martín michael tionletters lingelbach sanjana srivastava bokui shen kent vainio cem gokmen gokul dharan tanish jain ericjang alexirpan mohikhansari danielkappler etal igibson2 object-centricsimulationfor frederik ebert corey lynch sergey levine and robotlearningofeverydayhouseholdtasks arxiv chelseafinn bc-z zero-shottaskgeneraliza- preprintarxiv tionwithroboticimitationlearning inconference onrobotlearning pages991 pmlr guohao li hasan abed al kader hammoud hani itani dmitrii khizbullin and bernard ghanem ziweiji nayeonlee ritafrieske tiezhengyu dan 2023b camel communicative agents for mind su yan xu etsuko ishii ye jin bang andrea exploration of large scale language model society madotto andpascalefung surveyofhalluci- arxivpreprintarxiv nationinnaturallanguagegeneration acmcomput- ingsurveys jiachen li qiaozi gao michael johnston xiaofeng gao xuehaihe suhailashakiah hangjieshi reza yunfan jiang agrim gupta zichen zhang guanzhi ghanadan and william yang wang 2023c mas- wang yongqiangdou yanjunchen lifei-fei an- teringrobotmanipulationwithmultimodalprompts ima anandkumar yuke zhu and linxi fan throughpretrainingandmulti-taskfine-tuning arxiv vima generalrobotmanipulationwithmultimodal preprintarxiv prompts arxiv andrejkarpathy armandjoulin andliffei-fei junnanli dongxuli silviosavarese andstevenhoi deepfragmentembeddingsforbidirectionalimage 2023d blip- bootstrappinglanguage-imagepre- sentencemapping advancesinneuralinformation training with frozen image encoders and large lan- processingsystems guagemodels arxivpreprintarxiv pushkalkatara zhouxian andkaterinafragkiadaki kunchang li yinan he wang yi yizhuo li wen- gen2sim scaling up robot learning in sim- haiwang pingluo yaliwang liminwang and ulation with generative models arxiv preprint yuqiao 2023e videochat chat-centricvideoun- arxiv derstanding arxivpreprintarxiv erickolve roozbehmottaghi winsonhan elivan- xinghang li minghuan liu hanbo zhang cunjun derbilt lucaweihs alvaroherrasti mattdeitke yu jiexu hongtaowu chilamcheang yajing kianaehsani danielgordon yukezhu etal weinan zhang huaping liu et al 2023f vision- ai2-thor aninteractive3denvironmentforvisualai languagefoundationmodelsaseffectiverobotimita- arxivpreprintarxiv tors arxivpreprintarxiv jackyliang wenlonghuang feixia pengxu karol hengyuanhu etal human-levelplayinthe hausman brian ichter pete florence and andy gameofdiplomacybycombininglanguagemodels zeng code as policies language model withstrategicreasoning science programs for embodied control in arxiv preprint arxiv mayank mittal calvin yu qinxi yu jingzhou liu xiwenliang liangma shanshanguo jianhuahan nikita rudin david hoeller jia lin yuan ritvik hang xu shikui ma and xiaodan liang singh yunrongguo hammadmazhar etal mo-vln amulti-taskbenchmarkforopen-setzero- orbit aunifiedsimulationframeworkforinteractive shotvision-and-languagenavigation arxivpreprint robot learning environments ieee robotics and arxiv automationletters tsung-yilin michaelmaire sergebelongie lubomir volodymyr mnih koray kavukcuoglu david silver bourdev rossgirshick jameshays pietroperona andrei a rusu joel veness marc g bellemare devaramanan c lawrencezitnick andpiotrdol- alex graves martin riedmiller andreas k fidje- lár microsoftcoco commonobjectsincon- land georg ostrovski et al human-level text proceedingsofeccv controlthroughdeepreinforcementlearning nature ckarenliuanddannegrut theroleofphysics- basedsimulatorsinrobotics annualreviewofcon- matthias müller vincent casser jean lahoud neil trol robotics andautonomoussystems smith and bernard ghanem sim4cv a photo-realisticsimulatorforcomputervisionappli- yechengjasonma williamliang guanzhiwang de- cations internationaljournalofcomputervision anhuang osbertbastani dineshjayaraman yuke zhu linxifan andanimaanandkumar eu- reka human-level reward design via coding large zheni xiao-xindeng congtai xin-yuezhu xi- languagemodels arxivpreprintarxiv angwu yong-jinliu andlongzeng grid scene-graph-based instruction-driven robotic task muhammad maaz hanoona rasheed salman khan planning arxivpreprintarxiv andfahadshahbazkhan video-chatgpt to- wardsdetailedvideounderstandingvialargevision openai gpt-4technicalreport technicalre- andlanguagemodels port openai ruimao qianliu kaihe weili anderikcambria longouyang jeffreywu xujiang diogoalmeida the biases of pre-trained language models carrollwainwright pamelamishkin chongzhang anempiricalstudyonprompt-basedsentimentanal- sandhiniagarwal katarinaslama alexray etal ysisandemotiondetection ieeetransactionson training languagemodelsto followinstruc- affectivecomputing tions with human feedback advances in neural informationprocessingsystems gary marcus and ernest davis rebooting ai building artificial intelligence we can trust pan- meenalparakh alishafong anthonysimeonov ab- theon hishekgupta taochen andpulkitagrawal pablo martinez-gonzalez sergiu oprea alberto human-assistedcontinualrobotlearningwithfoun- garcia-garcia alvaro jover-alvarez sergio orts- dationmodels arxivpreprintarxiv escolano and jose garcia-rodriguez un- jaesungpark jackhessel khyathichandu paulpu realrox an extremely photorealistic virtual reality liang ximinglu peterwest qiuyuanhuang jian- environmentforroboticssimulationsandsynthetic fenggao alifarhadi andyejinchoi 2023a multi- datageneration virtualreality modalagent localizedsymbolicknowledgedistil- joshua maynez shashi narayan bernd bohnet and lationforvisualcommonsensemodels inneurips ryan mcdonald on faithfulness and factu- alityinabstractivesummarization inproceedings of the 58th annual meeting of the association for jaesungpark jackhessel khyathichandu paulpu computational linguistics pages on- liang ximing lu peter west youngjae yu qi- line associationforcomputationallinguistics uyuanhuang jianfenggao alifarhadi andyejin choi 2023b localizedsymbolicknowledgedistil- oier mees lukas hermann erick rosete-beas and lation for visual commonsense models in thirty- wolfram burgard calvin a benchmark seventhconferenceonneuralinformationprocess- for language-conditioned policy learning for long- ingsystems horizon robot manipulation tasks ieee robotics andautomationletters joonsungpark josephco brien carriejcai mered- ith ringel morris percy liang and michael s metafundamentalairesearch antonbakhtin noam bernstein 2023c generative agents interac- brown emily dinan gabriele farina colin fla- tive simulacra of human behavior arxiv preprint herty daniel fried andrew goff jonathan gray arxiv baolinpeng michelgalley pengchenghe haocheng daichi saito kazuhiro sasabuchi naoki wake jun yujiaxie yuhu qiuyuanhuang larsliden zhou takamatsu hideki koike and katsushi ikeuchi yu weizhuchen etal checkyourfactsand task-grasping from a demonstrated human try again improving large language models with strategy in2022ieee-ras21stinternationalcon- externalknowledgeandautomatedfeedback arxiv ference on humanoid robots humanoids pages preprintarxiv xavier puig kevin ra marko boben jiaman li bidiptasarkar andyshih anddorsasadigh di- tingwu wang sanja fidler and antonio torralba verse conventions for human-ai collaboration in virtualhome simulatinghouseholdactivities thirty-seventh conference on neural information viaprograms in2018ieeeinternationalconfer- processingsystems ence on computer vision and pattern recognition cvpr pages8494 kazuhiro sasabuchi daichi saito atsushi kanehira naokiwake juntakamatsu andkatsushiikeuchi xavier puig eric undersander andrew szot task-sequencing simulator integrated ma- mikaeldallairecote tsung-yenyang ruslanpart- chinelearningtoexecutionsimulationforrobotma- sey rutadesai alexanderwilliamclegg michal nipulation arxivpreprintarxiv hlavac so yeon min et al habitat a co-habitat for humans avatars and robots arxiv preprintarxiv manolis savva abhishek kadian oleksandr maksymets yili zhao erik wijmans bhavana santhoshkumarramakrishnan devendrasinghchap- jain julianstraub jialiu vladlenkoltun jitendra lot ziadal-halah jitendramalik andkristengrau- malik etal habitat aplatformforembodied man poni potentialfunctionsforobjectgoal ai research in proceedings of the ieee cvf navigation with interaction-free learning in pro- internationalconferenceoncomputervision pages ceedingsoftheieee cvfconferenceoncomputer visionandpatternrecognition pages18890 johnschulman filipwolski prafulladhariwal alec shreyassundararaman vanyacohen davidpaulius radford andolegklimov proximalpolicy ifrahidrees ericrosen raymooney andstefanie optimizationalgorithms tellex cape correctiveactionsfromprecon- dition errors using large language models in 2nd brennanshacklett lucguyrosenzweig zhiqiangxie workshop on language and robot learning lan- bidiptasarkar andrewszot erikwijmans vladlen guageasgrounding koltun dhruvbatra andkayvonfatahalian an extensible data-oriented architecture for high- kanishkarao chrisharris alexirpan sergeylevine performance many-worldsimulation acmtrans julianibarz andmohikhansari rl-cyclegan graph reinforcementlearningawaresimulation-to-real in proceedingsoftheieee cvfconferenceoncom- dhruvshah błaz ejosin ski sergeylevine etal 2023a putervisionandpatternrecognition pages11157 lm-nav roboticnavigationwithlargepre-trained modelsoflanguage vision andaction inconfer- vikas raunak arul menezes and marcin junczys- enceonrobotlearning pages492 pmlr dowmunt the curious case of hallucina- tionsinneuralmachinetranslation arxivpreprint rutav shah roberto martín-martín and yuke zhu arxiv 2023b mutex learning unified policies from multimodal task specifications arxiv preprint mengye ren ryan kiros and richard zemel arxiv exploring models and data for image question an- swering advancesinneuralinformationprocessing shitalshah debadeeptadey chrislovett andashish systems kapoor airsim high-fidelityvisualandphys- icalsimulationforautonomousvehicles infieldand annarohrbach lisaannehendricks kayleeburns servicerobotics resultsofthe11thinternational trevor darrell and kate saenko object conference pages621 springer hallucination in image captioning arxiv preprint arxiv piyush sharma nan ding sebastian goodman and radusoricut conceptualcaptions acleaned antoni rosinol john j leonard and luca carlone hypernymed imagealt-textdatasetforautomaticim- nerf-slam real-time dense monocular agecaptioning proceedingsofthe56thannualmeet- slam with neural radiance fields arxiv preprint ingoftheassociationforcomputationallinguistics arxiv daichi saito kazuhiro sasabuchi naoki wake at- mohitshridhar lucasmanuelli anddieterfox sushikanehira juntakamatsu hidekikoike and perceiver-actor amulti-tasktransformerforrobotic katsushiikeuchi constraint-awarepolicyfor manipulation in conference on robot learning compliantmanipulation pages785 pmlr kurtshuster spencerpoff moyachen douwekiela naoki wake atsushi kanehira kazuhiro sasabuchi and jason weston retrieval augmentation juntakamatsu andkatsushiikeuchi 2023a bias reduceshallucinationinconversation arxivpreprint inemotionrecognitionwithchatgpt arxivpreprint arxiv arxiv amanpreet singh vivek natarajan meet shah naoki wake atsushi kanehira kazuhiro sasabuchi yu jiang xinlei chen dhruv batra devi parikh juntakamatsu andkatsushiikeuchi 2023b chat- andmarcusrohrbach towardsvqamodels gpt empowered long-step robot control in various thatcanread inproceedingsoftheieee cvfcon- environments a case application ieee access ferenceoncomputervisionandpatternrecognition pages8317 naoki wake atsushi kanehira kazuhiro sasabuchi sumedh a sontakke jesse zhang sébastien mr juntakamatsu andkatsushiikeuchi 2023c gpt- arnold karl pertsch erdem bıyık dorsa sadigh 4v ision for robotics multimodal task plan- chelsea finn and laurent itti roboclip ning from human demonstration arxiv preprint onedemonstrationisenoughtolearnrobotpolicies arxiv arxivpreprintarxiv sanjanasrivastava chengshuli michaellingelbach naoki wake atsushi kanehira kazuhiro sasabuchi robertomartín-martín feixia kentelliottvainio jun takamatsu and katsushi ikeuchi 2023d gpt zheng lian cem gokmen shyamal buch karen modelsmeetroboticapplications co-speechgestur- liu et al behavior benchmark for every- ingchatsystem arxivpreprintarxiv dayhouseholdactivitiesinvirtual interactive and ecological environments in conference on robot boruiwang qiuyuanhuang budhadityadeb aaronl learning pages477 pmlr halfaker liqun shao daniel mcduff ahmed awadallah dragomir radev and jianfeng gao andrew szot alex clegg eric undersander erik 2023a logicaltransformers infusinglogicalstruc- wijmans yili zhao john turner noah maestre turesintopre-trainedlanguagemodels inproceed- mustafa mukadam devendra chaplot oleksandr ingsofacl2023 maksymets aaron gokaslan vladimir vondrus sameerdharur franziskameier wojciechgaluba guanzhi wang yuqi xie yunfan jiang ajay man- angelchang zsoltkira vladlenkoltun jitendra dlekar chaoweixiao yukezhu linxifan andan- malik manolissavva anddhruvbatra habi- imaanandkumar 2023b voyager anopen-ended tat2 traininghomeassistantstorearrangetheir embodiedagentwithlargelanguagemodels arxiv habitat inadvancesinneuralinformationprocess- preprintarxiv ingsystems neurips hitoshi teshima naoki wake diego thomas yuta xinwang qiuyuanhuang aslicelikyilmaz jianfeng nakashima hiroshikawasaki andkatsushiikeuchi gao dinghanshen yuan-fangweng williamyang deepgesturegenerationforsocialrobotsusing wang andleizhang reinforcedcross-modal type-specific libraries in ieee rsj interna- matchingandself-supervisedimitationlearningfor tionalconferenceonintelligentrobotsandsystems vision-languagenavigation incvpr2019 iros pages8286 ieee yiwang yinanhe yizhuoli kunchangli jiashuo joshtobin rachelfong alexray jonasschneider yu xinma xinyuanchen yaohuiwang pingluo wojciech zaremba and pieter abbeel do- ziwei liu yali wang limin wang and yu qiao mainrandomizationfortransferringdeepneuralnet- 2023c internvid alarge-scalevideo-textdatasetfor works from simulation to the real world in multimodalunderstandingandgeneration ieee rsj international conference on intelligent robotsandsystems iros pages23 ieee yufeiwang zhouxian fengchen tsun-hsuanwang yianwang katerinafragkiadaki zackoryerickson nathan tsoi alec xiang peter yu samuel s sohn david held and chuang gan 2023d robogen greg schwartz subashri ramesh mohamed hus- towardsunleashinginfinitedataforautomatedrobot sein anjali w gupta mubbasir kapadia and learning via generative simulation arxiv preprint marynel vázquez sean formalizing arxiv andgeneratingsocialsituationsforrobotnavigation ieeeroboticsandautomationletters zihaowang shaofeicai anjiliu xiaojianma and yitaoliang 2023e describe explain planandse- naoki wake riku arakawa iori yanokura takuya lect interactiveplanningwithlargelanguagemodels kiyokawa kazuhirosasabuchi juntakamatsu and enablesopen-worldmulti-taskagents arxivpreprint katsushiikeuchi alearning-from-observation arxiv framework one-shot robot teaching for grasp- manipulation-releasehouseholdoperations in2021 p h winston the m i t robot in d michie ieee siceinternationalsymposiumonsysteminte- editor machineintelligence7 edinburghuniversity gration sii ieee press edinburgh scotland jingkang yang yuhao dong shuai liu bo li gengze zhou yicong hong and qi wu 2023a ziyue wang chencheng jiang haoran tan ji- navgpt explicitreasoninginvision-and-language amu kang yuanhan zhang kaiyang zhou et al navigation with large language models arxiv 2023a octopus embodied vision-language pro- preprintarxiv grammer from environmental feedback arxiv preprintarxiv haoyuzhou mingyuding weikunpeng masayoshi tomizuka linshao andchuanggan 2023b gen- kailaiyang shaoxiongji tianlinzhang qianqianxie eralizablelong-horizonmanipulationswithlargelan- andsophiaananiadou 2023b ontheevaluationsof guagemodels arxivpreprintarxiv chatgptandemotion-enhancedpromptingformental healthanalysis arxivpreprintarxiv yiyang zhou chenhang cui jaehong yoon linjun zhang zhundeng chelseafinn mohitbansal and shunyu yao jeffrey zhao dian yu nan du izhak huaxiuyao 2023c analyzingandmitigatingobject shafran karthiknarasimhan andyuancao hallucinationinlargevision-languagemodels arxiv react synergizingreasoningandactinginlanguage preprintarxiv models deyaozhu junchen xiaoqianshen xiangli and yang ye hengxu you and jing du im- mohamedelhoseiny minigpt- enhancing provedtrustinhuman-robotcollaborationwithchat- vision-languageunderstandingwithadvancedlarge gpt ieeeaccess languagemodels jun-yanzhu taesungpark phillipisola andalexeia peteryoung alicelai micahhodosh andjuliahock- efros 2017a unpairedimage-to-imagetranslation enmaier from image descriptions to visual usingcycle-consistentadversarialnetworks inpro- denotations newsimilaritymetricsforsemanticin- ceedings of the ieee international conference on ferenceovereventdescriptions proceedingsofthe computervision pages2223 annualmeetingoftheassociationforcomputational linguistics shaojunzhu andrewkimmel kostasebekris and abdeslam boularias 2017b fast model identifi- lichengyu patrickpoirson shanyang alexanderc cation via physics engines for data-efficient policy berg andtamaralberg modelingcontext search arxivpreprintarxiv inreferringexpressions incomputervision eccv 14theuropeanconference amsterdam the netherlands october11- proceedings part ii14 pages69 springer wenhao yu nimrod gileadi chuyuan fu sean kir- mani kuang-huei lee montse gonzalez arenas hao-tienlewischiang tomerez leonardhasen- clever jan humplik et al language to re- wards for robotic skill synthesis arxiv preprint arxiv andyzeng peteflorence jonathantompson stefan welker jonathanchien mariaattarian travisarm- strong ivankrasin danduong vikassindhwani etal transporternetworks rearrangingthe visualworldforroboticmanipulation inconference onrobotlearning pages726 pmlr sixian zhang xinhang song yubing bai weijie li yakuichu andshuqiangjiang hierarchical object-to-zonegraphforobjectnavigation inpro- ceedingsoftheieee cvfinternationalconference oncomputervision pages15130 weixiangzhao yanyanzhao xinlu shilongwang yanpeng tong and bing qin is chat- gptequippedwithemotionaldialoguecapabilities arxivpreprintarxiv zhidezhong jiakaicao songengu siruixie weibo gao liyi luo zike yan hao zhao and guyue zhou assist interactivescenenodesforscal- ableandrealisticindoorsimulation arxivpreprint arxiv appendices for agent ai towards a holistic intelligence a intentioninformationand largeactionmodelsforgeneralpurposerobotics manipulationforembodiedaction optimizeandvalidatethealgorithmsinreal-world scenarioswithlargeactionmodelsonphoenix ex- languageconditionedinternetactioninstruction ploreapplicationsindiversedomains ensuringro- entails the ability of a robotic system to inter- bustnessandscalability refinealgorithmsbased pretandexecutetasksbasedonlanguageinstruc- on real-world evaluation feedback and scale for tions thisaspectisparticularlycrucialforcreating broaderclouddeploymentintheembodiedsystem intuitive and user-friendly interfaces for human- robotinteraction throughnaturallanguagecom- b agentforcross-modalityand mands userscanspecifygoalsandtaskstorobots mix-reality in a manner similar to human-human communi- b agentsforcross-modalunderstanding cation wang et al thereby lowering the barrier to operating robotic systems in a practi- multi-modal understanding is a significant chal- cal scenario for instance a user could instruct a lengeforcreatinggeneralistaiagentsduetothe service robot to pick up the red apple from the lackoflarge-scaledatasetsthatcontainvision lan- table andtherobotwouldparsethisinstruction guage andagentbehavior moregenerally training identifythereferredobjectandexecutethetaskof dataforaiagentsisoftenmodalityspecific this pickingitup wakeetal 2023b thecorechal- resultsinmostmodernmulti-modalsystemsusing lenge lies in developing robust natural language a combination of frozen submodules some no- processingandunderstandingalgorithmsthatcan tableexamplesareflamingo alayracetal accurately interpret a wide array of instructions blip- lietal 2023d vlc guietal 2022a ranging from direct commands to more abstract andark huangetal 2023b allofwhichutilize directives and enable the robot to convert these a frozen llm and frozen visual encoder these instructionsintoactionabletasks furthermore en- submodules are trained individually on separate suringthatrobotscangeneralizetheseinstructions datasets andthenadaptationlayersaretrainedto across diverse tasks and environments is critical encode the visual encoder into the llm embed- for enhancing their versatility and utility in real- dingspace inordertomakefurtherprogressfor world applications the use of language input to cross-modalunderstandingforaiagents itislikely guiderobot staskplanninghasgainedattentionin thatthestrategyofusingfrozenllmsandvisual thecontextofarobotframeworkcalledtaskand encoders will need to change indeed rt- a motionplanning garrettetal recentvisual-languagemodelthatiscapableoftak- inaddition duranteetal 2024b learnabout ingactionswithinthedomainofroboticsshowed theintricatechallengesoflargeactionmodelsfor significantlyimprovedperformancewhenjointly embodied systems e g robotic it begin with a tuning the visual encoder and llm for robotics low-level action manipulation foundational mod- andvisual-languagetasks brohanetal els it explore solutions to issues such as action b agentsforcross-domainunderstanding resignation adaptabilitytodynamicenvironments andtheefficientmanagementofhigh-dimensional akeychallengeforcreatinggeneralistagentsisthe actionspaces whentransfertonextphase weim- distinctivevisualappearanceanddisparateaction plementandrefinealgorithms ensuringscalability spacesacrossdifferentdomains humanspossess andeffectivenessinsimulationsonourserver de- thecapabilitytointerpretimagesandvideosfrom velopandimplementfoundationalalgorithmsfor various sources including the real world video large action models emphasizing efficiency and games and specialized domains such as robotics scalability focus on addressing issues related to andhealthcare duranteetal 2024a oncethey pre-training fine-tuning andmodeloptimization becomefamiliarwiththespecificdetailsofthese conduct initial simulations on azure to validate areas however existing llms and vlms often algorithmicconcepts theultimateobjectiveinthe demonstrate significant differences between the thirdphase istooptimizeandvalidatethesealgo- datatheyweretrainedonandthevarieddomains rithms in real-world scenarios exploring diverse in which they are applied and notably training applications and contributing to the evolution of agentmodelstopredictspecificactionspresentsa considerable challenge when trying to develop a agentthatisrespectfulandaccessibletoallusers singlepolicythatcaneffectivelylearnmultiplecon- regardlessoftheirbackgroundoridentity trolsystemsacrossdomains huangetal 2023b d hallucinations generally theapproachmostmodernworkstake whenapplyingsystemswithinspecificdomainsis agentsthatgeneratetextareoftenpronetohalluci- to start from a pretrained foundation model and nations whichareinstanceswherethegenerated then finetune a separate model for each specific text is nonsensical or unfaithful to the provided domain this fails to capture any commonalities sourcecontent raunaketal maynezetal betweendomainsandresultsinasmallertotalset hallucinations can be split into two cate- ofdatausedfortraininginsteadofleveragingeach gories intrinsicandextrinsic jietal in- domain sdata trinsic hallucinations are hallucinations that are contradictory to the source material whereas ex- b interactiveagentforcross-modalityand trinsichallucinationsarewhenthegeneratedtext cross-reality containsadditionalinformationthatwasnotorigi- developingaiagentsthatcansuccessfullyunder- nallyincludedinthesourcematerial stand and perform tasks across different realities somepromisingroutesforreducingtherateof isanon-goingchallengethathasseensomerecent hallucination in language generation involve us- success for image and scene generation huang ing retrieval-augmented generation lewis et al et al 2023b in particular it is challenging for shuster et al or other methods for agents to simultaneously understand real-world grounding natural language outputs via external andvirtualrealityenvironmentsduetotheirvisual knowledgeretrieval dzirietal pengetal dissimilarities and separate environment physics generally thesemethodsseektoaugment within the context of cross-reality sim to real languagegenerationbyretrievingadditionalsource transferisaparticularlyimportantproblemwhen materialandbyprovidingmechanismstocheckfor using simulation-trained policies for real-world contradictionsbetweenthegeneratedresponseand data whichwediscussinthenextsection thesourcematerial withinthecontextofmulti-modalagentsystems c bias have multimodality been shown to hallucinate as well zhou et al 2023c one common cause of aiagentsbasedonllmsorlmms largemulti- hallucinationforvision-basedlanguage-generation modalmodels havebiasesduetoseveralfactors isduetotheover-relianceonco-occurrenceofob- inherentintheirdesignandtrainingprocess when jectsandvisualcuesinthetrainingdata rohrbach designingtheseaiagents wemustbemindfulof etal aiagentsthatexclusivelyrelyupon beinginclusiveandawareoftheneedsofallend pretrained large foundation models and use lim- usersandstakeholders inthecontextofaiagents itedenvironment-specificfinetuningcanbepartic- inclusivity refers to the measures and principles ularlyvulnerabletohallucinationssincetheyrely employedtoensurethattheagent sresponsesand upontheinternalknowledge-baseofthepretrained interactionsareinclusive respectful andsensitive models for generating actions and may not accu- toawiderangeofusersfromdiversebackgrounds ratelyunderstandthedynamicsoftheworldstate despitethesemeasures aiagentsstillexhibitbi- inwhichtheyaredeployed ases ongoing efforts in agent ai research and developmentarefocusedonfurtherreducingthese biases and enhancing the inclusivity and fairness of agent ai systems despite these measures ai agentsstillexhibitbiases ongoingeffortsinagent airesearchanddevelopmentarefocusedonfurther reducingthesebiasesandenhancingtheinclusivity and fairness of agent ai systems despite these efforts it simportanttobeawareofthepotential forbiasesinresponsesandtointerpretthemwith criticalthinking continuousimprovementsinai agent technology and ethical practices aim to re- ducethesebiasesovertime oneoftheoverarch- inggoalsforinclusivityinagentaiistocreatean