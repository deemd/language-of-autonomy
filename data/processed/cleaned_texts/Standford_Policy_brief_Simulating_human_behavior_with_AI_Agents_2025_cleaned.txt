policy brief hai policy society may simulating human key takeaways simulating human attitudes and behavior with ai behaviors could enable researchers to test interventions and theories and gain real world insights agents we built an ai agent architecture that can simulate real people in ways far more complex than joon sung park carolyn q zou aaron shaw traditional approaches using benjamin mako hill carrie j cai meredith ringel morris this architecture we created generative agents that simulate robb willer percy liang michael s bernstein individuals each using an llm paired with an in depth interview transcript of the individual ai agents have been gaining widespread attention among the general public as ai systems that can pursue complex goals and directly take actions in both virtual and real world environments today people can use ai agents to test these generative agents we to make payments reserve flights and place grocery orders for them and evaluated the agents responses there is great excitement about the potential for ai agents to manage even against the corresponding person s responses to major social science more sophisticated tasks surveys and experiments we found that the agents replicated real participants responses however a different type of ai agent a simulation of human behaviors and as accurately as the individuals attitudes is also on the rise these simulation ai agents aim to be useful replicated their own answers two weeks later on the general at asking what if questions about how people might respond to a range social survey of social political or informational contexts if these agents achieve high accuracy they could enable researchers to test a broad set of interventions and theories such as how people would react to new public health because these generative agents messages product launches or major economic or political shocks across hold sensitive data and can mimic individual behavior policymakers economics sociology organizations and political science new ways of and researchers must work simulating individual behavior and the behavior of groups of individuals together to ensure that appropriate could help expand our understanding of social interactions institutions monitoring and consent mechanisms are used to help and networks while work on these kinds of agents is progressing current mitigate risks while also harnessing architectures must cover some distance before their use is reliable potential benefits policy brief simulating human behavior with ai agents in our paper generative agent simulations of people we introduce an ai agent architecture that generative ai models offer simulates more than real people the agent the opportunity to build general architecture built by combining the transcripts of two hour qualitative interviews with a large language purpose agents that can simulate model llm and scored against social science human attitudes across a variety benchmarks successfully replicated real individuals responses to survey questions as accurately of contexts as participants replicate their own answers across surveys staggered two weeks apart the generative agents performed comparably in predicting people s personality traits and experiment outcomes and were less biased than previously used simulation tools turn can limit the generalizability and accuracy of the simulation results this architecture underscores the benefits of using generative agents as a research tool to glean new generative ai models offer the opportunity to build insights into real world individual behavior however general purpose agents that can simulate human researchers and policymakers must also mitigate the attitudes across a variety of contexts to create risks of using generative agents in such contexts simulations that better reflect the myriad often including harms related to over reliance on agents idiosyncratic factors that influence individuals privacy and reputation attitudes beliefs and behaviors we built a novel generative agent architecture that combines llms with in depth interviews with real individuals introduction we recruited individuals representative of simulations in which agents are used to model the the u s population across age gender race region behaviors and interactions of individuals have been education and political ideology to participate a popular tool for empirical social research for years in two hour qualitative interviews these in depth even before the emergence of ai agents traditional interviews which included both pre specified approaches to building agent architectures such as questions and adaptive follow up questions are a agent based models or game theory rely on clear foundational social science method that has been sets of rules and environments manually specified by successfully used by researchers to predict life the researchers while these rules make it relatively outcomes beyond what could be learned from easy to interpret results they also limit the contexts in traditional surveys and demographic instruments we which traditional agents can act while oversimplifying also developed an ai interviewer to ask participants the real life complexity of human behavior this in the questions based on a semi structured interview policy brief simulating human behavior with ai agents protocol from the american voices project which games public goods game and prisoner s dilemma ranged from life stories to people s views on current and five social science experiments with control and social issues treatment conditions for the general social survey which has categorical responses we measured then we built the generative agents based on accuracy and correlation based on whether the agent participants full interview transcripts and an llm selects the same survey response as the person for when a generative agent was queried the full transcript the big five inventory and the economic games which was injected into the model prompt which instructed the have continuous responses we assessed accuracy model to imitate the relevant individual when responding and correlation using mean absolute error to questions including forced choice prompts surveys and multi stage interactional settings research outcomes once the generative agents were in place we evaluated them on their ability to predict participants overall the generative agents proved remarkably responses to common social science surveys and effective in simulating individuals real world experiments which the participants completed after personalities for example the generative agents their in depth interviews we tested on the core predicted participants responses to the general module of the general social survey widely used to social survey with an average normalized accuracy assess survey respondents demographic backgrounds of meaning that on average generative agents behaviors attitudes and beliefs the  item big replicated participant responses as accurately as five inventory designed to assess an individual s the participants themselves when they were asked to personality five well known behavioral economic retake the surveys and experiments two weeks later games the dictator game first and second player trust this result is to percentage points higher than the accuracy of traditional demographic based and persona based agents that use the same llms but do not have access to the interviews the generative agents also outperformed the generative agents proved demographic and persona based agents on the big five personality test achieving a normalized remarkably effective in correlation of when replicating real individuals simulating individuals openness conscientiousness extraversion agreeableness and neuroticism but they performed real world personalities similarly as demographic and persona based agents for the economic games with a normalized correlation of i e as high as the participants own correlation with themselves two weeks later across an policy brief simulating human behavior with ai agents while gender based demographic parity difference remained fairly consistent across tasks likely due to the interview based generative already low levels of discrepancy agents consistently reduced biases across tasks compared to demographic based agents policy discussion aggregate of the dictator game the first and second generative agents could become useful tools for player trust games the public goods game and the estimating attitudes and survey based experimental prisoner s dilemma treatment effects for example if you were considering the sorts of survey questions you might ask in a beyond those tests we evaluated the generative national survey generative agents could help to agents behavior in a set of social science experiments estimate average responses the population might give these included investigations of how perceived intent however many open questions remain how accurate affects blame assignment and how fairness influences are generative agents when simulating behavior in emotional responses real world participants and the addition to attitudes what innovations are needed for generative agents agreed on the replication results of generative agent simulations to accurately estimate the all five studies we tested impacts of policy changes while we will continue to build the empirical and technical research to expand the generative agents also lessened bias in the horizon of generative agents we urge policymakers predictive accuracy across social groups given to critically examine analyses that overclaim what rightful concerns about ai systems disadvantaging or generative agents can actually achieve today misrepresenting underrepresented populations we conducted a subgroup analysis focused on political one important risk for policymakers practitioners ideology race and gender these are dimensions researchers and others using generative agents of particular interest in the literature we used the is overreliance on generative agents when simulation demographic parity difference which measures accuracy is low to ensure that policymakers the performance difference between the best  and don t rely on an inaccurate simulation we must develop worst performing groups to quantify bias notably tools and methodologies so they know when they we found that the interview based generative agents can and can t trust these simulations additionally consistently reduced biases across tasks compared to policymakers should not apply generative agents beyond demographic based agents drops in political ideology the range of applications that have been validated bias and racial bias vary depending on the survey a second major risk relates to privacy the interview policy brief simulating human behavior with ai agents data used to build the generative agents is often sensitive and data leaks could cause considerable one important risk for harm to interviewees other concerns include the co option of individuals likenesses as these agents policymakers practitioners can believably replicate a person s answers in a survey researchers and others using response or experiment significant reputational harm could also result from someone manipulating agent generative agents is overreliance responses to falsely attribute defamatory statements on generative agents when to individuals whose data is used in the agent bank simulation accuracy is low a range of other ethical and legal questions must also be considered for example what are the ethical implications of using ai agents that simulate policymakers and researchers should work together a deceased person how should human consent be to ensure that appropriate monitoring and consent managed and what are the risks of agents being mechanisms are used to enhance trust protect misused for fraudulent purposes given the inherent individual rights and mitigate the risks of generative uncertainty of future advancements in generative ai agent use for example our team proposed the such as ai models future reasoning abilities managing possibility of an audit log for the use of every agent in these risks early on is crucial policymakers should our agent bank that way individuals who participated consider establishing bright line rules that determine in a survey and had their preferences captured by a how ai agents may or may not be used for human generative agent could see what the agent is doing simulation purposes and exert control over it over time permission could be we made the decision not to release our generative granted one day and withdrawn a month later reflecting agents for public use instead to support further individual consent translating such protections into research while protecting participant privacy we policy such as making them part of grant terms and have chosen to provide controlled research only conditions would help researchers to detect and api access to our agent bank we grant open mitigate malicious use of generative agents built using access to aggregated responses on fixed tasks for people s personal data shared via in depth interviews general research use and restrict access to individual responses on open tasks for researchers following a looking forward generative agents hold serious review process ensuring the agents are accessible promise for enhancing human behavioral research and while minimizing risks associated with the source developing new insights into personal preferences and interviews other researchers building similar systems decision making however mitigating the risks of these should replicate our safeguards and policymakers innovations through research and policy controls on weighing how generative agents could be used in agent access and auditing will be crucial to harnessing research settings should explore requirements for their opportunities in economics political science individual data rights access and deletion and beyond reference the original article is joon sung park is a meredith ringel morris accessible at joon sung park carolyn phd student in computer is director and principal science in the human  scientist for human ai q zou et al generative agent computer interaction interaction at google simulations of people arxiv org and natural language deepmind november processing groups at abs stanford university carolyn q zou is robb willer is a professor a phd student in of sociology and by stanford university s institute for human  computer science at courtesy psychology centered artificial intelligence hai stanford university and business at stanford applies rigorous analysis and research university to pressing policy questions on artificial intelligence a pillar of hai is to inform aaron shaw is an percy liang is an associate associate professor professor of computer policymakers industry leaders and civil in the department of science at stanford society by disseminating scholarship to communication studies at university and a senior a wide audience hai is a nonpartisan northwestern university fellow at stanford hai research institute representing a range of voices the views expressed in this policy benjamin mako hill michael s bernstein is an brief reflect the views of the authors is an associate professor associate professor of for further information please contact in the department of computer science at stanford communication at the university and a senior fellow university of washington at stanford hai carrie j cai is a senior staff research scientist at google deepmind and manager area lead of human ai interaction in google s people ai research group stanford hai jane stanford way stanford ca   t f e hai stanford edu