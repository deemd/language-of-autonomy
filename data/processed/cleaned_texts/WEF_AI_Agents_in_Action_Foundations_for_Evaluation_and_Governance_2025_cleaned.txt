in collaboration with capgemini ai agents in action foundations for evaluation and governance w h i t e p a p e r n o v e m b e r images adobe stock contents foreword executive summary introduction evolving technical foundations of ai agents the software architecture of an ai agent communication protocols and interoperability cybersecurity considerations foundations for ai agent evaluation and governance classification evaluation risk assessment g overnance considerations for ai agents a progressive approach looking ahead multi agent ecosystems conclusion contributors endnotes disclaimer this document is published by the world economic forum as a contribution to a project insight area or interaction the findings interpretations and conclusions expressed herein are a result of a collaborative process facilitated and endorsed by the world economic forum but whose results do not necessarily represent the views of the world economic forum nor the entirety of its members partners or other stakeholders world economic forum all rights reserved no part of this publication may be reproduced or transmitted in any form or by any means including photocopying and recording or by any information storage and retrieval system ai agents in action foundations for evaluation and governance november ai agents in action foundations for evaluation and governance foreword cathy li roshan gya head centre for ai chief executive officer excellence member of capgemini invent the executive committee world economic forum in recent years organizations have moved beyond through the ai governance alliance the world predictive models and chat interfaces to experiment economic forum and capgemini are advancing with artificial intelligence ai in more transformative this subject in collaboration with the ai community ways ai agents are now emerging as integrated signalling that now is the time to prepare for an collaborators in business public services and agentic future if adopters start small iterate everyday life the adoption of ai agents could carefully and apply proportionate safeguards bring significant gains in efficiency altered kinds of agents can be deployed in ways that amplify human machine interaction and the advent of novel human capabilities unlock productivity and digital ecosystems establish a foundation for more complex multi agent ecosystems to emerge over time unless a careful this transition faces multiple obstacles that need to be and deliberate approach to adoption is adopted addressed moving from models to agents represents untested use cases could outpace oversight and more than a technical milestone and requires lead to misaligned incentives emergent risks and organizations to rethink how they design evaluate and loss of public trust govern advanced agentic systems many companies are now questioning what agents can accomplish as with any transformative technology the alongside the practical steps needed to adopt and opportunities presented by ai agents must be deploy them safely responsibly and effectively accompanied by a responsibility to guide their development and deployment with care through this paper was developed to help answer those cross functional efforts and collaborative questions by mapping the evolving foundations governance ai agents can be integrated in ways of agentic systems classifying their roles that amplify human ingenuity promote innovation identifying new ways to evaluate them and outlining and improve overall quality of life this paper is a progressive governance approaches the paper step in that direction offering guidance to help early offers practical guidance for leaders navigating adopters navigate the complex and often uneven adoption in real world contexts path of ai agent adoption ai agents in action foundations for evaluation and governance executive summary this paper explores the emergence of ai agents outlining their technical foundations classification evaluation and governance to support safe and effective adoption this report has been tailored mainly for adopters classification that differentiates agents by their role of ai agents including decision makers technical autonomy authority predictability and operational leaders and practitioners seeking to integrate ai context thirdly it suggests a progressive governance agents into organizational workflows and services approach that directly connects evaluation and safeguards to an agent s task scope and while ai agents are gaining traction there remains deployment environment limited guidance on how to design test and oversee them responsibly this paper aims to help together these elements guide adopters with a fill that gap by providing a structured foundation for conceptual blueprint for moving from experimentation the safe and effective deployment of these systems to deployment the report highlights the importance of aligning adoption with evaluation and governance the paper makes three key contributions firstly practices to ensure that ai agents are successfully it covers the technical foundations of ai agents deployed while trust safety and accountability including their architectures protocols and security are maintained considerations secondly it offers a functional ai agents in action foundations for evaluation and governance introduction ai agents are shifting from prototypes to deployment bringing both transformative opportunities and novel governance challenges ai agents are gradually becoming embedded in today is the rise of data driven models particularly an increasing number of tasks workflows and generative artificial intelligence ai and large language use cases that span cloud and edge computing models llms which are enabling the emergence leading the way to more widespread adoption of a new generation of llm based agents these as the transition from prototyping to deployment systems can generate plans simulate reasoning accelerates current adoption remains concentrated and adapt their behaviour through feedback among early adopters according to a recent global mechanisms in ways that were previously not survey of executives of organizations plan to possible this evolution has sparked a new integrate agents within the next one to three years wave of experimentation with researchers and indicating that most efforts are still in the planning or companies rapidly creating prototypes of agents pilot phase while moving towards wider adoption in various fields this report focuses mainly on llm based agents ai agents is sometimes the concept of software agents has been studied used in short whose growing capabilities create for decades in fields such as robotics autonomous both significant opportunities for adoption and a systems and distributed computing what is different new set of challenges in governance and safety figure foundations for the responsible adoption of ai agents technical foundations lay the groundwork functional evaluation and classification governance define the scale with agent s role confidence ai agents in action foundations for evaluation and governance llm based ai agents for example introduce new pillars across classification evaluation risk assessment risks such as goal misalignment behavioural drift and governance which together form the foundation tool misuse and emergent coordination failures for a progressive approach to adoption and that traditional software governance models are deployment figure presents the general content unable to manage unlike conventional software of this report which helps guide the responsible agents are increasingly assuming roles that adoption and deployment of ai agents resemble those of human decision makers rather than static tools this means that governance the goal is to equip adopters providers technical models designed solely for access control and leaders organizational decision makers and other system reliability are no longer sufficient a more stakeholders with a shared understanding of the useful comparison is the governance applied current state of agentic systems and emerging to human users who must earn permissions oversight practices building on established accountability and trust by demonstrating performance ai governance principles and frameworks over time similarly trust in ai agents can be such as those developed by the organisation established by testing their behaviour against for economic co operation and development validated cases running them in human in the  oecd national institute of standards and loop configurations and gradually expanding technology nist international organization for autonomy only once reliability has been sufficiently standardization iso international electrotechnical demonstrated in both cases the principle of least commission iec and others this paper privilege remains essential with access limited to introduces additional principles addressing information and actions necessary for the task autonomy authority operational context and systemic risk that extend existing governance this report aims to provide a forward looking analysis guidance from an agent focused lens the of the evolving landscape of ai agents focusing insights have been informed by working group on the capabilities infrastructure classification and meetings workshops and extensive interviews with safeguards necessary for responsible deployment members of the safe systems and technologies to this end it is structured around four foundational working group of the ai governance alliance ai agents in action foundations for evaluation and governance evolving technical foundations of ai agents the architecture protocols and security models of ai agents dictate how they integrate into organizations and interact with the world while the core architecture of ai agents is beginning with the same level of rigour as onboarding a new to take shape practices for agent deployment employee including clearly defined roles safeguards integration and governance remain nascent as and structured oversight mechanisms this section organizations begin to hire ai agents to support or outlines the technical foundations that enable agentic augment human teams or perform tasks that impact systems and the architecture decisions that shape the physical world adoption should be treated how they are built deployed and governed t he software architecture of an ai agent building agents the adoption of llm based agents by industry between models tools data sources and humans requires not just marks a broader shift in software development from this layered setup introduces new complexity engineering but rigid rules based systems to more flexible intent  in how agents behave generalize and interact also orchestration driven interactions for instance in call centres with their environment reinforcing the need for and coordination early chatbots that followed scripted decision trees structured scaffolding are now giving way to agentic systems capable between models of understanding intent managing context and today ai agent architectures are organized into tools data sources escalating decisions more dynamically this evolution three interconnected layers consisting and humans towards agentic ai represents a fundamental change of application orchestration and reasoning in control and autonomy where tasks traditionally which collectively enable intelligent context  performed by humans are delegated to machines aware and business aligned automation at a high level agent architectures are designed to interface to enable this shift ai agents draw on four with users and systems coordinate complex tasks technological paradigms using external tools and application programming interfaces apis and support decision making classical software deterministic logic and rule  through a combination of language models based execution reasoning modules and control logic together these layers provide the technical foundation that neural networks pattern recognition and underpins how agents operate statistical learning the application layer along with protocols such foundation models general purpose adaptive as model context protocol mcp and agent to  systems that interpret instructions and act agent protocol a a integrates the agent into contextually specific processes or user workflows it receives input through user interfaces or apis and translates it into autonomous control mechanisms that enable structured signals application logic applies domain  systems to plan coordinate and act with minimal specific rules and constraints to ensure the agent s human oversight output i e forecast decisions actions messages etc is aligned with user expectations and business as a result building agents requires not just requirements this layer can run in the cloud or on  engineering but also orchestration and coordination prem in edge computing equipment ai agents in action foundations for evaluation and governance understanding the orchestration layer framework layer operate beyond traditional network boundaries this architecture is governs how the agent interprets inputs invokes introducing novel cybersecurity concerns key to anticipating tools and coordinates tasks while some llm how agents will providers  have integrated tools directly into their the reasoning layer underpins the agent s ability solutions this can create rigid and vendor locked to generate predict classify or apply rules in engage with users systems agentic frameworks overcome this pursuit of its goals depending on the task the and systems by standardizing tools and systems integration reasoning layer can draw on a range of models coordinate remaining llm agnostic and spanning multiple including deterministic rule based approaches workflows and workloads across cloud and edge this enables ai and classical machine learning as well as small make context  agents to employ a range of reasoning strategies or large language models and other generative aware decisions and support features such as code execution or architectures the choice of model shapes how search and use protocols like mcp to connect the agent processes information adapts to context with enterprise resources including databases and ultimately carries out its assigned role and customer relationship management crm systems most agents also include specialized figure illustrates this layered architecture showing sub agents that handle distinct tasks which makes how internal components across application them functionally part of a multi agent system orchestration and reasoning work together to the orchestration layer is critical in this regard as support dynamic agent behaviour while maintaining it coordinates sub agents assigns responsibilities secure boundaries across organizational systems and manages dependencies between them it also enables model switching allowing organizations to in combination these layers constitute the assign different models to various tasks based on technical backbone that governs agent their complexity cost or performance importantly functionality for organizations implementing ai agents have a unique architecture that can ai agents understanding this architecture is be extended beyond the organization s security key to anticipating how agents will engage perimeter their ability to invoke external tools and with users and systems coordinate workflows communicate with other agents enables them to and make context aware decisions figure software architecture of an ai agent internal organization resources third party resources environment event user al agent boundary it applications percepts actions al agent crm messaging input output application ui api code database agentic framework mcp al agent orchestration planning memory tools workflow a a application orchestration models reasoning generative non generative mechanistic reasoning ai agents in action foundations for evaluation and governance communication protocols and interoperability mcp has gained the landscape of advanced llm based agents external data sources apis and enterprise widespread support is supported by new protocols that enable more systems through a standardized protocol across leading seamless integration and collaboration the mcp rather than developing bespoke integrations agent frameworks for example aims to standardize the connection for each agent task pairing mcp allows agents between enterprise software systems external to act as clients that request access to services and is increasingly data sources and agents while protocols such via mcp compliant servers for example an viewed as a core as a a and the agntcy architecture s agent agent using mcp can check a calendar retrieve mechanism connect protocol acp offer tools to facilitate emails update database content or update interaction between varying ai agents forming the crm records through a shared interface interoperability layer for multi agent systems mas this significantly reduces friction speeds up as these protocols are implemented across cloud deployment and supports modular plug and play platforms enterprise networks and edge devices capabilities across tools and environments they are necessary for running agentic code while connecting with real world sensor data and systems mcp has gained widespread support across leading agent frameworks and is increasingly introduced by anthropic in late mcp  viewed as a core mechanism for connecting enables agents to connect with internal or agents to the broader enterprise infrastructure figure illustration of mcp based agent communication overview of mcp ai agent ai agent mcp mcp mcp client client client messaging database database user updates a record send an email read a record mcp mcp server server messaging database acknowledge update mcp server updates the database database update confirmed messaging database ai agents in action foundations for evaluation and governance where mcp focuses on communication between released by google in april a a operates agents and external or internal systems protocols through a common communication interface and like a a enable agents to discover each other introduces the concept of agent cards similar to interact collaborate and delegate tasks whether model cards  which are structured descriptions operating within an organization s security perimeter of an agent s identity along with its capabilities or outside it these protocols address a growing and skills this allows for automatic discovery need in complex environments where multiple and coordination between agents and systems agents work together across organizational or technical boundaries enabling agents from different vendors to communicate effectively figure illustration of agent to agent communication protocol ai agent ai agent a a protocol agents agents agents card llm llm agent framework agent framework task manager mcp a a artefact handler apis and enterprise apis and enterprise applications applications beyond communication and discovery new between agents strategy privacy and security standards are also emerging that address how considerations often shape how and whether agents transact and exchange value released systems should be integrated and are important by google in september the agent for enterprises to carefully consider payments protocol ap  enables secure auditable transactions under user defined for example communication between different agents limits unlike mcp and a a which focus on could raise concerns about access control data data exchange and task coordination ap  confidentiality or compliance across jurisdictions addresses complex financial operations choosing whether to expose a capability to other agents becomes a governance decision as much despite this progress interoperability remains as a technical choice a key challenge technical compatibility alone does not guarantee successful coordination ai agents in action foundations for evaluation and governance cybersecurity considerations security as ai agents move into enterprise and consumer  while protocols such as mcp and a a can strategies have facing environments they extend rather than streamline integration they also expand the attack evolved from replace existing security challenges security surface   by introducing new external dependencies perimeter defences strategies have evolved from perimeter defences and interfaces as illustrated in figure the very to layered defence in depth and more recently interoperability that enhances agent capabilities to layered defence to the zero trust model these changes reflect also exposes enterprises to unpredictable inputs in depth and more broader transformations such as cloud adoption and vulnerabilities from third parties for adopters recently to the distributed workforces and interconnected this means that every agent interaction should be zero trust model ecosystems all of which have already weakened treated as untrusted by default and that verifying the notion of a clear boundary between internal identity permissions and context is necessary and external networks agents build on this before granting access trajectory but add additional layers of risk that must be managed proactively finally agents can be misused they might be exploited through design flaws or prompt injections by autonomously invoking tools and communicating or even intentionally deployed for malicious purposes across organizational lines e g via mcp and such as accessing private data or spreading a a agents embed external services databases misinformation unlike traditional attacks autonomous and peer agents into enterprise workflows this agents can act with speed and persistence making multiplication of identities and connections makes attribution and accountability harder organizations identity management micro segmentation and should prepare for this by implementing strong ongoing verification of agent activity essential audit trails inent response plans and clear accountability structures ai agents in action foundations for evaluation and governance foundations for ai agent evaluation and governance a structured foundation for evaluating and governing ai agents enables consistent assessment and oversight across contexts systematic as ai agents mature and adoption increases a performance identifying risks and establishing classification is functional understanding of their roles and properties governance mechanisms that scale with an important because is beginning to take shape rather than classifying agent s autonomy authority and function it provides a agents solely by modality e g text speech vision or domain e g customer service decision support to address classification evaluation risk assessment common basis for workflow orchestration it is more effective to and governance it is useful to distinguish between comparing agents evaluate them according to their intended purpose two main stakeholder perspectives anticipating risks core properties and operating context this approach and linking creates a clearer foundation for assessing impacts provider refers to organizations or individuals evaluation and and designing safeguards that are proportionate to that supply ai systems platforms or tools their governance an agent s role systematic classification is important responsibilities include ensuring that products because it provides a common basis for comparing are developed and maintained in accordance agents anticipating risks and linking evaluation with responsible and ethical guidelines and and governance decisions to the realities of how that the necessary documentation and support an agent operates without it oversight risks may are provided become inconsistent reactive or disconnected from an agent s actual capabilities and environment adopter refers to individuals within an organization who use ai systems encompassing to establish this foundation this report responsibilities such as procurement and introduces four foundational pillars which deployment procurement involves the in combination provide a structured responsibility of acquiring ai solutions for approach to assessment and adoption organizational use by conducting due diligence and ensuring that all ai agent solutions comply classification establish the agent s with organizational policies and regulatory characteristics and operational context requirements deployment is the responsibility to inform downstream assessment for implementing ai systems in accordance with documented requirements and plans while evaluation generate evidence of performance ensuring that risks and impacts of the ai agent and limitations in representative settings are properly assessed and managed risk assessment analyse potential harm the adopter depends on the provider for using classification and evaluation as inputs transparent documentation model and system specifications and sufficient performance and risk governance translate classification information to support responsible deployment and evaluation and risk assessment results oversight throughout the system life cycle into safeguards and accountability proportionate to the agent s profile the four pillars form a continuous and parallel progression in which classification provides these foundations apply to diverse ai agents structure evaluation establishes evidence risk encompassing both virtual and embodied assessment identifies and mitigates potential systems in different operational contexts harms and governance translates those insights they provide a consistent basis for assessing into safeguards and accountability ai agents in action foundations for evaluation and governance figure foundations for ai agent evaluation and governance classification dimensions evalution criteria risk assessment life cycle progressive governance practices c lassification classification defines an agent s characteristics role reflects the breadth of tasks an agent and operating context to guide evaluation risk can perform specialized agents are narrowly assessment and governance focused and optimized for specific domains while generalized agents can adapt across domains to to support evaluation and risk assessment agents address a broader range of tasks or challenges can be described across a set of dimensions that for instance a tax filing agent designed only capture both their internal characteristics and the to prepare returns is specialized whereas a external contexts in which they operate these personal digital assistant that manages scheduling dimensions provide a structured approach to email drafting and online search operates as a analyse and compare agents across applications generalist agent ensuring clarity about their design choices and real  world effects predictability describes the stability and repeatability of agent behaviour deterministic in combination the proposed dimensions define agents produce consistent identical outputs how an agent operates what actions it is permitted when given the same inputs which makes their to take and the complexity of the context it is performance highly predictable and easier to deployed in the agent s overall impact can be seen validate non deterministic agents by contrast as a profile that emerges from the interaction of may evolve learn or generate variable outputs these dimensions reflecting the benefits or risks of over time this variability can support creativity its application in practice adaptation and exploration but it reduces the reliability of producing identical results under function refers to the specific role purpose or identical conditions for adopters predictability set of tasks the agent is designed to perform determines how much confidence they can place it describes what the agent does in practice in an agent s outputs how reproducible those independent of the environment it is deployed outputs are and what level of oversight is required in for example a coding co pilot that generates to manage variability in practice software snippets and a triage assistant that prioritizes patients in an emergency department autonomy captures the degree to which an agent have distinct functions even though both operate in can define and pursue objectives the spectrum digital workflows ranges from simple command response systems to ai agents in action foundations for evaluation and governance establishing agents capable of planning and executing actions autonomy and authority can be combined in levels of independently across authorized environments different ways depending on an agent s purpose autonomy can help autonomy in this context refers to an agent s capacity and design they are not inherent system properties organizations set to dee when and how to act toward a goal but design choices that can be made based on the adapting to changing conditions without human agents intended functions risk considerations and clear expectations guidance automation on the other hand refers to oversight requirements they can also be calibrated for functionality systems that execute predefined functions reliably during assessment or adjusted in real time and implement under specified conditions without human intervention proportionate the key distinction is that autonomy entails decision  operational context refers to the use case and governance making flexibility i e choosing what to do whereas environment in which the agent operates the mechanisms automation emphasizes execution reliability i e doing environment is especially critical as it determines what the system is programmed to do observability predictability of outcomes interaction with other agents and how conditions evolve in the automotive sector sae international s over time taxonomy and definitions for terms related to driving automation systems for on road motor use case defines the domain and environment vehicles   framework defines driving automation where the agent performs its distinct function from level no automation to level full for stakeholders for example an autonomous automation a similar spectrum can be applied cleaning agent in the residential sector performs to ai agents this spectrum can be conceived household vacuuming and floor cleaning as part of as moving from no autonomy for example a of routine home maintenance simple chatbot that only answers user queries to full autonomy for example a customer service environment represents the operating conditions agent that automates interactions resolves queries the agent functions under ranging from simple and personalizes responses using a company s and predictable settings to complex uncertain knowledge base establishing levels of autonomy and dynamic contexts a complex environment can help organizations set clear expectations is one where the agent navigates and acts under for functionality and implement proportionate uncertainty with incomplete or noisy information governance mechanisms unpredictable outcomes changing conditions over time continuous ranges of possible actions or states authority defines the actions an agent is permitted and interactions with other agents whose behaviour to take it sets the boundaries of system access also affects results by contrast a simple environment such as permissions to use tools interact with is one where the agent operates with complete databases or execute transactions like autonomy information predictable and static outcomes authority exists on a sliding scale from read only independent episodes a finite set of states or access to full administrative control actions and no need to consider other actors figure classification dimensions agent characteristics operational context function use case what does the agent do application domain and environment where the agent performs its function role environment specialist generalist simple complex predictability deterministic non deterministic autonomy low high authority low high ai agents in action foundations for evaluation and governance an example of an operational context could mitigated by adjusting agent parameters like be a fraud detection agent in online banking autonomy and authority and or by constraining the agent accesses transaction data and user the context in which the agent operates examples history but cannot fully observe external factors include limiting a robot to a controlled zone or like user intentions or hidden fraud tactics it confining a software agent to a sandbox functions stochastically with outcomes influenced by unpredictable variables such as varying an ai agent s role autonomy authority predictability fraud methods or user behaviours rather than and operational context collectively shape its for organizations guaranteed results the setup is sequential overall impact defined as the degree of benefit refining risk assessments with each detection or harm it may generate highly autonomous adopting ai operating in a fast changing environment authorized and non deterministic behaviour in a understanding it requires continuous monitoring by human complex operational context may deliver strong and clearly defining reviewers and other security systems performance but also carry greater risks the operational context is for organizations adopting ai understanding the following example illustrates how these essential to ensure and clearly defining the operational context dimensions can be applied in practice through effectiveness in is essential to ensure effectiveness in actual the classification of a basic ai agent a robot actual deployment deployment settings potential issues can be vacuum cleaner ai agents in action foundations for evaluation and governance case study robot vacuum cleaner classification robot vacuum cleaner agent characteristics operational context function use case autonomous indoor navigation and cleaning floors a home vacuum robot operates in the household services domain autonomously navigating a residential environment to clean floors for occupants role specialist generalist environment predictability simple complex deterministic non deterministic autonomy low high authority low high robot vacuum cleaner classification autonomy medium it operates independently within mapped areas of the home s floorplan function the primary function is autonomous indoor authority low it is limited to sensing movement navigation and cleaning interpreting spatial layouts avoiding and vacuuming obstacles and adapting to changing floor conditions while it operates autonomously within mapped areas and operational context schedules it does not make decisions that affect other systems or safety critical outcomes use case home vacuuming role specialist it only does one specific job vacuuming the floors environment moderate the environment is primarily household environments with occasional dynamic obstacles predictability deterministic it follows specific instructions and task planning but may follow unspecified routes ai agents in action foundations for evaluation and governance as agents become more embedded in tools guide governance and oversight align platforms and workflows the proposed dimensions safeguards controls and monitoring can help organizations define specific agent roles mechanisms with the nature and complexity of and levels of integration while evaluating benefits the agent s role and limitations in context and implement oversight mechanisms that match their capabilities taking support interoperability and scaling these dimensions into consideration can help structure agent types in ways that facilitate providers and adopters to coordination in multi agent environments and integration across systems clarify functional scope define what an agent is designed to do under what conditions and without clear classification organizations may where its responsibilities begin and end adopt ai agents without fully understanding what they are designed to do how they operate the support assessment evaluate the technical impact they may have on their environment or organizational safety and security implications the oversight mechanisms they require this lack of deploying specific agents in their contexts of clarity could result in gaps in safety security control privacy reliability and accountability figure foundations for ai agent evaluation and governance classification dimensions progressive governance practices access traceability legal long term testing control identity compliance management validation trustworthiness monitoring manual human and more explainability logging redundancy oversight define classification evaluation risk assessment the use dimensions criteria life cycle tool call function predictability capabilities define context evaluate risks success task success edge case role use case identify risks manage risks rate robustness task completion autonomy environment trust indicators analyse risks time authority error types and more ai agents in action foundations for evaluation and governance e valuation robust evaluation is crucial for assessing providing real world measures of reasoning agent performance and limitations across code modification and system integration   diverse contexts hcast compares agent performance to as organizations begin deploying agents with human developers in areas such as programming different functional roles the need for structured tasks offering calibrated insights into agent evaluation becomes more important this section coding capabilities for example   explores how evaluation methodologies are evolving to reflect this growing complexity although these emerging benchmarks offer valuable signals they are typically built for academic or agent evaluation refers to the measurement of an research settings where tasks are predefined ai agent s performance and operation in representative environments are static and outcomes are often contexts generating evidence about how well it deterministic they rarely capture operational achieves intended functions under what conditions realities such as ambiguous success criteria or and with what limitations this means that robust dynamic workflows evaluation frameworks are essential for building trust in ai agents performance by providing clear evaluation requires clear performance metrics that multidimensional assessments of agent capabilities capture both task level and system level outcomes and limitations evaluations can help organizations examples include task success rate completion develop appropriate expectations and confidence time error types tool call success throughput in agentic systems robustness against edge cases and user trust indicators these metrics help establish whether while the evaluation of foundation models such the system delivers its functions reliably and provide as llms is supported by a rich landscape of the operational evidence that later informs risk standardized benchmarks agent evaluation assessment and governance decisions remains nascent unlike static model testing agents operate as orchestrated systems that combine tool providers benchmark systems to assess technical use memory decision making and user interaction maturity while procurers and deployers are which exceed the scope of traditional benchmarks responsible for ensuring that agents operate in response several agent specific capability safely and compliantly within specific industry benchmarks have begun to emerge organizational and operational contexts therefore deployment environments provide the most agentbench tests agents in interactive accurate ground truth but deployers often lack the environments like web browsing and games resources to design comprehensive benchmarks in and is useful for evaluating real time decision  many cases this makes collaboration with providers making and adaptability   essential to establishing meaningful metrics swe bench evaluates an agent s ability to an effective provider focused evaluation should begin resolve github issues in open source repositories with a technical screening of baseline capabilities ai agents in action foundations for evaluation and governance an effective such as reasoning planning and tool use once emerging evaluation tools are increasingly applied provider focused validated in sandbox environments that mirror in enterprise settings to support the continuous evaluation should real world tasks agents may progress to controlled assessment of agentic systems helping to track begin with a deployment where they are integrated into workflows reasoning compare outcomes to expectations technical screening under close monitoring with safeguards in place to and detect anomalies that are overlooked by confirm that they align with human or established traditional testing major cloud providers have also of baseline decisions full deployment should only follow once started embedding such frameworks into their ai capabilities such as reliability has been demonstrated with fallback platforms highlighting the importance of deployer  reasoning planning mechanisms and defined human oversight audit side evaluation for adoption and tool use logs are central throughout this life cycle providing structured records of agent activity and the rationale by approaching evaluation as a structured context  behind it audit logs also support governance aware and continuous process organizations can by enabling oversight and accountability aiding more effectively determine whether an agent is fit debugging by tracing errors and points of failure for deployment and helping inform evaluation to illustrate how these principles apply in practice the following principles support this life cycle of the following illustration examines a coding co pilot agent evaluation agent the illustration applies the evaluation dimensions from a deployer s perspective showing contextualization reflect the tools how task level and system level metrics can be workflows and edge cases the agent will used to assess reliability safety and overall encounter in practice performance in an operational setting multidimensional assessment define success effective evaluation depends on close collaboration across various factors including accuracy between providers and adopters where transparent robustness latency tolerance compliance documentation model specifications and performance and user trust reports from providers enable deployers to validate reliability identify risks and apply safeguards temporal and behavioural monitoring track throughout the system life cycle performance over time to detect regressions shifts in behaviour or failures to adapt to the results form an integrated performance evolving inputs profile that informs subsequent risk assessment and governance figure foundations for ai agent evaluation and governance evaluation criteria progressive governance practices access traceability legal long term testing control identity compliance management validation trustworthiness monitoring manual human and more explainability logging redundancy oversight define classification evaluation risk assessment the use dimensions criteria life cycle tool call function predictability capabilities define context evaluate risks success task success edge case role use case identify risks manage risks rate robustness task completion autonomy environment trust indicators analyse risks time authority error types and more ai agents in action foundations for evaluation and governance case study coding co pilot evaluation coding co pilot agent characteristics operational context function use case assists human developers with code generation and debugging a coding co pilot operates in the software development domain assisting programmers within their coding environment by generating completing and debugging role code to improve productivity and reduce errors specialist generalist environment predictability simple complex deterministic non deterministic autonomy low high authority low high coding co pilot evaluation robustness exposing the agent to ambiguous or conflicting code to assess recovery error handling and adaptability evaluation starts with controlled tests in development environments to verify productivity gains while ensuring human trust gathering user feedback on reliability safety reliability and compliance evaluation follows several and usefulness key steps including monitoring using continuous logging to detect performance contextualization testing across coding tasks such as drift anomalous tool use or regressions after deployment code generation debugging and documentation to reflect real workflows performance measuring task success rate completion time and error frequency along with system metrics like tool call success ai agents in action foundations for evaluation and governance r isk assessment risk assessment identifies and analyses risk assessment draws on an agent s defined potential harms linking evaluation results classification dimensions to identify and analyse to oversight potential risks considering factors such as cybersecurity threats safety hazards operational evaluation establishes how the system performs vulnerabilities legal and regulatory requirements whereas risk assessment determines whether the and stakeholder impacts it also incorporates agent and its use present risks that need to be evidence from evaluation activities such as understood assessed and mitigated evaluation sandbox testing and pilot deployments including provides evidence as to whether the set mitigations task success rates error patterns and robustness are effective and met in implementation to make this process operational organizations can the goal of risk   assessment is to identify analyse follow a five step life cycle that can be scaled to the and prioritize the ways an agent could fail or be complexity of the use case misused estimate likelihood and severity and determine whether it can operate within acceptable the life cycle outlined in figure links the boundaries with appropriate controls this applies outputs of classification and evaluation directly to single agents and multi agent systems software  to risk management and progressive governance based and embodied deployments and covers practices the following table provides an both technical and organizational vulnerabilities example of how the risk assessment process can be structured in practice figure foundations for ai agent evaluation and governance risk assessment life cycle progressive governance practices access traceability legal long term testing control identity compliance management validation trustworthiness monitoring manual human and more explainability logging redundancy oversight define classification evaluation risk assessment the use dimensions criteria life cycle tool call function predictability capabilities define context evaluate risks success task success edge case role use case identify risks manage risks rate robustness task completion autonomy environment trust indicators analyse risks time authority error types and more ai agents in action foundations for evaluation and governance table risk assessment life cycle for ai agents step objective example activities example outputs define context establish the scope of the determine internal and external context context definition assessment system boundaries strategic goals legal framework risk management plan objectives and criteria for stakeholders managing risk risk evaluation criteria define boundaries intended use assumptions establish risk criteria likelihood impact scales acceptance threshold identify risks identify potential technical brainstorm workshops risk identification risk register listing risks organizational and ecosystem e g hazard identification threat causes impacts risks harms and affected parties identification etc identification of sources of risk causes failure mode analysis analyse risks understand the nature likelihood assess probability and impact risk analysis scores and consequence of each risk considering for example characteristics showing likelihood impact and quantify them like autonomy and authority ratings and rationale predictability and operational context identify existing controls or guardrails apply qualitative or quantitative methods for risk estimation use evaluation results to inform likelihood and impact evaluate risks compare analysis results with rank and prioritize risks risk ranking summary risk criteria to determine priority use evaluation results for quantifying risk acceptance and tolerability and prioritizing risks evaluations use performance metrics and test confidence to inform risk thresholds manage risks implement risk response actions assign owners of preventive detective control actions avoid mitigate transfer accept and response controls implementation plan and monitor risks evidence these controls through residual risk profile evaluation results risk assessment report address emerging risks as systems evolve or context changes evidence logs integrate feedback loops for monitoring reports continuing monitoring revised frameworks coordinate inent response and impact mitigation improved processes update governance and controls based on lessons learned defining clear risk criteria and tolerability thresholds reliability robustness and observed error rates and applying them consistently to prioritize and this relationship establishes a clear connection evaluate risks remains a central challenge in ai between how an agent is designed how it performs risk management and how risks are managed providing the basis for proportionate governance and oversight the identification analysis and evaluation of risks are directly linked to the classification dimensions applying this approach in practice helps introduced earlier allowing organizations to demonstrate how structured risk assessment understand how factors such as autonomy authority translates classification and evaluation evidence predictability and environmental complexity shape into measurable controls the following example overall risk levels for ai agents inherent risk illustrates the risk assessment process in the combines likelihood and impact while residual risk context of an autonomous vehicle reflects the effectiveness of applied mitigations informed by evaluation evidence such as system ai agents in action foundations for evaluation and governance case study autonomous vehicle risk assessment autonomous vehicle agent characteristics operational context function use case performs the complete driving task without human control an autonomous vehicle operates in the transportation domain navigating public or private road environments to transport passengers or goods safely and efficiently role without direct human control specialist generalist environment predictability simple complex deterministic non deterministic autonomy low high authority low high autonomous vehicle risk assessment quantitative scoring combines these factors and is weighted according to the vehicle s autonomy and authority levels risk assessment focuses on identifying and mitigating possible mitigation measures may include redundancy and diversity failures across perception decision making and control systems in critical sensors reduction of autonomy or authority key risk areas include sensor malfunction data drift adversarial thresholds anomaly detection mechanisms and real time interference and coordination failures with other vehicles or inent reporting residual risk is evaluated after these infrastructure that could lead for example to loss of steering safeguards are applied drawing on evidence from controlled or braking control and eventual collisions testing field trials and continuous monitoring the results each risk is analysed for its likelihood for example the frequency determine whether the system can safely progress to wider of sensor failure leading to braking failure and its impact for deployment or requires additional control layers example the severity of injury fatality or legal consequence ai agents in action foundations for evaluation and governance risk assessment should be treated as a continuous a control plan with clear ownership and verification iterative process rather than a single checkpoint and validation steps operating limits and monitoring ongoing monitoring regression testing periodic requirements and a deployment status these reassessment and inent reviews are essential to outputs feed directly into progressive governance maintaining alignment as agentic systems evolve the ensuring oversight scales in line with an agent s outputs of this process should include a risk register demonstrated risk profile and operating context g overnance considerations for ai agents a progressive approach governance progressive governance approaches scale across these levels governance mechanisms levels are informed oversight and safeguards in proportion to the advance in both scope and sophistication the by risk assessment autonomy authority and complexity of the agent focus shifts from operational safeguards to outcomes ensuring comprehensive risk management with early that controls scale evaluation and risk assessment provide critical levels emphasizing reactive measures while more insights into an agent s capabilities performance advanced levels incorporate proactive monitoring with demonstrated reliability security safety and alignment governance accountability frameworks and systemic autonomy authority however determines whether those insights translate risk assessments and contextual into effective oversight and responsible adoption complexity governance refers to the structured application of this progression is evident across key areas such technical safeguards and operational ethical and as monitoring accountability risk management organizational processes intended to ensure agents transparency adaptability and scope monitoring remain within acceptable risk boundaries over time evolves from basic logging to real time ai  as agents become more capable and integrated into assisted oversight incorporating the automated core workflows governance must evolve from basic analysis of logs to detect anomalies and precautionary measures to dynamic multi layered deviations in system behaviour in parallel risk systems of control and accountability governance management advances from static checklists to levels are informed by risk assessment outcomes dynamic predictive modelling while the scope ensuring that controls scale with demonstrated of governance expands from narrow task  autonomy authority and contextual complexity specific oversight to consideration of broader ecosystem impacts a progressive set of governance levels can be distinguished ranging from baseline safeguards to operational environments are dynamic and enhanced controls and systemic risk management effective governance often requires recalibrating these levels correspond to the agent s classification autonomy and authority in real time the profile which is linked to its function predictability following example illustrates this through autonomy authority and operational context a personal assistant agent whose level of oversight therefore intensifies as agents move autonomy and authority is dynamically adjusted from narrow low risk applications to complex high  to ensure ongoing compliance impact environments ai agents in action foundations for evaluation and governance case study personal assistant governance considerations agent characteristics agent characteristics operational context function use case assists users by organizing schedules managing communication it operates in the personal productivity domain and coordinating managing tasks communications and information across a user s digital environment to support daily coordination role and decision making specialist generalist environment predictability simple complex deterministic non deterministic autonomy low high authority low high personal assistant governance key governance risks include data overreach privacy considerations violations prompt manipulation and unauthorized actions such as unintended communication governance focuses on scaling oversight in line with the mitigation measures include least privilege access consent  personal assistant s autonomy authority and environmental based data sharing input and output filtering audit logging complexity unlike narrow task agents a personal assistant and human approval for sensitive actions adaptive controls operates across multiple platforms such as email calendars should reduce permissions upon detecting anomalies or messaging and enterprise tools raising questions about the policy breaches supported by continuous monitoring and extent of information it can access interpret and act upon on inent reporting behalf of the user as integration deepens and authority expands e g from drafting messages to sending them or booking travel governance mechanisms must increase ai agents in action foundations for evaluation and governance the example illustrates that an agent s overall impact a human in the loop hitl configuration ensures emerges from the interaction of multiple dimensions that agents can suggest or prepare actions but final across function role predictability autonomy decisions remain subject to explicit human approval authority and context as these dimensions shift in more stable or clearly defined environments a so does the risk profile reinforcing the need for human on the loop hotl configuration allows governance frameworks that are both progressive agents to act within defined boundaries while and adaptive humans monitor behaviour receive alerts and retain the ability to intervene or override when necessary effective governance requires maintaining an integrating these oversight models into governance appropriate level of human oversight in relation to structures helps maintain accountability and the agent s autonomy authority and operational human judgment as agents operate with greater context in high risk or less predictable settings independence and scale table baseline governance mechanisms for ai agents governance area foundational mechanism purpose enforce least privilege access define prevent each agent from accessing unnecessary task boundaries data systems or tools reduce risk of misuse or acental harm access control conduct a data protection impact assessment ensure data handling and processing complies with dpia perform privacy and regulation compliance relevant laws and regulations checks such as general data protection regulation or the california consumer privacy act ccpa legal and compliance perform sandbox runs or controlled pilots with validate expected behaviour detect errors and prevent non production data install input output filters untested code from affecting live systems conduct perform third party audits audits code red teaming etc testing and validation implement logging for all agent actions set up maintain traceability for accountability enable anomaly alerts or dashboards early detection inent response and post  inent analysis monitoring and logging define and assign oversight models including ensure accountable human control for material hitl hotl require policy review before decisions keep behaviour aligned with organizational deployment and set supervisory triggers policies and provide escalation paths when the agent for exceptions acts unexpectedly human oversight assign unique agent identifiers tag outputs to the attribute actions and outcomes to specific agents responsible agent instance enable forensic review and performance tracking traceability and identity establish protocols for ongoing monitoring ensure continued alignment performance and updates and eventual decommissioning relevance throughout the agent s life cycle long term management implement explainability tools establish ensure agent behaviour is interpretable and trust metrics measurable build user confidence trustworthiness and explainability establish manual redundancy procedures to preserve data integrity and plan for human resources ensure the sustained continuity of critical to take over business use cases manual redundancy ai agents in action foundations for evaluation and governance figure foundations for ai agent evaluation and governance progressive governance practices progressive governance practices access traceability legal long term testing control identity compliance management validation trustworthiness monitoring manual human and more explainability logging redundancy oversight define classification evaluation risk assessment the use dimensions criteria life cycle tool call function predictability capabilities define context evaluate risks success task success edge case role use case identify risks manage risks rate robustness task completion autonomy environment trust indicators analyse risks time authority error types and more prior to for all agents regardless of their level of autonomy the detection of anomalies early while balancing deployment authority or the complexity of their operational concerns about privacy and surveillance risks agents should context specific governance mechanisms should associated with monitoring at scale human undergo sandbox serve as a baseline for adoption at a minimum oversight through policy reviews audit log analysis every agent should operate under strict access and supervisory triggers helps ensure alignment or controlled pilot control based on the principle of least privilege with organizational priorities unique identifiers and testing using non  with clear task boundaries that prevent unnecessary output tagging support attribution performance production data to system or data access basic legal and compliance tracking and post inent analysis in practice validate expected checks such as data protection impact the depth of safeguards should scale with the behaviour assessments and privacy compliance reviews agent s autonomy authority complexity of context are necessary to ensure alignment with regulatory and overall impact higher risk systems require obligations in addition technical controls such as proportionally greater investment in monitoring and input and output filters can help constrain agent oversight with a deliberate balance between human behaviour by screening potentially harmful irrelevant review and automated continuous monitoring or non compliant interactions before they propagate through the system by embedding these measures into the life cycle of all agents organizations establish a governance prior to deployment agents should undergo baseline that can scale proportionally with complexity sandbox or controlled pilot testing using non  and risk this foundation helps address immediate production data to validate expected behaviour operational safety and compliance needs creating and mitigate unintended effects all actions and the structures and practices upon which more planning should be recorded in an audit log for advanced context specific governance mechanisms traceability supported by monitoring tools or alerts can be layered as agents become more autonomous tailored to the agent s overall profile this enables integrated and capable ai agents in action foundations for evaluation and governance looking ahead multi  agent ecosystems future ecosystems of interacting agents introduce new risks that demand interoperable standards and oversight as organizations future ecosystems of interacting agents embodied agents embodied agents extend begin to deploy introduce new risks that demand interoperable governance challenges into the physical world multiple agents standards and oversight where oversight mechanisms must address across departments both digital actions and consider physical safety systems and the future of ai agents will happen in a much reliability and human interaction broader space than enterprise automation and networks a new will increasingly be defined by the emergence as organizations begin to deploy multiple agents class of failure of multi agent ecosystems in these ecosystems across departments systems and networks a modes is emerging agents are expected to interact negotiate and new class of failure modes is emerging linked to collaborate across organizational and technical potentially misaligned interactions between agents boundaries in many ways the interconnectedness a few examples include of these systems will redefine the future of ai moving beyond traditional enterprise automation orchestration drift when agents are plugged to allow agents to negotiate collaborate and into other agents without shared context or coordinate autonomously while this shift opens coordination logic workflows can become brittle new opportunities for innovation it also introduces or unpredictable challenges around alignment trust emergent behaviours and system design given the complex semantic misalignment when two agents nature of these systems ensuring responsible interpret the same instruction differently it behaviour and effective use requires robust can lead to conflicting actions or duplicated mechanisms for monitoring and assessing agent effort with implications for safety reliability interactions a few examples of emerging multi  and coordination agent ecosystems and their implications are security and trust gaps without shared trust agent to agent commerce agents can initiate frameworks agents may inadvertently expose transactions request services or exchange sensitive data or interact with malicious actors data with other agents forming a new layer of exploiting vulnerabilities in the system internet activity with considerable downstream economic implications interconnectedness and cascading effects failures in tightly linked agents or systems can internet of agents beyond isolated interactions propagate across networks creating a chain large scale networks of agents could form of disruptions an internet of agents raising questions of interoperability standards governance and systemic complexity as the number and societal impact diversity of interacting agents grow the likelihood of emergent behaviours and cascading failures trust frameworks for inter agent collaboration increases making them more difficult to anticipate as agents begin operating autonomously trace or diagnose across boundaries establishing shared norms credentialing systems and behavioural standards although the widespread deployment of multi agent is critical to verify identity capabilities and reliability ecosystems is still in its early stages providers and adopters must now anticipate the associated risks agent governance and oversight as agent as organizations experiment and pilot agents capabilities advance dedicated governor or misaligned interactions are already creating new auditor agents will monitor audit or regulate failure modes understanding possible challenges the actions of other agents validating transactions such as orchestration drift semantic misalignment detecting anomalies and correcting unsafe or and cascading failures enables adopters to implement unintended behaviours they enable scalable safeguards before scaling a proactive approach oversight in complex ecosystems but they risk ensures responsible growth aligning governance overreliance on agents supervising other agents with technical capabilities and defined boundaries ai agents in action foundations for evaluation and governance conclusion agents have already begun moving into production as the development of agents advances across various domains including customer support towards multi agent ecosystems the need for workflow automation autonomous research and shared protocols interoperability standards and more as adoption advances and as early use coordinated oversight is only going to increase cases move from single agents to more complex cross functional governance that links technical interconnected systems expectations for scalable assurance with organizational accountability is oversight grow considered key to preventing cascading failures and ensuring responsible oversight at scale this report has outlined the foundations for ai agent evaluation and governance presenting a at the core of this long term transition is effective conceptual approach to classification evaluation human ai collaboration in evolving governance risk assessment and governance that supports practices clear responsibility for objectives responsible adoption the proposed dimensions supervision and outcomes must be supported by aim to help organizations better understand what novel tools and processes that maintain systems an agent does how it operates and its place within as understandable safe and secure in practice the broader organization evaluation provides evidence of performance and reliability while ultimately the responsible deployment of agentic risk assessment identifies potential harms and systems depends on a baseline of trust transparency mitigations governance helps translate these and accountability that remains valid for all digital insights into safeguards and concrete accountability systems with thoughtful design careful evaluation mechanisms which can then scale as the agent s and proportionate governance ai agents are likely capability is extended to more complex use cases to amplify human capabilities improve productivity and scenarios and over time meaningfully contribute to both public and private value ai agents in action foundations for evaluation and governance contributors the world economic forum s ai governance capgemini alliance safe systems and technologies working group convenes chief science officers and ai producers to advance thought leadership olivier denti surrounding ai agents from their architecture to data architect ai capgemini invent applications social implications guardrails and governance structures this initiative promotes jason deperro the development of safety mechanisms and human ai collaboration director capgemini invent encourages collaboration on best practices for the design and implementation of ai systems jeanne heur  vice president digital trust security capgemini invent world economic forum raymond millward genai for r d technical solution lead capgemini benjamin cedric larsen engineering initiatives lead ai safety centre for ai excellence efi raili safety authority technology and innovation capgemini engineering acknowledgements animashree anima anandkumar kevin chung bren professor of computing and mathematical chief strategy officer writer sciences california institute of technology caltech cathy cobey mandanna appanderanda nanaiah global trusted ai advisory leader ey head infosys responsible ai north america infosys ben colman nebahat arslan co founder and chief executive officer reality director group general counsel and partnership defender officer women in ai sakyasingha dasgupta mennatallah el assady founder and chief executive officer edgecortix professor of interactive visualization and intelligence augmentation eth zurich umeshwar dayal senior fellow and senior vice president hitachi ricardo baeza yates america corporate chief scientist hitachi wasp professor kth royal institute of technology sweden mona diab director language technologies institute amir banifatemi carnegie mellon university chief responsible ai officer cognizant yawen duan william bartholomew ai safety research manager concordia ai director of public policy responsible ai microsoft gilles fayad aaron bawcom adviser institute of electrical and electronics field chief technology officer invisible technologies engineers ieee pete bernard claudia fischer chief executive officer edge ai foundation public policy planning global affairs openai fabio casati jenn gamble lead ai trust and governance lab servicenow head data science distyl ai ai agents in action foundations for evaluation and governance chen goldberg mao matsumoto senior vice president engineering coreweave head nec fellow office nec tom gruber sean mcgregor founder humanistic ai agentic product safety lead mlcommons gillian hadfield risto miikkulainen professor of law and professor of strategic professor of computer science the university of management university of toronto texas at austin peter hallinan satwik mishra director responsible artificial intelligence amazon executive director centre for trustworthy web services aws technology ctt bennet hillenbrand margaret mitchell agentic product safety lead mlcommons researcher and chief ethics scientist hugging face babak hodjat chief ai officer cognizant jessica newman director ai security initiative centre for long term sean kask cybersecurity uc berkeley chief ai strategy officer sap mark nitzberg robert katz executive director center for human compatible vice president responsible ai and tech salesforce ai uc berkeley michael kearns henrik ohlsson founding director warren center for network and vice president chief data scientist c  ai data sciences university of pennsylvania dmytro ovcharenko steven kelly ai chief technology officer ministry of digital chief trust officer institute for security and technology transformation of ukraine alex lebrun maria pocovi co founder and chief executive officer nabla global head of responsible ai uniphore stefan leichenauer reza rooholamini vice president engineering sandboxaq chief scientific artificial intelligence and innovation officer ccc intelligent solutions tze yun leong professor of computer science national university long ruan of singapore chief technology officer astra tech scott likens jason ruger global ai and innovation technology lead pwc chief information security officer lenovo ramana lokanathan daniela rus senior vice president engineering and ai director computer science and artificial automation anywhere intelligence laboratory csail massachusetts institute of technology mit nada madkour non resident research fellow university of jun seita california berkeley team director medical science deep learning team riken richard mallah principal ai safety strategist future of life institute norihiro suzuki chairman of the board hitachi pilar manch n research institute hitachi senior director engineering google sumit taneja gaonyalelwe maribe senior vice president and global head artificial head data analytics and ai old mutual intelligence ai consulting and implementation exl service darko matovski founder and chief executive officer causalens ai agents in action foundations for evaluation and governance fabian theis science director helmholtz association world economic forum li tieyan chief ai security scientist huawei technologies abhi balakrishnan initiatives lead ai and innovation lisa titus centre for ai excellence ai policy manager meta maria basso kush varshney head ai applications and impact ibm fellow ibm centre for ai excellence anthony vetro daniel dobrygowski president chief executive officer ieee fellow head governance and trust centre for ai mitsubishi electric research laboratories excellence tiffany wang xingyu audrey duet founder stealth head data and ai innovation centre for ai excellence andrea wong global head responsible ai policy ginelle greene trust and safety bytedance initiatives lead artificial intelligence and energy centre for ai excellence lauren woodman chief executive officer datakind connie kuang initiatives lead technology convergence centre michael young for ai excellence vice president of products private ai cathy li xiaohui yuan head centre for ai excellence member of the director innovation research center senior executive committee expert tri tencent holdings hesham zafar andy zhang lead partner engagement centre for ai excellence researcher stanford university leonid zhukov production vice president of data science boston consulting group x bcg x director bcg global ai institute boston consulting group bcg laurence denmark creative director studio miko blake elsey designer studio miko will liley editor studio miko ai agents in action foundations for evaluation and governance endnotes capgemini research institute harnessing the value of generative ai uploads final web version report gen ai in organization refresh pdf organisation for economic co operation and development oecd recommendation of the council on artificial intelligence national institute of standards and technology nist artificial intelligence risk management framework ai rmf international organization for standardization iso iso iec information technology artificial intelligence guidance on risk management claude docs n d features overview anthropic introducing the model context protocol surapaneni r m jha m vakoc and t segal announcing the agent agent protocol a a google for developers mitchell m s wu a zaldivar p barnes et al model cards for model reporting fat proceedings of the conference on fairness accountability and transparency pp   doi parikh s and r surapaneni powering ai commerce with the new agent payments protocol ap  google cloud cloudflare n d zero trust security what is a zero trust network glossary what is zero trust hasan m m l hao e fallahzadeh b adams et al model context protocol mcp at first glance studying the security and maintainability of mcp servers lynch b and r harang from prompts to pwns exploiting and securing ai agents usa  presentations us  lynch from prompts to pwns pdf adapted from international organization for standardization iso iso iec information technology artificial intelligence management system national institute of standards and technology nist artificial intelligence risk management framework ai rmf publication get pdf cfm pub id ibid capgemini n d business meet agentic ai autonomous and agentic systems   may pdf sae international j              taxonomy and definitions for terms related to driving automation systems for on road motor vehicles automation systems road motor vehicles russell s j and p norvig artificial intelligence a modern approach pearson hendrycks d c burns s basart a zou et al measuring massive multitask language understanding srivastava a a rastogi a rao a a shoeb et al beyond the imitation game quantifying and extrapolating the capabilities of language models transactions on machine learning research tmlr liang p r bommasani t lee d tsipras et al holistic evaluation of language models transactions on machine learning research tmlr liu x h yu h zhang y xu et al agentbench evaluating llms as agents international conference on learning representations iclr jimenez c e j yang a wettig s yao et al swe bench can language models resolve real world github issues rein d j becker a deng s nix et al hcast human calibrated autonomy software tasks abs risk refers to the composite measure of an event s probability or likelihood of occurring and the magnitude or degree of the consequences of the corresponding event national institute of standards and technology nist artificial intelligence risk management framework generative artificial intelligence profile ai   pdf adapted from international organization for standardization iso iso iec information technology artificial intelligence management system national institute of standards and technology nist artificial intelligence risk management framework ai rmf publication get pdf cfm pub id ai agents in action foundations for evaluation and governance the world economic forum committed to improving the state of the world is the international organization for public private cooperation the forum engages the foremost political business and other leaders of society to shape global regional and industry agendas world economic forum route de la capite ch  cologny geneva switzerland tel fax